// Copyright (c) 2015-2019 The Khronos Group Inc.
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// 
//     http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// 
// ---- Exceptions to the Apache 2.0 License: ----
// 
// As an exception, if you use this Software to generate code and portions of
// this Software are embedded into the generated code as a result, you may
// redistribute such product without providing attribution as would otherwise
// be required by Sections 4(a), 4(b) and 4(d) of the License.
// 
// In addition, if you combine or link code generated by this Software with
// software that is licensed under the GPLv2 or the LGPL v2.0 or 2.1
// ("`Combined Software`") and if a court of competent jurisdiction determines
// that the patent provision (Section 3), the indemnity provision (Section 9)
// or other Section of the License conflicts with the conditions of the
// applicable GPL or LGPL license, you may retroactively and prospectively
// choose to deem waived or otherwise exclude such Section(s) of the License,
// but only in their entirety and only with respect to the Combined Software.
//     

// This header is generated from the Khronos Vulkan XML API Registry.

#ifndef VULKAN_HPP
#define VULKAN_HPP

#include <algorithm>
#include <array>
#include <cstddef>
#include <cstdint>
#include <cstring>
#include <initializer_list>
#include <string>
#include <system_error>
#include <tuple>
#include <type_traits>
#include <vulkan/vulkan.h>

#if !defined(VULKAN_HPP_DISABLE_ENHANCED_MODE)
# include <memory>
# include <vector>
#endif

#if !defined(VULKAN_HPP_ASSERT)
# include <cassert>
# define VULKAN_HPP_ASSERT   assert
#endif

#if defined(__linux__) || defined(__APPLE__)
# include <dlfcn.h>
#endif

static_assert( VK_HEADER_VERSION ==  126 , "Wrong VK_HEADER_VERSION!" );

// 32-bit vulkan is not typesafe for handles, so don't allow copy constructors on this platform by default.
// To enable this feature on 32-bit platforms please define VULKAN_HPP_TYPESAFE_CONVERSION
#if defined(__LP64__) || defined(_WIN64) || (defined(__x86_64__) && !defined(__ILP32__) ) || defined(_M_X64) || defined(__ia64) || defined (_M_IA64) || defined(__aarch64__) || defined(__powerpc64__)
# if !defined( VULKAN_HPP_TYPESAFE_CONVERSION )
#  define VULKAN_HPP_TYPESAFE_CONVERSION
# endif
#endif

// <tuple> includes <sys/sysmacros.h> through some other header
// this results in major(x) being resolved to gnu_dev_major(x)
// which is an expression in a constructor initializer list.
#if defined(major)
  #undef major
#endif
#if defined(minor)
  #undef minor
#endif

// Windows defines MemoryBarrier which is deprecated and collides
// with the vk::MemoryBarrier struct.
#if defined(MemoryBarrier)
  #undef MemoryBarrier
#endif

#if !defined(VULKAN_HPP_HAS_UNRESTRICTED_UNIONS)
# if defined(__clang__)
#  if __has_feature(cxx_unrestricted_unions)
#   define VULKAN_HPP_HAS_UNRESTRICTED_UNIONS
#  endif
# elif defined(__GNUC__)
#  define GCC_VERSION (__GNUC__ * 10000 + __GNUC_MINOR__ * 100 + __GNUC_PATCHLEVEL__)
#  if 40600 <= GCC_VERSION
#   define VULKAN_HPP_HAS_UNRESTRICTED_UNIONS
#  endif
# elif defined(_MSC_VER)
#  if 1900 <= _MSC_VER
#   define VULKAN_HPP_HAS_UNRESTRICTED_UNIONS
#  endif
# endif
#endif

#if !defined(VULKAN_HPP_INLINE)
# if defined(__clang__)
#  if __has_attribute(always_inline)
#   define VULKAN_HPP_INLINE __attribute__((always_inline)) __inline__
#  else
#   define VULKAN_HPP_INLINE inline
#  endif
# elif defined(__GNUC__)
#  define VULKAN_HPP_INLINE __attribute__((always_inline)) __inline__
# elif defined(_MSC_VER)
#  define VULKAN_HPP_INLINE inline
# else
#  define VULKAN_HPP_INLINE inline
# endif
#endif

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
# define VULKAN_HPP_TYPESAFE_EXPLICIT
#else
# define VULKAN_HPP_TYPESAFE_EXPLICIT explicit
#endif

#if defined(__cpp_constexpr)
# define VULKAN_HPP_CONSTEXPR constexpr
# if __cpp_constexpr >= 201304
#  define VULKAN_HPP_CONSTEXPR_14  constexpr
# else
#  define VULKAN_HPP_CONSTEXPR_14
# endif
# define VULKAN_HPP_CONST_OR_CONSTEXPR  constexpr
#else
# define VULKAN_HPP_CONSTEXPR
# define VULKAN_HPP_CONSTEXPR_14
# define VULKAN_HPP_CONST_OR_CONSTEXPR  const
#endif

#if !defined(VULKAN_HPP_NOEXCEPT)
# if defined(_MSC_VER) && (_MSC_VER <= 1800)
#  define VULKAN_HPP_NOEXCEPT
# else
#  define VULKAN_HPP_NOEXCEPT noexcept
#  define VULKAN_HPP_HAS_NOEXCEPT 1
# endif
#endif

#if !defined(VULKAN_HPP_NAMESPACE)
#define VULKAN_HPP_NAMESPACE vk
#endif

#define VULKAN_HPP_STRINGIFY2(text) #text
#define VULKAN_HPP_STRINGIFY(text) VULKAN_HPP_STRINGIFY2(text)
#define VULKAN_HPP_NAMESPACE_STRING VULKAN_HPP_STRINGIFY(VULKAN_HPP_NAMESPACE)

namespace VULKAN_HPP_NAMESPACE
{
#if !defined(VULKAN_HPP_DISABLE_ENHANCED_MODE)
  template <typename T>
  class ArrayProxy
  {
  public:
    VULKAN_HPP_CONSTEXPR ArrayProxy(std::nullptr_t) VULKAN_HPP_NOEXCEPT
      : m_count(0)
      , m_ptr(nullptr)
    {}

    ArrayProxy(T & ptr) VULKAN_HPP_NOEXCEPT
      : m_count(1)
      , m_ptr(&ptr)
    {}

    ArrayProxy(uint32_t count, T * ptr) VULKAN_HPP_NOEXCEPT
      : m_count(count)
      , m_ptr(ptr)
    {}

    template <size_t N>
    ArrayProxy(std::array<typename std::remove_const<T>::type, N> & data) VULKAN_HPP_NOEXCEPT
      : m_count(N)
      , m_ptr(data.data())
    {}

    template <size_t N>
    ArrayProxy(std::array<typename std::remove_const<T>::type, N> const& data) VULKAN_HPP_NOEXCEPT
      : m_count(N)
      , m_ptr(data.data())
    {}

    template <class Allocator = std::allocator<typename std::remove_const<T>::type>>
    ArrayProxy(std::vector<typename std::remove_const<T>::type, Allocator> & data) VULKAN_HPP_NOEXCEPT
      : m_count(static_cast<uint32_t>(data.size()))
      , m_ptr(data.data())
    {}

    template <class Allocator = std::allocator<typename std::remove_const<T>::type>>
    ArrayProxy(std::vector<typename std::remove_const<T>::type, Allocator> const& data) VULKAN_HPP_NOEXCEPT
      : m_count(static_cast<uint32_t>(data.size()))
      , m_ptr(data.data())
    {}

    ArrayProxy(std::initializer_list<T> const& data) VULKAN_HPP_NOEXCEPT
      : m_count(static_cast<uint32_t>(data.end() - data.begin()))
      , m_ptr(data.begin())
    {}

    const T * begin() const VULKAN_HPP_NOEXCEPT
    {
      return m_ptr;
    }

    const T * end() const VULKAN_HPP_NOEXCEPT
    {
      return m_ptr + m_count;
    }

    const T & front() const VULKAN_HPP_NOEXCEPT
    {
      VULKAN_HPP_ASSERT(m_count && m_ptr);
      return *m_ptr;
    }

    const T & back() const VULKAN_HPP_NOEXCEPT
    {
      VULKAN_HPP_ASSERT(m_count && m_ptr);
      return *(m_ptr + m_count - 1);
    }

    bool empty() const VULKAN_HPP_NOEXCEPT
    {
      return (m_count == 0);
    }

    uint32_t size() const VULKAN_HPP_NOEXCEPT
    {
      return m_count;
    }

    T * data() const VULKAN_HPP_NOEXCEPT
    {
      return m_ptr;
    }

  private:
    uint32_t  m_count;
    T *       m_ptr;
  };
#endif

  template <typename FlagBitsType> struct FlagTraits
  {
    enum { allFlags = 0 };
  };

  template <typename BitType, typename MaskType = VkFlags>
  class Flags
  {
  public:
    VULKAN_HPP_CONSTEXPR Flags() VULKAN_HPP_NOEXCEPT
      : m_mask(0)
    {}

    VULKAN_HPP_CONSTEXPR Flags(BitType bit) VULKAN_HPP_NOEXCEPT
      : m_mask(static_cast<MaskType>(bit))
    {}

    VULKAN_HPP_CONSTEXPR Flags(Flags<BitType> const& rhs) VULKAN_HPP_NOEXCEPT
      : m_mask(rhs.m_mask)
    {}

    VULKAN_HPP_CONSTEXPR explicit Flags(MaskType flags) VULKAN_HPP_NOEXCEPT
      : m_mask(flags)
    {}

    Flags<BitType> & operator=(Flags<BitType> const& rhs) VULKAN_HPP_NOEXCEPT
    {
      m_mask = rhs.m_mask;
      return *this;
    }

    Flags<BitType> & operator|=(Flags<BitType> const& rhs) VULKAN_HPP_NOEXCEPT
    {
      m_mask |= rhs.m_mask;
      return *this;
    }

    Flags<BitType> & operator&=(Flags<BitType> const& rhs) VULKAN_HPP_NOEXCEPT
    {
      m_mask &= rhs.m_mask;
      return *this;
    }

    Flags<BitType> & operator^=(Flags<BitType> const& rhs) VULKAN_HPP_NOEXCEPT
    {
      m_mask ^= rhs.m_mask;
      return *this;
    }

    VULKAN_HPP_CONSTEXPR Flags<BitType> operator|(Flags<BitType> const& rhs) const VULKAN_HPP_NOEXCEPT
    {
      return Flags<BitType>(m_mask | rhs.m_mask);
    }

    VULKAN_HPP_CONSTEXPR Flags<BitType> operator&(Flags<BitType> const& rhs) const VULKAN_HPP_NOEXCEPT
    {
      return Flags<BitType>(m_mask & rhs.m_mask);
    }

    VULKAN_HPP_CONSTEXPR Flags<BitType> operator^(Flags<BitType> const& rhs) const VULKAN_HPP_NOEXCEPT
    {
      return Flags<BitType>(m_mask ^ rhs.m_mask);
    }

    VULKAN_HPP_CONSTEXPR bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return !m_mask;
    }

    VULKAN_HPP_CONSTEXPR Flags<BitType> operator~() const VULKAN_HPP_NOEXCEPT
    {
      return Flags<BitType>(m_mask ^ FlagTraits<BitType>::allFlags);
    }

    VULKAN_HPP_CONSTEXPR bool operator==(Flags<BitType> const& rhs) const VULKAN_HPP_NOEXCEPT
    {
      return m_mask == rhs.m_mask;
    }

    VULKAN_HPP_CONSTEXPR bool operator!=(Flags<BitType> const& rhs) const VULKAN_HPP_NOEXCEPT
    {
      return m_mask != rhs.m_mask;
    }

    explicit VULKAN_HPP_CONSTEXPR operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return !!m_mask;
    }

    explicit VULKAN_HPP_CONSTEXPR operator MaskType() const VULKAN_HPP_NOEXCEPT
    {
        return m_mask;
    }

  private:
    MaskType  m_mask;
  };

  template <typename BitType>
  VULKAN_HPP_CONSTEXPR Flags<BitType> operator|(BitType bit, Flags<BitType> const& flags) VULKAN_HPP_NOEXCEPT
  {
    return flags | bit;
  }

  template <typename BitType>
  VULKAN_HPP_CONSTEXPR Flags<BitType> operator&(BitType bit, Flags<BitType> const& flags) VULKAN_HPP_NOEXCEPT
  {
    return flags & bit;
  }

  template <typename BitType>
  VULKAN_HPP_CONSTEXPR Flags<BitType> operator^(BitType bit, Flags<BitType> const& flags) VULKAN_HPP_NOEXCEPT
  {
    return flags ^ bit;
  }

  template <typename BitType>
  VULKAN_HPP_CONSTEXPR bool operator==(BitType bit, Flags<BitType> const& flags) VULKAN_HPP_NOEXCEPT
  {
    return flags == bit;
  }

  template <typename BitType>
  VULKAN_HPP_CONSTEXPR bool operator!=(BitType bit, Flags<BitType> const& flags) VULKAN_HPP_NOEXCEPT
  {
    return flags != bit;
  }

  template <typename RefType>
  class Optional
  {
  public:
    Optional(RefType & reference) VULKAN_HPP_NOEXCEPT { m_ptr = &reference; }
    Optional(RefType * ptr) VULKAN_HPP_NOEXCEPT { m_ptr = ptr; }
    Optional(std::nullptr_t) VULKAN_HPP_NOEXCEPT { m_ptr = nullptr; }

    operator RefType*() const VULKAN_HPP_NOEXCEPT { return m_ptr; }
    RefType const* operator->() const VULKAN_HPP_NOEXCEPT { return m_ptr; }
    explicit operator bool() const VULKAN_HPP_NOEXCEPT { return !!m_ptr; }

  private:
    RefType *m_ptr;
  };

  template <typename X, typename Y> struct isStructureChainValid { enum { value = false }; };

  template <typename P, typename T>
  struct TypeList
  {
    using list = P;
    using last = T;
  };

  template <typename List, typename X>
  struct extendCheck
  {
    static const bool valid = isStructureChainValid<typename List::last, X>::value || extendCheck<typename List::list,X>::valid;
  };

  template <typename T, typename X>
  struct extendCheck<TypeList<void,T>,X>
  {
    static const bool valid = isStructureChainValid<T, X>::value;
  };

  template <typename X>
  struct extendCheck<void,X>
  {
    static const bool valid = true;
  };

  template <class Element>
  class StructureChainElement
  {
  public:
    explicit operator Element&() VULKAN_HPP_NOEXCEPT { return value; }
    explicit operator const Element&() const VULKAN_HPP_NOEXCEPT { return value; }
  private:
    Element value;
  };

  template<typename ...StructureElements>
  class StructureChain : private StructureChainElement<StructureElements>...
  {
  public:
    StructureChain() VULKAN_HPP_NOEXCEPT
    {
      link<void, StructureElements...>();
    }

    StructureChain(StructureChain const &rhs) VULKAN_HPP_NOEXCEPT
    {
      linkAndCopy<void, StructureElements...>(rhs);
    }

    StructureChain(StructureElements const &... elems) VULKAN_HPP_NOEXCEPT
    {
      linkAndCopyElements<void, StructureElements...>(elems...);
    }

    StructureChain& operator=(StructureChain const &rhs) VULKAN_HPP_NOEXCEPT
    {
      linkAndCopy<void, StructureElements...>(rhs);
      return *this;
    }

    template<typename ClassType> ClassType& get() VULKAN_HPP_NOEXCEPT { return static_cast<ClassType&>(*this);}

    template<typename ClassTypeA, typename ClassTypeB, typename ...ClassTypes>
    std::tuple<ClassTypeA, ClassTypeB, ClassTypes...> get()
    {
        return std::tuple_cat(
            std::make_tuple(get<ClassTypeA>(),get<ClassTypeB>()),
            std::make_tuple(get<ClassTypes>()...)
        );
    }

  private:
    template<typename List, typename X>
    void link() VULKAN_HPP_NOEXCEPT
    {
      static_assert(extendCheck<List, X>::valid, "The structure chain is not valid!");
    }

    template<typename List, typename X, typename Y, typename ...Z>
    void link() VULKAN_HPP_NOEXCEPT
    {
      static_assert(extendCheck<List,X>::valid, "The structure chain is not valid!");
      X& x = static_cast<X&>(*this);
      Y& y = static_cast<Y&>(*this);
      x.pNext = &y;
      link<TypeList<List, X>, Y, Z...>();
    }

    template<typename List, typename X>
    void linkAndCopy(StructureChain const &rhs) VULKAN_HPP_NOEXCEPT
    {
      static_assert(extendCheck<List, X>::valid, "The structure chain is not valid!");
      static_cast<X&>(*this) = static_cast<X const &>(rhs);
    }

    template<typename List, typename X, typename Y, typename ...Z>
    void linkAndCopy(StructureChain const &rhs) VULKAN_HPP_NOEXCEPT
    {
      static_assert(extendCheck<List, X>::valid, "The structure chain is not valid!");
      X& x = static_cast<X&>(*this);
      Y& y = static_cast<Y&>(*this);
      x = static_cast<X const &>(rhs);
      x.pNext = &y;
      linkAndCopy<TypeList<List, X>, Y, Z...>(rhs);
    }

    template<typename List, typename X>
    void linkAndCopyElements(X const &xelem) VULKAN_HPP_NOEXCEPT
    {
      static_assert(extendCheck<List, X>::valid, "The structure chain is not valid!");
      static_cast<X&>(*this) = xelem;
    }

    template<typename List, typename X, typename Y, typename ...Z>
    void linkAndCopyElements(X const &xelem, Y const &yelem, Z const &... zelem) VULKAN_HPP_NOEXCEPT
    {
      static_assert(extendCheck<List, X>::valid, "The structure chain is not valid!");
      X& x = static_cast<X&>(*this);
      Y& y = static_cast<Y&>(*this);
      x = xelem;
      x.pNext = &y;
      linkAndCopyElements<TypeList<List, X>, Y, Z...>(yelem, zelem...);
    }
  };

#if !defined(VULKAN_HPP_NO_SMART_HANDLE)
  template <typename Type, typename Dispatch> class UniqueHandleTraits;

  template <typename Type, typename Dispatch>
  class UniqueHandle : public UniqueHandleTraits<Type,Dispatch>::deleter
  {
  private:
    using Deleter = typename UniqueHandleTraits<Type,Dispatch>::deleter;

  public:
    using element_type = Type;

    explicit UniqueHandle( Type const& value = Type(), Deleter const& deleter = Deleter() ) VULKAN_HPP_NOEXCEPT
      : Deleter( deleter)
      , m_value( value )
    {}

    UniqueHandle( UniqueHandle const& ) = delete;

    UniqueHandle( UniqueHandle && other ) VULKAN_HPP_NOEXCEPT
      : Deleter( std::move( static_cast<Deleter&>( other ) ) )
      , m_value( other.release() )
    {}

    ~UniqueHandle() VULKAN_HPP_NOEXCEPT
    {
      if ( m_value ) this->destroy( m_value );
    }

    UniqueHandle & operator=( UniqueHandle const& ) = delete;

    UniqueHandle & operator=( UniqueHandle && other ) VULKAN_HPP_NOEXCEPT
    {
      reset( other.release() );
      *static_cast<Deleter*>(this) = std::move( static_cast<Deleter&>(other) );
      return *this;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_value.operator bool();
    }

    Type const* operator->() const VULKAN_HPP_NOEXCEPT
    {
      return &m_value;
    }

    Type * operator->() VULKAN_HPP_NOEXCEPT
    {
      return &m_value;
    }

    Type const& operator*() const VULKAN_HPP_NOEXCEPT
    {
      return m_value;
    }

    Type & operator*() VULKAN_HPP_NOEXCEPT
    {
      return m_value;
    }

    const Type & get() const VULKAN_HPP_NOEXCEPT
    {
      return m_value;
    }

    Type & get() VULKAN_HPP_NOEXCEPT
    {
      return m_value;
    }

    void reset( Type const& value = Type() ) VULKAN_HPP_NOEXCEPT
    {
      if ( m_value != value )
      {
        if ( m_value ) this->destroy( m_value );
        m_value = value;
      }
    }

    Type release() VULKAN_HPP_NOEXCEPT
    {
      Type value = m_value;
      m_value = nullptr;
      return value;
    }

    void swap( UniqueHandle<Type,Dispatch> & rhs ) VULKAN_HPP_NOEXCEPT
    {
      std::swap(m_value, rhs.m_value);
      std::swap(static_cast<Deleter&>(*this), static_cast<Deleter&>(rhs));
    }

  private:
    Type    m_value;
  };

  template <typename UniqueType>
  VULKAN_HPP_INLINE std::vector<typename UniqueType::element_type> uniqueToRaw(std::vector<UniqueType> const& handles)
  {
    std::vector<typename UniqueType::element_type> newBuffer(handles.size());
    std::transform(handles.begin(), handles.end(), newBuffer.begin(), [](UniqueType const& handle) { return handle.get(); });
    return newBuffer;
  }

  template <typename Type, typename Dispatch>
  VULKAN_HPP_INLINE void swap( UniqueHandle<Type,Dispatch> & lhs, UniqueHandle<Type,Dispatch> & rhs ) VULKAN_HPP_NOEXCEPT
  {
    lhs.swap( rhs );
  }
#endif

#if !defined(VK_NO_PROTOTYPES)
  class DispatchLoaderStatic
  {
  public:
    VkResult vkCreateInstance( const VkInstanceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkInstance* pInstance ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateInstance( pCreateInfo, pAllocator, pInstance );
    }

    VkResult vkEnumerateInstanceExtensionProperties( const char* pLayerName, uint32_t* pPropertyCount, VkExtensionProperties* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumerateInstanceExtensionProperties( pLayerName, pPropertyCount, pProperties );
    }

    VkResult vkEnumerateInstanceLayerProperties( uint32_t* pPropertyCount, VkLayerProperties* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumerateInstanceLayerProperties( pPropertyCount, pProperties );
    }

    VkResult vkEnumerateInstanceVersion( uint32_t* pApiVersion ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumerateInstanceVersion( pApiVersion );
    }

    VkResult vkBeginCommandBuffer( VkCommandBuffer commandBuffer, const VkCommandBufferBeginInfo* pBeginInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBeginCommandBuffer( commandBuffer, pBeginInfo );
    }

    void vkCmdBeginConditionalRenderingEXT( VkCommandBuffer commandBuffer, const VkConditionalRenderingBeginInfoEXT* pConditionalRenderingBegin ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBeginConditionalRenderingEXT( commandBuffer, pConditionalRenderingBegin );
    }

    void vkCmdBeginDebugUtilsLabelEXT( VkCommandBuffer commandBuffer, const VkDebugUtilsLabelEXT* pLabelInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBeginDebugUtilsLabelEXT( commandBuffer, pLabelInfo );
    }

    void vkCmdBeginQuery( VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query, VkQueryControlFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBeginQuery( commandBuffer, queryPool, query, flags );
    }

    void vkCmdBeginQueryIndexedEXT( VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query, VkQueryControlFlags flags, uint32_t index ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBeginQueryIndexedEXT( commandBuffer, queryPool, query, flags, index );
    }

    void vkCmdBeginRenderPass( VkCommandBuffer commandBuffer, const VkRenderPassBeginInfo* pRenderPassBegin, VkSubpassContents contents ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBeginRenderPass( commandBuffer, pRenderPassBegin, contents );
    }

    void vkCmdBeginRenderPass2KHR( VkCommandBuffer commandBuffer, const VkRenderPassBeginInfo* pRenderPassBegin, const VkSubpassBeginInfoKHR* pSubpassBeginInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBeginRenderPass2KHR( commandBuffer, pRenderPassBegin, pSubpassBeginInfo );
    }

    void vkCmdBeginTransformFeedbackEXT( VkCommandBuffer commandBuffer, uint32_t firstCounterBuffer, uint32_t counterBufferCount, const VkBuffer* pCounterBuffers, const VkDeviceSize* pCounterBufferOffsets ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBeginTransformFeedbackEXT( commandBuffer, firstCounterBuffer, counterBufferCount, pCounterBuffers, pCounterBufferOffsets );
    }

    void vkCmdBindDescriptorSets( VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t firstSet, uint32_t descriptorSetCount, const VkDescriptorSet* pDescriptorSets, uint32_t dynamicOffsetCount, const uint32_t* pDynamicOffsets ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBindDescriptorSets( commandBuffer, pipelineBindPoint, layout, firstSet, descriptorSetCount, pDescriptorSets, dynamicOffsetCount, pDynamicOffsets );
    }

    void vkCmdBindIndexBuffer( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkIndexType indexType ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBindIndexBuffer( commandBuffer, buffer, offset, indexType );
    }

    void vkCmdBindPipeline( VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipeline pipeline ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBindPipeline( commandBuffer, pipelineBindPoint, pipeline );
    }

    void vkCmdBindShadingRateImageNV( VkCommandBuffer commandBuffer, VkImageView imageView, VkImageLayout imageLayout ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBindShadingRateImageNV( commandBuffer, imageView, imageLayout );
    }

    void vkCmdBindTransformFeedbackBuffersEXT( VkCommandBuffer commandBuffer, uint32_t firstBinding, uint32_t bindingCount, const VkBuffer* pBuffers, const VkDeviceSize* pOffsets, const VkDeviceSize* pSizes ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBindTransformFeedbackBuffersEXT( commandBuffer, firstBinding, bindingCount, pBuffers, pOffsets, pSizes );
    }

    void vkCmdBindVertexBuffers( VkCommandBuffer commandBuffer, uint32_t firstBinding, uint32_t bindingCount, const VkBuffer* pBuffers, const VkDeviceSize* pOffsets ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBindVertexBuffers( commandBuffer, firstBinding, bindingCount, pBuffers, pOffsets );
    }

    void vkCmdBlitImage( VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkImageBlit* pRegions, VkFilter filter ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBlitImage( commandBuffer, srcImage, srcImageLayout, dstImage, dstImageLayout, regionCount, pRegions, filter );
    }

    void vkCmdBuildAccelerationStructureNV( VkCommandBuffer commandBuffer, const VkAccelerationStructureInfoNV* pInfo, VkBuffer instanceData, VkDeviceSize instanceOffset, VkBool32 update, VkAccelerationStructureNV dst, VkAccelerationStructureNV src, VkBuffer scratch, VkDeviceSize scratchOffset ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdBuildAccelerationStructureNV( commandBuffer, pInfo, instanceData, instanceOffset, update, dst, src, scratch, scratchOffset );
    }

    void vkCmdClearAttachments( VkCommandBuffer commandBuffer, uint32_t attachmentCount, const VkClearAttachment* pAttachments, uint32_t rectCount, const VkClearRect* pRects ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdClearAttachments( commandBuffer, attachmentCount, pAttachments, rectCount, pRects );
    }

    void vkCmdClearColorImage( VkCommandBuffer commandBuffer, VkImage image, VkImageLayout imageLayout, const VkClearColorValue* pColor, uint32_t rangeCount, const VkImageSubresourceRange* pRanges ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdClearColorImage( commandBuffer, image, imageLayout, pColor, rangeCount, pRanges );
    }

    void vkCmdClearDepthStencilImage( VkCommandBuffer commandBuffer, VkImage image, VkImageLayout imageLayout, const VkClearDepthStencilValue* pDepthStencil, uint32_t rangeCount, const VkImageSubresourceRange* pRanges ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdClearDepthStencilImage( commandBuffer, image, imageLayout, pDepthStencil, rangeCount, pRanges );
    }

    void vkCmdCopyAccelerationStructureNV( VkCommandBuffer commandBuffer, VkAccelerationStructureNV dst, VkAccelerationStructureNV src, VkCopyAccelerationStructureModeNV mode ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdCopyAccelerationStructureNV( commandBuffer, dst, src, mode );
    }

    void vkCmdCopyBuffer( VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkBuffer dstBuffer, uint32_t regionCount, const VkBufferCopy* pRegions ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdCopyBuffer( commandBuffer, srcBuffer, dstBuffer, regionCount, pRegions );
    }

    void vkCmdCopyBufferToImage( VkCommandBuffer commandBuffer, VkBuffer srcBuffer, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkBufferImageCopy* pRegions ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdCopyBufferToImage( commandBuffer, srcBuffer, dstImage, dstImageLayout, regionCount, pRegions );
    }

    void vkCmdCopyImage( VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkImageCopy* pRegions ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdCopyImage( commandBuffer, srcImage, srcImageLayout, dstImage, dstImageLayout, regionCount, pRegions );
    }

    void vkCmdCopyImageToBuffer( VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkBuffer dstBuffer, uint32_t regionCount, const VkBufferImageCopy* pRegions ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdCopyImageToBuffer( commandBuffer, srcImage, srcImageLayout, dstBuffer, regionCount, pRegions );
    }

    void vkCmdCopyQueryPoolResults( VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, VkBuffer dstBuffer, VkDeviceSize dstOffset, VkDeviceSize stride, VkQueryResultFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdCopyQueryPoolResults( commandBuffer, queryPool, firstQuery, queryCount, dstBuffer, dstOffset, stride, flags );
    }

    void vkCmdDebugMarkerBeginEXT( VkCommandBuffer commandBuffer, const VkDebugMarkerMarkerInfoEXT* pMarkerInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDebugMarkerBeginEXT( commandBuffer, pMarkerInfo );
    }

    void vkCmdDebugMarkerEndEXT( VkCommandBuffer commandBuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDebugMarkerEndEXT( commandBuffer );
    }

    void vkCmdDebugMarkerInsertEXT( VkCommandBuffer commandBuffer, const VkDebugMarkerMarkerInfoEXT* pMarkerInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDebugMarkerInsertEXT( commandBuffer, pMarkerInfo );
    }

    void vkCmdDispatch( VkCommandBuffer commandBuffer, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDispatch( commandBuffer, groupCountX, groupCountY, groupCountZ );
    }

    void vkCmdDispatchBase( VkCommandBuffer commandBuffer, uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDispatchBase( commandBuffer, baseGroupX, baseGroupY, baseGroupZ, groupCountX, groupCountY, groupCountZ );
    }

    void vkCmdDispatchBaseKHR( VkCommandBuffer commandBuffer, uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDispatchBaseKHR( commandBuffer, baseGroupX, baseGroupY, baseGroupZ, groupCountX, groupCountY, groupCountZ );
    }

    void vkCmdDispatchIndirect( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDispatchIndirect( commandBuffer, buffer, offset );
    }

    void vkCmdDraw( VkCommandBuffer commandBuffer, uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDraw( commandBuffer, vertexCount, instanceCount, firstVertex, firstInstance );
    }

    void vkCmdDrawIndexed( VkCommandBuffer commandBuffer, uint32_t indexCount, uint32_t instanceCount, uint32_t firstIndex, int32_t vertexOffset, uint32_t firstInstance ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndexed( commandBuffer, indexCount, instanceCount, firstIndex, vertexOffset, firstInstance );
    }

    void vkCmdDrawIndexedIndirect( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndexedIndirect( commandBuffer, buffer, offset, drawCount, stride );
    }

    void vkCmdDrawIndexedIndirectCountAMD( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndexedIndirectCountAMD( commandBuffer, buffer, offset, countBuffer, countBufferOffset, maxDrawCount, stride );
    }

    void vkCmdDrawIndexedIndirectCountKHR( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndexedIndirectCountKHR( commandBuffer, buffer, offset, countBuffer, countBufferOffset, maxDrawCount, stride );
    }

    void vkCmdDrawIndirect( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndirect( commandBuffer, buffer, offset, drawCount, stride );
    }

    void vkCmdDrawIndirectByteCountEXT( VkCommandBuffer commandBuffer, uint32_t instanceCount, uint32_t firstInstance, VkBuffer counterBuffer, VkDeviceSize counterBufferOffset, uint32_t counterOffset, uint32_t vertexStride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndirectByteCountEXT( commandBuffer, instanceCount, firstInstance, counterBuffer, counterBufferOffset, counterOffset, vertexStride );
    }

    void vkCmdDrawIndirectCountAMD( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndirectCountAMD( commandBuffer, buffer, offset, countBuffer, countBufferOffset, maxDrawCount, stride );
    }

    void vkCmdDrawIndirectCountKHR( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawIndirectCountKHR( commandBuffer, buffer, offset, countBuffer, countBufferOffset, maxDrawCount, stride );
    }

    void vkCmdDrawMeshTasksIndirectCountNV( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, VkBuffer countBuffer, VkDeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawMeshTasksIndirectCountNV( commandBuffer, buffer, offset, countBuffer, countBufferOffset, maxDrawCount, stride );
    }

    void vkCmdDrawMeshTasksIndirectNV( VkCommandBuffer commandBuffer, VkBuffer buffer, VkDeviceSize offset, uint32_t drawCount, uint32_t stride ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawMeshTasksIndirectNV( commandBuffer, buffer, offset, drawCount, stride );
    }

    void vkCmdDrawMeshTasksNV( VkCommandBuffer commandBuffer, uint32_t taskCount, uint32_t firstTask ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdDrawMeshTasksNV( commandBuffer, taskCount, firstTask );
    }

    void vkCmdEndConditionalRenderingEXT( VkCommandBuffer commandBuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdEndConditionalRenderingEXT( commandBuffer );
    }

    void vkCmdEndDebugUtilsLabelEXT( VkCommandBuffer commandBuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdEndDebugUtilsLabelEXT( commandBuffer );
    }

    void vkCmdEndQuery( VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdEndQuery( commandBuffer, queryPool, query );
    }

    void vkCmdEndQueryIndexedEXT( VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t query, uint32_t index ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdEndQueryIndexedEXT( commandBuffer, queryPool, query, index );
    }

    void vkCmdEndRenderPass( VkCommandBuffer commandBuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdEndRenderPass( commandBuffer );
    }

    void vkCmdEndRenderPass2KHR( VkCommandBuffer commandBuffer, const VkSubpassEndInfoKHR* pSubpassEndInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdEndRenderPass2KHR( commandBuffer, pSubpassEndInfo );
    }

    void vkCmdEndTransformFeedbackEXT( VkCommandBuffer commandBuffer, uint32_t firstCounterBuffer, uint32_t counterBufferCount, const VkBuffer* pCounterBuffers, const VkDeviceSize* pCounterBufferOffsets ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdEndTransformFeedbackEXT( commandBuffer, firstCounterBuffer, counterBufferCount, pCounterBuffers, pCounterBufferOffsets );
    }

    void vkCmdExecuteCommands( VkCommandBuffer commandBuffer, uint32_t commandBufferCount, const VkCommandBuffer* pCommandBuffers ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdExecuteCommands( commandBuffer, commandBufferCount, pCommandBuffers );
    }

    void vkCmdFillBuffer( VkCommandBuffer commandBuffer, VkBuffer dstBuffer, VkDeviceSize dstOffset, VkDeviceSize size, uint32_t data ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdFillBuffer( commandBuffer, dstBuffer, dstOffset, size, data );
    }

    void vkCmdInsertDebugUtilsLabelEXT( VkCommandBuffer commandBuffer, const VkDebugUtilsLabelEXT* pLabelInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdInsertDebugUtilsLabelEXT( commandBuffer, pLabelInfo );
    }

    void vkCmdNextSubpass( VkCommandBuffer commandBuffer, VkSubpassContents contents ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdNextSubpass( commandBuffer, contents );
    }

    void vkCmdNextSubpass2KHR( VkCommandBuffer commandBuffer, const VkSubpassBeginInfoKHR* pSubpassBeginInfo, const VkSubpassEndInfoKHR* pSubpassEndInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdNextSubpass2KHR( commandBuffer, pSubpassBeginInfo, pSubpassEndInfo );
    }

    void vkCmdPipelineBarrier( VkCommandBuffer commandBuffer, VkPipelineStageFlags srcStageMask, VkPipelineStageFlags dstStageMask, VkDependencyFlags dependencyFlags, uint32_t memoryBarrierCount, const VkMemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const VkBufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const VkImageMemoryBarrier* pImageMemoryBarriers ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdPipelineBarrier( commandBuffer, srcStageMask, dstStageMask, dependencyFlags, memoryBarrierCount, pMemoryBarriers, bufferMemoryBarrierCount, pBufferMemoryBarriers, imageMemoryBarrierCount, pImageMemoryBarriers );
    }

    void vkCmdProcessCommandsNVX( VkCommandBuffer commandBuffer, const VkCmdProcessCommandsInfoNVX* pProcessCommandsInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdProcessCommandsNVX( commandBuffer, pProcessCommandsInfo );
    }

    void vkCmdPushConstants( VkCommandBuffer commandBuffer, VkPipelineLayout layout, VkShaderStageFlags stageFlags, uint32_t offset, uint32_t size, const void* pValues ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdPushConstants( commandBuffer, layout, stageFlags, offset, size, pValues );
    }

    void vkCmdPushDescriptorSetKHR( VkCommandBuffer commandBuffer, VkPipelineBindPoint pipelineBindPoint, VkPipelineLayout layout, uint32_t set, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdPushDescriptorSetKHR( commandBuffer, pipelineBindPoint, layout, set, descriptorWriteCount, pDescriptorWrites );
    }

    void vkCmdPushDescriptorSetWithTemplateKHR( VkCommandBuffer commandBuffer, VkDescriptorUpdateTemplate descriptorUpdateTemplate, VkPipelineLayout layout, uint32_t set, const void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdPushDescriptorSetWithTemplateKHR( commandBuffer, descriptorUpdateTemplate, layout, set, pData );
    }

    void vkCmdReserveSpaceForCommandsNVX( VkCommandBuffer commandBuffer, const VkCmdReserveSpaceForCommandsInfoNVX* pReserveSpaceInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdReserveSpaceForCommandsNVX( commandBuffer, pReserveSpaceInfo );
    }

    void vkCmdResetEvent( VkCommandBuffer commandBuffer, VkEvent event, VkPipelineStageFlags stageMask ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdResetEvent( commandBuffer, event, stageMask );
    }

    void vkCmdResetQueryPool( VkCommandBuffer commandBuffer, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdResetQueryPool( commandBuffer, queryPool, firstQuery, queryCount );
    }

    void vkCmdResolveImage( VkCommandBuffer commandBuffer, VkImage srcImage, VkImageLayout srcImageLayout, VkImage dstImage, VkImageLayout dstImageLayout, uint32_t regionCount, const VkImageResolve* pRegions ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdResolveImage( commandBuffer, srcImage, srcImageLayout, dstImage, dstImageLayout, regionCount, pRegions );
    }

    void vkCmdSetBlendConstants( VkCommandBuffer commandBuffer, const float blendConstants[4] ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetBlendConstants( commandBuffer, blendConstants );
    }

    void vkCmdSetCheckpointNV( VkCommandBuffer commandBuffer, const void* pCheckpointMarker ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetCheckpointNV( commandBuffer, pCheckpointMarker );
    }

    void vkCmdSetCoarseSampleOrderNV( VkCommandBuffer commandBuffer, VkCoarseSampleOrderTypeNV sampleOrderType, uint32_t customSampleOrderCount, const VkCoarseSampleOrderCustomNV* pCustomSampleOrders ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetCoarseSampleOrderNV( commandBuffer, sampleOrderType, customSampleOrderCount, pCustomSampleOrders );
    }

    void vkCmdSetDepthBias( VkCommandBuffer commandBuffer, float depthBiasConstantFactor, float depthBiasClamp, float depthBiasSlopeFactor ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetDepthBias( commandBuffer, depthBiasConstantFactor, depthBiasClamp, depthBiasSlopeFactor );
    }

    void vkCmdSetDepthBounds( VkCommandBuffer commandBuffer, float minDepthBounds, float maxDepthBounds ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetDepthBounds( commandBuffer, minDepthBounds, maxDepthBounds );
    }

    void vkCmdSetDeviceMask( VkCommandBuffer commandBuffer, uint32_t deviceMask ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetDeviceMask( commandBuffer, deviceMask );
    }

    void vkCmdSetDeviceMaskKHR( VkCommandBuffer commandBuffer, uint32_t deviceMask ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetDeviceMaskKHR( commandBuffer, deviceMask );
    }

    void vkCmdSetDiscardRectangleEXT( VkCommandBuffer commandBuffer, uint32_t firstDiscardRectangle, uint32_t discardRectangleCount, const VkRect2D* pDiscardRectangles ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetDiscardRectangleEXT( commandBuffer, firstDiscardRectangle, discardRectangleCount, pDiscardRectangles );
    }

    void vkCmdSetEvent( VkCommandBuffer commandBuffer, VkEvent event, VkPipelineStageFlags stageMask ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetEvent( commandBuffer, event, stageMask );
    }

    void vkCmdSetExclusiveScissorNV( VkCommandBuffer commandBuffer, uint32_t firstExclusiveScissor, uint32_t exclusiveScissorCount, const VkRect2D* pExclusiveScissors ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetExclusiveScissorNV( commandBuffer, firstExclusiveScissor, exclusiveScissorCount, pExclusiveScissors );
    }

    void vkCmdSetLineStippleEXT( VkCommandBuffer commandBuffer, uint32_t lineStippleFactor, uint16_t lineStipplePattern ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetLineStippleEXT( commandBuffer, lineStippleFactor, lineStipplePattern );
    }

    void vkCmdSetLineWidth( VkCommandBuffer commandBuffer, float lineWidth ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetLineWidth( commandBuffer, lineWidth );
    }

    VkResult vkCmdSetPerformanceMarkerINTEL( VkCommandBuffer commandBuffer, const VkPerformanceMarkerInfoINTEL* pMarkerInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetPerformanceMarkerINTEL( commandBuffer, pMarkerInfo );
    }

    VkResult vkCmdSetPerformanceOverrideINTEL( VkCommandBuffer commandBuffer, const VkPerformanceOverrideInfoINTEL* pOverrideInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetPerformanceOverrideINTEL( commandBuffer, pOverrideInfo );
    }

    VkResult vkCmdSetPerformanceStreamMarkerINTEL( VkCommandBuffer commandBuffer, const VkPerformanceStreamMarkerInfoINTEL* pMarkerInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetPerformanceStreamMarkerINTEL( commandBuffer, pMarkerInfo );
    }

    void vkCmdSetSampleLocationsEXT( VkCommandBuffer commandBuffer, const VkSampleLocationsInfoEXT* pSampleLocationsInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetSampleLocationsEXT( commandBuffer, pSampleLocationsInfo );
    }

    void vkCmdSetScissor( VkCommandBuffer commandBuffer, uint32_t firstScissor, uint32_t scissorCount, const VkRect2D* pScissors ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetScissor( commandBuffer, firstScissor, scissorCount, pScissors );
    }

    void vkCmdSetStencilCompareMask( VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, uint32_t compareMask ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetStencilCompareMask( commandBuffer, faceMask, compareMask );
    }

    void vkCmdSetStencilReference( VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, uint32_t reference ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetStencilReference( commandBuffer, faceMask, reference );
    }

    void vkCmdSetStencilWriteMask( VkCommandBuffer commandBuffer, VkStencilFaceFlags faceMask, uint32_t writeMask ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetStencilWriteMask( commandBuffer, faceMask, writeMask );
    }

    void vkCmdSetViewport( VkCommandBuffer commandBuffer, uint32_t firstViewport, uint32_t viewportCount, const VkViewport* pViewports ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetViewport( commandBuffer, firstViewport, viewportCount, pViewports );
    }

    void vkCmdSetViewportShadingRatePaletteNV( VkCommandBuffer commandBuffer, uint32_t firstViewport, uint32_t viewportCount, const VkShadingRatePaletteNV* pShadingRatePalettes ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetViewportShadingRatePaletteNV( commandBuffer, firstViewport, viewportCount, pShadingRatePalettes );
    }

    void vkCmdSetViewportWScalingNV( VkCommandBuffer commandBuffer, uint32_t firstViewport, uint32_t viewportCount, const VkViewportWScalingNV* pViewportWScalings ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdSetViewportWScalingNV( commandBuffer, firstViewport, viewportCount, pViewportWScalings );
    }

    void vkCmdTraceRaysNV( VkCommandBuffer commandBuffer, VkBuffer raygenShaderBindingTableBuffer, VkDeviceSize raygenShaderBindingOffset, VkBuffer missShaderBindingTableBuffer, VkDeviceSize missShaderBindingOffset, VkDeviceSize missShaderBindingStride, VkBuffer hitShaderBindingTableBuffer, VkDeviceSize hitShaderBindingOffset, VkDeviceSize hitShaderBindingStride, VkBuffer callableShaderBindingTableBuffer, VkDeviceSize callableShaderBindingOffset, VkDeviceSize callableShaderBindingStride, uint32_t width, uint32_t height, uint32_t depth ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdTraceRaysNV( commandBuffer, raygenShaderBindingTableBuffer, raygenShaderBindingOffset, missShaderBindingTableBuffer, missShaderBindingOffset, missShaderBindingStride, hitShaderBindingTableBuffer, hitShaderBindingOffset, hitShaderBindingStride, callableShaderBindingTableBuffer, callableShaderBindingOffset, callableShaderBindingStride, width, height, depth );
    }

    void vkCmdUpdateBuffer( VkCommandBuffer commandBuffer, VkBuffer dstBuffer, VkDeviceSize dstOffset, VkDeviceSize dataSize, const void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdUpdateBuffer( commandBuffer, dstBuffer, dstOffset, dataSize, pData );
    }

    void vkCmdWaitEvents( VkCommandBuffer commandBuffer, uint32_t eventCount, const VkEvent* pEvents, VkPipelineStageFlags srcStageMask, VkPipelineStageFlags dstStageMask, uint32_t memoryBarrierCount, const VkMemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const VkBufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const VkImageMemoryBarrier* pImageMemoryBarriers ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdWaitEvents( commandBuffer, eventCount, pEvents, srcStageMask, dstStageMask, memoryBarrierCount, pMemoryBarriers, bufferMemoryBarrierCount, pBufferMemoryBarriers, imageMemoryBarrierCount, pImageMemoryBarriers );
    }

    void vkCmdWriteAccelerationStructuresPropertiesNV( VkCommandBuffer commandBuffer, uint32_t accelerationStructureCount, const VkAccelerationStructureNV* pAccelerationStructures, VkQueryType queryType, VkQueryPool queryPool, uint32_t firstQuery ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdWriteAccelerationStructuresPropertiesNV( commandBuffer, accelerationStructureCount, pAccelerationStructures, queryType, queryPool, firstQuery );
    }

    void vkCmdWriteBufferMarkerAMD( VkCommandBuffer commandBuffer, VkPipelineStageFlagBits pipelineStage, VkBuffer dstBuffer, VkDeviceSize dstOffset, uint32_t marker ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdWriteBufferMarkerAMD( commandBuffer, pipelineStage, dstBuffer, dstOffset, marker );
    }

    void vkCmdWriteTimestamp( VkCommandBuffer commandBuffer, VkPipelineStageFlagBits pipelineStage, VkQueryPool queryPool, uint32_t query ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCmdWriteTimestamp( commandBuffer, pipelineStage, queryPool, query );
    }

    VkResult vkEndCommandBuffer( VkCommandBuffer commandBuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEndCommandBuffer( commandBuffer );
    }

    VkResult vkResetCommandBuffer( VkCommandBuffer commandBuffer, VkCommandBufferResetFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkResetCommandBuffer( commandBuffer, flags );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkAcquireFullScreenExclusiveModeEXT( VkDevice device, VkSwapchainKHR swapchain ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAcquireFullScreenExclusiveModeEXT( device, swapchain );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkAcquireNextImage2KHR( VkDevice device, const VkAcquireNextImageInfoKHR* pAcquireInfo, uint32_t* pImageIndex ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAcquireNextImage2KHR( device, pAcquireInfo, pImageIndex );
    }

    VkResult vkAcquireNextImageKHR( VkDevice device, VkSwapchainKHR swapchain, uint64_t timeout, VkSemaphore semaphore, VkFence fence, uint32_t* pImageIndex ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAcquireNextImageKHR( device, swapchain, timeout, semaphore, fence, pImageIndex );
    }

    VkResult vkAcquirePerformanceConfigurationINTEL( VkDevice device, const VkPerformanceConfigurationAcquireInfoINTEL* pAcquireInfo, VkPerformanceConfigurationINTEL* pConfiguration ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAcquirePerformanceConfigurationINTEL( device, pAcquireInfo, pConfiguration );
    }

    VkResult vkAllocateCommandBuffers( VkDevice device, const VkCommandBufferAllocateInfo* pAllocateInfo, VkCommandBuffer* pCommandBuffers ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAllocateCommandBuffers( device, pAllocateInfo, pCommandBuffers );
    }

    VkResult vkAllocateDescriptorSets( VkDevice device, const VkDescriptorSetAllocateInfo* pAllocateInfo, VkDescriptorSet* pDescriptorSets ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAllocateDescriptorSets( device, pAllocateInfo, pDescriptorSets );
    }

    VkResult vkAllocateMemory( VkDevice device, const VkMemoryAllocateInfo* pAllocateInfo, const VkAllocationCallbacks* pAllocator, VkDeviceMemory* pMemory ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAllocateMemory( device, pAllocateInfo, pAllocator, pMemory );
    }

    VkResult vkBindAccelerationStructureMemoryNV( VkDevice device, uint32_t bindInfoCount, const VkBindAccelerationStructureMemoryInfoNV* pBindInfos ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBindAccelerationStructureMemoryNV( device, bindInfoCount, pBindInfos );
    }

    VkResult vkBindBufferMemory( VkDevice device, VkBuffer buffer, VkDeviceMemory memory, VkDeviceSize memoryOffset ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBindBufferMemory( device, buffer, memory, memoryOffset );
    }

    VkResult vkBindBufferMemory2( VkDevice device, uint32_t bindInfoCount, const VkBindBufferMemoryInfo* pBindInfos ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBindBufferMemory2( device, bindInfoCount, pBindInfos );
    }

    VkResult vkBindBufferMemory2KHR( VkDevice device, uint32_t bindInfoCount, const VkBindBufferMemoryInfo* pBindInfos ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBindBufferMemory2KHR( device, bindInfoCount, pBindInfos );
    }

    VkResult vkBindImageMemory( VkDevice device, VkImage image, VkDeviceMemory memory, VkDeviceSize memoryOffset ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBindImageMemory( device, image, memory, memoryOffset );
    }

    VkResult vkBindImageMemory2( VkDevice device, uint32_t bindInfoCount, const VkBindImageMemoryInfo* pBindInfos ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBindImageMemory2( device, bindInfoCount, pBindInfos );
    }

    VkResult vkBindImageMemory2KHR( VkDevice device, uint32_t bindInfoCount, const VkBindImageMemoryInfo* pBindInfos ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkBindImageMemory2KHR( device, bindInfoCount, pBindInfos );
    }

    VkResult vkCompileDeferredNV( VkDevice device, VkPipeline pipeline, uint32_t shader ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCompileDeferredNV( device, pipeline, shader );
    }

    VkResult vkCreateAccelerationStructureNV( VkDevice device, const VkAccelerationStructureCreateInfoNV* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkAccelerationStructureNV* pAccelerationStructure ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateAccelerationStructureNV( device, pCreateInfo, pAllocator, pAccelerationStructure );
    }

    VkResult vkCreateBuffer( VkDevice device, const VkBufferCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkBuffer* pBuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateBuffer( device, pCreateInfo, pAllocator, pBuffer );
    }

    VkResult vkCreateBufferView( VkDevice device, const VkBufferViewCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkBufferView* pView ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateBufferView( device, pCreateInfo, pAllocator, pView );
    }

    VkResult vkCreateCommandPool( VkDevice device, const VkCommandPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkCommandPool* pCommandPool ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateCommandPool( device, pCreateInfo, pAllocator, pCommandPool );
    }

    VkResult vkCreateComputePipelines( VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount, const VkComputePipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateComputePipelines( device, pipelineCache, createInfoCount, pCreateInfos, pAllocator, pPipelines );
    }

    VkResult vkCreateDescriptorPool( VkDevice device, const VkDescriptorPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorPool* pDescriptorPool ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDescriptorPool( device, pCreateInfo, pAllocator, pDescriptorPool );
    }

    VkResult vkCreateDescriptorSetLayout( VkDevice device, const VkDescriptorSetLayoutCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorSetLayout* pSetLayout ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDescriptorSetLayout( device, pCreateInfo, pAllocator, pSetLayout );
    }

    VkResult vkCreateDescriptorUpdateTemplate( VkDevice device, const VkDescriptorUpdateTemplateCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorUpdateTemplate* pDescriptorUpdateTemplate ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDescriptorUpdateTemplate( device, pCreateInfo, pAllocator, pDescriptorUpdateTemplate );
    }

    VkResult vkCreateDescriptorUpdateTemplateKHR( VkDevice device, const VkDescriptorUpdateTemplateCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDescriptorUpdateTemplate* pDescriptorUpdateTemplate ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDescriptorUpdateTemplateKHR( device, pCreateInfo, pAllocator, pDescriptorUpdateTemplate );
    }

    VkResult vkCreateEvent( VkDevice device, const VkEventCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkEvent* pEvent ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateEvent( device, pCreateInfo, pAllocator, pEvent );
    }

    VkResult vkCreateFence( VkDevice device, const VkFenceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkFence* pFence ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateFence( device, pCreateInfo, pAllocator, pFence );
    }

    VkResult vkCreateFramebuffer( VkDevice device, const VkFramebufferCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkFramebuffer* pFramebuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateFramebuffer( device, pCreateInfo, pAllocator, pFramebuffer );
    }

    VkResult vkCreateGraphicsPipelines( VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount, const VkGraphicsPipelineCreateInfo* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateGraphicsPipelines( device, pipelineCache, createInfoCount, pCreateInfos, pAllocator, pPipelines );
    }

    VkResult vkCreateImage( VkDevice device, const VkImageCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkImage* pImage ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateImage( device, pCreateInfo, pAllocator, pImage );
    }

    VkResult vkCreateImageView( VkDevice device, const VkImageViewCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkImageView* pView ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateImageView( device, pCreateInfo, pAllocator, pView );
    }

    VkResult vkCreateIndirectCommandsLayoutNVX( VkDevice device, const VkIndirectCommandsLayoutCreateInfoNVX* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkIndirectCommandsLayoutNVX* pIndirectCommandsLayout ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateIndirectCommandsLayoutNVX( device, pCreateInfo, pAllocator, pIndirectCommandsLayout );
    }

    VkResult vkCreateObjectTableNVX( VkDevice device, const VkObjectTableCreateInfoNVX* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkObjectTableNVX* pObjectTable ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateObjectTableNVX( device, pCreateInfo, pAllocator, pObjectTable );
    }

    VkResult vkCreatePipelineCache( VkDevice device, const VkPipelineCacheCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkPipelineCache* pPipelineCache ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreatePipelineCache( device, pCreateInfo, pAllocator, pPipelineCache );
    }

    VkResult vkCreatePipelineLayout( VkDevice device, const VkPipelineLayoutCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkPipelineLayout* pPipelineLayout ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreatePipelineLayout( device, pCreateInfo, pAllocator, pPipelineLayout );
    }

    VkResult vkCreateQueryPool( VkDevice device, const VkQueryPoolCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkQueryPool* pQueryPool ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateQueryPool( device, pCreateInfo, pAllocator, pQueryPool );
    }

    VkResult vkCreateRayTracingPipelinesNV( VkDevice device, VkPipelineCache pipelineCache, uint32_t createInfoCount, const VkRayTracingPipelineCreateInfoNV* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkPipeline* pPipelines ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateRayTracingPipelinesNV( device, pipelineCache, createInfoCount, pCreateInfos, pAllocator, pPipelines );
    }

    VkResult vkCreateRenderPass( VkDevice device, const VkRenderPassCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkRenderPass* pRenderPass ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateRenderPass( device, pCreateInfo, pAllocator, pRenderPass );
    }

    VkResult vkCreateRenderPass2KHR( VkDevice device, const VkRenderPassCreateInfo2KHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkRenderPass* pRenderPass ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateRenderPass2KHR( device, pCreateInfo, pAllocator, pRenderPass );
    }

    VkResult vkCreateSampler( VkDevice device, const VkSamplerCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSampler* pSampler ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateSampler( device, pCreateInfo, pAllocator, pSampler );
    }

    VkResult vkCreateSamplerYcbcrConversion( VkDevice device, const VkSamplerYcbcrConversionCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSamplerYcbcrConversion* pYcbcrConversion ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateSamplerYcbcrConversion( device, pCreateInfo, pAllocator, pYcbcrConversion );
    }

    VkResult vkCreateSamplerYcbcrConversionKHR( VkDevice device, const VkSamplerYcbcrConversionCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSamplerYcbcrConversion* pYcbcrConversion ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateSamplerYcbcrConversionKHR( device, pCreateInfo, pAllocator, pYcbcrConversion );
    }

    VkResult vkCreateSemaphore( VkDevice device, const VkSemaphoreCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSemaphore* pSemaphore ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateSemaphore( device, pCreateInfo, pAllocator, pSemaphore );
    }

    VkResult vkCreateShaderModule( VkDevice device, const VkShaderModuleCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkShaderModule* pShaderModule ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateShaderModule( device, pCreateInfo, pAllocator, pShaderModule );
    }

    VkResult vkCreateSharedSwapchainsKHR( VkDevice device, uint32_t swapchainCount, const VkSwapchainCreateInfoKHR* pCreateInfos, const VkAllocationCallbacks* pAllocator, VkSwapchainKHR* pSwapchains ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateSharedSwapchainsKHR( device, swapchainCount, pCreateInfos, pAllocator, pSwapchains );
    }

    VkResult vkCreateSwapchainKHR( VkDevice device, const VkSwapchainCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSwapchainKHR* pSwapchain ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateSwapchainKHR( device, pCreateInfo, pAllocator, pSwapchain );
    }

    VkResult vkCreateValidationCacheEXT( VkDevice device, const VkValidationCacheCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkValidationCacheEXT* pValidationCache ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateValidationCacheEXT( device, pCreateInfo, pAllocator, pValidationCache );
    }

    VkResult vkDebugMarkerSetObjectNameEXT( VkDevice device, const VkDebugMarkerObjectNameInfoEXT* pNameInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDebugMarkerSetObjectNameEXT( device, pNameInfo );
    }

    VkResult vkDebugMarkerSetObjectTagEXT( VkDevice device, const VkDebugMarkerObjectTagInfoEXT* pTagInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDebugMarkerSetObjectTagEXT( device, pTagInfo );
    }

    void vkDestroyAccelerationStructureNV( VkDevice device, VkAccelerationStructureNV accelerationStructure, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyAccelerationStructureNV( device, accelerationStructure, pAllocator );
    }

    void vkDestroyBuffer( VkDevice device, VkBuffer buffer, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyBuffer( device, buffer, pAllocator );
    }

    void vkDestroyBufferView( VkDevice device, VkBufferView bufferView, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyBufferView( device, bufferView, pAllocator );
    }

    void vkDestroyCommandPool( VkDevice device, VkCommandPool commandPool, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyCommandPool( device, commandPool, pAllocator );
    }

    void vkDestroyDescriptorPool( VkDevice device, VkDescriptorPool descriptorPool, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyDescriptorPool( device, descriptorPool, pAllocator );
    }

    void vkDestroyDescriptorSetLayout( VkDevice device, VkDescriptorSetLayout descriptorSetLayout, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyDescriptorSetLayout( device, descriptorSetLayout, pAllocator );
    }

    void vkDestroyDescriptorUpdateTemplate( VkDevice device, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyDescriptorUpdateTemplate( device, descriptorUpdateTemplate, pAllocator );
    }

    void vkDestroyDescriptorUpdateTemplateKHR( VkDevice device, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyDescriptorUpdateTemplateKHR( device, descriptorUpdateTemplate, pAllocator );
    }

    void vkDestroyDevice( VkDevice device, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyDevice( device, pAllocator );
    }

    void vkDestroyEvent( VkDevice device, VkEvent event, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyEvent( device, event, pAllocator );
    }

    void vkDestroyFence( VkDevice device, VkFence fence, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyFence( device, fence, pAllocator );
    }

    void vkDestroyFramebuffer( VkDevice device, VkFramebuffer framebuffer, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyFramebuffer( device, framebuffer, pAllocator );
    }

    void vkDestroyImage( VkDevice device, VkImage image, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyImage( device, image, pAllocator );
    }

    void vkDestroyImageView( VkDevice device, VkImageView imageView, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyImageView( device, imageView, pAllocator );
    }

    void vkDestroyIndirectCommandsLayoutNVX( VkDevice device, VkIndirectCommandsLayoutNVX indirectCommandsLayout, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyIndirectCommandsLayoutNVX( device, indirectCommandsLayout, pAllocator );
    }

    void vkDestroyObjectTableNVX( VkDevice device, VkObjectTableNVX objectTable, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyObjectTableNVX( device, objectTable, pAllocator );
    }

    void vkDestroyPipeline( VkDevice device, VkPipeline pipeline, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyPipeline( device, pipeline, pAllocator );
    }

    void vkDestroyPipelineCache( VkDevice device, VkPipelineCache pipelineCache, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyPipelineCache( device, pipelineCache, pAllocator );
    }

    void vkDestroyPipelineLayout( VkDevice device, VkPipelineLayout pipelineLayout, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyPipelineLayout( device, pipelineLayout, pAllocator );
    }

    void vkDestroyQueryPool( VkDevice device, VkQueryPool queryPool, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyQueryPool( device, queryPool, pAllocator );
    }

    void vkDestroyRenderPass( VkDevice device, VkRenderPass renderPass, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyRenderPass( device, renderPass, pAllocator );
    }

    void vkDestroySampler( VkDevice device, VkSampler sampler, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroySampler( device, sampler, pAllocator );
    }

    void vkDestroySamplerYcbcrConversion( VkDevice device, VkSamplerYcbcrConversion ycbcrConversion, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroySamplerYcbcrConversion( device, ycbcrConversion, pAllocator );
    }

    void vkDestroySamplerYcbcrConversionKHR( VkDevice device, VkSamplerYcbcrConversion ycbcrConversion, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroySamplerYcbcrConversionKHR( device, ycbcrConversion, pAllocator );
    }

    void vkDestroySemaphore( VkDevice device, VkSemaphore semaphore, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroySemaphore( device, semaphore, pAllocator );
    }

    void vkDestroyShaderModule( VkDevice device, VkShaderModule shaderModule, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyShaderModule( device, shaderModule, pAllocator );
    }

    void vkDestroySwapchainKHR( VkDevice device, VkSwapchainKHR swapchain, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroySwapchainKHR( device, swapchain, pAllocator );
    }

    void vkDestroyValidationCacheEXT( VkDevice device, VkValidationCacheEXT validationCache, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyValidationCacheEXT( device, validationCache, pAllocator );
    }

    VkResult vkDeviceWaitIdle( VkDevice device ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDeviceWaitIdle( device );
    }

    VkResult vkDisplayPowerControlEXT( VkDevice device, VkDisplayKHR display, const VkDisplayPowerInfoEXT* pDisplayPowerInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDisplayPowerControlEXT( device, display, pDisplayPowerInfo );
    }

    VkResult vkFlushMappedMemoryRanges( VkDevice device, uint32_t memoryRangeCount, const VkMappedMemoryRange* pMemoryRanges ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkFlushMappedMemoryRanges( device, memoryRangeCount, pMemoryRanges );
    }

    void vkFreeCommandBuffers( VkDevice device, VkCommandPool commandPool, uint32_t commandBufferCount, const VkCommandBuffer* pCommandBuffers ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkFreeCommandBuffers( device, commandPool, commandBufferCount, pCommandBuffers );
    }

    VkResult vkFreeDescriptorSets( VkDevice device, VkDescriptorPool descriptorPool, uint32_t descriptorSetCount, const VkDescriptorSet* pDescriptorSets ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkFreeDescriptorSets( device, descriptorPool, descriptorSetCount, pDescriptorSets );
    }

    void vkFreeMemory( VkDevice device, VkDeviceMemory memory, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkFreeMemory( device, memory, pAllocator );
    }

    VkResult vkGetAccelerationStructureHandleNV( VkDevice device, VkAccelerationStructureNV accelerationStructure, size_t dataSize, void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetAccelerationStructureHandleNV( device, accelerationStructure, dataSize, pData );
    }

    void vkGetAccelerationStructureMemoryRequirementsNV( VkDevice device, const VkAccelerationStructureMemoryRequirementsInfoNV* pInfo, VkMemoryRequirements2KHR* pMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetAccelerationStructureMemoryRequirementsNV( device, pInfo, pMemoryRequirements );
    }

#ifdef VK_USE_PLATFORM_ANDROID_KHR
    VkResult vkGetAndroidHardwareBufferPropertiesANDROID( VkDevice device, const struct AHardwareBuffer* buffer, VkAndroidHardwareBufferPropertiesANDROID* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetAndroidHardwareBufferPropertiesANDROID( device, buffer, pProperties );
    }
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

    VkDeviceAddress vkGetBufferDeviceAddressEXT( VkDevice device, const VkBufferDeviceAddressInfoEXT* pInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetBufferDeviceAddressEXT( device, pInfo );
    }

    void vkGetBufferMemoryRequirements( VkDevice device, VkBuffer buffer, VkMemoryRequirements* pMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetBufferMemoryRequirements( device, buffer, pMemoryRequirements );
    }

    void vkGetBufferMemoryRequirements2( VkDevice device, const VkBufferMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetBufferMemoryRequirements2( device, pInfo, pMemoryRequirements );
    }

    void vkGetBufferMemoryRequirements2KHR( VkDevice device, const VkBufferMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetBufferMemoryRequirements2KHR( device, pInfo, pMemoryRequirements );
    }

    VkResult vkGetCalibratedTimestampsEXT( VkDevice device, uint32_t timestampCount, const VkCalibratedTimestampInfoEXT* pTimestampInfos, uint64_t* pTimestamps, uint64_t* pMaxDeviation ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetCalibratedTimestampsEXT( device, timestampCount, pTimestampInfos, pTimestamps, pMaxDeviation );
    }

    void vkGetDescriptorSetLayoutSupport( VkDevice device, const VkDescriptorSetLayoutCreateInfo* pCreateInfo, VkDescriptorSetLayoutSupport* pSupport ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDescriptorSetLayoutSupport( device, pCreateInfo, pSupport );
    }

    void vkGetDescriptorSetLayoutSupportKHR( VkDevice device, const VkDescriptorSetLayoutCreateInfo* pCreateInfo, VkDescriptorSetLayoutSupport* pSupport ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDescriptorSetLayoutSupportKHR( device, pCreateInfo, pSupport );
    }

    void vkGetDeviceGroupPeerMemoryFeatures( VkDevice device, uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, VkPeerMemoryFeatureFlags* pPeerMemoryFeatures ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceGroupPeerMemoryFeatures( device, heapIndex, localDeviceIndex, remoteDeviceIndex, pPeerMemoryFeatures );
    }

    void vkGetDeviceGroupPeerMemoryFeaturesKHR( VkDevice device, uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, VkPeerMemoryFeatureFlags* pPeerMemoryFeatures ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceGroupPeerMemoryFeaturesKHR( device, heapIndex, localDeviceIndex, remoteDeviceIndex, pPeerMemoryFeatures );
    }

    VkResult vkGetDeviceGroupPresentCapabilitiesKHR( VkDevice device, VkDeviceGroupPresentCapabilitiesKHR* pDeviceGroupPresentCapabilities ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceGroupPresentCapabilitiesKHR( device, pDeviceGroupPresentCapabilities );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkGetDeviceGroupSurfacePresentModes2EXT( VkDevice device, const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, VkDeviceGroupPresentModeFlagsKHR* pModes ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceGroupSurfacePresentModes2EXT( device, pSurfaceInfo, pModes );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkGetDeviceGroupSurfacePresentModesKHR( VkDevice device, VkSurfaceKHR surface, VkDeviceGroupPresentModeFlagsKHR* pModes ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceGroupSurfacePresentModesKHR( device, surface, pModes );
    }

    void vkGetDeviceMemoryCommitment( VkDevice device, VkDeviceMemory memory, VkDeviceSize* pCommittedMemoryInBytes ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceMemoryCommitment( device, memory, pCommittedMemoryInBytes );
    }

    PFN_vkVoidFunction vkGetDeviceProcAddr( VkDevice device, const char* pName ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceProcAddr( device, pName );
    }

    void vkGetDeviceQueue( VkDevice device, uint32_t queueFamilyIndex, uint32_t queueIndex, VkQueue* pQueue ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceQueue( device, queueFamilyIndex, queueIndex, pQueue );
    }

    void vkGetDeviceQueue2( VkDevice device, const VkDeviceQueueInfo2* pQueueInfo, VkQueue* pQueue ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDeviceQueue2( device, pQueueInfo, pQueue );
    }

    VkResult vkGetEventStatus( VkDevice device, VkEvent event ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetEventStatus( device, event );
    }

    VkResult vkGetFenceFdKHR( VkDevice device, const VkFenceGetFdInfoKHR* pGetFdInfo, int* pFd ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetFenceFdKHR( device, pGetFdInfo, pFd );
    }

    VkResult vkGetFenceStatus( VkDevice device, VkFence fence ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetFenceStatus( device, fence );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkGetFenceWin32HandleKHR( VkDevice device, const VkFenceGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetFenceWin32HandleKHR( device, pGetWin32HandleInfo, pHandle );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkGetImageDrmFormatModifierPropertiesEXT( VkDevice device, VkImage image, VkImageDrmFormatModifierPropertiesEXT* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageDrmFormatModifierPropertiesEXT( device, image, pProperties );
    }

    void vkGetImageMemoryRequirements( VkDevice device, VkImage image, VkMemoryRequirements* pMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageMemoryRequirements( device, image, pMemoryRequirements );
    }

    void vkGetImageMemoryRequirements2( VkDevice device, const VkImageMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageMemoryRequirements2( device, pInfo, pMemoryRequirements );
    }

    void vkGetImageMemoryRequirements2KHR( VkDevice device, const VkImageMemoryRequirementsInfo2* pInfo, VkMemoryRequirements2* pMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageMemoryRequirements2KHR( device, pInfo, pMemoryRequirements );
    }

    void vkGetImageSparseMemoryRequirements( VkDevice device, VkImage image, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements* pSparseMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageSparseMemoryRequirements( device, image, pSparseMemoryRequirementCount, pSparseMemoryRequirements );
    }

    void vkGetImageSparseMemoryRequirements2( VkDevice device, const VkImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements2* pSparseMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageSparseMemoryRequirements2( device, pInfo, pSparseMemoryRequirementCount, pSparseMemoryRequirements );
    }

    void vkGetImageSparseMemoryRequirements2KHR( VkDevice device, const VkImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, VkSparseImageMemoryRequirements2* pSparseMemoryRequirements ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageSparseMemoryRequirements2KHR( device, pInfo, pSparseMemoryRequirementCount, pSparseMemoryRequirements );
    }

    void vkGetImageSubresourceLayout( VkDevice device, VkImage image, const VkImageSubresource* pSubresource, VkSubresourceLayout* pLayout ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageSubresourceLayout( device, image, pSubresource, pLayout );
    }

    uint32_t vkGetImageViewHandleNVX( VkDevice device, const VkImageViewHandleInfoNVX* pInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetImageViewHandleNVX( device, pInfo );
    }

#ifdef VK_USE_PLATFORM_ANDROID_KHR
    VkResult vkGetMemoryAndroidHardwareBufferANDROID( VkDevice device, const VkMemoryGetAndroidHardwareBufferInfoANDROID* pInfo, struct AHardwareBuffer** pBuffer ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetMemoryAndroidHardwareBufferANDROID( device, pInfo, pBuffer );
    }
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

    VkResult vkGetMemoryFdKHR( VkDevice device, const VkMemoryGetFdInfoKHR* pGetFdInfo, int* pFd ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetMemoryFdKHR( device, pGetFdInfo, pFd );
    }

    VkResult vkGetMemoryFdPropertiesKHR( VkDevice device, VkExternalMemoryHandleTypeFlagBits handleType, int fd, VkMemoryFdPropertiesKHR* pMemoryFdProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetMemoryFdPropertiesKHR( device, handleType, fd, pMemoryFdProperties );
    }

    VkResult vkGetMemoryHostPointerPropertiesEXT( VkDevice device, VkExternalMemoryHandleTypeFlagBits handleType, const void* pHostPointer, VkMemoryHostPointerPropertiesEXT* pMemoryHostPointerProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetMemoryHostPointerPropertiesEXT( device, handleType, pHostPointer, pMemoryHostPointerProperties );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkGetMemoryWin32HandleKHR( VkDevice device, const VkMemoryGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetMemoryWin32HandleKHR( device, pGetWin32HandleInfo, pHandle );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkGetMemoryWin32HandleNV( VkDevice device, VkDeviceMemory memory, VkExternalMemoryHandleTypeFlagsNV handleType, HANDLE* pHandle ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetMemoryWin32HandleNV( device, memory, handleType, pHandle );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkGetMemoryWin32HandlePropertiesKHR( VkDevice device, VkExternalMemoryHandleTypeFlagBits handleType, HANDLE handle, VkMemoryWin32HandlePropertiesKHR* pMemoryWin32HandleProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetMemoryWin32HandlePropertiesKHR( device, handleType, handle, pMemoryWin32HandleProperties );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkGetPastPresentationTimingGOOGLE( VkDevice device, VkSwapchainKHR swapchain, uint32_t* pPresentationTimingCount, VkPastPresentationTimingGOOGLE* pPresentationTimings ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPastPresentationTimingGOOGLE( device, swapchain, pPresentationTimingCount, pPresentationTimings );
    }

    VkResult vkGetPerformanceParameterINTEL( VkDevice device, VkPerformanceParameterTypeINTEL parameter, VkPerformanceValueINTEL* pValue ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPerformanceParameterINTEL( device, parameter, pValue );
    }

    VkResult vkGetPipelineCacheData( VkDevice device, VkPipelineCache pipelineCache, size_t* pDataSize, void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPipelineCacheData( device, pipelineCache, pDataSize, pData );
    }

    VkResult vkGetPipelineExecutableInternalRepresentationsKHR( VkDevice device, const VkPipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pInternalRepresentationCount, VkPipelineExecutableInternalRepresentationKHR* pInternalRepresentations ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPipelineExecutableInternalRepresentationsKHR( device, pExecutableInfo, pInternalRepresentationCount, pInternalRepresentations );
    }

    VkResult vkGetPipelineExecutablePropertiesKHR( VkDevice device, const VkPipelineInfoKHR* pPipelineInfo, uint32_t* pExecutableCount, VkPipelineExecutablePropertiesKHR* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPipelineExecutablePropertiesKHR( device, pPipelineInfo, pExecutableCount, pProperties );
    }

    VkResult vkGetPipelineExecutableStatisticsKHR( VkDevice device, const VkPipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pStatisticCount, VkPipelineExecutableStatisticKHR* pStatistics ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPipelineExecutableStatisticsKHR( device, pExecutableInfo, pStatisticCount, pStatistics );
    }

    VkResult vkGetQueryPoolResults( VkDevice device, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, size_t dataSize, void* pData, VkDeviceSize stride, VkQueryResultFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetQueryPoolResults( device, queryPool, firstQuery, queryCount, dataSize, pData, stride, flags );
    }

    VkResult vkGetRayTracingShaderGroupHandlesNV( VkDevice device, VkPipeline pipeline, uint32_t firstGroup, uint32_t groupCount, size_t dataSize, void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetRayTracingShaderGroupHandlesNV( device, pipeline, firstGroup, groupCount, dataSize, pData );
    }

    VkResult vkGetRefreshCycleDurationGOOGLE( VkDevice device, VkSwapchainKHR swapchain, VkRefreshCycleDurationGOOGLE* pDisplayTimingProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetRefreshCycleDurationGOOGLE( device, swapchain, pDisplayTimingProperties );
    }

    void vkGetRenderAreaGranularity( VkDevice device, VkRenderPass renderPass, VkExtent2D* pGranularity ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetRenderAreaGranularity( device, renderPass, pGranularity );
    }

    VkResult vkGetSemaphoreCounterValueKHR( VkDevice device, VkSemaphore semaphore, uint64_t* pValue ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetSemaphoreCounterValueKHR( device, semaphore, pValue );
    }

    VkResult vkGetSemaphoreFdKHR( VkDevice device, const VkSemaphoreGetFdInfoKHR* pGetFdInfo, int* pFd ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetSemaphoreFdKHR( device, pGetFdInfo, pFd );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkGetSemaphoreWin32HandleKHR( VkDevice device, const VkSemaphoreGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetSemaphoreWin32HandleKHR( device, pGetWin32HandleInfo, pHandle );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkGetShaderInfoAMD( VkDevice device, VkPipeline pipeline, VkShaderStageFlagBits shaderStage, VkShaderInfoTypeAMD infoType, size_t* pInfoSize, void* pInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetShaderInfoAMD( device, pipeline, shaderStage, infoType, pInfoSize, pInfo );
    }

    VkResult vkGetSwapchainCounterEXT( VkDevice device, VkSwapchainKHR swapchain, VkSurfaceCounterFlagBitsEXT counter, uint64_t* pCounterValue ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetSwapchainCounterEXT( device, swapchain, counter, pCounterValue );
    }

    VkResult vkGetSwapchainImagesKHR( VkDevice device, VkSwapchainKHR swapchain, uint32_t* pSwapchainImageCount, VkImage* pSwapchainImages ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetSwapchainImagesKHR( device, swapchain, pSwapchainImageCount, pSwapchainImages );
    }

    VkResult vkGetSwapchainStatusKHR( VkDevice device, VkSwapchainKHR swapchain ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetSwapchainStatusKHR( device, swapchain );
    }

    VkResult vkGetValidationCacheDataEXT( VkDevice device, VkValidationCacheEXT validationCache, size_t* pDataSize, void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetValidationCacheDataEXT( device, validationCache, pDataSize, pData );
    }

    VkResult vkImportFenceFdKHR( VkDevice device, const VkImportFenceFdInfoKHR* pImportFenceFdInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkImportFenceFdKHR( device, pImportFenceFdInfo );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkImportFenceWin32HandleKHR( VkDevice device, const VkImportFenceWin32HandleInfoKHR* pImportFenceWin32HandleInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkImportFenceWin32HandleKHR( device, pImportFenceWin32HandleInfo );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkImportSemaphoreFdKHR( VkDevice device, const VkImportSemaphoreFdInfoKHR* pImportSemaphoreFdInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkImportSemaphoreFdKHR( device, pImportSemaphoreFdInfo );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkImportSemaphoreWin32HandleKHR( VkDevice device, const VkImportSemaphoreWin32HandleInfoKHR* pImportSemaphoreWin32HandleInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkImportSemaphoreWin32HandleKHR( device, pImportSemaphoreWin32HandleInfo );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkInitializePerformanceApiINTEL( VkDevice device, const VkInitializePerformanceApiInfoINTEL* pInitializeInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkInitializePerformanceApiINTEL( device, pInitializeInfo );
    }

    VkResult vkInvalidateMappedMemoryRanges( VkDevice device, uint32_t memoryRangeCount, const VkMappedMemoryRange* pMemoryRanges ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkInvalidateMappedMemoryRanges( device, memoryRangeCount, pMemoryRanges );
    }

    VkResult vkMapMemory( VkDevice device, VkDeviceMemory memory, VkDeviceSize offset, VkDeviceSize size, VkMemoryMapFlags flags, void** ppData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkMapMemory( device, memory, offset, size, flags, ppData );
    }

    VkResult vkMergePipelineCaches( VkDevice device, VkPipelineCache dstCache, uint32_t srcCacheCount, const VkPipelineCache* pSrcCaches ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkMergePipelineCaches( device, dstCache, srcCacheCount, pSrcCaches );
    }

    VkResult vkMergeValidationCachesEXT( VkDevice device, VkValidationCacheEXT dstCache, uint32_t srcCacheCount, const VkValidationCacheEXT* pSrcCaches ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkMergeValidationCachesEXT( device, dstCache, srcCacheCount, pSrcCaches );
    }

    VkResult vkRegisterDeviceEventEXT( VkDevice device, const VkDeviceEventInfoEXT* pDeviceEventInfo, const VkAllocationCallbacks* pAllocator, VkFence* pFence ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkRegisterDeviceEventEXT( device, pDeviceEventInfo, pAllocator, pFence );
    }

    VkResult vkRegisterDisplayEventEXT( VkDevice device, VkDisplayKHR display, const VkDisplayEventInfoEXT* pDisplayEventInfo, const VkAllocationCallbacks* pAllocator, VkFence* pFence ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkRegisterDisplayEventEXT( device, display, pDisplayEventInfo, pAllocator, pFence );
    }

    VkResult vkRegisterObjectsNVX( VkDevice device, VkObjectTableNVX objectTable, uint32_t objectCount, const VkObjectTableEntryNVX* const* ppObjectTableEntries, const uint32_t* pObjectIndices ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkRegisterObjectsNVX( device, objectTable, objectCount, ppObjectTableEntries, pObjectIndices );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkReleaseFullScreenExclusiveModeEXT( VkDevice device, VkSwapchainKHR swapchain ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkReleaseFullScreenExclusiveModeEXT( device, swapchain );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkReleasePerformanceConfigurationINTEL( VkDevice device, VkPerformanceConfigurationINTEL configuration ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkReleasePerformanceConfigurationINTEL( device, configuration );
    }

    VkResult vkResetCommandPool( VkDevice device, VkCommandPool commandPool, VkCommandPoolResetFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkResetCommandPool( device, commandPool, flags );
    }

    VkResult vkResetDescriptorPool( VkDevice device, VkDescriptorPool descriptorPool, VkDescriptorPoolResetFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkResetDescriptorPool( device, descriptorPool, flags );
    }

    VkResult vkResetEvent( VkDevice device, VkEvent event ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkResetEvent( device, event );
    }

    VkResult vkResetFences( VkDevice device, uint32_t fenceCount, const VkFence* pFences ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkResetFences( device, fenceCount, pFences );
    }

    void vkResetQueryPoolEXT( VkDevice device, VkQueryPool queryPool, uint32_t firstQuery, uint32_t queryCount ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkResetQueryPoolEXT( device, queryPool, firstQuery, queryCount );
    }

    VkResult vkSetDebugUtilsObjectNameEXT( VkDevice device, const VkDebugUtilsObjectNameInfoEXT* pNameInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkSetDebugUtilsObjectNameEXT( device, pNameInfo );
    }

    VkResult vkSetDebugUtilsObjectTagEXT( VkDevice device, const VkDebugUtilsObjectTagInfoEXT* pTagInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkSetDebugUtilsObjectTagEXT( device, pTagInfo );
    }

    VkResult vkSetEvent( VkDevice device, VkEvent event ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkSetEvent( device, event );
    }

    void vkSetHdrMetadataEXT( VkDevice device, uint32_t swapchainCount, const VkSwapchainKHR* pSwapchains, const VkHdrMetadataEXT* pMetadata ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkSetHdrMetadataEXT( device, swapchainCount, pSwapchains, pMetadata );
    }

    void vkSetLocalDimmingAMD( VkDevice device, VkSwapchainKHR swapChain, VkBool32 localDimmingEnable ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkSetLocalDimmingAMD( device, swapChain, localDimmingEnable );
    }

    VkResult vkSignalSemaphoreKHR( VkDevice device, const VkSemaphoreSignalInfoKHR* pSignalInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkSignalSemaphoreKHR( device, pSignalInfo );
    }

    void vkTrimCommandPool( VkDevice device, VkCommandPool commandPool, VkCommandPoolTrimFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkTrimCommandPool( device, commandPool, flags );
    }

    void vkTrimCommandPoolKHR( VkDevice device, VkCommandPool commandPool, VkCommandPoolTrimFlags flags ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkTrimCommandPoolKHR( device, commandPool, flags );
    }

    void vkUninitializePerformanceApiINTEL( VkDevice device ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkUninitializePerformanceApiINTEL( device );
    }

    void vkUnmapMemory( VkDevice device, VkDeviceMemory memory ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkUnmapMemory( device, memory );
    }

    VkResult vkUnregisterObjectsNVX( VkDevice device, VkObjectTableNVX objectTable, uint32_t objectCount, const VkObjectEntryTypeNVX* pObjectEntryTypes, const uint32_t* pObjectIndices ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkUnregisterObjectsNVX( device, objectTable, objectCount, pObjectEntryTypes, pObjectIndices );
    }

    void vkUpdateDescriptorSetWithTemplate( VkDevice device, VkDescriptorSet descriptorSet, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkUpdateDescriptorSetWithTemplate( device, descriptorSet, descriptorUpdateTemplate, pData );
    }

    void vkUpdateDescriptorSetWithTemplateKHR( VkDevice device, VkDescriptorSet descriptorSet, VkDescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkUpdateDescriptorSetWithTemplateKHR( device, descriptorSet, descriptorUpdateTemplate, pData );
    }

    void vkUpdateDescriptorSets( VkDevice device, uint32_t descriptorWriteCount, const VkWriteDescriptorSet* pDescriptorWrites, uint32_t descriptorCopyCount, const VkCopyDescriptorSet* pDescriptorCopies ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkUpdateDescriptorSets( device, descriptorWriteCount, pDescriptorWrites, descriptorCopyCount, pDescriptorCopies );
    }

    VkResult vkWaitForFences( VkDevice device, uint32_t fenceCount, const VkFence* pFences, VkBool32 waitAll, uint64_t timeout ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkWaitForFences( device, fenceCount, pFences, waitAll, timeout );
    }

    VkResult vkWaitSemaphoresKHR( VkDevice device, const VkSemaphoreWaitInfoKHR* pWaitInfo, uint64_t timeout ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkWaitSemaphoresKHR( device, pWaitInfo, timeout );
    }

#ifdef VK_USE_PLATFORM_ANDROID_KHR
    VkResult vkCreateAndroidSurfaceKHR( VkInstance instance, const VkAndroidSurfaceCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateAndroidSurfaceKHR( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

    VkResult vkCreateDebugReportCallbackEXT( VkInstance instance, const VkDebugReportCallbackCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDebugReportCallbackEXT* pCallback ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDebugReportCallbackEXT( instance, pCreateInfo, pAllocator, pCallback );
    }

    VkResult vkCreateDebugUtilsMessengerEXT( VkInstance instance, const VkDebugUtilsMessengerCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDebugUtilsMessengerEXT* pMessenger ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDebugUtilsMessengerEXT( instance, pCreateInfo, pAllocator, pMessenger );
    }

    VkResult vkCreateDisplayPlaneSurfaceKHR( VkInstance instance, const VkDisplaySurfaceCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDisplayPlaneSurfaceKHR( instance, pCreateInfo, pAllocator, pSurface );
    }

    VkResult vkCreateHeadlessSurfaceEXT( VkInstance instance, const VkHeadlessSurfaceCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateHeadlessSurfaceEXT( instance, pCreateInfo, pAllocator, pSurface );
    }

#ifdef VK_USE_PLATFORM_IOS_MVK
    VkResult vkCreateIOSSurfaceMVK( VkInstance instance, const VkIOSSurfaceCreateInfoMVK* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateIOSSurfaceMVK( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_IOS_MVK*/

#ifdef VK_USE_PLATFORM_FUCHSIA
    VkResult vkCreateImagePipeSurfaceFUCHSIA( VkInstance instance, const VkImagePipeSurfaceCreateInfoFUCHSIA* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateImagePipeSurfaceFUCHSIA( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_FUCHSIA*/

#ifdef VK_USE_PLATFORM_MACOS_MVK
    VkResult vkCreateMacOSSurfaceMVK( VkInstance instance, const VkMacOSSurfaceCreateInfoMVK* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateMacOSSurfaceMVK( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_MACOS_MVK*/

#ifdef VK_USE_PLATFORM_METAL_EXT
    VkResult vkCreateMetalSurfaceEXT( VkInstance instance, const VkMetalSurfaceCreateInfoEXT* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateMetalSurfaceEXT( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_METAL_EXT*/

#ifdef VK_USE_PLATFORM_GGP
    VkResult vkCreateStreamDescriptorSurfaceGGP( VkInstance instance, const VkStreamDescriptorSurfaceCreateInfoGGP* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateStreamDescriptorSurfaceGGP( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_GGP*/

#ifdef VK_USE_PLATFORM_VI_NN
    VkResult vkCreateViSurfaceNN( VkInstance instance, const VkViSurfaceCreateInfoNN* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateViSurfaceNN( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_VI_NN*/

#ifdef VK_USE_PLATFORM_WAYLAND_KHR
    VkResult vkCreateWaylandSurfaceKHR( VkInstance instance, const VkWaylandSurfaceCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateWaylandSurfaceKHR( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkCreateWin32SurfaceKHR( VkInstance instance, const VkWin32SurfaceCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateWin32SurfaceKHR( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_XCB_KHR
    VkResult vkCreateXcbSurfaceKHR( VkInstance instance, const VkXcbSurfaceCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateXcbSurfaceKHR( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR
    VkResult vkCreateXlibSurfaceKHR( VkInstance instance, const VkXlibSurfaceCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkSurfaceKHR* pSurface ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateXlibSurfaceKHR( instance, pCreateInfo, pAllocator, pSurface );
    }
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

    void vkDebugReportMessageEXT( VkInstance instance, VkDebugReportFlagsEXT flags, VkDebugReportObjectTypeEXT objectType, uint64_t object, size_t location, int32_t messageCode, const char* pLayerPrefix, const char* pMessage ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDebugReportMessageEXT( instance, flags, objectType, object, location, messageCode, pLayerPrefix, pMessage );
    }

    void vkDestroyDebugReportCallbackEXT( VkInstance instance, VkDebugReportCallbackEXT callback, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyDebugReportCallbackEXT( instance, callback, pAllocator );
    }

    void vkDestroyDebugUtilsMessengerEXT( VkInstance instance, VkDebugUtilsMessengerEXT messenger, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyDebugUtilsMessengerEXT( instance, messenger, pAllocator );
    }

    void vkDestroyInstance( VkInstance instance, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroyInstance( instance, pAllocator );
    }

    void vkDestroySurfaceKHR( VkInstance instance, VkSurfaceKHR surface, const VkAllocationCallbacks* pAllocator ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkDestroySurfaceKHR( instance, surface, pAllocator );
    }

    VkResult vkEnumeratePhysicalDeviceGroups( VkInstance instance, uint32_t* pPhysicalDeviceGroupCount, VkPhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumeratePhysicalDeviceGroups( instance, pPhysicalDeviceGroupCount, pPhysicalDeviceGroupProperties );
    }

    VkResult vkEnumeratePhysicalDeviceGroupsKHR( VkInstance instance, uint32_t* pPhysicalDeviceGroupCount, VkPhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumeratePhysicalDeviceGroupsKHR( instance, pPhysicalDeviceGroupCount, pPhysicalDeviceGroupProperties );
    }

    VkResult vkEnumeratePhysicalDevices( VkInstance instance, uint32_t* pPhysicalDeviceCount, VkPhysicalDevice* pPhysicalDevices ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumeratePhysicalDevices( instance, pPhysicalDeviceCount, pPhysicalDevices );
    }

    PFN_vkVoidFunction vkGetInstanceProcAddr( VkInstance instance, const char* pName ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetInstanceProcAddr( instance, pName );
    }

    void vkSubmitDebugUtilsMessageEXT( VkInstance instance, VkDebugUtilsMessageSeverityFlagBitsEXT messageSeverity, VkDebugUtilsMessageTypeFlagsEXT messageTypes, const VkDebugUtilsMessengerCallbackDataEXT* pCallbackData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkSubmitDebugUtilsMessageEXT( instance, messageSeverity, messageTypes, pCallbackData );
    }

#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
    VkResult vkAcquireXlibDisplayEXT( VkPhysicalDevice physicalDevice, Display* dpy, VkDisplayKHR display ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkAcquireXlibDisplayEXT( physicalDevice, dpy, display );
    }
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/

    VkResult vkCreateDevice( VkPhysicalDevice physicalDevice, const VkDeviceCreateInfo* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDevice* pDevice ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDevice( physicalDevice, pCreateInfo, pAllocator, pDevice );
    }

    VkResult vkCreateDisplayModeKHR( VkPhysicalDevice physicalDevice, VkDisplayKHR display, const VkDisplayModeCreateInfoKHR* pCreateInfo, const VkAllocationCallbacks* pAllocator, VkDisplayModeKHR* pMode ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkCreateDisplayModeKHR( physicalDevice, display, pCreateInfo, pAllocator, pMode );
    }

    VkResult vkEnumerateDeviceExtensionProperties( VkPhysicalDevice physicalDevice, const char* pLayerName, uint32_t* pPropertyCount, VkExtensionProperties* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumerateDeviceExtensionProperties( physicalDevice, pLayerName, pPropertyCount, pProperties );
    }

    VkResult vkEnumerateDeviceLayerProperties( VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkLayerProperties* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkEnumerateDeviceLayerProperties( physicalDevice, pPropertyCount, pProperties );
    }

    VkResult vkGetDisplayModeProperties2KHR( VkPhysicalDevice physicalDevice, VkDisplayKHR display, uint32_t* pPropertyCount, VkDisplayModeProperties2KHR* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDisplayModeProperties2KHR( physicalDevice, display, pPropertyCount, pProperties );
    }

    VkResult vkGetDisplayModePropertiesKHR( VkPhysicalDevice physicalDevice, VkDisplayKHR display, uint32_t* pPropertyCount, VkDisplayModePropertiesKHR* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDisplayModePropertiesKHR( physicalDevice, display, pPropertyCount, pProperties );
    }

    VkResult vkGetDisplayPlaneCapabilities2KHR( VkPhysicalDevice physicalDevice, const VkDisplayPlaneInfo2KHR* pDisplayPlaneInfo, VkDisplayPlaneCapabilities2KHR* pCapabilities ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDisplayPlaneCapabilities2KHR( physicalDevice, pDisplayPlaneInfo, pCapabilities );
    }

    VkResult vkGetDisplayPlaneCapabilitiesKHR( VkPhysicalDevice physicalDevice, VkDisplayModeKHR mode, uint32_t planeIndex, VkDisplayPlaneCapabilitiesKHR* pCapabilities ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDisplayPlaneCapabilitiesKHR( physicalDevice, mode, planeIndex, pCapabilities );
    }

    VkResult vkGetDisplayPlaneSupportedDisplaysKHR( VkPhysicalDevice physicalDevice, uint32_t planeIndex, uint32_t* pDisplayCount, VkDisplayKHR* pDisplays ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetDisplayPlaneSupportedDisplaysKHR( physicalDevice, planeIndex, pDisplayCount, pDisplays );
    }

    VkResult vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( VkPhysicalDevice physicalDevice, uint32_t* pTimeDomainCount, VkTimeDomainEXT* pTimeDomains ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( physicalDevice, pTimeDomainCount, pTimeDomains );
    }

    VkResult vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkCooperativeMatrixPropertiesNV* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( physicalDevice, pPropertyCount, pProperties );
    }

    VkResult vkGetPhysicalDeviceDisplayPlaneProperties2KHR( VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayPlaneProperties2KHR* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceDisplayPlaneProperties2KHR( physicalDevice, pPropertyCount, pProperties );
    }

    VkResult vkGetPhysicalDeviceDisplayPlanePropertiesKHR( VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayPlanePropertiesKHR* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceDisplayPlanePropertiesKHR( physicalDevice, pPropertyCount, pProperties );
    }

    VkResult vkGetPhysicalDeviceDisplayProperties2KHR( VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayProperties2KHR* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceDisplayProperties2KHR( physicalDevice, pPropertyCount, pProperties );
    }

    VkResult vkGetPhysicalDeviceDisplayPropertiesKHR( VkPhysicalDevice physicalDevice, uint32_t* pPropertyCount, VkDisplayPropertiesKHR* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceDisplayPropertiesKHR( physicalDevice, pPropertyCount, pProperties );
    }

    void vkGetPhysicalDeviceExternalBufferProperties( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalBufferInfo* pExternalBufferInfo, VkExternalBufferProperties* pExternalBufferProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceExternalBufferProperties( physicalDevice, pExternalBufferInfo, pExternalBufferProperties );
    }

    void vkGetPhysicalDeviceExternalBufferPropertiesKHR( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalBufferInfo* pExternalBufferInfo, VkExternalBufferProperties* pExternalBufferProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceExternalBufferPropertiesKHR( physicalDevice, pExternalBufferInfo, pExternalBufferProperties );
    }

    void vkGetPhysicalDeviceExternalFenceProperties( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalFenceInfo* pExternalFenceInfo, VkExternalFenceProperties* pExternalFenceProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceExternalFenceProperties( physicalDevice, pExternalFenceInfo, pExternalFenceProperties );
    }

    void vkGetPhysicalDeviceExternalFencePropertiesKHR( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalFenceInfo* pExternalFenceInfo, VkExternalFenceProperties* pExternalFenceProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceExternalFencePropertiesKHR( physicalDevice, pExternalFenceInfo, pExternalFenceProperties );
    }

    VkResult vkGetPhysicalDeviceExternalImageFormatPropertiesNV( VkPhysicalDevice physicalDevice, VkFormat format, VkImageType type, VkImageTiling tiling, VkImageUsageFlags usage, VkImageCreateFlags flags, VkExternalMemoryHandleTypeFlagsNV externalHandleType, VkExternalImageFormatPropertiesNV* pExternalImageFormatProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceExternalImageFormatPropertiesNV( physicalDevice, format, type, tiling, usage, flags, externalHandleType, pExternalImageFormatProperties );
    }

    void vkGetPhysicalDeviceExternalSemaphoreProperties( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, VkExternalSemaphoreProperties* pExternalSemaphoreProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceExternalSemaphoreProperties( physicalDevice, pExternalSemaphoreInfo, pExternalSemaphoreProperties );
    }

    void vkGetPhysicalDeviceExternalSemaphorePropertiesKHR( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, VkExternalSemaphoreProperties* pExternalSemaphoreProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceExternalSemaphorePropertiesKHR( physicalDevice, pExternalSemaphoreInfo, pExternalSemaphoreProperties );
    }

    void vkGetPhysicalDeviceFeatures( VkPhysicalDevice physicalDevice, VkPhysicalDeviceFeatures* pFeatures ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceFeatures( physicalDevice, pFeatures );
    }

    void vkGetPhysicalDeviceFeatures2( VkPhysicalDevice physicalDevice, VkPhysicalDeviceFeatures2* pFeatures ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceFeatures2( physicalDevice, pFeatures );
    }

    void vkGetPhysicalDeviceFeatures2KHR( VkPhysicalDevice physicalDevice, VkPhysicalDeviceFeatures2* pFeatures ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceFeatures2KHR( physicalDevice, pFeatures );
    }

    void vkGetPhysicalDeviceFormatProperties( VkPhysicalDevice physicalDevice, VkFormat format, VkFormatProperties* pFormatProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceFormatProperties( physicalDevice, format, pFormatProperties );
    }

    void vkGetPhysicalDeviceFormatProperties2( VkPhysicalDevice physicalDevice, VkFormat format, VkFormatProperties2* pFormatProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceFormatProperties2( physicalDevice, format, pFormatProperties );
    }

    void vkGetPhysicalDeviceFormatProperties2KHR( VkPhysicalDevice physicalDevice, VkFormat format, VkFormatProperties2* pFormatProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceFormatProperties2KHR( physicalDevice, format, pFormatProperties );
    }

    void vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX( VkPhysicalDevice physicalDevice, VkDeviceGeneratedCommandsFeaturesNVX* pFeatures, VkDeviceGeneratedCommandsLimitsNVX* pLimits ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX( physicalDevice, pFeatures, pLimits );
    }

    VkResult vkGetPhysicalDeviceImageFormatProperties( VkPhysicalDevice physicalDevice, VkFormat format, VkImageType type, VkImageTiling tiling, VkImageUsageFlags usage, VkImageCreateFlags flags, VkImageFormatProperties* pImageFormatProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceImageFormatProperties( physicalDevice, format, type, tiling, usage, flags, pImageFormatProperties );
    }

    VkResult vkGetPhysicalDeviceImageFormatProperties2( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceImageFormatInfo2* pImageFormatInfo, VkImageFormatProperties2* pImageFormatProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceImageFormatProperties2( physicalDevice, pImageFormatInfo, pImageFormatProperties );
    }

    VkResult vkGetPhysicalDeviceImageFormatProperties2KHR( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceImageFormatInfo2* pImageFormatInfo, VkImageFormatProperties2* pImageFormatProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceImageFormatProperties2KHR( physicalDevice, pImageFormatInfo, pImageFormatProperties );
    }

    void vkGetPhysicalDeviceMemoryProperties( VkPhysicalDevice physicalDevice, VkPhysicalDeviceMemoryProperties* pMemoryProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceMemoryProperties( physicalDevice, pMemoryProperties );
    }

    void vkGetPhysicalDeviceMemoryProperties2( VkPhysicalDevice physicalDevice, VkPhysicalDeviceMemoryProperties2* pMemoryProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceMemoryProperties2( physicalDevice, pMemoryProperties );
    }

    void vkGetPhysicalDeviceMemoryProperties2KHR( VkPhysicalDevice physicalDevice, VkPhysicalDeviceMemoryProperties2* pMemoryProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceMemoryProperties2KHR( physicalDevice, pMemoryProperties );
    }

    void vkGetPhysicalDeviceMultisamplePropertiesEXT( VkPhysicalDevice physicalDevice, VkSampleCountFlagBits samples, VkMultisamplePropertiesEXT* pMultisampleProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceMultisamplePropertiesEXT( physicalDevice, samples, pMultisampleProperties );
    }

    VkResult vkGetPhysicalDevicePresentRectanglesKHR( VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, uint32_t* pRectCount, VkRect2D* pRects ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDevicePresentRectanglesKHR( physicalDevice, surface, pRectCount, pRects );
    }

    void vkGetPhysicalDeviceProperties( VkPhysicalDevice physicalDevice, VkPhysicalDeviceProperties* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceProperties( physicalDevice, pProperties );
    }

    void vkGetPhysicalDeviceProperties2( VkPhysicalDevice physicalDevice, VkPhysicalDeviceProperties2* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceProperties2( physicalDevice, pProperties );
    }

    void vkGetPhysicalDeviceProperties2KHR( VkPhysicalDevice physicalDevice, VkPhysicalDeviceProperties2* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceProperties2KHR( physicalDevice, pProperties );
    }

    void vkGetPhysicalDeviceQueueFamilyProperties( VkPhysicalDevice physicalDevice, uint32_t* pQueueFamilyPropertyCount, VkQueueFamilyProperties* pQueueFamilyProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceQueueFamilyProperties( physicalDevice, pQueueFamilyPropertyCount, pQueueFamilyProperties );
    }

    void vkGetPhysicalDeviceQueueFamilyProperties2( VkPhysicalDevice physicalDevice, uint32_t* pQueueFamilyPropertyCount, VkQueueFamilyProperties2* pQueueFamilyProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceQueueFamilyProperties2( physicalDevice, pQueueFamilyPropertyCount, pQueueFamilyProperties );
    }

    void vkGetPhysicalDeviceQueueFamilyProperties2KHR( VkPhysicalDevice physicalDevice, uint32_t* pQueueFamilyPropertyCount, VkQueueFamilyProperties2* pQueueFamilyProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceQueueFamilyProperties2KHR( physicalDevice, pQueueFamilyPropertyCount, pQueueFamilyProperties );
    }

    void vkGetPhysicalDeviceSparseImageFormatProperties( VkPhysicalDevice physicalDevice, VkFormat format, VkImageType type, VkSampleCountFlagBits samples, VkImageUsageFlags usage, VkImageTiling tiling, uint32_t* pPropertyCount, VkSparseImageFormatProperties* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSparseImageFormatProperties( physicalDevice, format, type, samples, usage, tiling, pPropertyCount, pProperties );
    }

    void vkGetPhysicalDeviceSparseImageFormatProperties2( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, VkSparseImageFormatProperties2* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSparseImageFormatProperties2( physicalDevice, pFormatInfo, pPropertyCount, pProperties );
    }

    void vkGetPhysicalDeviceSparseImageFormatProperties2KHR( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, VkSparseImageFormatProperties2* pProperties ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSparseImageFormatProperties2KHR( physicalDevice, pFormatInfo, pPropertyCount, pProperties );
    }

    VkResult vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( VkPhysicalDevice physicalDevice, uint32_t* pCombinationCount, VkFramebufferMixedSamplesCombinationNV* pCombinations ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( physicalDevice, pCombinationCount, pCombinations );
    }

    VkResult vkGetPhysicalDeviceSurfaceCapabilities2EXT( VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, VkSurfaceCapabilities2EXT* pSurfaceCapabilities ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfaceCapabilities2EXT( physicalDevice, surface, pSurfaceCapabilities );
    }

    VkResult vkGetPhysicalDeviceSurfaceCapabilities2KHR( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, VkSurfaceCapabilities2KHR* pSurfaceCapabilities ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfaceCapabilities2KHR( physicalDevice, pSurfaceInfo, pSurfaceCapabilities );
    }

    VkResult vkGetPhysicalDeviceSurfaceCapabilitiesKHR( VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, VkSurfaceCapabilitiesKHR* pSurfaceCapabilities ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfaceCapabilitiesKHR( physicalDevice, surface, pSurfaceCapabilities );
    }

    VkResult vkGetPhysicalDeviceSurfaceFormats2KHR( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, uint32_t* pSurfaceFormatCount, VkSurfaceFormat2KHR* pSurfaceFormats ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfaceFormats2KHR( physicalDevice, pSurfaceInfo, pSurfaceFormatCount, pSurfaceFormats );
    }

    VkResult vkGetPhysicalDeviceSurfaceFormatsKHR( VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, uint32_t* pSurfaceFormatCount, VkSurfaceFormatKHR* pSurfaceFormats ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfaceFormatsKHR( physicalDevice, surface, pSurfaceFormatCount, pSurfaceFormats );
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkResult vkGetPhysicalDeviceSurfacePresentModes2EXT( VkPhysicalDevice physicalDevice, const VkPhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, uint32_t* pPresentModeCount, VkPresentModeKHR* pPresentModes ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfacePresentModes2EXT( physicalDevice, pSurfaceInfo, pPresentModeCount, pPresentModes );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    VkResult vkGetPhysicalDeviceSurfacePresentModesKHR( VkPhysicalDevice physicalDevice, VkSurfaceKHR surface, uint32_t* pPresentModeCount, VkPresentModeKHR* pPresentModes ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfacePresentModesKHR( physicalDevice, surface, pPresentModeCount, pPresentModes );
    }

    VkResult vkGetPhysicalDeviceSurfaceSupportKHR( VkPhysicalDevice physicalDevice, uint32_t queueFamilyIndex, VkSurfaceKHR surface, VkBool32* pSupported ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceSurfaceSupportKHR( physicalDevice, queueFamilyIndex, surface, pSupported );
    }

#ifdef VK_USE_PLATFORM_WAYLAND_KHR
    VkBool32 vkGetPhysicalDeviceWaylandPresentationSupportKHR( VkPhysicalDevice physicalDevice, uint32_t queueFamilyIndex, struct wl_display* display ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceWaylandPresentationSupportKHR( physicalDevice, queueFamilyIndex, display );
    }
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    VkBool32 vkGetPhysicalDeviceWin32PresentationSupportKHR( VkPhysicalDevice physicalDevice, uint32_t queueFamilyIndex ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceWin32PresentationSupportKHR( physicalDevice, queueFamilyIndex );
    }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_XCB_KHR
    VkBool32 vkGetPhysicalDeviceXcbPresentationSupportKHR( VkPhysicalDevice physicalDevice, uint32_t queueFamilyIndex, xcb_connection_t* connection, xcb_visualid_t visual_id ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceXcbPresentationSupportKHR( physicalDevice, queueFamilyIndex, connection, visual_id );
    }
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR
    VkBool32 vkGetPhysicalDeviceXlibPresentationSupportKHR( VkPhysicalDevice physicalDevice, uint32_t queueFamilyIndex, Display* dpy, VisualID visualID ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetPhysicalDeviceXlibPresentationSupportKHR( physicalDevice, queueFamilyIndex, dpy, visualID );
    }
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
    VkResult vkGetRandROutputDisplayEXT( VkPhysicalDevice physicalDevice, Display* dpy, RROutput rrOutput, VkDisplayKHR* pDisplay ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetRandROutputDisplayEXT( physicalDevice, dpy, rrOutput, pDisplay );
    }
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/

    VkResult vkReleaseDisplayEXT( VkPhysicalDevice physicalDevice, VkDisplayKHR display ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkReleaseDisplayEXT( physicalDevice, display );
    }

    void vkGetQueueCheckpointDataNV( VkQueue queue, uint32_t* pCheckpointDataCount, VkCheckpointDataNV* pCheckpointData ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkGetQueueCheckpointDataNV( queue, pCheckpointDataCount, pCheckpointData );
    }

    void vkQueueBeginDebugUtilsLabelEXT( VkQueue queue, const VkDebugUtilsLabelEXT* pLabelInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueueBeginDebugUtilsLabelEXT( queue, pLabelInfo );
    }

    VkResult vkQueueBindSparse( VkQueue queue, uint32_t bindInfoCount, const VkBindSparseInfo* pBindInfo, VkFence fence ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueueBindSparse( queue, bindInfoCount, pBindInfo, fence );
    }

    void vkQueueEndDebugUtilsLabelEXT( VkQueue queue ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueueEndDebugUtilsLabelEXT( queue );
    }

    void vkQueueInsertDebugUtilsLabelEXT( VkQueue queue, const VkDebugUtilsLabelEXT* pLabelInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueueInsertDebugUtilsLabelEXT( queue, pLabelInfo );
    }

    VkResult vkQueuePresentKHR( VkQueue queue, const VkPresentInfoKHR* pPresentInfo ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueuePresentKHR( queue, pPresentInfo );
    }

    VkResult vkQueueSetPerformanceConfigurationINTEL( VkQueue queue, VkPerformanceConfigurationINTEL configuration ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueueSetPerformanceConfigurationINTEL( queue, configuration );
    }

    VkResult vkQueueSubmit( VkQueue queue, uint32_t submitCount, const VkSubmitInfo* pSubmits, VkFence fence ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueueSubmit( queue, submitCount, pSubmits, fence );
    }

    VkResult vkQueueWaitIdle( VkQueue queue ) const VULKAN_HPP_NOEXCEPT
    {
      return ::vkQueueWaitIdle( queue );
    }
  };
#endif

  class DispatchLoaderDynamic;
#if !defined(VULKAN_HPP_DISPATCH_LOADER_DYNAMIC)
# if defined(VK_NO_PROTOTYPES)
#  define VULKAN_HPP_DISPATCH_LOADER_DYNAMIC 1
# else
#  define VULKAN_HPP_DISPATCH_LOADER_DYNAMIC 0
# endif
#endif

#if !defined(VULKAN_HPP_DEFAULT_DISPATCHER)
# if VULKAN_HPP_DISPATCH_LOADER_DYNAMIC == 1
#  define VULKAN_HPP_DEFAULT_DISPATCHER ::vk::defaultDispatchLoaderDynamic
#  define VULKAN_HPP_DEFAULT_DISPATCH_LOADER_DYNAMIC_STORAGE namespace vk { DispatchLoaderDynamic defaultDispatchLoaderDynamic; }
  extern DispatchLoaderDynamic defaultDispatchLoaderDynamic;
# else
#  define VULKAN_HPP_DEFAULT_DISPATCHER ::vk::DispatchLoaderStatic()
#  define VULKAN_HPP_DEFAULT_DISPATCH_LOADER_DYNAMIC_STORAGE
# endif
#endif

#if !defined(VULKAN_HPP_DEFAULT_DISPATCHER_TYPE)
# if VULKAN_HPP_DISPATCH_LOADER_DYNAMIC == 1
  #define VULKAN_HPP_DEFAULT_DISPATCHER_TYPE ::vk::DispatchLoaderDynamic
# else
#  define VULKAN_HPP_DEFAULT_DISPATCHER_TYPE ::vk::DispatchLoaderStatic
# endif
#endif

  struct AllocationCallbacks;

  template <typename OwnerType, typename Dispatch>
  class ObjectDestroy
  {
    public:
      ObjectDestroy( OwnerType owner = OwnerType(), Optional<const AllocationCallbacks> allocationCallbacks = nullptr, Dispatch const &dispatch = VULKAN_HPP_DEFAULT_DISPATCHER ) VULKAN_HPP_NOEXCEPT
        : m_owner( owner )
        , m_allocationCallbacks( allocationCallbacks )
        , m_dispatch( &dispatch )
      {}

      OwnerType getOwner() const VULKAN_HPP_NOEXCEPT { return m_owner; }
      Optional<const AllocationCallbacks> getAllocator() const VULKAN_HPP_NOEXCEPT { return m_allocationCallbacks; }

    protected:
      template <typename T>
      void destroy(T t) VULKAN_HPP_NOEXCEPT
      {
        m_owner.destroy( t, m_allocationCallbacks, *m_dispatch );
      }

    private:
      OwnerType m_owner;
      Optional<const AllocationCallbacks> m_allocationCallbacks;
      Dispatch const* m_dispatch;
  };

  class NoParent;

  template <typename Dispatch>
  class ObjectDestroy<NoParent,Dispatch>
  {
    public:
      ObjectDestroy( Optional<const AllocationCallbacks> allocationCallbacks = nullptr, Dispatch const &dispatch = VULKAN_HPP_DEFAULT_DISPATCHER ) VULKAN_HPP_NOEXCEPT
        : m_allocationCallbacks( allocationCallbacks )
        , m_dispatch( &dispatch )
      {}

      Optional<const AllocationCallbacks> getAllocator() const VULKAN_HPP_NOEXCEPT { return m_allocationCallbacks; }

    protected:
      template <typename T>
      void destroy(T t) VULKAN_HPP_NOEXCEPT
      {
        t.destroy( m_allocationCallbacks, *m_dispatch );
      }

    private:
      Optional<const AllocationCallbacks> m_allocationCallbacks;
      Dispatch const* m_dispatch;
  };

  template <typename OwnerType, typename Dispatch>
  class ObjectFree
  {
    public:
      ObjectFree( OwnerType owner = OwnerType(), Optional<const AllocationCallbacks> allocationCallbacks = nullptr, Dispatch const &dispatch = VULKAN_HPP_DEFAULT_DISPATCHER ) VULKAN_HPP_NOEXCEPT
        : m_owner( owner )
        , m_allocationCallbacks( allocationCallbacks )
        , m_dispatch( &dispatch )
      {}

      OwnerType getOwner() const VULKAN_HPP_NOEXCEPT { return m_owner; }
      Optional<const AllocationCallbacks> getAllocator() const VULKAN_HPP_NOEXCEPT { return m_allocationCallbacks; }

    protected:
      template <typename T>
      void destroy(T t) VULKAN_HPP_NOEXCEPT
      {
        m_owner.free( t, m_allocationCallbacks, *m_dispatch );
      }

    private:
      OwnerType m_owner;
      Optional<const AllocationCallbacks> m_allocationCallbacks;
      Dispatch const* m_dispatch;
  };

  template <typename OwnerType, typename PoolType, typename Dispatch>
  class PoolFree
  {
    public:
      PoolFree( OwnerType owner = OwnerType(), PoolType pool = PoolType(), Dispatch const &dispatch = VULKAN_HPP_DEFAULT_DISPATCHER ) VULKAN_HPP_NOEXCEPT
        : m_owner( owner )
        , m_pool( pool )
        , m_dispatch( &dispatch )
      {}

      OwnerType getOwner() const VULKAN_HPP_NOEXCEPT { return m_owner; }
      PoolType getPool() const VULKAN_HPP_NOEXCEPT { return m_pool; }

    protected:
      template <typename T>
      void destroy(T t) VULKAN_HPP_NOEXCEPT
      {
        m_owner.free( m_pool, t, *m_dispatch );
      }

    private:
      OwnerType m_owner;
      PoolType m_pool;
      Dispatch const* m_dispatch;
  };

  template <typename T, size_t N, size_t I>
  class ConstExpressionArrayCopy
  {
    public:
      VULKAN_HPP_CONSTEXPR_14 static void copy(T dst[N], std::array<T,N> const& src) VULKAN_HPP_NOEXCEPT
      {
        dst[I-1] = src[I-1];
        ConstExpressionArrayCopy<T, N, I - 1>::copy(dst, src);
      }
  };

  template <typename T, size_t N>
  class ConstExpressionArrayCopy<T, N, 0>
  {
    public:
      VULKAN_HPP_CONSTEXPR_14 static void copy(T /*dst*/[N], std::array<T,N> const& /*src*/) VULKAN_HPP_NOEXCEPT {}
  };

  using Bool32 = uint32_t;
  using DeviceAddress = uint64_t;
  using DeviceSize = uint64_t;
  using SampleMask = uint32_t;

  enum class AccelerationStructureMemoryRequirementsTypeNV
  {
    eObject = VK_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_TYPE_OBJECT_NV,
    eBuildScratch = VK_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_TYPE_BUILD_SCRATCH_NV,
    eUpdateScratch = VK_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_TYPE_UPDATE_SCRATCH_NV
  };

  VULKAN_HPP_INLINE std::string to_string( AccelerationStructureMemoryRequirementsTypeNV value )
  {
    switch ( value )
    {
      case AccelerationStructureMemoryRequirementsTypeNV::eObject : return "Object";
      case AccelerationStructureMemoryRequirementsTypeNV::eBuildScratch : return "BuildScratch";
      case AccelerationStructureMemoryRequirementsTypeNV::eUpdateScratch : return "UpdateScratch";
      default: return "invalid";
    }
  }

  enum class AccelerationStructureTypeNV
  {
    eTopLevel = VK_ACCELERATION_STRUCTURE_TYPE_TOP_LEVEL_NV,
    eBottomLevel = VK_ACCELERATION_STRUCTURE_TYPE_BOTTOM_LEVEL_NV
  };

  VULKAN_HPP_INLINE std::string to_string( AccelerationStructureTypeNV value )
  {
    switch ( value )
    {
      case AccelerationStructureTypeNV::eTopLevel : return "TopLevel";
      case AccelerationStructureTypeNV::eBottomLevel : return "BottomLevel";
      default: return "invalid";
    }
  }

  enum class AttachmentLoadOp
  {
    eLoad = VK_ATTACHMENT_LOAD_OP_LOAD,
    eClear = VK_ATTACHMENT_LOAD_OP_CLEAR,
    eDontCare = VK_ATTACHMENT_LOAD_OP_DONT_CARE
  };

  VULKAN_HPP_INLINE std::string to_string( AttachmentLoadOp value )
  {
    switch ( value )
    {
      case AttachmentLoadOp::eLoad : return "Load";
      case AttachmentLoadOp::eClear : return "Clear";
      case AttachmentLoadOp::eDontCare : return "DontCare";
      default: return "invalid";
    }
  }

  enum class AttachmentStoreOp
  {
    eStore = VK_ATTACHMENT_STORE_OP_STORE,
    eDontCare = VK_ATTACHMENT_STORE_OP_DONT_CARE
  };

  VULKAN_HPP_INLINE std::string to_string( AttachmentStoreOp value )
  {
    switch ( value )
    {
      case AttachmentStoreOp::eStore : return "Store";
      case AttachmentStoreOp::eDontCare : return "DontCare";
      default: return "invalid";
    }
  }

  enum class BlendFactor
  {
    eZero = VK_BLEND_FACTOR_ZERO,
    eOne = VK_BLEND_FACTOR_ONE,
    eSrcColor = VK_BLEND_FACTOR_SRC_COLOR,
    eOneMinusSrcColor = VK_BLEND_FACTOR_ONE_MINUS_SRC_COLOR,
    eDstColor = VK_BLEND_FACTOR_DST_COLOR,
    eOneMinusDstColor = VK_BLEND_FACTOR_ONE_MINUS_DST_COLOR,
    eSrcAlpha = VK_BLEND_FACTOR_SRC_ALPHA,
    eOneMinusSrcAlpha = VK_BLEND_FACTOR_ONE_MINUS_SRC_ALPHA,
    eDstAlpha = VK_BLEND_FACTOR_DST_ALPHA,
    eOneMinusDstAlpha = VK_BLEND_FACTOR_ONE_MINUS_DST_ALPHA,
    eConstantColor = VK_BLEND_FACTOR_CONSTANT_COLOR,
    eOneMinusConstantColor = VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_COLOR,
    eConstantAlpha = VK_BLEND_FACTOR_CONSTANT_ALPHA,
    eOneMinusConstantAlpha = VK_BLEND_FACTOR_ONE_MINUS_CONSTANT_ALPHA,
    eSrcAlphaSaturate = VK_BLEND_FACTOR_SRC_ALPHA_SATURATE,
    eSrc1Color = VK_BLEND_FACTOR_SRC1_COLOR,
    eOneMinusSrc1Color = VK_BLEND_FACTOR_ONE_MINUS_SRC1_COLOR,
    eSrc1Alpha = VK_BLEND_FACTOR_SRC1_ALPHA,
    eOneMinusSrc1Alpha = VK_BLEND_FACTOR_ONE_MINUS_SRC1_ALPHA
  };

  VULKAN_HPP_INLINE std::string to_string( BlendFactor value )
  {
    switch ( value )
    {
      case BlendFactor::eZero : return "Zero";
      case BlendFactor::eOne : return "One";
      case BlendFactor::eSrcColor : return "SrcColor";
      case BlendFactor::eOneMinusSrcColor : return "OneMinusSrcColor";
      case BlendFactor::eDstColor : return "DstColor";
      case BlendFactor::eOneMinusDstColor : return "OneMinusDstColor";
      case BlendFactor::eSrcAlpha : return "SrcAlpha";
      case BlendFactor::eOneMinusSrcAlpha : return "OneMinusSrcAlpha";
      case BlendFactor::eDstAlpha : return "DstAlpha";
      case BlendFactor::eOneMinusDstAlpha : return "OneMinusDstAlpha";
      case BlendFactor::eConstantColor : return "ConstantColor";
      case BlendFactor::eOneMinusConstantColor : return "OneMinusConstantColor";
      case BlendFactor::eConstantAlpha : return "ConstantAlpha";
      case BlendFactor::eOneMinusConstantAlpha : return "OneMinusConstantAlpha";
      case BlendFactor::eSrcAlphaSaturate : return "SrcAlphaSaturate";
      case BlendFactor::eSrc1Color : return "Src1Color";
      case BlendFactor::eOneMinusSrc1Color : return "OneMinusSrc1Color";
      case BlendFactor::eSrc1Alpha : return "Src1Alpha";
      case BlendFactor::eOneMinusSrc1Alpha : return "OneMinusSrc1Alpha";
      default: return "invalid";
    }
  }

  enum class BlendOp
  {
    eAdd = VK_BLEND_OP_ADD,
    eSubtract = VK_BLEND_OP_SUBTRACT,
    eReverseSubtract = VK_BLEND_OP_REVERSE_SUBTRACT,
    eMin = VK_BLEND_OP_MIN,
    eMax = VK_BLEND_OP_MAX,
    eZeroEXT = VK_BLEND_OP_ZERO_EXT,
    eSrcEXT = VK_BLEND_OP_SRC_EXT,
    eDstEXT = VK_BLEND_OP_DST_EXT,
    eSrcOverEXT = VK_BLEND_OP_SRC_OVER_EXT,
    eDstOverEXT = VK_BLEND_OP_DST_OVER_EXT,
    eSrcInEXT = VK_BLEND_OP_SRC_IN_EXT,
    eDstInEXT = VK_BLEND_OP_DST_IN_EXT,
    eSrcOutEXT = VK_BLEND_OP_SRC_OUT_EXT,
    eDstOutEXT = VK_BLEND_OP_DST_OUT_EXT,
    eSrcAtopEXT = VK_BLEND_OP_SRC_ATOP_EXT,
    eDstAtopEXT = VK_BLEND_OP_DST_ATOP_EXT,
    eXorEXT = VK_BLEND_OP_XOR_EXT,
    eMultiplyEXT = VK_BLEND_OP_MULTIPLY_EXT,
    eScreenEXT = VK_BLEND_OP_SCREEN_EXT,
    eOverlayEXT = VK_BLEND_OP_OVERLAY_EXT,
    eDarkenEXT = VK_BLEND_OP_DARKEN_EXT,
    eLightenEXT = VK_BLEND_OP_LIGHTEN_EXT,
    eColordodgeEXT = VK_BLEND_OP_COLORDODGE_EXT,
    eColorburnEXT = VK_BLEND_OP_COLORBURN_EXT,
    eHardlightEXT = VK_BLEND_OP_HARDLIGHT_EXT,
    eSoftlightEXT = VK_BLEND_OP_SOFTLIGHT_EXT,
    eDifferenceEXT = VK_BLEND_OP_DIFFERENCE_EXT,
    eExclusionEXT = VK_BLEND_OP_EXCLUSION_EXT,
    eInvertEXT = VK_BLEND_OP_INVERT_EXT,
    eInvertRgbEXT = VK_BLEND_OP_INVERT_RGB_EXT,
    eLineardodgeEXT = VK_BLEND_OP_LINEARDODGE_EXT,
    eLinearburnEXT = VK_BLEND_OP_LINEARBURN_EXT,
    eVividlightEXT = VK_BLEND_OP_VIVIDLIGHT_EXT,
    eLinearlightEXT = VK_BLEND_OP_LINEARLIGHT_EXT,
    ePinlightEXT = VK_BLEND_OP_PINLIGHT_EXT,
    eHardmixEXT = VK_BLEND_OP_HARDMIX_EXT,
    eHslHueEXT = VK_BLEND_OP_HSL_HUE_EXT,
    eHslSaturationEXT = VK_BLEND_OP_HSL_SATURATION_EXT,
    eHslColorEXT = VK_BLEND_OP_HSL_COLOR_EXT,
    eHslLuminosityEXT = VK_BLEND_OP_HSL_LUMINOSITY_EXT,
    ePlusEXT = VK_BLEND_OP_PLUS_EXT,
    ePlusClampedEXT = VK_BLEND_OP_PLUS_CLAMPED_EXT,
    ePlusClampedAlphaEXT = VK_BLEND_OP_PLUS_CLAMPED_ALPHA_EXT,
    ePlusDarkerEXT = VK_BLEND_OP_PLUS_DARKER_EXT,
    eMinusEXT = VK_BLEND_OP_MINUS_EXT,
    eMinusClampedEXT = VK_BLEND_OP_MINUS_CLAMPED_EXT,
    eContrastEXT = VK_BLEND_OP_CONTRAST_EXT,
    eInvertOvgEXT = VK_BLEND_OP_INVERT_OVG_EXT,
    eRedEXT = VK_BLEND_OP_RED_EXT,
    eGreenEXT = VK_BLEND_OP_GREEN_EXT,
    eBlueEXT = VK_BLEND_OP_BLUE_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( BlendOp value )
  {
    switch ( value )
    {
      case BlendOp::eAdd : return "Add";
      case BlendOp::eSubtract : return "Subtract";
      case BlendOp::eReverseSubtract : return "ReverseSubtract";
      case BlendOp::eMin : return "Min";
      case BlendOp::eMax : return "Max";
      case BlendOp::eZeroEXT : return "ZeroEXT";
      case BlendOp::eSrcEXT : return "SrcEXT";
      case BlendOp::eDstEXT : return "DstEXT";
      case BlendOp::eSrcOverEXT : return "SrcOverEXT";
      case BlendOp::eDstOverEXT : return "DstOverEXT";
      case BlendOp::eSrcInEXT : return "SrcInEXT";
      case BlendOp::eDstInEXT : return "DstInEXT";
      case BlendOp::eSrcOutEXT : return "SrcOutEXT";
      case BlendOp::eDstOutEXT : return "DstOutEXT";
      case BlendOp::eSrcAtopEXT : return "SrcAtopEXT";
      case BlendOp::eDstAtopEXT : return "DstAtopEXT";
      case BlendOp::eXorEXT : return "XorEXT";
      case BlendOp::eMultiplyEXT : return "MultiplyEXT";
      case BlendOp::eScreenEXT : return "ScreenEXT";
      case BlendOp::eOverlayEXT : return "OverlayEXT";
      case BlendOp::eDarkenEXT : return "DarkenEXT";
      case BlendOp::eLightenEXT : return "LightenEXT";
      case BlendOp::eColordodgeEXT : return "ColordodgeEXT";
      case BlendOp::eColorburnEXT : return "ColorburnEXT";
      case BlendOp::eHardlightEXT : return "HardlightEXT";
      case BlendOp::eSoftlightEXT : return "SoftlightEXT";
      case BlendOp::eDifferenceEXT : return "DifferenceEXT";
      case BlendOp::eExclusionEXT : return "ExclusionEXT";
      case BlendOp::eInvertEXT : return "InvertEXT";
      case BlendOp::eInvertRgbEXT : return "InvertRgbEXT";
      case BlendOp::eLineardodgeEXT : return "LineardodgeEXT";
      case BlendOp::eLinearburnEXT : return "LinearburnEXT";
      case BlendOp::eVividlightEXT : return "VividlightEXT";
      case BlendOp::eLinearlightEXT : return "LinearlightEXT";
      case BlendOp::ePinlightEXT : return "PinlightEXT";
      case BlendOp::eHardmixEXT : return "HardmixEXT";
      case BlendOp::eHslHueEXT : return "HslHueEXT";
      case BlendOp::eHslSaturationEXT : return "HslSaturationEXT";
      case BlendOp::eHslColorEXT : return "HslColorEXT";
      case BlendOp::eHslLuminosityEXT : return "HslLuminosityEXT";
      case BlendOp::ePlusEXT : return "PlusEXT";
      case BlendOp::ePlusClampedEXT : return "PlusClampedEXT";
      case BlendOp::ePlusClampedAlphaEXT : return "PlusClampedAlphaEXT";
      case BlendOp::ePlusDarkerEXT : return "PlusDarkerEXT";
      case BlendOp::eMinusEXT : return "MinusEXT";
      case BlendOp::eMinusClampedEXT : return "MinusClampedEXT";
      case BlendOp::eContrastEXT : return "ContrastEXT";
      case BlendOp::eInvertOvgEXT : return "InvertOvgEXT";
      case BlendOp::eRedEXT : return "RedEXT";
      case BlendOp::eGreenEXT : return "GreenEXT";
      case BlendOp::eBlueEXT : return "BlueEXT";
      default: return "invalid";
    }
  }

  enum class BlendOverlapEXT
  {
    eUncorrelated = VK_BLEND_OVERLAP_UNCORRELATED_EXT,
    eDisjoint = VK_BLEND_OVERLAP_DISJOINT_EXT,
    eConjoint = VK_BLEND_OVERLAP_CONJOINT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( BlendOverlapEXT value )
  {
    switch ( value )
    {
      case BlendOverlapEXT::eUncorrelated : return "Uncorrelated";
      case BlendOverlapEXT::eDisjoint : return "Disjoint";
      case BlendOverlapEXT::eConjoint : return "Conjoint";
      default: return "invalid";
    }
  }

  enum class BorderColor
  {
    eFloatTransparentBlack = VK_BORDER_COLOR_FLOAT_TRANSPARENT_BLACK,
    eIntTransparentBlack = VK_BORDER_COLOR_INT_TRANSPARENT_BLACK,
    eFloatOpaqueBlack = VK_BORDER_COLOR_FLOAT_OPAQUE_BLACK,
    eIntOpaqueBlack = VK_BORDER_COLOR_INT_OPAQUE_BLACK,
    eFloatOpaqueWhite = VK_BORDER_COLOR_FLOAT_OPAQUE_WHITE,
    eIntOpaqueWhite = VK_BORDER_COLOR_INT_OPAQUE_WHITE
  };

  VULKAN_HPP_INLINE std::string to_string( BorderColor value )
  {
    switch ( value )
    {
      case BorderColor::eFloatTransparentBlack : return "FloatTransparentBlack";
      case BorderColor::eIntTransparentBlack : return "IntTransparentBlack";
      case BorderColor::eFloatOpaqueBlack : return "FloatOpaqueBlack";
      case BorderColor::eIntOpaqueBlack : return "IntOpaqueBlack";
      case BorderColor::eFloatOpaqueWhite : return "FloatOpaqueWhite";
      case BorderColor::eIntOpaqueWhite : return "IntOpaqueWhite";
      default: return "invalid";
    }
  }

  enum class ChromaLocation
  {
    eCositedEven = VK_CHROMA_LOCATION_COSITED_EVEN,
    eMidpoint = VK_CHROMA_LOCATION_MIDPOINT,
    eCositedEvenKHR = VK_CHROMA_LOCATION_COSITED_EVEN_KHR,
    eMidpointKHR = VK_CHROMA_LOCATION_MIDPOINT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ChromaLocation value )
  {
    switch ( value )
    {
      case ChromaLocation::eCositedEven : return "CositedEven";
      case ChromaLocation::eMidpoint : return "Midpoint";
      default: return "invalid";
    }
  }

  enum class CoarseSampleOrderTypeNV
  {
    eDefault = VK_COARSE_SAMPLE_ORDER_TYPE_DEFAULT_NV,
    eCustom = VK_COARSE_SAMPLE_ORDER_TYPE_CUSTOM_NV,
    ePixelMajor = VK_COARSE_SAMPLE_ORDER_TYPE_PIXEL_MAJOR_NV,
    eSampleMajor = VK_COARSE_SAMPLE_ORDER_TYPE_SAMPLE_MAJOR_NV
  };

  VULKAN_HPP_INLINE std::string to_string( CoarseSampleOrderTypeNV value )
  {
    switch ( value )
    {
      case CoarseSampleOrderTypeNV::eDefault : return "Default";
      case CoarseSampleOrderTypeNV::eCustom : return "Custom";
      case CoarseSampleOrderTypeNV::ePixelMajor : return "PixelMajor";
      case CoarseSampleOrderTypeNV::eSampleMajor : return "SampleMajor";
      default: return "invalid";
    }
  }

  enum class ColorSpaceKHR
  {
    eSrgbNonlinear = VK_COLOR_SPACE_SRGB_NONLINEAR_KHR,
    eDisplayP3NonlinearEXT = VK_COLOR_SPACE_DISPLAY_P3_NONLINEAR_EXT,
    eExtendedSrgbLinearEXT = VK_COLOR_SPACE_EXTENDED_SRGB_LINEAR_EXT,
    eDisplayP3LinearEXT = VK_COLOR_SPACE_DISPLAY_P3_LINEAR_EXT,
    eDciP3NonlinearEXT = VK_COLOR_SPACE_DCI_P3_NONLINEAR_EXT,
    eBt709LinearEXT = VK_COLOR_SPACE_BT709_LINEAR_EXT,
    eBt709NonlinearEXT = VK_COLOR_SPACE_BT709_NONLINEAR_EXT,
    eBt2020LinearEXT = VK_COLOR_SPACE_BT2020_LINEAR_EXT,
    eHdr10St2084EXT = VK_COLOR_SPACE_HDR10_ST2084_EXT,
    eDolbyvisionEXT = VK_COLOR_SPACE_DOLBYVISION_EXT,
    eHdr10HlgEXT = VK_COLOR_SPACE_HDR10_HLG_EXT,
    eAdobergbLinearEXT = VK_COLOR_SPACE_ADOBERGB_LINEAR_EXT,
    eAdobergbNonlinearEXT = VK_COLOR_SPACE_ADOBERGB_NONLINEAR_EXT,
    ePassThroughEXT = VK_COLOR_SPACE_PASS_THROUGH_EXT,
    eExtendedSrgbNonlinearEXT = VK_COLOR_SPACE_EXTENDED_SRGB_NONLINEAR_EXT,
    eDisplayNativeAMD = VK_COLOR_SPACE_DISPLAY_NATIVE_AMD,
    eVkColorspaceSrgbNonlinear = VK_COLORSPACE_SRGB_NONLINEAR_KHR,
    eDciP3LinearEXT = VK_COLOR_SPACE_DCI_P3_LINEAR_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ColorSpaceKHR value )
  {
    switch ( value )
    {
      case ColorSpaceKHR::eSrgbNonlinear : return "SrgbNonlinear";
      case ColorSpaceKHR::eDisplayP3NonlinearEXT : return "DisplayP3NonlinearEXT";
      case ColorSpaceKHR::eExtendedSrgbLinearEXT : return "ExtendedSrgbLinearEXT";
      case ColorSpaceKHR::eDisplayP3LinearEXT : return "DisplayP3LinearEXT";
      case ColorSpaceKHR::eDciP3NonlinearEXT : return "DciP3NonlinearEXT";
      case ColorSpaceKHR::eBt709LinearEXT : return "Bt709LinearEXT";
      case ColorSpaceKHR::eBt709NonlinearEXT : return "Bt709NonlinearEXT";
      case ColorSpaceKHR::eBt2020LinearEXT : return "Bt2020LinearEXT";
      case ColorSpaceKHR::eHdr10St2084EXT : return "Hdr10St2084EXT";
      case ColorSpaceKHR::eDolbyvisionEXT : return "DolbyvisionEXT";
      case ColorSpaceKHR::eHdr10HlgEXT : return "Hdr10HlgEXT";
      case ColorSpaceKHR::eAdobergbLinearEXT : return "AdobergbLinearEXT";
      case ColorSpaceKHR::eAdobergbNonlinearEXT : return "AdobergbNonlinearEXT";
      case ColorSpaceKHR::ePassThroughEXT : return "PassThroughEXT";
      case ColorSpaceKHR::eExtendedSrgbNonlinearEXT : return "ExtendedSrgbNonlinearEXT";
      case ColorSpaceKHR::eDisplayNativeAMD : return "DisplayNativeAMD";
      default: return "invalid";
    }
  }

  enum class CommandBufferLevel
  {
    ePrimary = VK_COMMAND_BUFFER_LEVEL_PRIMARY,
    eSecondary = VK_COMMAND_BUFFER_LEVEL_SECONDARY
  };

  VULKAN_HPP_INLINE std::string to_string( CommandBufferLevel value )
  {
    switch ( value )
    {
      case CommandBufferLevel::ePrimary : return "Primary";
      case CommandBufferLevel::eSecondary : return "Secondary";
      default: return "invalid";
    }
  }

  enum class CompareOp
  {
    eNever = VK_COMPARE_OP_NEVER,
    eLess = VK_COMPARE_OP_LESS,
    eEqual = VK_COMPARE_OP_EQUAL,
    eLessOrEqual = VK_COMPARE_OP_LESS_OR_EQUAL,
    eGreater = VK_COMPARE_OP_GREATER,
    eNotEqual = VK_COMPARE_OP_NOT_EQUAL,
    eGreaterOrEqual = VK_COMPARE_OP_GREATER_OR_EQUAL,
    eAlways = VK_COMPARE_OP_ALWAYS
  };

  VULKAN_HPP_INLINE std::string to_string( CompareOp value )
  {
    switch ( value )
    {
      case CompareOp::eNever : return "Never";
      case CompareOp::eLess : return "Less";
      case CompareOp::eEqual : return "Equal";
      case CompareOp::eLessOrEqual : return "LessOrEqual";
      case CompareOp::eGreater : return "Greater";
      case CompareOp::eNotEqual : return "NotEqual";
      case CompareOp::eGreaterOrEqual : return "GreaterOrEqual";
      case CompareOp::eAlways : return "Always";
      default: return "invalid";
    }
  }

  enum class ComponentSwizzle
  {
    eIdentity = VK_COMPONENT_SWIZZLE_IDENTITY,
    eZero = VK_COMPONENT_SWIZZLE_ZERO,
    eOne = VK_COMPONENT_SWIZZLE_ONE,
    eR = VK_COMPONENT_SWIZZLE_R,
    eG = VK_COMPONENT_SWIZZLE_G,
    eB = VK_COMPONENT_SWIZZLE_B,
    eA = VK_COMPONENT_SWIZZLE_A
  };

  VULKAN_HPP_INLINE std::string to_string( ComponentSwizzle value )
  {
    switch ( value )
    {
      case ComponentSwizzle::eIdentity : return "Identity";
      case ComponentSwizzle::eZero : return "Zero";
      case ComponentSwizzle::eOne : return "One";
      case ComponentSwizzle::eR : return "R";
      case ComponentSwizzle::eG : return "G";
      case ComponentSwizzle::eB : return "B";
      case ComponentSwizzle::eA : return "A";
      default: return "invalid";
    }
  }

  enum class ComponentTypeNV
  {
    eFloat16 = VK_COMPONENT_TYPE_FLOAT16_NV,
    eFloat32 = VK_COMPONENT_TYPE_FLOAT32_NV,
    eFloat64 = VK_COMPONENT_TYPE_FLOAT64_NV,
    eSint8 = VK_COMPONENT_TYPE_SINT8_NV,
    eSint16 = VK_COMPONENT_TYPE_SINT16_NV,
    eSint32 = VK_COMPONENT_TYPE_SINT32_NV,
    eSint64 = VK_COMPONENT_TYPE_SINT64_NV,
    eUint8 = VK_COMPONENT_TYPE_UINT8_NV,
    eUint16 = VK_COMPONENT_TYPE_UINT16_NV,
    eUint32 = VK_COMPONENT_TYPE_UINT32_NV,
    eUint64 = VK_COMPONENT_TYPE_UINT64_NV
  };

  VULKAN_HPP_INLINE std::string to_string( ComponentTypeNV value )
  {
    switch ( value )
    {
      case ComponentTypeNV::eFloat16 : return "Float16";
      case ComponentTypeNV::eFloat32 : return "Float32";
      case ComponentTypeNV::eFloat64 : return "Float64";
      case ComponentTypeNV::eSint8 : return "Sint8";
      case ComponentTypeNV::eSint16 : return "Sint16";
      case ComponentTypeNV::eSint32 : return "Sint32";
      case ComponentTypeNV::eSint64 : return "Sint64";
      case ComponentTypeNV::eUint8 : return "Uint8";
      case ComponentTypeNV::eUint16 : return "Uint16";
      case ComponentTypeNV::eUint32 : return "Uint32";
      case ComponentTypeNV::eUint64 : return "Uint64";
      default: return "invalid";
    }
  }

  enum class ConservativeRasterizationModeEXT
  {
    eDisabled = VK_CONSERVATIVE_RASTERIZATION_MODE_DISABLED_EXT,
    eOverestimate = VK_CONSERVATIVE_RASTERIZATION_MODE_OVERESTIMATE_EXT,
    eUnderestimate = VK_CONSERVATIVE_RASTERIZATION_MODE_UNDERESTIMATE_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ConservativeRasterizationModeEXT value )
  {
    switch ( value )
    {
      case ConservativeRasterizationModeEXT::eDisabled : return "Disabled";
      case ConservativeRasterizationModeEXT::eOverestimate : return "Overestimate";
      case ConservativeRasterizationModeEXT::eUnderestimate : return "Underestimate";
      default: return "invalid";
    }
  }

  enum class CopyAccelerationStructureModeNV
  {
    eClone = VK_COPY_ACCELERATION_STRUCTURE_MODE_CLONE_NV,
    eCompact = VK_COPY_ACCELERATION_STRUCTURE_MODE_COMPACT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( CopyAccelerationStructureModeNV value )
  {
    switch ( value )
    {
      case CopyAccelerationStructureModeNV::eClone : return "Clone";
      case CopyAccelerationStructureModeNV::eCompact : return "Compact";
      default: return "invalid";
    }
  }

  enum class CoverageModulationModeNV
  {
    eNone = VK_COVERAGE_MODULATION_MODE_NONE_NV,
    eRgb = VK_COVERAGE_MODULATION_MODE_RGB_NV,
    eAlpha = VK_COVERAGE_MODULATION_MODE_ALPHA_NV,
    eRgba = VK_COVERAGE_MODULATION_MODE_RGBA_NV
  };

  VULKAN_HPP_INLINE std::string to_string( CoverageModulationModeNV value )
  {
    switch ( value )
    {
      case CoverageModulationModeNV::eNone : return "None";
      case CoverageModulationModeNV::eRgb : return "Rgb";
      case CoverageModulationModeNV::eAlpha : return "Alpha";
      case CoverageModulationModeNV::eRgba : return "Rgba";
      default: return "invalid";
    }
  }

  enum class CoverageReductionModeNV
  {
    eMerge = VK_COVERAGE_REDUCTION_MODE_MERGE_NV,
    eTruncate = VK_COVERAGE_REDUCTION_MODE_TRUNCATE_NV
  };

  VULKAN_HPP_INLINE std::string to_string( CoverageReductionModeNV value )
  {
    switch ( value )
    {
      case CoverageReductionModeNV::eMerge : return "Merge";
      case CoverageReductionModeNV::eTruncate : return "Truncate";
      default: return "invalid";
    }
  }

  enum class DebugReportObjectTypeEXT
  {
    eUnknown = VK_DEBUG_REPORT_OBJECT_TYPE_UNKNOWN_EXT,
    eInstance = VK_DEBUG_REPORT_OBJECT_TYPE_INSTANCE_EXT,
    ePhysicalDevice = VK_DEBUG_REPORT_OBJECT_TYPE_PHYSICAL_DEVICE_EXT,
    eDevice = VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_EXT,
    eQueue = VK_DEBUG_REPORT_OBJECT_TYPE_QUEUE_EXT,
    eSemaphore = VK_DEBUG_REPORT_OBJECT_TYPE_SEMAPHORE_EXT,
    eCommandBuffer = VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_BUFFER_EXT,
    eFence = VK_DEBUG_REPORT_OBJECT_TYPE_FENCE_EXT,
    eDeviceMemory = VK_DEBUG_REPORT_OBJECT_TYPE_DEVICE_MEMORY_EXT,
    eBuffer = VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_EXT,
    eImage = VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_EXT,
    eEvent = VK_DEBUG_REPORT_OBJECT_TYPE_EVENT_EXT,
    eQueryPool = VK_DEBUG_REPORT_OBJECT_TYPE_QUERY_POOL_EXT,
    eBufferView = VK_DEBUG_REPORT_OBJECT_TYPE_BUFFER_VIEW_EXT,
    eImageView = VK_DEBUG_REPORT_OBJECT_TYPE_IMAGE_VIEW_EXT,
    eShaderModule = VK_DEBUG_REPORT_OBJECT_TYPE_SHADER_MODULE_EXT,
    ePipelineCache = VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_CACHE_EXT,
    ePipelineLayout = VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_LAYOUT_EXT,
    eRenderPass = VK_DEBUG_REPORT_OBJECT_TYPE_RENDER_PASS_EXT,
    ePipeline = VK_DEBUG_REPORT_OBJECT_TYPE_PIPELINE_EXT,
    eDescriptorSetLayout = VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT_EXT,
    eSampler = VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_EXT,
    eDescriptorPool = VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_POOL_EXT,
    eDescriptorSet = VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_SET_EXT,
    eFramebuffer = VK_DEBUG_REPORT_OBJECT_TYPE_FRAMEBUFFER_EXT,
    eCommandPool = VK_DEBUG_REPORT_OBJECT_TYPE_COMMAND_POOL_EXT,
    eSurfaceKHR = VK_DEBUG_REPORT_OBJECT_TYPE_SURFACE_KHR_EXT,
    eSwapchainKHR = VK_DEBUG_REPORT_OBJECT_TYPE_SWAPCHAIN_KHR_EXT,
    eDebugReportCallbackEXT = VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT_EXT,
    eDisplayKHR = VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_KHR_EXT,
    eDisplayModeKHR = VK_DEBUG_REPORT_OBJECT_TYPE_DISPLAY_MODE_KHR_EXT,
    eObjectTableNVX = VK_DEBUG_REPORT_OBJECT_TYPE_OBJECT_TABLE_NVX_EXT,
    eIndirectCommandsLayoutNVX = VK_DEBUG_REPORT_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_NVX_EXT,
    eValidationCacheEXT = VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT_EXT,
    eSamplerYcbcrConversion = VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_EXT,
    eDescriptorUpdateTemplate = VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_EXT,
    eAccelerationStructureNV = VK_DEBUG_REPORT_OBJECT_TYPE_ACCELERATION_STRUCTURE_NV_EXT,
    eDebugReport = VK_DEBUG_REPORT_OBJECT_TYPE_DEBUG_REPORT_EXT,
    eValidationCache = VK_DEBUG_REPORT_OBJECT_TYPE_VALIDATION_CACHE_EXT,
    eDescriptorUpdateTemplateKHR = VK_DEBUG_REPORT_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_KHR_EXT,
    eSamplerYcbcrConversionKHR = VK_DEBUG_REPORT_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_KHR_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DebugReportObjectTypeEXT value )
  {
    switch ( value )
    {
      case DebugReportObjectTypeEXT::eUnknown : return "Unknown";
      case DebugReportObjectTypeEXT::eInstance : return "Instance";
      case DebugReportObjectTypeEXT::ePhysicalDevice : return "PhysicalDevice";
      case DebugReportObjectTypeEXT::eDevice : return "Device";
      case DebugReportObjectTypeEXT::eQueue : return "Queue";
      case DebugReportObjectTypeEXT::eSemaphore : return "Semaphore";
      case DebugReportObjectTypeEXT::eCommandBuffer : return "CommandBuffer";
      case DebugReportObjectTypeEXT::eFence : return "Fence";
      case DebugReportObjectTypeEXT::eDeviceMemory : return "DeviceMemory";
      case DebugReportObjectTypeEXT::eBuffer : return "Buffer";
      case DebugReportObjectTypeEXT::eImage : return "Image";
      case DebugReportObjectTypeEXT::eEvent : return "Event";
      case DebugReportObjectTypeEXT::eQueryPool : return "QueryPool";
      case DebugReportObjectTypeEXT::eBufferView : return "BufferView";
      case DebugReportObjectTypeEXT::eImageView : return "ImageView";
      case DebugReportObjectTypeEXT::eShaderModule : return "ShaderModule";
      case DebugReportObjectTypeEXT::ePipelineCache : return "PipelineCache";
      case DebugReportObjectTypeEXT::ePipelineLayout : return "PipelineLayout";
      case DebugReportObjectTypeEXT::eRenderPass : return "RenderPass";
      case DebugReportObjectTypeEXT::ePipeline : return "Pipeline";
      case DebugReportObjectTypeEXT::eDescriptorSetLayout : return "DescriptorSetLayout";
      case DebugReportObjectTypeEXT::eSampler : return "Sampler";
      case DebugReportObjectTypeEXT::eDescriptorPool : return "DescriptorPool";
      case DebugReportObjectTypeEXT::eDescriptorSet : return "DescriptorSet";
      case DebugReportObjectTypeEXT::eFramebuffer : return "Framebuffer";
      case DebugReportObjectTypeEXT::eCommandPool : return "CommandPool";
      case DebugReportObjectTypeEXT::eSurfaceKHR : return "SurfaceKHR";
      case DebugReportObjectTypeEXT::eSwapchainKHR : return "SwapchainKHR";
      case DebugReportObjectTypeEXT::eDebugReportCallbackEXT : return "DebugReportCallbackEXT";
      case DebugReportObjectTypeEXT::eDisplayKHR : return "DisplayKHR";
      case DebugReportObjectTypeEXT::eDisplayModeKHR : return "DisplayModeKHR";
      case DebugReportObjectTypeEXT::eObjectTableNVX : return "ObjectTableNVX";
      case DebugReportObjectTypeEXT::eIndirectCommandsLayoutNVX : return "IndirectCommandsLayoutNVX";
      case DebugReportObjectTypeEXT::eValidationCacheEXT : return "ValidationCacheEXT";
      case DebugReportObjectTypeEXT::eSamplerYcbcrConversion : return "SamplerYcbcrConversion";
      case DebugReportObjectTypeEXT::eDescriptorUpdateTemplate : return "DescriptorUpdateTemplate";
      case DebugReportObjectTypeEXT::eAccelerationStructureNV : return "AccelerationStructureNV";
      default: return "invalid";
    }
  }

  enum class DescriptorType
  {
    eSampler = VK_DESCRIPTOR_TYPE_SAMPLER,
    eCombinedImageSampler = VK_DESCRIPTOR_TYPE_COMBINED_IMAGE_SAMPLER,
    eSampledImage = VK_DESCRIPTOR_TYPE_SAMPLED_IMAGE,
    eStorageImage = VK_DESCRIPTOR_TYPE_STORAGE_IMAGE,
    eUniformTexelBuffer = VK_DESCRIPTOR_TYPE_UNIFORM_TEXEL_BUFFER,
    eStorageTexelBuffer = VK_DESCRIPTOR_TYPE_STORAGE_TEXEL_BUFFER,
    eUniformBuffer = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER,
    eStorageBuffer = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER,
    eUniformBufferDynamic = VK_DESCRIPTOR_TYPE_UNIFORM_BUFFER_DYNAMIC,
    eStorageBufferDynamic = VK_DESCRIPTOR_TYPE_STORAGE_BUFFER_DYNAMIC,
    eInputAttachment = VK_DESCRIPTOR_TYPE_INPUT_ATTACHMENT,
    eInlineUniformBlockEXT = VK_DESCRIPTOR_TYPE_INLINE_UNIFORM_BLOCK_EXT,
    eAccelerationStructureNV = VK_DESCRIPTOR_TYPE_ACCELERATION_STRUCTURE_NV
  };

  VULKAN_HPP_INLINE std::string to_string( DescriptorType value )
  {
    switch ( value )
    {
      case DescriptorType::eSampler : return "Sampler";
      case DescriptorType::eCombinedImageSampler : return "CombinedImageSampler";
      case DescriptorType::eSampledImage : return "SampledImage";
      case DescriptorType::eStorageImage : return "StorageImage";
      case DescriptorType::eUniformTexelBuffer : return "UniformTexelBuffer";
      case DescriptorType::eStorageTexelBuffer : return "StorageTexelBuffer";
      case DescriptorType::eUniformBuffer : return "UniformBuffer";
      case DescriptorType::eStorageBuffer : return "StorageBuffer";
      case DescriptorType::eUniformBufferDynamic : return "UniformBufferDynamic";
      case DescriptorType::eStorageBufferDynamic : return "StorageBufferDynamic";
      case DescriptorType::eInputAttachment : return "InputAttachment";
      case DescriptorType::eInlineUniformBlockEXT : return "InlineUniformBlockEXT";
      case DescriptorType::eAccelerationStructureNV : return "AccelerationStructureNV";
      default: return "invalid";
    }
  }

  enum class DescriptorUpdateTemplateType
  {
    eDescriptorSet = VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_DESCRIPTOR_SET,
    ePushDescriptorsKHR = VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_PUSH_DESCRIPTORS_KHR,
    eDescriptorSetKHR = VK_DESCRIPTOR_UPDATE_TEMPLATE_TYPE_DESCRIPTOR_SET_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( DescriptorUpdateTemplateType value )
  {
    switch ( value )
    {
      case DescriptorUpdateTemplateType::eDescriptorSet : return "DescriptorSet";
      case DescriptorUpdateTemplateType::ePushDescriptorsKHR : return "PushDescriptorsKHR";
      default: return "invalid";
    }
  }

  enum class DeviceEventTypeEXT
  {
    eDisplayHotplug = VK_DEVICE_EVENT_TYPE_DISPLAY_HOTPLUG_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DeviceEventTypeEXT value )
  {
    switch ( value )
    {
      case DeviceEventTypeEXT::eDisplayHotplug : return "DisplayHotplug";
      default: return "invalid";
    }
  }

  enum class DiscardRectangleModeEXT
  {
    eInclusive = VK_DISCARD_RECTANGLE_MODE_INCLUSIVE_EXT,
    eExclusive = VK_DISCARD_RECTANGLE_MODE_EXCLUSIVE_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DiscardRectangleModeEXT value )
  {
    switch ( value )
    {
      case DiscardRectangleModeEXT::eInclusive : return "Inclusive";
      case DiscardRectangleModeEXT::eExclusive : return "Exclusive";
      default: return "invalid";
    }
  }

  enum class DisplayEventTypeEXT
  {
    eFirstPixelOut = VK_DISPLAY_EVENT_TYPE_FIRST_PIXEL_OUT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DisplayEventTypeEXT value )
  {
    switch ( value )
    {
      case DisplayEventTypeEXT::eFirstPixelOut : return "FirstPixelOut";
      default: return "invalid";
    }
  }

  enum class DisplayPowerStateEXT
  {
    eOff = VK_DISPLAY_POWER_STATE_OFF_EXT,
    eSuspend = VK_DISPLAY_POWER_STATE_SUSPEND_EXT,
    eOn = VK_DISPLAY_POWER_STATE_ON_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DisplayPowerStateEXT value )
  {
    switch ( value )
    {
      case DisplayPowerStateEXT::eOff : return "Off";
      case DisplayPowerStateEXT::eSuspend : return "Suspend";
      case DisplayPowerStateEXT::eOn : return "On";
      default: return "invalid";
    }
  }

  enum class DriverIdKHR
  {
    eAmdProprietary = VK_DRIVER_ID_AMD_PROPRIETARY_KHR,
    eAmdOpenSource = VK_DRIVER_ID_AMD_OPEN_SOURCE_KHR,
    eMesaRadv = VK_DRIVER_ID_MESA_RADV_KHR,
    eNvidiaProprietary = VK_DRIVER_ID_NVIDIA_PROPRIETARY_KHR,
    eIntelProprietaryWindows = VK_DRIVER_ID_INTEL_PROPRIETARY_WINDOWS_KHR,
    eIntelOpenSourceMESA = VK_DRIVER_ID_INTEL_OPEN_SOURCE_MESA_KHR,
    eImaginationProprietary = VK_DRIVER_ID_IMAGINATION_PROPRIETARY_KHR,
    eQualcommProprietary = VK_DRIVER_ID_QUALCOMM_PROPRIETARY_KHR,
    eArmProprietary = VK_DRIVER_ID_ARM_PROPRIETARY_KHR,
    eGoogleSwiftshader = VK_DRIVER_ID_GOOGLE_SWIFTSHADER_KHR,
    eGgpProprietary = VK_DRIVER_ID_GGP_PROPRIETARY_KHR,
    eBroadcomProprietary = VK_DRIVER_ID_BROADCOM_PROPRIETARY_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( DriverIdKHR value )
  {
    switch ( value )
    {
      case DriverIdKHR::eAmdProprietary : return "AmdProprietary";
      case DriverIdKHR::eAmdOpenSource : return "AmdOpenSource";
      case DriverIdKHR::eMesaRadv : return "MesaRadv";
      case DriverIdKHR::eNvidiaProprietary : return "NvidiaProprietary";
      case DriverIdKHR::eIntelProprietaryWindows : return "IntelProprietaryWindows";
      case DriverIdKHR::eIntelOpenSourceMESA : return "IntelOpenSourceMESA";
      case DriverIdKHR::eImaginationProprietary : return "ImaginationProprietary";
      case DriverIdKHR::eQualcommProprietary : return "QualcommProprietary";
      case DriverIdKHR::eArmProprietary : return "ArmProprietary";
      case DriverIdKHR::eGoogleSwiftshader : return "GoogleSwiftshader";
      case DriverIdKHR::eGgpProprietary : return "GgpProprietary";
      case DriverIdKHR::eBroadcomProprietary : return "BroadcomProprietary";
      default: return "invalid";
    }
  }

  enum class DynamicState
  {
    eViewport = VK_DYNAMIC_STATE_VIEWPORT,
    eScissor = VK_DYNAMIC_STATE_SCISSOR,
    eLineWidth = VK_DYNAMIC_STATE_LINE_WIDTH,
    eDepthBias = VK_DYNAMIC_STATE_DEPTH_BIAS,
    eBlendConstants = VK_DYNAMIC_STATE_BLEND_CONSTANTS,
    eDepthBounds = VK_DYNAMIC_STATE_DEPTH_BOUNDS,
    eStencilCompareMask = VK_DYNAMIC_STATE_STENCIL_COMPARE_MASK,
    eStencilWriteMask = VK_DYNAMIC_STATE_STENCIL_WRITE_MASK,
    eStencilReference = VK_DYNAMIC_STATE_STENCIL_REFERENCE,
    eViewportWScalingNV = VK_DYNAMIC_STATE_VIEWPORT_W_SCALING_NV,
    eDiscardRectangleEXT = VK_DYNAMIC_STATE_DISCARD_RECTANGLE_EXT,
    eSampleLocationsEXT = VK_DYNAMIC_STATE_SAMPLE_LOCATIONS_EXT,
    eViewportShadingRatePaletteNV = VK_DYNAMIC_STATE_VIEWPORT_SHADING_RATE_PALETTE_NV,
    eViewportCoarseSampleOrderNV = VK_DYNAMIC_STATE_VIEWPORT_COARSE_SAMPLE_ORDER_NV,
    eExclusiveScissorNV = VK_DYNAMIC_STATE_EXCLUSIVE_SCISSOR_NV,
    eLineStippleEXT = VK_DYNAMIC_STATE_LINE_STIPPLE_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DynamicState value )
  {
    switch ( value )
    {
      case DynamicState::eViewport : return "Viewport";
      case DynamicState::eScissor : return "Scissor";
      case DynamicState::eLineWidth : return "LineWidth";
      case DynamicState::eDepthBias : return "DepthBias";
      case DynamicState::eBlendConstants : return "BlendConstants";
      case DynamicState::eDepthBounds : return "DepthBounds";
      case DynamicState::eStencilCompareMask : return "StencilCompareMask";
      case DynamicState::eStencilWriteMask : return "StencilWriteMask";
      case DynamicState::eStencilReference : return "StencilReference";
      case DynamicState::eViewportWScalingNV : return "ViewportWScalingNV";
      case DynamicState::eDiscardRectangleEXT : return "DiscardRectangleEXT";
      case DynamicState::eSampleLocationsEXT : return "SampleLocationsEXT";
      case DynamicState::eViewportShadingRatePaletteNV : return "ViewportShadingRatePaletteNV";
      case DynamicState::eViewportCoarseSampleOrderNV : return "ViewportCoarseSampleOrderNV";
      case DynamicState::eExclusiveScissorNV : return "ExclusiveScissorNV";
      case DynamicState::eLineStippleEXT : return "LineStippleEXT";
      default: return "invalid";
    }
  }

  enum class Filter
  {
    eNearest = VK_FILTER_NEAREST,
    eLinear = VK_FILTER_LINEAR,
    eCubicIMG = VK_FILTER_CUBIC_IMG,
    eCubicEXT = VK_FILTER_CUBIC_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( Filter value )
  {
    switch ( value )
    {
      case Filter::eNearest : return "Nearest";
      case Filter::eLinear : return "Linear";
      case Filter::eCubicIMG : return "CubicIMG";
      default: return "invalid";
    }
  }

  enum class Format
  {
    eUndefined = VK_FORMAT_UNDEFINED,
    eR4G4UnormPack8 = VK_FORMAT_R4G4_UNORM_PACK8,
    eR4G4B4A4UnormPack16 = VK_FORMAT_R4G4B4A4_UNORM_PACK16,
    eB4G4R4A4UnormPack16 = VK_FORMAT_B4G4R4A4_UNORM_PACK16,
    eR5G6B5UnormPack16 = VK_FORMAT_R5G6B5_UNORM_PACK16,
    eB5G6R5UnormPack16 = VK_FORMAT_B5G6R5_UNORM_PACK16,
    eR5G5B5A1UnormPack16 = VK_FORMAT_R5G5B5A1_UNORM_PACK16,
    eB5G5R5A1UnormPack16 = VK_FORMAT_B5G5R5A1_UNORM_PACK16,
    eA1R5G5B5UnormPack16 = VK_FORMAT_A1R5G5B5_UNORM_PACK16,
    eR8Unorm = VK_FORMAT_R8_UNORM,
    eR8Snorm = VK_FORMAT_R8_SNORM,
    eR8Uscaled = VK_FORMAT_R8_USCALED,
    eR8Sscaled = VK_FORMAT_R8_SSCALED,
    eR8Uint = VK_FORMAT_R8_UINT,
    eR8Sint = VK_FORMAT_R8_SINT,
    eR8Srgb = VK_FORMAT_R8_SRGB,
    eR8G8Unorm = VK_FORMAT_R8G8_UNORM,
    eR8G8Snorm = VK_FORMAT_R8G8_SNORM,
    eR8G8Uscaled = VK_FORMAT_R8G8_USCALED,
    eR8G8Sscaled = VK_FORMAT_R8G8_SSCALED,
    eR8G8Uint = VK_FORMAT_R8G8_UINT,
    eR8G8Sint = VK_FORMAT_R8G8_SINT,
    eR8G8Srgb = VK_FORMAT_R8G8_SRGB,
    eR8G8B8Unorm = VK_FORMAT_R8G8B8_UNORM,
    eR8G8B8Snorm = VK_FORMAT_R8G8B8_SNORM,
    eR8G8B8Uscaled = VK_FORMAT_R8G8B8_USCALED,
    eR8G8B8Sscaled = VK_FORMAT_R8G8B8_SSCALED,
    eR8G8B8Uint = VK_FORMAT_R8G8B8_UINT,
    eR8G8B8Sint = VK_FORMAT_R8G8B8_SINT,
    eR8G8B8Srgb = VK_FORMAT_R8G8B8_SRGB,
    eB8G8R8Unorm = VK_FORMAT_B8G8R8_UNORM,
    eB8G8R8Snorm = VK_FORMAT_B8G8R8_SNORM,
    eB8G8R8Uscaled = VK_FORMAT_B8G8R8_USCALED,
    eB8G8R8Sscaled = VK_FORMAT_B8G8R8_SSCALED,
    eB8G8R8Uint = VK_FORMAT_B8G8R8_UINT,
    eB8G8R8Sint = VK_FORMAT_B8G8R8_SINT,
    eB8G8R8Srgb = VK_FORMAT_B8G8R8_SRGB,
    eR8G8B8A8Unorm = VK_FORMAT_R8G8B8A8_UNORM,
    eR8G8B8A8Snorm = VK_FORMAT_R8G8B8A8_SNORM,
    eR8G8B8A8Uscaled = VK_FORMAT_R8G8B8A8_USCALED,
    eR8G8B8A8Sscaled = VK_FORMAT_R8G8B8A8_SSCALED,
    eR8G8B8A8Uint = VK_FORMAT_R8G8B8A8_UINT,
    eR8G8B8A8Sint = VK_FORMAT_R8G8B8A8_SINT,
    eR8G8B8A8Srgb = VK_FORMAT_R8G8B8A8_SRGB,
    eB8G8R8A8Unorm = VK_FORMAT_B8G8R8A8_UNORM,
    eB8G8R8A8Snorm = VK_FORMAT_B8G8R8A8_SNORM,
    eB8G8R8A8Uscaled = VK_FORMAT_B8G8R8A8_USCALED,
    eB8G8R8A8Sscaled = VK_FORMAT_B8G8R8A8_SSCALED,
    eB8G8R8A8Uint = VK_FORMAT_B8G8R8A8_UINT,
    eB8G8R8A8Sint = VK_FORMAT_B8G8R8A8_SINT,
    eB8G8R8A8Srgb = VK_FORMAT_B8G8R8A8_SRGB,
    eA8B8G8R8UnormPack32 = VK_FORMAT_A8B8G8R8_UNORM_PACK32,
    eA8B8G8R8SnormPack32 = VK_FORMAT_A8B8G8R8_SNORM_PACK32,
    eA8B8G8R8UscaledPack32 = VK_FORMAT_A8B8G8R8_USCALED_PACK32,
    eA8B8G8R8SscaledPack32 = VK_FORMAT_A8B8G8R8_SSCALED_PACK32,
    eA8B8G8R8UintPack32 = VK_FORMAT_A8B8G8R8_UINT_PACK32,
    eA8B8G8R8SintPack32 = VK_FORMAT_A8B8G8R8_SINT_PACK32,
    eA8B8G8R8SrgbPack32 = VK_FORMAT_A8B8G8R8_SRGB_PACK32,
    eA2R10G10B10UnormPack32 = VK_FORMAT_A2R10G10B10_UNORM_PACK32,
    eA2R10G10B10SnormPack32 = VK_FORMAT_A2R10G10B10_SNORM_PACK32,
    eA2R10G10B10UscaledPack32 = VK_FORMAT_A2R10G10B10_USCALED_PACK32,
    eA2R10G10B10SscaledPack32 = VK_FORMAT_A2R10G10B10_SSCALED_PACK32,
    eA2R10G10B10UintPack32 = VK_FORMAT_A2R10G10B10_UINT_PACK32,
    eA2R10G10B10SintPack32 = VK_FORMAT_A2R10G10B10_SINT_PACK32,
    eA2B10G10R10UnormPack32 = VK_FORMAT_A2B10G10R10_UNORM_PACK32,
    eA2B10G10R10SnormPack32 = VK_FORMAT_A2B10G10R10_SNORM_PACK32,
    eA2B10G10R10UscaledPack32 = VK_FORMAT_A2B10G10R10_USCALED_PACK32,
    eA2B10G10R10SscaledPack32 = VK_FORMAT_A2B10G10R10_SSCALED_PACK32,
    eA2B10G10R10UintPack32 = VK_FORMAT_A2B10G10R10_UINT_PACK32,
    eA2B10G10R10SintPack32 = VK_FORMAT_A2B10G10R10_SINT_PACK32,
    eR16Unorm = VK_FORMAT_R16_UNORM,
    eR16Snorm = VK_FORMAT_R16_SNORM,
    eR16Uscaled = VK_FORMAT_R16_USCALED,
    eR16Sscaled = VK_FORMAT_R16_SSCALED,
    eR16Uint = VK_FORMAT_R16_UINT,
    eR16Sint = VK_FORMAT_R16_SINT,
    eR16Sfloat = VK_FORMAT_R16_SFLOAT,
    eR16G16Unorm = VK_FORMAT_R16G16_UNORM,
    eR16G16Snorm = VK_FORMAT_R16G16_SNORM,
    eR16G16Uscaled = VK_FORMAT_R16G16_USCALED,
    eR16G16Sscaled = VK_FORMAT_R16G16_SSCALED,
    eR16G16Uint = VK_FORMAT_R16G16_UINT,
    eR16G16Sint = VK_FORMAT_R16G16_SINT,
    eR16G16Sfloat = VK_FORMAT_R16G16_SFLOAT,
    eR16G16B16Unorm = VK_FORMAT_R16G16B16_UNORM,
    eR16G16B16Snorm = VK_FORMAT_R16G16B16_SNORM,
    eR16G16B16Uscaled = VK_FORMAT_R16G16B16_USCALED,
    eR16G16B16Sscaled = VK_FORMAT_R16G16B16_SSCALED,
    eR16G16B16Uint = VK_FORMAT_R16G16B16_UINT,
    eR16G16B16Sint = VK_FORMAT_R16G16B16_SINT,
    eR16G16B16Sfloat = VK_FORMAT_R16G16B16_SFLOAT,
    eR16G16B16A16Unorm = VK_FORMAT_R16G16B16A16_UNORM,
    eR16G16B16A16Snorm = VK_FORMAT_R16G16B16A16_SNORM,
    eR16G16B16A16Uscaled = VK_FORMAT_R16G16B16A16_USCALED,
    eR16G16B16A16Sscaled = VK_FORMAT_R16G16B16A16_SSCALED,
    eR16G16B16A16Uint = VK_FORMAT_R16G16B16A16_UINT,
    eR16G16B16A16Sint = VK_FORMAT_R16G16B16A16_SINT,
    eR16G16B16A16Sfloat = VK_FORMAT_R16G16B16A16_SFLOAT,
    eR32Uint = VK_FORMAT_R32_UINT,
    eR32Sint = VK_FORMAT_R32_SINT,
    eR32Sfloat = VK_FORMAT_R32_SFLOAT,
    eR32G32Uint = VK_FORMAT_R32G32_UINT,
    eR32G32Sint = VK_FORMAT_R32G32_SINT,
    eR32G32Sfloat = VK_FORMAT_R32G32_SFLOAT,
    eR32G32B32Uint = VK_FORMAT_R32G32B32_UINT,
    eR32G32B32Sint = VK_FORMAT_R32G32B32_SINT,
    eR32G32B32Sfloat = VK_FORMAT_R32G32B32_SFLOAT,
    eR32G32B32A32Uint = VK_FORMAT_R32G32B32A32_UINT,
    eR32G32B32A32Sint = VK_FORMAT_R32G32B32A32_SINT,
    eR32G32B32A32Sfloat = VK_FORMAT_R32G32B32A32_SFLOAT,
    eR64Uint = VK_FORMAT_R64_UINT,
    eR64Sint = VK_FORMAT_R64_SINT,
    eR64Sfloat = VK_FORMAT_R64_SFLOAT,
    eR64G64Uint = VK_FORMAT_R64G64_UINT,
    eR64G64Sint = VK_FORMAT_R64G64_SINT,
    eR64G64Sfloat = VK_FORMAT_R64G64_SFLOAT,
    eR64G64B64Uint = VK_FORMAT_R64G64B64_UINT,
    eR64G64B64Sint = VK_FORMAT_R64G64B64_SINT,
    eR64G64B64Sfloat = VK_FORMAT_R64G64B64_SFLOAT,
    eR64G64B64A64Uint = VK_FORMAT_R64G64B64A64_UINT,
    eR64G64B64A64Sint = VK_FORMAT_R64G64B64A64_SINT,
    eR64G64B64A64Sfloat = VK_FORMAT_R64G64B64A64_SFLOAT,
    eB10G11R11UfloatPack32 = VK_FORMAT_B10G11R11_UFLOAT_PACK32,
    eE5B9G9R9UfloatPack32 = VK_FORMAT_E5B9G9R9_UFLOAT_PACK32,
    eD16Unorm = VK_FORMAT_D16_UNORM,
    eX8D24UnormPack32 = VK_FORMAT_X8_D24_UNORM_PACK32,
    eD32Sfloat = VK_FORMAT_D32_SFLOAT,
    eS8Uint = VK_FORMAT_S8_UINT,
    eD16UnormS8Uint = VK_FORMAT_D16_UNORM_S8_UINT,
    eD24UnormS8Uint = VK_FORMAT_D24_UNORM_S8_UINT,
    eD32SfloatS8Uint = VK_FORMAT_D32_SFLOAT_S8_UINT,
    eBc1RgbUnormBlock = VK_FORMAT_BC1_RGB_UNORM_BLOCK,
    eBc1RgbSrgbBlock = VK_FORMAT_BC1_RGB_SRGB_BLOCK,
    eBc1RgbaUnormBlock = VK_FORMAT_BC1_RGBA_UNORM_BLOCK,
    eBc1RgbaSrgbBlock = VK_FORMAT_BC1_RGBA_SRGB_BLOCK,
    eBc2UnormBlock = VK_FORMAT_BC2_UNORM_BLOCK,
    eBc2SrgbBlock = VK_FORMAT_BC2_SRGB_BLOCK,
    eBc3UnormBlock = VK_FORMAT_BC3_UNORM_BLOCK,
    eBc3SrgbBlock = VK_FORMAT_BC3_SRGB_BLOCK,
    eBc4UnormBlock = VK_FORMAT_BC4_UNORM_BLOCK,
    eBc4SnormBlock = VK_FORMAT_BC4_SNORM_BLOCK,
    eBc5UnormBlock = VK_FORMAT_BC5_UNORM_BLOCK,
    eBc5SnormBlock = VK_FORMAT_BC5_SNORM_BLOCK,
    eBc6HUfloatBlock = VK_FORMAT_BC6H_UFLOAT_BLOCK,
    eBc6HSfloatBlock = VK_FORMAT_BC6H_SFLOAT_BLOCK,
    eBc7UnormBlock = VK_FORMAT_BC7_UNORM_BLOCK,
    eBc7SrgbBlock = VK_FORMAT_BC7_SRGB_BLOCK,
    eEtc2R8G8B8UnormBlock = VK_FORMAT_ETC2_R8G8B8_UNORM_BLOCK,
    eEtc2R8G8B8SrgbBlock = VK_FORMAT_ETC2_R8G8B8_SRGB_BLOCK,
    eEtc2R8G8B8A1UnormBlock = VK_FORMAT_ETC2_R8G8B8A1_UNORM_BLOCK,
    eEtc2R8G8B8A1SrgbBlock = VK_FORMAT_ETC2_R8G8B8A1_SRGB_BLOCK,
    eEtc2R8G8B8A8UnormBlock = VK_FORMAT_ETC2_R8G8B8A8_UNORM_BLOCK,
    eEtc2R8G8B8A8SrgbBlock = VK_FORMAT_ETC2_R8G8B8A8_SRGB_BLOCK,
    eEacR11UnormBlock = VK_FORMAT_EAC_R11_UNORM_BLOCK,
    eEacR11SnormBlock = VK_FORMAT_EAC_R11_SNORM_BLOCK,
    eEacR11G11UnormBlock = VK_FORMAT_EAC_R11G11_UNORM_BLOCK,
    eEacR11G11SnormBlock = VK_FORMAT_EAC_R11G11_SNORM_BLOCK,
    eAstc4x4UnormBlock = VK_FORMAT_ASTC_4x4_UNORM_BLOCK,
    eAstc4x4SrgbBlock = VK_FORMAT_ASTC_4x4_SRGB_BLOCK,
    eAstc5x4UnormBlock = VK_FORMAT_ASTC_5x4_UNORM_BLOCK,
    eAstc5x4SrgbBlock = VK_FORMAT_ASTC_5x4_SRGB_BLOCK,
    eAstc5x5UnormBlock = VK_FORMAT_ASTC_5x5_UNORM_BLOCK,
    eAstc5x5SrgbBlock = VK_FORMAT_ASTC_5x5_SRGB_BLOCK,
    eAstc6x5UnormBlock = VK_FORMAT_ASTC_6x5_UNORM_BLOCK,
    eAstc6x5SrgbBlock = VK_FORMAT_ASTC_6x5_SRGB_BLOCK,
    eAstc6x6UnormBlock = VK_FORMAT_ASTC_6x6_UNORM_BLOCK,
    eAstc6x6SrgbBlock = VK_FORMAT_ASTC_6x6_SRGB_BLOCK,
    eAstc8x5UnormBlock = VK_FORMAT_ASTC_8x5_UNORM_BLOCK,
    eAstc8x5SrgbBlock = VK_FORMAT_ASTC_8x5_SRGB_BLOCK,
    eAstc8x6UnormBlock = VK_FORMAT_ASTC_8x6_UNORM_BLOCK,
    eAstc8x6SrgbBlock = VK_FORMAT_ASTC_8x6_SRGB_BLOCK,
    eAstc8x8UnormBlock = VK_FORMAT_ASTC_8x8_UNORM_BLOCK,
    eAstc8x8SrgbBlock = VK_FORMAT_ASTC_8x8_SRGB_BLOCK,
    eAstc10x5UnormBlock = VK_FORMAT_ASTC_10x5_UNORM_BLOCK,
    eAstc10x5SrgbBlock = VK_FORMAT_ASTC_10x5_SRGB_BLOCK,
    eAstc10x6UnormBlock = VK_FORMAT_ASTC_10x6_UNORM_BLOCK,
    eAstc10x6SrgbBlock = VK_FORMAT_ASTC_10x6_SRGB_BLOCK,
    eAstc10x8UnormBlock = VK_FORMAT_ASTC_10x8_UNORM_BLOCK,
    eAstc10x8SrgbBlock = VK_FORMAT_ASTC_10x8_SRGB_BLOCK,
    eAstc10x10UnormBlock = VK_FORMAT_ASTC_10x10_UNORM_BLOCK,
    eAstc10x10SrgbBlock = VK_FORMAT_ASTC_10x10_SRGB_BLOCK,
    eAstc12x10UnormBlock = VK_FORMAT_ASTC_12x10_UNORM_BLOCK,
    eAstc12x10SrgbBlock = VK_FORMAT_ASTC_12x10_SRGB_BLOCK,
    eAstc12x12UnormBlock = VK_FORMAT_ASTC_12x12_UNORM_BLOCK,
    eAstc12x12SrgbBlock = VK_FORMAT_ASTC_12x12_SRGB_BLOCK,
    eG8B8G8R8422Unorm = VK_FORMAT_G8B8G8R8_422_UNORM,
    eB8G8R8G8422Unorm = VK_FORMAT_B8G8R8G8_422_UNORM,
    eG8B8R83Plane420Unorm = VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM,
    eG8B8R82Plane420Unorm = VK_FORMAT_G8_B8R8_2PLANE_420_UNORM,
    eG8B8R83Plane422Unorm = VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM,
    eG8B8R82Plane422Unorm = VK_FORMAT_G8_B8R8_2PLANE_422_UNORM,
    eG8B8R83Plane444Unorm = VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM,
    eR10X6UnormPack16 = VK_FORMAT_R10X6_UNORM_PACK16,
    eR10X6G10X6Unorm2Pack16 = VK_FORMAT_R10X6G10X6_UNORM_2PACK16,
    eR10X6G10X6B10X6A10X6Unorm4Pack16 = VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16,
    eG10X6B10X6G10X6R10X6422Unorm4Pack16 = VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16,
    eB10X6G10X6R10X6G10X6422Unorm4Pack16 = VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16,
    eG10X6B10X6R10X63Plane420Unorm3Pack16 = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16,
    eG10X6B10X6R10X62Plane420Unorm3Pack16 = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16,
    eG10X6B10X6R10X63Plane422Unorm3Pack16 = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16,
    eG10X6B10X6R10X62Plane422Unorm3Pack16 = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16,
    eG10X6B10X6R10X63Plane444Unorm3Pack16 = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16,
    eR12X4UnormPack16 = VK_FORMAT_R12X4_UNORM_PACK16,
    eR12X4G12X4Unorm2Pack16 = VK_FORMAT_R12X4G12X4_UNORM_2PACK16,
    eR12X4G12X4B12X4A12X4Unorm4Pack16 = VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16,
    eG12X4B12X4G12X4R12X4422Unorm4Pack16 = VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16,
    eB12X4G12X4R12X4G12X4422Unorm4Pack16 = VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16,
    eG12X4B12X4R12X43Plane420Unorm3Pack16 = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16,
    eG12X4B12X4R12X42Plane420Unorm3Pack16 = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16,
    eG12X4B12X4R12X43Plane422Unorm3Pack16 = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16,
    eG12X4B12X4R12X42Plane422Unorm3Pack16 = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16,
    eG12X4B12X4R12X43Plane444Unorm3Pack16 = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16,
    eG16B16G16R16422Unorm = VK_FORMAT_G16B16G16R16_422_UNORM,
    eB16G16R16G16422Unorm = VK_FORMAT_B16G16R16G16_422_UNORM,
    eG16B16R163Plane420Unorm = VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM,
    eG16B16R162Plane420Unorm = VK_FORMAT_G16_B16R16_2PLANE_420_UNORM,
    eG16B16R163Plane422Unorm = VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM,
    eG16B16R162Plane422Unorm = VK_FORMAT_G16_B16R16_2PLANE_422_UNORM,
    eG16B16R163Plane444Unorm = VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM,
    ePvrtc12BppUnormBlockIMG = VK_FORMAT_PVRTC1_2BPP_UNORM_BLOCK_IMG,
    ePvrtc14BppUnormBlockIMG = VK_FORMAT_PVRTC1_4BPP_UNORM_BLOCK_IMG,
    ePvrtc22BppUnormBlockIMG = VK_FORMAT_PVRTC2_2BPP_UNORM_BLOCK_IMG,
    ePvrtc24BppUnormBlockIMG = VK_FORMAT_PVRTC2_4BPP_UNORM_BLOCK_IMG,
    ePvrtc12BppSrgbBlockIMG = VK_FORMAT_PVRTC1_2BPP_SRGB_BLOCK_IMG,
    ePvrtc14BppSrgbBlockIMG = VK_FORMAT_PVRTC1_4BPP_SRGB_BLOCK_IMG,
    ePvrtc22BppSrgbBlockIMG = VK_FORMAT_PVRTC2_2BPP_SRGB_BLOCK_IMG,
    ePvrtc24BppSrgbBlockIMG = VK_FORMAT_PVRTC2_4BPP_SRGB_BLOCK_IMG,
    eAstc4x4SfloatBlockEXT = VK_FORMAT_ASTC_4x4_SFLOAT_BLOCK_EXT,
    eAstc5x4SfloatBlockEXT = VK_FORMAT_ASTC_5x4_SFLOAT_BLOCK_EXT,
    eAstc5x5SfloatBlockEXT = VK_FORMAT_ASTC_5x5_SFLOAT_BLOCK_EXT,
    eAstc6x5SfloatBlockEXT = VK_FORMAT_ASTC_6x5_SFLOAT_BLOCK_EXT,
    eAstc6x6SfloatBlockEXT = VK_FORMAT_ASTC_6x6_SFLOAT_BLOCK_EXT,
    eAstc8x5SfloatBlockEXT = VK_FORMAT_ASTC_8x5_SFLOAT_BLOCK_EXT,
    eAstc8x6SfloatBlockEXT = VK_FORMAT_ASTC_8x6_SFLOAT_BLOCK_EXT,
    eAstc8x8SfloatBlockEXT = VK_FORMAT_ASTC_8x8_SFLOAT_BLOCK_EXT,
    eAstc10x5SfloatBlockEXT = VK_FORMAT_ASTC_10x5_SFLOAT_BLOCK_EXT,
    eAstc10x6SfloatBlockEXT = VK_FORMAT_ASTC_10x6_SFLOAT_BLOCK_EXT,
    eAstc10x8SfloatBlockEXT = VK_FORMAT_ASTC_10x8_SFLOAT_BLOCK_EXT,
    eAstc10x10SfloatBlockEXT = VK_FORMAT_ASTC_10x10_SFLOAT_BLOCK_EXT,
    eAstc12x10SfloatBlockEXT = VK_FORMAT_ASTC_12x10_SFLOAT_BLOCK_EXT,
    eAstc12x12SfloatBlockEXT = VK_FORMAT_ASTC_12x12_SFLOAT_BLOCK_EXT,
    eG8B8G8R8422UnormKHR = VK_FORMAT_G8B8G8R8_422_UNORM_KHR,
    eB8G8R8G8422UnormKHR = VK_FORMAT_B8G8R8G8_422_UNORM_KHR,
    eG8B8R83Plane420UnormKHR = VK_FORMAT_G8_B8_R8_3PLANE_420_UNORM_KHR,
    eG8B8R82Plane420UnormKHR = VK_FORMAT_G8_B8R8_2PLANE_420_UNORM_KHR,
    eG8B8R83Plane422UnormKHR = VK_FORMAT_G8_B8_R8_3PLANE_422_UNORM_KHR,
    eG8B8R82Plane422UnormKHR = VK_FORMAT_G8_B8R8_2PLANE_422_UNORM_KHR,
    eG8B8R83Plane444UnormKHR = VK_FORMAT_G8_B8_R8_3PLANE_444_UNORM_KHR,
    eR10X6UnormPack16KHR = VK_FORMAT_R10X6_UNORM_PACK16_KHR,
    eR10X6G10X6Unorm2Pack16KHR = VK_FORMAT_R10X6G10X6_UNORM_2PACK16_KHR,
    eR10X6G10X6B10X6A10X6Unorm4Pack16KHR = VK_FORMAT_R10X6G10X6B10X6A10X6_UNORM_4PACK16_KHR,
    eG10X6B10X6G10X6R10X6422Unorm4Pack16KHR = VK_FORMAT_G10X6B10X6G10X6R10X6_422_UNORM_4PACK16_KHR,
    eB10X6G10X6R10X6G10X6422Unorm4Pack16KHR = VK_FORMAT_B10X6G10X6R10X6G10X6_422_UNORM_4PACK16_KHR,
    eG10X6B10X6R10X63Plane420Unorm3Pack16KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_420_UNORM_3PACK16_KHR,
    eG10X6B10X6R10X62Plane420Unorm3Pack16KHR = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_420_UNORM_3PACK16_KHR,
    eG10X6B10X6R10X63Plane422Unorm3Pack16KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_422_UNORM_3PACK16_KHR,
    eG10X6B10X6R10X62Plane422Unorm3Pack16KHR = VK_FORMAT_G10X6_B10X6R10X6_2PLANE_422_UNORM_3PACK16_KHR,
    eG10X6B10X6R10X63Plane444Unorm3Pack16KHR = VK_FORMAT_G10X6_B10X6_R10X6_3PLANE_444_UNORM_3PACK16_KHR,
    eR12X4UnormPack16KHR = VK_FORMAT_R12X4_UNORM_PACK16_KHR,
    eR12X4G12X4Unorm2Pack16KHR = VK_FORMAT_R12X4G12X4_UNORM_2PACK16_KHR,
    eR12X4G12X4B12X4A12X4Unorm4Pack16KHR = VK_FORMAT_R12X4G12X4B12X4A12X4_UNORM_4PACK16_KHR,
    eG12X4B12X4G12X4R12X4422Unorm4Pack16KHR = VK_FORMAT_G12X4B12X4G12X4R12X4_422_UNORM_4PACK16_KHR,
    eB12X4G12X4R12X4G12X4422Unorm4Pack16KHR = VK_FORMAT_B12X4G12X4R12X4G12X4_422_UNORM_4PACK16_KHR,
    eG12X4B12X4R12X43Plane420Unorm3Pack16KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_420_UNORM_3PACK16_KHR,
    eG12X4B12X4R12X42Plane420Unorm3Pack16KHR = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_420_UNORM_3PACK16_KHR,
    eG12X4B12X4R12X43Plane422Unorm3Pack16KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_422_UNORM_3PACK16_KHR,
    eG12X4B12X4R12X42Plane422Unorm3Pack16KHR = VK_FORMAT_G12X4_B12X4R12X4_2PLANE_422_UNORM_3PACK16_KHR,
    eG12X4B12X4R12X43Plane444Unorm3Pack16KHR = VK_FORMAT_G12X4_B12X4_R12X4_3PLANE_444_UNORM_3PACK16_KHR,
    eG16B16G16R16422UnormKHR = VK_FORMAT_G16B16G16R16_422_UNORM_KHR,
    eB16G16R16G16422UnormKHR = VK_FORMAT_B16G16R16G16_422_UNORM_KHR,
    eG16B16R163Plane420UnormKHR = VK_FORMAT_G16_B16_R16_3PLANE_420_UNORM_KHR,
    eG16B16R162Plane420UnormKHR = VK_FORMAT_G16_B16R16_2PLANE_420_UNORM_KHR,
    eG16B16R163Plane422UnormKHR = VK_FORMAT_G16_B16_R16_3PLANE_422_UNORM_KHR,
    eG16B16R162Plane422UnormKHR = VK_FORMAT_G16_B16R16_2PLANE_422_UNORM_KHR,
    eG16B16R163Plane444UnormKHR = VK_FORMAT_G16_B16_R16_3PLANE_444_UNORM_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( Format value )
  {
    switch ( value )
    {
      case Format::eUndefined : return "Undefined";
      case Format::eR4G4UnormPack8 : return "R4G4UnormPack8";
      case Format::eR4G4B4A4UnormPack16 : return "R4G4B4A4UnormPack16";
      case Format::eB4G4R4A4UnormPack16 : return "B4G4R4A4UnormPack16";
      case Format::eR5G6B5UnormPack16 : return "R5G6B5UnormPack16";
      case Format::eB5G6R5UnormPack16 : return "B5G6R5UnormPack16";
      case Format::eR5G5B5A1UnormPack16 : return "R5G5B5A1UnormPack16";
      case Format::eB5G5R5A1UnormPack16 : return "B5G5R5A1UnormPack16";
      case Format::eA1R5G5B5UnormPack16 : return "A1R5G5B5UnormPack16";
      case Format::eR8Unorm : return "R8Unorm";
      case Format::eR8Snorm : return "R8Snorm";
      case Format::eR8Uscaled : return "R8Uscaled";
      case Format::eR8Sscaled : return "R8Sscaled";
      case Format::eR8Uint : return "R8Uint";
      case Format::eR8Sint : return "R8Sint";
      case Format::eR8Srgb : return "R8Srgb";
      case Format::eR8G8Unorm : return "R8G8Unorm";
      case Format::eR8G8Snorm : return "R8G8Snorm";
      case Format::eR8G8Uscaled : return "R8G8Uscaled";
      case Format::eR8G8Sscaled : return "R8G8Sscaled";
      case Format::eR8G8Uint : return "R8G8Uint";
      case Format::eR8G8Sint : return "R8G8Sint";
      case Format::eR8G8Srgb : return "R8G8Srgb";
      case Format::eR8G8B8Unorm : return "R8G8B8Unorm";
      case Format::eR8G8B8Snorm : return "R8G8B8Snorm";
      case Format::eR8G8B8Uscaled : return "R8G8B8Uscaled";
      case Format::eR8G8B8Sscaled : return "R8G8B8Sscaled";
      case Format::eR8G8B8Uint : return "R8G8B8Uint";
      case Format::eR8G8B8Sint : return "R8G8B8Sint";
      case Format::eR8G8B8Srgb : return "R8G8B8Srgb";
      case Format::eB8G8R8Unorm : return "B8G8R8Unorm";
      case Format::eB8G8R8Snorm : return "B8G8R8Snorm";
      case Format::eB8G8R8Uscaled : return "B8G8R8Uscaled";
      case Format::eB8G8R8Sscaled : return "B8G8R8Sscaled";
      case Format::eB8G8R8Uint : return "B8G8R8Uint";
      case Format::eB8G8R8Sint : return "B8G8R8Sint";
      case Format::eB8G8R8Srgb : return "B8G8R8Srgb";
      case Format::eR8G8B8A8Unorm : return "R8G8B8A8Unorm";
      case Format::eR8G8B8A8Snorm : return "R8G8B8A8Snorm";
      case Format::eR8G8B8A8Uscaled : return "R8G8B8A8Uscaled";
      case Format::eR8G8B8A8Sscaled : return "R8G8B8A8Sscaled";
      case Format::eR8G8B8A8Uint : return "R8G8B8A8Uint";
      case Format::eR8G8B8A8Sint : return "R8G8B8A8Sint";
      case Format::eR8G8B8A8Srgb : return "R8G8B8A8Srgb";
      case Format::eB8G8R8A8Unorm : return "B8G8R8A8Unorm";
      case Format::eB8G8R8A8Snorm : return "B8G8R8A8Snorm";
      case Format::eB8G8R8A8Uscaled : return "B8G8R8A8Uscaled";
      case Format::eB8G8R8A8Sscaled : return "B8G8R8A8Sscaled";
      case Format::eB8G8R8A8Uint : return "B8G8R8A8Uint";
      case Format::eB8G8R8A8Sint : return "B8G8R8A8Sint";
      case Format::eB8G8R8A8Srgb : return "B8G8R8A8Srgb";
      case Format::eA8B8G8R8UnormPack32 : return "A8B8G8R8UnormPack32";
      case Format::eA8B8G8R8SnormPack32 : return "A8B8G8R8SnormPack32";
      case Format::eA8B8G8R8UscaledPack32 : return "A8B8G8R8UscaledPack32";
      case Format::eA8B8G8R8SscaledPack32 : return "A8B8G8R8SscaledPack32";
      case Format::eA8B8G8R8UintPack32 : return "A8B8G8R8UintPack32";
      case Format::eA8B8G8R8SintPack32 : return "A8B8G8R8SintPack32";
      case Format::eA8B8G8R8SrgbPack32 : return "A8B8G8R8SrgbPack32";
      case Format::eA2R10G10B10UnormPack32 : return "A2R10G10B10UnormPack32";
      case Format::eA2R10G10B10SnormPack32 : return "A2R10G10B10SnormPack32";
      case Format::eA2R10G10B10UscaledPack32 : return "A2R10G10B10UscaledPack32";
      case Format::eA2R10G10B10SscaledPack32 : return "A2R10G10B10SscaledPack32";
      case Format::eA2R10G10B10UintPack32 : return "A2R10G10B10UintPack32";
      case Format::eA2R10G10B10SintPack32 : return "A2R10G10B10SintPack32";
      case Format::eA2B10G10R10UnormPack32 : return "A2B10G10R10UnormPack32";
      case Format::eA2B10G10R10SnormPack32 : return "A2B10G10R10SnormPack32";
      case Format::eA2B10G10R10UscaledPack32 : return "A2B10G10R10UscaledPack32";
      case Format::eA2B10G10R10SscaledPack32 : return "A2B10G10R10SscaledPack32";
      case Format::eA2B10G10R10UintPack32 : return "A2B10G10R10UintPack32";
      case Format::eA2B10G10R10SintPack32 : return "A2B10G10R10SintPack32";
      case Format::eR16Unorm : return "R16Unorm";
      case Format::eR16Snorm : return "R16Snorm";
      case Format::eR16Uscaled : return "R16Uscaled";
      case Format::eR16Sscaled : return "R16Sscaled";
      case Format::eR16Uint : return "R16Uint";
      case Format::eR16Sint : return "R16Sint";
      case Format::eR16Sfloat : return "R16Sfloat";
      case Format::eR16G16Unorm : return "R16G16Unorm";
      case Format::eR16G16Snorm : return "R16G16Snorm";
      case Format::eR16G16Uscaled : return "R16G16Uscaled";
      case Format::eR16G16Sscaled : return "R16G16Sscaled";
      case Format::eR16G16Uint : return "R16G16Uint";
      case Format::eR16G16Sint : return "R16G16Sint";
      case Format::eR16G16Sfloat : return "R16G16Sfloat";
      case Format::eR16G16B16Unorm : return "R16G16B16Unorm";
      case Format::eR16G16B16Snorm : return "R16G16B16Snorm";
      case Format::eR16G16B16Uscaled : return "R16G16B16Uscaled";
      case Format::eR16G16B16Sscaled : return "R16G16B16Sscaled";
      case Format::eR16G16B16Uint : return "R16G16B16Uint";
      case Format::eR16G16B16Sint : return "R16G16B16Sint";
      case Format::eR16G16B16Sfloat : return "R16G16B16Sfloat";
      case Format::eR16G16B16A16Unorm : return "R16G16B16A16Unorm";
      case Format::eR16G16B16A16Snorm : return "R16G16B16A16Snorm";
      case Format::eR16G16B16A16Uscaled : return "R16G16B16A16Uscaled";
      case Format::eR16G16B16A16Sscaled : return "R16G16B16A16Sscaled";
      case Format::eR16G16B16A16Uint : return "R16G16B16A16Uint";
      case Format::eR16G16B16A16Sint : return "R16G16B16A16Sint";
      case Format::eR16G16B16A16Sfloat : return "R16G16B16A16Sfloat";
      case Format::eR32Uint : return "R32Uint";
      case Format::eR32Sint : return "R32Sint";
      case Format::eR32Sfloat : return "R32Sfloat";
      case Format::eR32G32Uint : return "R32G32Uint";
      case Format::eR32G32Sint : return "R32G32Sint";
      case Format::eR32G32Sfloat : return "R32G32Sfloat";
      case Format::eR32G32B32Uint : return "R32G32B32Uint";
      case Format::eR32G32B32Sint : return "R32G32B32Sint";
      case Format::eR32G32B32Sfloat : return "R32G32B32Sfloat";
      case Format::eR32G32B32A32Uint : return "R32G32B32A32Uint";
      case Format::eR32G32B32A32Sint : return "R32G32B32A32Sint";
      case Format::eR32G32B32A32Sfloat : return "R32G32B32A32Sfloat";
      case Format::eR64Uint : return "R64Uint";
      case Format::eR64Sint : return "R64Sint";
      case Format::eR64Sfloat : return "R64Sfloat";
      case Format::eR64G64Uint : return "R64G64Uint";
      case Format::eR64G64Sint : return "R64G64Sint";
      case Format::eR64G64Sfloat : return "R64G64Sfloat";
      case Format::eR64G64B64Uint : return "R64G64B64Uint";
      case Format::eR64G64B64Sint : return "R64G64B64Sint";
      case Format::eR64G64B64Sfloat : return "R64G64B64Sfloat";
      case Format::eR64G64B64A64Uint : return "R64G64B64A64Uint";
      case Format::eR64G64B64A64Sint : return "R64G64B64A64Sint";
      case Format::eR64G64B64A64Sfloat : return "R64G64B64A64Sfloat";
      case Format::eB10G11R11UfloatPack32 : return "B10G11R11UfloatPack32";
      case Format::eE5B9G9R9UfloatPack32 : return "E5B9G9R9UfloatPack32";
      case Format::eD16Unorm : return "D16Unorm";
      case Format::eX8D24UnormPack32 : return "X8D24UnormPack32";
      case Format::eD32Sfloat : return "D32Sfloat";
      case Format::eS8Uint : return "S8Uint";
      case Format::eD16UnormS8Uint : return "D16UnormS8Uint";
      case Format::eD24UnormS8Uint : return "D24UnormS8Uint";
      case Format::eD32SfloatS8Uint : return "D32SfloatS8Uint";
      case Format::eBc1RgbUnormBlock : return "Bc1RgbUnormBlock";
      case Format::eBc1RgbSrgbBlock : return "Bc1RgbSrgbBlock";
      case Format::eBc1RgbaUnormBlock : return "Bc1RgbaUnormBlock";
      case Format::eBc1RgbaSrgbBlock : return "Bc1RgbaSrgbBlock";
      case Format::eBc2UnormBlock : return "Bc2UnormBlock";
      case Format::eBc2SrgbBlock : return "Bc2SrgbBlock";
      case Format::eBc3UnormBlock : return "Bc3UnormBlock";
      case Format::eBc3SrgbBlock : return "Bc3SrgbBlock";
      case Format::eBc4UnormBlock : return "Bc4UnormBlock";
      case Format::eBc4SnormBlock : return "Bc4SnormBlock";
      case Format::eBc5UnormBlock : return "Bc5UnormBlock";
      case Format::eBc5SnormBlock : return "Bc5SnormBlock";
      case Format::eBc6HUfloatBlock : return "Bc6HUfloatBlock";
      case Format::eBc6HSfloatBlock : return "Bc6HSfloatBlock";
      case Format::eBc7UnormBlock : return "Bc7UnormBlock";
      case Format::eBc7SrgbBlock : return "Bc7SrgbBlock";
      case Format::eEtc2R8G8B8UnormBlock : return "Etc2R8G8B8UnormBlock";
      case Format::eEtc2R8G8B8SrgbBlock : return "Etc2R8G8B8SrgbBlock";
      case Format::eEtc2R8G8B8A1UnormBlock : return "Etc2R8G8B8A1UnormBlock";
      case Format::eEtc2R8G8B8A1SrgbBlock : return "Etc2R8G8B8A1SrgbBlock";
      case Format::eEtc2R8G8B8A8UnormBlock : return "Etc2R8G8B8A8UnormBlock";
      case Format::eEtc2R8G8B8A8SrgbBlock : return "Etc2R8G8B8A8SrgbBlock";
      case Format::eEacR11UnormBlock : return "EacR11UnormBlock";
      case Format::eEacR11SnormBlock : return "EacR11SnormBlock";
      case Format::eEacR11G11UnormBlock : return "EacR11G11UnormBlock";
      case Format::eEacR11G11SnormBlock : return "EacR11G11SnormBlock";
      case Format::eAstc4x4UnormBlock : return "Astc4x4UnormBlock";
      case Format::eAstc4x4SrgbBlock : return "Astc4x4SrgbBlock";
      case Format::eAstc5x4UnormBlock : return "Astc5x4UnormBlock";
      case Format::eAstc5x4SrgbBlock : return "Astc5x4SrgbBlock";
      case Format::eAstc5x5UnormBlock : return "Astc5x5UnormBlock";
      case Format::eAstc5x5SrgbBlock : return "Astc5x5SrgbBlock";
      case Format::eAstc6x5UnormBlock : return "Astc6x5UnormBlock";
      case Format::eAstc6x5SrgbBlock : return "Astc6x5SrgbBlock";
      case Format::eAstc6x6UnormBlock : return "Astc6x6UnormBlock";
      case Format::eAstc6x6SrgbBlock : return "Astc6x6SrgbBlock";
      case Format::eAstc8x5UnormBlock : return "Astc8x5UnormBlock";
      case Format::eAstc8x5SrgbBlock : return "Astc8x5SrgbBlock";
      case Format::eAstc8x6UnormBlock : return "Astc8x6UnormBlock";
      case Format::eAstc8x6SrgbBlock : return "Astc8x6SrgbBlock";
      case Format::eAstc8x8UnormBlock : return "Astc8x8UnormBlock";
      case Format::eAstc8x8SrgbBlock : return "Astc8x8SrgbBlock";
      case Format::eAstc10x5UnormBlock : return "Astc10x5UnormBlock";
      case Format::eAstc10x5SrgbBlock : return "Astc10x5SrgbBlock";
      case Format::eAstc10x6UnormBlock : return "Astc10x6UnormBlock";
      case Format::eAstc10x6SrgbBlock : return "Astc10x6SrgbBlock";
      case Format::eAstc10x8UnormBlock : return "Astc10x8UnormBlock";
      case Format::eAstc10x8SrgbBlock : return "Astc10x8SrgbBlock";
      case Format::eAstc10x10UnormBlock : return "Astc10x10UnormBlock";
      case Format::eAstc10x10SrgbBlock : return "Astc10x10SrgbBlock";
      case Format::eAstc12x10UnormBlock : return "Astc12x10UnormBlock";
      case Format::eAstc12x10SrgbBlock : return "Astc12x10SrgbBlock";
      case Format::eAstc12x12UnormBlock : return "Astc12x12UnormBlock";
      case Format::eAstc12x12SrgbBlock : return "Astc12x12SrgbBlock";
      case Format::eG8B8G8R8422Unorm : return "G8B8G8R8422Unorm";
      case Format::eB8G8R8G8422Unorm : return "B8G8R8G8422Unorm";
      case Format::eG8B8R83Plane420Unorm : return "G8B8R83Plane420Unorm";
      case Format::eG8B8R82Plane420Unorm : return "G8B8R82Plane420Unorm";
      case Format::eG8B8R83Plane422Unorm : return "G8B8R83Plane422Unorm";
      case Format::eG8B8R82Plane422Unorm : return "G8B8R82Plane422Unorm";
      case Format::eG8B8R83Plane444Unorm : return "G8B8R83Plane444Unorm";
      case Format::eR10X6UnormPack16 : return "R10X6UnormPack16";
      case Format::eR10X6G10X6Unorm2Pack16 : return "R10X6G10X6Unorm2Pack16";
      case Format::eR10X6G10X6B10X6A10X6Unorm4Pack16 : return "R10X6G10X6B10X6A10X6Unorm4Pack16";
      case Format::eG10X6B10X6G10X6R10X6422Unorm4Pack16 : return "G10X6B10X6G10X6R10X6422Unorm4Pack16";
      case Format::eB10X6G10X6R10X6G10X6422Unorm4Pack16 : return "B10X6G10X6R10X6G10X6422Unorm4Pack16";
      case Format::eG10X6B10X6R10X63Plane420Unorm3Pack16 : return "G10X6B10X6R10X63Plane420Unorm3Pack16";
      case Format::eG10X6B10X6R10X62Plane420Unorm3Pack16 : return "G10X6B10X6R10X62Plane420Unorm3Pack16";
      case Format::eG10X6B10X6R10X63Plane422Unorm3Pack16 : return "G10X6B10X6R10X63Plane422Unorm3Pack16";
      case Format::eG10X6B10X6R10X62Plane422Unorm3Pack16 : return "G10X6B10X6R10X62Plane422Unorm3Pack16";
      case Format::eG10X6B10X6R10X63Plane444Unorm3Pack16 : return "G10X6B10X6R10X63Plane444Unorm3Pack16";
      case Format::eR12X4UnormPack16 : return "R12X4UnormPack16";
      case Format::eR12X4G12X4Unorm2Pack16 : return "R12X4G12X4Unorm2Pack16";
      case Format::eR12X4G12X4B12X4A12X4Unorm4Pack16 : return "R12X4G12X4B12X4A12X4Unorm4Pack16";
      case Format::eG12X4B12X4G12X4R12X4422Unorm4Pack16 : return "G12X4B12X4G12X4R12X4422Unorm4Pack16";
      case Format::eB12X4G12X4R12X4G12X4422Unorm4Pack16 : return "B12X4G12X4R12X4G12X4422Unorm4Pack16";
      case Format::eG12X4B12X4R12X43Plane420Unorm3Pack16 : return "G12X4B12X4R12X43Plane420Unorm3Pack16";
      case Format::eG12X4B12X4R12X42Plane420Unorm3Pack16 : return "G12X4B12X4R12X42Plane420Unorm3Pack16";
      case Format::eG12X4B12X4R12X43Plane422Unorm3Pack16 : return "G12X4B12X4R12X43Plane422Unorm3Pack16";
      case Format::eG12X4B12X4R12X42Plane422Unorm3Pack16 : return "G12X4B12X4R12X42Plane422Unorm3Pack16";
      case Format::eG12X4B12X4R12X43Plane444Unorm3Pack16 : return "G12X4B12X4R12X43Plane444Unorm3Pack16";
      case Format::eG16B16G16R16422Unorm : return "G16B16G16R16422Unorm";
      case Format::eB16G16R16G16422Unorm : return "B16G16R16G16422Unorm";
      case Format::eG16B16R163Plane420Unorm : return "G16B16R163Plane420Unorm";
      case Format::eG16B16R162Plane420Unorm : return "G16B16R162Plane420Unorm";
      case Format::eG16B16R163Plane422Unorm : return "G16B16R163Plane422Unorm";
      case Format::eG16B16R162Plane422Unorm : return "G16B16R162Plane422Unorm";
      case Format::eG16B16R163Plane444Unorm : return "G16B16R163Plane444Unorm";
      case Format::ePvrtc12BppUnormBlockIMG : return "Pvrtc12BppUnormBlockIMG";
      case Format::ePvrtc14BppUnormBlockIMG : return "Pvrtc14BppUnormBlockIMG";
      case Format::ePvrtc22BppUnormBlockIMG : return "Pvrtc22BppUnormBlockIMG";
      case Format::ePvrtc24BppUnormBlockIMG : return "Pvrtc24BppUnormBlockIMG";
      case Format::ePvrtc12BppSrgbBlockIMG : return "Pvrtc12BppSrgbBlockIMG";
      case Format::ePvrtc14BppSrgbBlockIMG : return "Pvrtc14BppSrgbBlockIMG";
      case Format::ePvrtc22BppSrgbBlockIMG : return "Pvrtc22BppSrgbBlockIMG";
      case Format::ePvrtc24BppSrgbBlockIMG : return "Pvrtc24BppSrgbBlockIMG";
      case Format::eAstc4x4SfloatBlockEXT : return "Astc4x4SfloatBlockEXT";
      case Format::eAstc5x4SfloatBlockEXT : return "Astc5x4SfloatBlockEXT";
      case Format::eAstc5x5SfloatBlockEXT : return "Astc5x5SfloatBlockEXT";
      case Format::eAstc6x5SfloatBlockEXT : return "Astc6x5SfloatBlockEXT";
      case Format::eAstc6x6SfloatBlockEXT : return "Astc6x6SfloatBlockEXT";
      case Format::eAstc8x5SfloatBlockEXT : return "Astc8x5SfloatBlockEXT";
      case Format::eAstc8x6SfloatBlockEXT : return "Astc8x6SfloatBlockEXT";
      case Format::eAstc8x8SfloatBlockEXT : return "Astc8x8SfloatBlockEXT";
      case Format::eAstc10x5SfloatBlockEXT : return "Astc10x5SfloatBlockEXT";
      case Format::eAstc10x6SfloatBlockEXT : return "Astc10x6SfloatBlockEXT";
      case Format::eAstc10x8SfloatBlockEXT : return "Astc10x8SfloatBlockEXT";
      case Format::eAstc10x10SfloatBlockEXT : return "Astc10x10SfloatBlockEXT";
      case Format::eAstc12x10SfloatBlockEXT : return "Astc12x10SfloatBlockEXT";
      case Format::eAstc12x12SfloatBlockEXT : return "Astc12x12SfloatBlockEXT";
      default: return "invalid";
    }
  }

  enum class FrontFace
  {
    eCounterClockwise = VK_FRONT_FACE_COUNTER_CLOCKWISE,
    eClockwise = VK_FRONT_FACE_CLOCKWISE
  };

  VULKAN_HPP_INLINE std::string to_string( FrontFace value )
  {
    switch ( value )
    {
      case FrontFace::eCounterClockwise : return "CounterClockwise";
      case FrontFace::eClockwise : return "Clockwise";
      default: return "invalid";
    }
  }

#ifdef VK_USE_PLATFORM_WIN32_KHR
  enum class FullScreenExclusiveEXT
  {
    eDefault = VK_FULL_SCREEN_EXCLUSIVE_DEFAULT_EXT,
    eAllowed = VK_FULL_SCREEN_EXCLUSIVE_ALLOWED_EXT,
    eDisallowed = VK_FULL_SCREEN_EXCLUSIVE_DISALLOWED_EXT,
    eApplicationControlled = VK_FULL_SCREEN_EXCLUSIVE_APPLICATION_CONTROLLED_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( FullScreenExclusiveEXT value )
  {
    switch ( value )
    {
      case FullScreenExclusiveEXT::eDefault : return "Default";
      case FullScreenExclusiveEXT::eAllowed : return "Allowed";
      case FullScreenExclusiveEXT::eDisallowed : return "Disallowed";
      case FullScreenExclusiveEXT::eApplicationControlled : return "ApplicationControlled";
      default: return "invalid";
    }
  }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  enum class GeometryTypeNV
  {
    eTriangles = VK_GEOMETRY_TYPE_TRIANGLES_NV,
    eAabbs = VK_GEOMETRY_TYPE_AABBS_NV
  };

  VULKAN_HPP_INLINE std::string to_string( GeometryTypeNV value )
  {
    switch ( value )
    {
      case GeometryTypeNV::eTriangles : return "Triangles";
      case GeometryTypeNV::eAabbs : return "Aabbs";
      default: return "invalid";
    }
  }

  enum class ImageLayout
  {
    eUndefined = VK_IMAGE_LAYOUT_UNDEFINED,
    eGeneral = VK_IMAGE_LAYOUT_GENERAL,
    eColorAttachmentOptimal = VK_IMAGE_LAYOUT_COLOR_ATTACHMENT_OPTIMAL,
    eDepthStencilAttachmentOptimal = VK_IMAGE_LAYOUT_DEPTH_STENCIL_ATTACHMENT_OPTIMAL,
    eDepthStencilReadOnlyOptimal = VK_IMAGE_LAYOUT_DEPTH_STENCIL_READ_ONLY_OPTIMAL,
    eShaderReadOnlyOptimal = VK_IMAGE_LAYOUT_SHADER_READ_ONLY_OPTIMAL,
    eTransferSrcOptimal = VK_IMAGE_LAYOUT_TRANSFER_SRC_OPTIMAL,
    eTransferDstOptimal = VK_IMAGE_LAYOUT_TRANSFER_DST_OPTIMAL,
    ePreinitialized = VK_IMAGE_LAYOUT_PREINITIALIZED,
    eDepthReadOnlyStencilAttachmentOptimal = VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL,
    eDepthAttachmentStencilReadOnlyOptimal = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL,
    ePresentSrcKHR = VK_IMAGE_LAYOUT_PRESENT_SRC_KHR,
    eSharedPresentKHR = VK_IMAGE_LAYOUT_SHARED_PRESENT_KHR,
    eShadingRateOptimalNV = VK_IMAGE_LAYOUT_SHADING_RATE_OPTIMAL_NV,
    eFragmentDensityMapOptimalEXT = VK_IMAGE_LAYOUT_FRAGMENT_DENSITY_MAP_OPTIMAL_EXT,
    eDepthReadOnlyStencilAttachmentOptimalKHR = VK_IMAGE_LAYOUT_DEPTH_READ_ONLY_STENCIL_ATTACHMENT_OPTIMAL_KHR,
    eDepthAttachmentStencilReadOnlyOptimalKHR = VK_IMAGE_LAYOUT_DEPTH_ATTACHMENT_STENCIL_READ_ONLY_OPTIMAL_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ImageLayout value )
  {
    switch ( value )
    {
      case ImageLayout::eUndefined : return "Undefined";
      case ImageLayout::eGeneral : return "General";
      case ImageLayout::eColorAttachmentOptimal : return "ColorAttachmentOptimal";
      case ImageLayout::eDepthStencilAttachmentOptimal : return "DepthStencilAttachmentOptimal";
      case ImageLayout::eDepthStencilReadOnlyOptimal : return "DepthStencilReadOnlyOptimal";
      case ImageLayout::eShaderReadOnlyOptimal : return "ShaderReadOnlyOptimal";
      case ImageLayout::eTransferSrcOptimal : return "TransferSrcOptimal";
      case ImageLayout::eTransferDstOptimal : return "TransferDstOptimal";
      case ImageLayout::ePreinitialized : return "Preinitialized";
      case ImageLayout::eDepthReadOnlyStencilAttachmentOptimal : return "DepthReadOnlyStencilAttachmentOptimal";
      case ImageLayout::eDepthAttachmentStencilReadOnlyOptimal : return "DepthAttachmentStencilReadOnlyOptimal";
      case ImageLayout::ePresentSrcKHR : return "PresentSrcKHR";
      case ImageLayout::eSharedPresentKHR : return "SharedPresentKHR";
      case ImageLayout::eShadingRateOptimalNV : return "ShadingRateOptimalNV";
      case ImageLayout::eFragmentDensityMapOptimalEXT : return "FragmentDensityMapOptimalEXT";
      default: return "invalid";
    }
  }

  enum class ImageTiling
  {
    eOptimal = VK_IMAGE_TILING_OPTIMAL,
    eLinear = VK_IMAGE_TILING_LINEAR,
    eDrmFormatModifierEXT = VK_IMAGE_TILING_DRM_FORMAT_MODIFIER_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ImageTiling value )
  {
    switch ( value )
    {
      case ImageTiling::eOptimal : return "Optimal";
      case ImageTiling::eLinear : return "Linear";
      case ImageTiling::eDrmFormatModifierEXT : return "DrmFormatModifierEXT";
      default: return "invalid";
    }
  }

  enum class ImageType
  {
    e1D = VK_IMAGE_TYPE_1D,
    e2D = VK_IMAGE_TYPE_2D,
    e3D = VK_IMAGE_TYPE_3D
  };

  VULKAN_HPP_INLINE std::string to_string( ImageType value )
  {
    switch ( value )
    {
      case ImageType::e1D : return "1D";
      case ImageType::e2D : return "2D";
      case ImageType::e3D : return "3D";
      default: return "invalid";
    }
  }

  enum class ImageViewType
  {
    e1D = VK_IMAGE_VIEW_TYPE_1D,
    e2D = VK_IMAGE_VIEW_TYPE_2D,
    e3D = VK_IMAGE_VIEW_TYPE_3D,
    eCube = VK_IMAGE_VIEW_TYPE_CUBE,
    e1DArray = VK_IMAGE_VIEW_TYPE_1D_ARRAY,
    e2DArray = VK_IMAGE_VIEW_TYPE_2D_ARRAY,
    eCubeArray = VK_IMAGE_VIEW_TYPE_CUBE_ARRAY
  };

  VULKAN_HPP_INLINE std::string to_string( ImageViewType value )
  {
    switch ( value )
    {
      case ImageViewType::e1D : return "1D";
      case ImageViewType::e2D : return "2D";
      case ImageViewType::e3D : return "3D";
      case ImageViewType::eCube : return "Cube";
      case ImageViewType::e1DArray : return "1DArray";
      case ImageViewType::e2DArray : return "2DArray";
      case ImageViewType::eCubeArray : return "CubeArray";
      default: return "invalid";
    }
  }

  enum class IndexType
  {
    eUint16 = VK_INDEX_TYPE_UINT16,
    eUint32 = VK_INDEX_TYPE_UINT32,
    eNoneNV = VK_INDEX_TYPE_NONE_NV,
    eUint8EXT = VK_INDEX_TYPE_UINT8_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( IndexType value )
  {
    switch ( value )
    {
      case IndexType::eUint16 : return "Uint16";
      case IndexType::eUint32 : return "Uint32";
      case IndexType::eNoneNV : return "NoneNV";
      case IndexType::eUint8EXT : return "Uint8EXT";
      default: return "invalid";
    }
  }

  enum class IndirectCommandsTokenTypeNVX
  {
    ePipeline = VK_INDIRECT_COMMANDS_TOKEN_TYPE_PIPELINE_NVX,
    eDescriptorSet = VK_INDIRECT_COMMANDS_TOKEN_TYPE_DESCRIPTOR_SET_NVX,
    eIndexBuffer = VK_INDIRECT_COMMANDS_TOKEN_TYPE_INDEX_BUFFER_NVX,
    eVertexBuffer = VK_INDIRECT_COMMANDS_TOKEN_TYPE_VERTEX_BUFFER_NVX,
    ePushConstant = VK_INDIRECT_COMMANDS_TOKEN_TYPE_PUSH_CONSTANT_NVX,
    eDrawIndexed = VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_INDEXED_NVX,
    eDraw = VK_INDIRECT_COMMANDS_TOKEN_TYPE_DRAW_NVX,
    eDispatch = VK_INDIRECT_COMMANDS_TOKEN_TYPE_DISPATCH_NVX
  };

  VULKAN_HPP_INLINE std::string to_string( IndirectCommandsTokenTypeNVX value )
  {
    switch ( value )
    {
      case IndirectCommandsTokenTypeNVX::ePipeline : return "Pipeline";
      case IndirectCommandsTokenTypeNVX::eDescriptorSet : return "DescriptorSet";
      case IndirectCommandsTokenTypeNVX::eIndexBuffer : return "IndexBuffer";
      case IndirectCommandsTokenTypeNVX::eVertexBuffer : return "VertexBuffer";
      case IndirectCommandsTokenTypeNVX::ePushConstant : return "PushConstant";
      case IndirectCommandsTokenTypeNVX::eDrawIndexed : return "DrawIndexed";
      case IndirectCommandsTokenTypeNVX::eDraw : return "Draw";
      case IndirectCommandsTokenTypeNVX::eDispatch : return "Dispatch";
      default: return "invalid";
    }
  }

  enum class InternalAllocationType
  {
    eExecutable = VK_INTERNAL_ALLOCATION_TYPE_EXECUTABLE
  };

  VULKAN_HPP_INLINE std::string to_string( InternalAllocationType value )
  {
    switch ( value )
    {
      case InternalAllocationType::eExecutable : return "Executable";
      default: return "invalid";
    }
  }

  enum class LineRasterizationModeEXT
  {
    eDefault = VK_LINE_RASTERIZATION_MODE_DEFAULT_EXT,
    eRectangular = VK_LINE_RASTERIZATION_MODE_RECTANGULAR_EXT,
    eBresenham = VK_LINE_RASTERIZATION_MODE_BRESENHAM_EXT,
    eRectangularSmooth = VK_LINE_RASTERIZATION_MODE_RECTANGULAR_SMOOTH_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( LineRasterizationModeEXT value )
  {
    switch ( value )
    {
      case LineRasterizationModeEXT::eDefault : return "Default";
      case LineRasterizationModeEXT::eRectangular : return "Rectangular";
      case LineRasterizationModeEXT::eBresenham : return "Bresenham";
      case LineRasterizationModeEXT::eRectangularSmooth : return "RectangularSmooth";
      default: return "invalid";
    }
  }

  enum class LogicOp
  {
    eClear = VK_LOGIC_OP_CLEAR,
    eAnd = VK_LOGIC_OP_AND,
    eAndReverse = VK_LOGIC_OP_AND_REVERSE,
    eCopy = VK_LOGIC_OP_COPY,
    eAndInverted = VK_LOGIC_OP_AND_INVERTED,
    eNoOp = VK_LOGIC_OP_NO_OP,
    eXor = VK_LOGIC_OP_XOR,
    eOr = VK_LOGIC_OP_OR,
    eNor = VK_LOGIC_OP_NOR,
    eEquivalent = VK_LOGIC_OP_EQUIVALENT,
    eInvert = VK_LOGIC_OP_INVERT,
    eOrReverse = VK_LOGIC_OP_OR_REVERSE,
    eCopyInverted = VK_LOGIC_OP_COPY_INVERTED,
    eOrInverted = VK_LOGIC_OP_OR_INVERTED,
    eNand = VK_LOGIC_OP_NAND,
    eSet = VK_LOGIC_OP_SET
  };

  VULKAN_HPP_INLINE std::string to_string( LogicOp value )
  {
    switch ( value )
    {
      case LogicOp::eClear : return "Clear";
      case LogicOp::eAnd : return "And";
      case LogicOp::eAndReverse : return "AndReverse";
      case LogicOp::eCopy : return "Copy";
      case LogicOp::eAndInverted : return "AndInverted";
      case LogicOp::eNoOp : return "NoOp";
      case LogicOp::eXor : return "Xor";
      case LogicOp::eOr : return "Or";
      case LogicOp::eNor : return "Nor";
      case LogicOp::eEquivalent : return "Equivalent";
      case LogicOp::eInvert : return "Invert";
      case LogicOp::eOrReverse : return "OrReverse";
      case LogicOp::eCopyInverted : return "CopyInverted";
      case LogicOp::eOrInverted : return "OrInverted";
      case LogicOp::eNand : return "Nand";
      case LogicOp::eSet : return "Set";
      default: return "invalid";
    }
  }

  enum class MemoryOverallocationBehaviorAMD
  {
    eDefault = VK_MEMORY_OVERALLOCATION_BEHAVIOR_DEFAULT_AMD,
    eAllowed = VK_MEMORY_OVERALLOCATION_BEHAVIOR_ALLOWED_AMD,
    eDisallowed = VK_MEMORY_OVERALLOCATION_BEHAVIOR_DISALLOWED_AMD
  };

  VULKAN_HPP_INLINE std::string to_string( MemoryOverallocationBehaviorAMD value )
  {
    switch ( value )
    {
      case MemoryOverallocationBehaviorAMD::eDefault : return "Default";
      case MemoryOverallocationBehaviorAMD::eAllowed : return "Allowed";
      case MemoryOverallocationBehaviorAMD::eDisallowed : return "Disallowed";
      default: return "invalid";
    }
  }

  enum class ObjectEntryTypeNVX
  {
    eDescriptorSet = VK_OBJECT_ENTRY_TYPE_DESCRIPTOR_SET_NVX,
    ePipeline = VK_OBJECT_ENTRY_TYPE_PIPELINE_NVX,
    eIndexBuffer = VK_OBJECT_ENTRY_TYPE_INDEX_BUFFER_NVX,
    eVertexBuffer = VK_OBJECT_ENTRY_TYPE_VERTEX_BUFFER_NVX,
    ePushConstant = VK_OBJECT_ENTRY_TYPE_PUSH_CONSTANT_NVX
  };

  VULKAN_HPP_INLINE std::string to_string( ObjectEntryTypeNVX value )
  {
    switch ( value )
    {
      case ObjectEntryTypeNVX::eDescriptorSet : return "DescriptorSet";
      case ObjectEntryTypeNVX::ePipeline : return "Pipeline";
      case ObjectEntryTypeNVX::eIndexBuffer : return "IndexBuffer";
      case ObjectEntryTypeNVX::eVertexBuffer : return "VertexBuffer";
      case ObjectEntryTypeNVX::ePushConstant : return "PushConstant";
      default: return "invalid";
    }
  }

  enum class ObjectType
  {
    eUnknown = VK_OBJECT_TYPE_UNKNOWN,
    eInstance = VK_OBJECT_TYPE_INSTANCE,
    ePhysicalDevice = VK_OBJECT_TYPE_PHYSICAL_DEVICE,
    eDevice = VK_OBJECT_TYPE_DEVICE,
    eQueue = VK_OBJECT_TYPE_QUEUE,
    eSemaphore = VK_OBJECT_TYPE_SEMAPHORE,
    eCommandBuffer = VK_OBJECT_TYPE_COMMAND_BUFFER,
    eFence = VK_OBJECT_TYPE_FENCE,
    eDeviceMemory = VK_OBJECT_TYPE_DEVICE_MEMORY,
    eBuffer = VK_OBJECT_TYPE_BUFFER,
    eImage = VK_OBJECT_TYPE_IMAGE,
    eEvent = VK_OBJECT_TYPE_EVENT,
    eQueryPool = VK_OBJECT_TYPE_QUERY_POOL,
    eBufferView = VK_OBJECT_TYPE_BUFFER_VIEW,
    eImageView = VK_OBJECT_TYPE_IMAGE_VIEW,
    eShaderModule = VK_OBJECT_TYPE_SHADER_MODULE,
    ePipelineCache = VK_OBJECT_TYPE_PIPELINE_CACHE,
    ePipelineLayout = VK_OBJECT_TYPE_PIPELINE_LAYOUT,
    eRenderPass = VK_OBJECT_TYPE_RENDER_PASS,
    ePipeline = VK_OBJECT_TYPE_PIPELINE,
    eDescriptorSetLayout = VK_OBJECT_TYPE_DESCRIPTOR_SET_LAYOUT,
    eSampler = VK_OBJECT_TYPE_SAMPLER,
    eDescriptorPool = VK_OBJECT_TYPE_DESCRIPTOR_POOL,
    eDescriptorSet = VK_OBJECT_TYPE_DESCRIPTOR_SET,
    eFramebuffer = VK_OBJECT_TYPE_FRAMEBUFFER,
    eCommandPool = VK_OBJECT_TYPE_COMMAND_POOL,
    eSamplerYcbcrConversion = VK_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION,
    eDescriptorUpdateTemplate = VK_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE,
    eSurfaceKHR = VK_OBJECT_TYPE_SURFACE_KHR,
    eSwapchainKHR = VK_OBJECT_TYPE_SWAPCHAIN_KHR,
    eDisplayKHR = VK_OBJECT_TYPE_DISPLAY_KHR,
    eDisplayModeKHR = VK_OBJECT_TYPE_DISPLAY_MODE_KHR,
    eDebugReportCallbackEXT = VK_OBJECT_TYPE_DEBUG_REPORT_CALLBACK_EXT,
    eObjectTableNVX = VK_OBJECT_TYPE_OBJECT_TABLE_NVX,
    eIndirectCommandsLayoutNVX = VK_OBJECT_TYPE_INDIRECT_COMMANDS_LAYOUT_NVX,
    eDebugUtilsMessengerEXT = VK_OBJECT_TYPE_DEBUG_UTILS_MESSENGER_EXT,
    eValidationCacheEXT = VK_OBJECT_TYPE_VALIDATION_CACHE_EXT,
    eAccelerationStructureNV = VK_OBJECT_TYPE_ACCELERATION_STRUCTURE_NV,
    ePerformanceConfigurationINTEL = VK_OBJECT_TYPE_PERFORMANCE_CONFIGURATION_INTEL,
    eDescriptorUpdateTemplateKHR = VK_OBJECT_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_KHR,
    eSamplerYcbcrConversionKHR = VK_OBJECT_TYPE_SAMPLER_YCBCR_CONVERSION_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ObjectType value )
  {
    switch ( value )
    {
      case ObjectType::eUnknown : return "Unknown";
      case ObjectType::eInstance : return "Instance";
      case ObjectType::ePhysicalDevice : return "PhysicalDevice";
      case ObjectType::eDevice : return "Device";
      case ObjectType::eQueue : return "Queue";
      case ObjectType::eSemaphore : return "Semaphore";
      case ObjectType::eCommandBuffer : return "CommandBuffer";
      case ObjectType::eFence : return "Fence";
      case ObjectType::eDeviceMemory : return "DeviceMemory";
      case ObjectType::eBuffer : return "Buffer";
      case ObjectType::eImage : return "Image";
      case ObjectType::eEvent : return "Event";
      case ObjectType::eQueryPool : return "QueryPool";
      case ObjectType::eBufferView : return "BufferView";
      case ObjectType::eImageView : return "ImageView";
      case ObjectType::eShaderModule : return "ShaderModule";
      case ObjectType::ePipelineCache : return "PipelineCache";
      case ObjectType::ePipelineLayout : return "PipelineLayout";
      case ObjectType::eRenderPass : return "RenderPass";
      case ObjectType::ePipeline : return "Pipeline";
      case ObjectType::eDescriptorSetLayout : return "DescriptorSetLayout";
      case ObjectType::eSampler : return "Sampler";
      case ObjectType::eDescriptorPool : return "DescriptorPool";
      case ObjectType::eDescriptorSet : return "DescriptorSet";
      case ObjectType::eFramebuffer : return "Framebuffer";
      case ObjectType::eCommandPool : return "CommandPool";
      case ObjectType::eSamplerYcbcrConversion : return "SamplerYcbcrConversion";
      case ObjectType::eDescriptorUpdateTemplate : return "DescriptorUpdateTemplate";
      case ObjectType::eSurfaceKHR : return "SurfaceKHR";
      case ObjectType::eSwapchainKHR : return "SwapchainKHR";
      case ObjectType::eDisplayKHR : return "DisplayKHR";
      case ObjectType::eDisplayModeKHR : return "DisplayModeKHR";
      case ObjectType::eDebugReportCallbackEXT : return "DebugReportCallbackEXT";
      case ObjectType::eObjectTableNVX : return "ObjectTableNVX";
      case ObjectType::eIndirectCommandsLayoutNVX : return "IndirectCommandsLayoutNVX";
      case ObjectType::eDebugUtilsMessengerEXT : return "DebugUtilsMessengerEXT";
      case ObjectType::eValidationCacheEXT : return "ValidationCacheEXT";
      case ObjectType::eAccelerationStructureNV : return "AccelerationStructureNV";
      case ObjectType::ePerformanceConfigurationINTEL : return "PerformanceConfigurationINTEL";
      default: return "invalid";
    }
  }

  enum class PerformanceConfigurationTypeINTEL
  {
    eCommandQueueMetricsDiscoveryActivated = VK_PERFORMANCE_CONFIGURATION_TYPE_COMMAND_QUEUE_METRICS_DISCOVERY_ACTIVATED_INTEL
  };

  VULKAN_HPP_INLINE std::string to_string( PerformanceConfigurationTypeINTEL value )
  {
    switch ( value )
    {
      case PerformanceConfigurationTypeINTEL::eCommandQueueMetricsDiscoveryActivated : return "CommandQueueMetricsDiscoveryActivated";
      default: return "invalid";
    }
  }

  enum class PerformanceOverrideTypeINTEL
  {
    eNullHardware = VK_PERFORMANCE_OVERRIDE_TYPE_NULL_HARDWARE_INTEL,
    eFlushGpuCaches = VK_PERFORMANCE_OVERRIDE_TYPE_FLUSH_GPU_CACHES_INTEL
  };

  VULKAN_HPP_INLINE std::string to_string( PerformanceOverrideTypeINTEL value )
  {
    switch ( value )
    {
      case PerformanceOverrideTypeINTEL::eNullHardware : return "NullHardware";
      case PerformanceOverrideTypeINTEL::eFlushGpuCaches : return "FlushGpuCaches";
      default: return "invalid";
    }
  }

  enum class PerformanceParameterTypeINTEL
  {
    eHwCountersSupported = VK_PERFORMANCE_PARAMETER_TYPE_HW_COUNTERS_SUPPORTED_INTEL,
    eStreamMarkerValidBits = VK_PERFORMANCE_PARAMETER_TYPE_STREAM_MARKER_VALID_BITS_INTEL
  };

  VULKAN_HPP_INLINE std::string to_string( PerformanceParameterTypeINTEL value )
  {
    switch ( value )
    {
      case PerformanceParameterTypeINTEL::eHwCountersSupported : return "HwCountersSupported";
      case PerformanceParameterTypeINTEL::eStreamMarkerValidBits : return "StreamMarkerValidBits";
      default: return "invalid";
    }
  }

  enum class PerformanceValueTypeINTEL
  {
    eUint32 = VK_PERFORMANCE_VALUE_TYPE_UINT32_INTEL,
    eUint64 = VK_PERFORMANCE_VALUE_TYPE_UINT64_INTEL,
    eFloat = VK_PERFORMANCE_VALUE_TYPE_FLOAT_INTEL,
    eBool = VK_PERFORMANCE_VALUE_TYPE_BOOL_INTEL,
    eString = VK_PERFORMANCE_VALUE_TYPE_STRING_INTEL
  };

  VULKAN_HPP_INLINE std::string to_string( PerformanceValueTypeINTEL value )
  {
    switch ( value )
    {
      case PerformanceValueTypeINTEL::eUint32 : return "Uint32";
      case PerformanceValueTypeINTEL::eUint64 : return "Uint64";
      case PerformanceValueTypeINTEL::eFloat : return "Float";
      case PerformanceValueTypeINTEL::eBool : return "Bool";
      case PerformanceValueTypeINTEL::eString : return "String";
      default: return "invalid";
    }
  }

  enum class PhysicalDeviceType
  {
    eOther = VK_PHYSICAL_DEVICE_TYPE_OTHER,
    eIntegratedGpu = VK_PHYSICAL_DEVICE_TYPE_INTEGRATED_GPU,
    eDiscreteGpu = VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU,
    eVirtualGpu = VK_PHYSICAL_DEVICE_TYPE_VIRTUAL_GPU,
    eCpu = VK_PHYSICAL_DEVICE_TYPE_CPU
  };

  VULKAN_HPP_INLINE std::string to_string( PhysicalDeviceType value )
  {
    switch ( value )
    {
      case PhysicalDeviceType::eOther : return "Other";
      case PhysicalDeviceType::eIntegratedGpu : return "IntegratedGpu";
      case PhysicalDeviceType::eDiscreteGpu : return "DiscreteGpu";
      case PhysicalDeviceType::eVirtualGpu : return "VirtualGpu";
      case PhysicalDeviceType::eCpu : return "Cpu";
      default: return "invalid";
    }
  }

  enum class PipelineBindPoint
  {
    eGraphics = VK_PIPELINE_BIND_POINT_GRAPHICS,
    eCompute = VK_PIPELINE_BIND_POINT_COMPUTE,
    eRayTracingNV = VK_PIPELINE_BIND_POINT_RAY_TRACING_NV
  };

  VULKAN_HPP_INLINE std::string to_string( PipelineBindPoint value )
  {
    switch ( value )
    {
      case PipelineBindPoint::eGraphics : return "Graphics";
      case PipelineBindPoint::eCompute : return "Compute";
      case PipelineBindPoint::eRayTracingNV : return "RayTracingNV";
      default: return "invalid";
    }
  }

  enum class PipelineCacheHeaderVersion
  {
    eOne = VK_PIPELINE_CACHE_HEADER_VERSION_ONE
  };

  VULKAN_HPP_INLINE std::string to_string( PipelineCacheHeaderVersion value )
  {
    switch ( value )
    {
      case PipelineCacheHeaderVersion::eOne : return "One";
      default: return "invalid";
    }
  }

  enum class PipelineExecutableStatisticFormatKHR
  {
    eBool32 = VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_BOOL32_KHR,
    eInt64 = VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_INT64_KHR,
    eUint64 = VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_UINT64_KHR,
    eFloat64 = VK_PIPELINE_EXECUTABLE_STATISTIC_FORMAT_FLOAT64_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( PipelineExecutableStatisticFormatKHR value )
  {
    switch ( value )
    {
      case PipelineExecutableStatisticFormatKHR::eBool32 : return "Bool32";
      case PipelineExecutableStatisticFormatKHR::eInt64 : return "Int64";
      case PipelineExecutableStatisticFormatKHR::eUint64 : return "Uint64";
      case PipelineExecutableStatisticFormatKHR::eFloat64 : return "Float64";
      default: return "invalid";
    }
  }

  enum class PointClippingBehavior
  {
    eAllClipPlanes = VK_POINT_CLIPPING_BEHAVIOR_ALL_CLIP_PLANES,
    eUserClipPlanesOnly = VK_POINT_CLIPPING_BEHAVIOR_USER_CLIP_PLANES_ONLY,
    eAllClipPlanesKHR = VK_POINT_CLIPPING_BEHAVIOR_ALL_CLIP_PLANES_KHR,
    eUserClipPlanesOnlyKHR = VK_POINT_CLIPPING_BEHAVIOR_USER_CLIP_PLANES_ONLY_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( PointClippingBehavior value )
  {
    switch ( value )
    {
      case PointClippingBehavior::eAllClipPlanes : return "AllClipPlanes";
      case PointClippingBehavior::eUserClipPlanesOnly : return "UserClipPlanesOnly";
      default: return "invalid";
    }
  }

  enum class PolygonMode
  {
    eFill = VK_POLYGON_MODE_FILL,
    eLine = VK_POLYGON_MODE_LINE,
    ePoint = VK_POLYGON_MODE_POINT,
    eFillRectangleNV = VK_POLYGON_MODE_FILL_RECTANGLE_NV
  };

  VULKAN_HPP_INLINE std::string to_string( PolygonMode value )
  {
    switch ( value )
    {
      case PolygonMode::eFill : return "Fill";
      case PolygonMode::eLine : return "Line";
      case PolygonMode::ePoint : return "Point";
      case PolygonMode::eFillRectangleNV : return "FillRectangleNV";
      default: return "invalid";
    }
  }

  enum class PresentModeKHR
  {
    eImmediate = VK_PRESENT_MODE_IMMEDIATE_KHR,
    eMailbox = VK_PRESENT_MODE_MAILBOX_KHR,
    eFifo = VK_PRESENT_MODE_FIFO_KHR,
    eFifoRelaxed = VK_PRESENT_MODE_FIFO_RELAXED_KHR,
    eSharedDemandRefresh = VK_PRESENT_MODE_SHARED_DEMAND_REFRESH_KHR,
    eSharedContinuousRefresh = VK_PRESENT_MODE_SHARED_CONTINUOUS_REFRESH_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( PresentModeKHR value )
  {
    switch ( value )
    {
      case PresentModeKHR::eImmediate : return "Immediate";
      case PresentModeKHR::eMailbox : return "Mailbox";
      case PresentModeKHR::eFifo : return "Fifo";
      case PresentModeKHR::eFifoRelaxed : return "FifoRelaxed";
      case PresentModeKHR::eSharedDemandRefresh : return "SharedDemandRefresh";
      case PresentModeKHR::eSharedContinuousRefresh : return "SharedContinuousRefresh";
      default: return "invalid";
    }
  }

  enum class PrimitiveTopology
  {
    ePointList = VK_PRIMITIVE_TOPOLOGY_POINT_LIST,
    eLineList = VK_PRIMITIVE_TOPOLOGY_LINE_LIST,
    eLineStrip = VK_PRIMITIVE_TOPOLOGY_LINE_STRIP,
    eTriangleList = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST,
    eTriangleStrip = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP,
    eTriangleFan = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_FAN,
    eLineListWithAdjacency = VK_PRIMITIVE_TOPOLOGY_LINE_LIST_WITH_ADJACENCY,
    eLineStripWithAdjacency = VK_PRIMITIVE_TOPOLOGY_LINE_STRIP_WITH_ADJACENCY,
    eTriangleListWithAdjacency = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST_WITH_ADJACENCY,
    eTriangleStripWithAdjacency = VK_PRIMITIVE_TOPOLOGY_TRIANGLE_STRIP_WITH_ADJACENCY,
    ePatchList = VK_PRIMITIVE_TOPOLOGY_PATCH_LIST
  };

  VULKAN_HPP_INLINE std::string to_string( PrimitiveTopology value )
  {
    switch ( value )
    {
      case PrimitiveTopology::ePointList : return "PointList";
      case PrimitiveTopology::eLineList : return "LineList";
      case PrimitiveTopology::eLineStrip : return "LineStrip";
      case PrimitiveTopology::eTriangleList : return "TriangleList";
      case PrimitiveTopology::eTriangleStrip : return "TriangleStrip";
      case PrimitiveTopology::eTriangleFan : return "TriangleFan";
      case PrimitiveTopology::eLineListWithAdjacency : return "LineListWithAdjacency";
      case PrimitiveTopology::eLineStripWithAdjacency : return "LineStripWithAdjacency";
      case PrimitiveTopology::eTriangleListWithAdjacency : return "TriangleListWithAdjacency";
      case PrimitiveTopology::eTriangleStripWithAdjacency : return "TriangleStripWithAdjacency";
      case PrimitiveTopology::ePatchList : return "PatchList";
      default: return "invalid";
    }
  }

  enum class QueryPoolSamplingModeINTEL
  {
    eManual = VK_QUERY_POOL_SAMPLING_MODE_MANUAL_INTEL
  };

  VULKAN_HPP_INLINE std::string to_string( QueryPoolSamplingModeINTEL value )
  {
    switch ( value )
    {
      case QueryPoolSamplingModeINTEL::eManual : return "Manual";
      default: return "invalid";
    }
  }

  enum class QueryType
  {
    eOcclusion = VK_QUERY_TYPE_OCCLUSION,
    ePipelineStatistics = VK_QUERY_TYPE_PIPELINE_STATISTICS,
    eTimestamp = VK_QUERY_TYPE_TIMESTAMP,
    eTransformFeedbackStreamEXT = VK_QUERY_TYPE_TRANSFORM_FEEDBACK_STREAM_EXT,
    eAccelerationStructureCompactedSizeNV = VK_QUERY_TYPE_ACCELERATION_STRUCTURE_COMPACTED_SIZE_NV,
    ePerformanceQueryINTEL = VK_QUERY_TYPE_PERFORMANCE_QUERY_INTEL
  };

  VULKAN_HPP_INLINE std::string to_string( QueryType value )
  {
    switch ( value )
    {
      case QueryType::eOcclusion : return "Occlusion";
      case QueryType::ePipelineStatistics : return "PipelineStatistics";
      case QueryType::eTimestamp : return "Timestamp";
      case QueryType::eTransformFeedbackStreamEXT : return "TransformFeedbackStreamEXT";
      case QueryType::eAccelerationStructureCompactedSizeNV : return "AccelerationStructureCompactedSizeNV";
      case QueryType::ePerformanceQueryINTEL : return "PerformanceQueryINTEL";
      default: return "invalid";
    }
  }

  enum class QueueGlobalPriorityEXT
  {
    eLow = VK_QUEUE_GLOBAL_PRIORITY_LOW_EXT,
    eMedium = VK_QUEUE_GLOBAL_PRIORITY_MEDIUM_EXT,
    eHigh = VK_QUEUE_GLOBAL_PRIORITY_HIGH_EXT,
    eRealtime = VK_QUEUE_GLOBAL_PRIORITY_REALTIME_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( QueueGlobalPriorityEXT value )
  {
    switch ( value )
    {
      case QueueGlobalPriorityEXT::eLow : return "Low";
      case QueueGlobalPriorityEXT::eMedium : return "Medium";
      case QueueGlobalPriorityEXT::eHigh : return "High";
      case QueueGlobalPriorityEXT::eRealtime : return "Realtime";
      default: return "invalid";
    }
  }

  enum class RasterizationOrderAMD
  {
    eStrict = VK_RASTERIZATION_ORDER_STRICT_AMD,
    eRelaxed = VK_RASTERIZATION_ORDER_RELAXED_AMD
  };

  VULKAN_HPP_INLINE std::string to_string( RasterizationOrderAMD value )
  {
    switch ( value )
    {
      case RasterizationOrderAMD::eStrict : return "Strict";
      case RasterizationOrderAMD::eRelaxed : return "Relaxed";
      default: return "invalid";
    }
  }

  enum class RayTracingShaderGroupTypeNV
  {
    eGeneral = VK_RAY_TRACING_SHADER_GROUP_TYPE_GENERAL_NV,
    eTrianglesHitGroup = VK_RAY_TRACING_SHADER_GROUP_TYPE_TRIANGLES_HIT_GROUP_NV,
    eProceduralHitGroup = VK_RAY_TRACING_SHADER_GROUP_TYPE_PROCEDURAL_HIT_GROUP_NV
  };

  VULKAN_HPP_INLINE std::string to_string( RayTracingShaderGroupTypeNV value )
  {
    switch ( value )
    {
      case RayTracingShaderGroupTypeNV::eGeneral : return "General";
      case RayTracingShaderGroupTypeNV::eTrianglesHitGroup : return "TrianglesHitGroup";
      case RayTracingShaderGroupTypeNV::eProceduralHitGroup : return "ProceduralHitGroup";
      default: return "invalid";
    }
  }

  enum class Result
  {
    eSuccess = VK_SUCCESS,
    eNotReady = VK_NOT_READY,
    eTimeout = VK_TIMEOUT,
    eEventSet = VK_EVENT_SET,
    eEventReset = VK_EVENT_RESET,
    eIncomplete = VK_INCOMPLETE,
    eErrorOutOfHostMemory = VK_ERROR_OUT_OF_HOST_MEMORY,
    eErrorOutOfDeviceMemory = VK_ERROR_OUT_OF_DEVICE_MEMORY,
    eErrorInitializationFailed = VK_ERROR_INITIALIZATION_FAILED,
    eErrorDeviceLost = VK_ERROR_DEVICE_LOST,
    eErrorMemoryMapFailed = VK_ERROR_MEMORY_MAP_FAILED,
    eErrorLayerNotPresent = VK_ERROR_LAYER_NOT_PRESENT,
    eErrorExtensionNotPresent = VK_ERROR_EXTENSION_NOT_PRESENT,
    eErrorFeatureNotPresent = VK_ERROR_FEATURE_NOT_PRESENT,
    eErrorIncompatibleDriver = VK_ERROR_INCOMPATIBLE_DRIVER,
    eErrorTooManyObjects = VK_ERROR_TOO_MANY_OBJECTS,
    eErrorFormatNotSupported = VK_ERROR_FORMAT_NOT_SUPPORTED,
    eErrorFragmentedPool = VK_ERROR_FRAGMENTED_POOL,
    eErrorOutOfPoolMemory = VK_ERROR_OUT_OF_POOL_MEMORY,
    eErrorInvalidExternalHandle = VK_ERROR_INVALID_EXTERNAL_HANDLE,
    eErrorSurfaceLostKHR = VK_ERROR_SURFACE_LOST_KHR,
    eErrorNativeWindowInUseKHR = VK_ERROR_NATIVE_WINDOW_IN_USE_KHR,
    eSuboptimalKHR = VK_SUBOPTIMAL_KHR,
    eErrorOutOfDateKHR = VK_ERROR_OUT_OF_DATE_KHR,
    eErrorIncompatibleDisplayKHR = VK_ERROR_INCOMPATIBLE_DISPLAY_KHR,
    eErrorValidationFailedEXT = VK_ERROR_VALIDATION_FAILED_EXT,
    eErrorInvalidShaderNV = VK_ERROR_INVALID_SHADER_NV,
    eErrorInvalidDrmFormatModifierPlaneLayoutEXT = VK_ERROR_INVALID_DRM_FORMAT_MODIFIER_PLANE_LAYOUT_EXT,
    eErrorFragmentationEXT = VK_ERROR_FRAGMENTATION_EXT,
    eErrorNotPermittedEXT = VK_ERROR_NOT_PERMITTED_EXT,
    eErrorInvalidDeviceAddressEXT = VK_ERROR_INVALID_DEVICE_ADDRESS_EXT,
    eErrorFullScreenExclusiveModeLostEXT = VK_ERROR_FULL_SCREEN_EXCLUSIVE_MODE_LOST_EXT,
    eErrorOutOfPoolMemoryKHR = VK_ERROR_OUT_OF_POOL_MEMORY_KHR,
    eErrorInvalidExternalHandleKHR = VK_ERROR_INVALID_EXTERNAL_HANDLE_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( Result value )
  {
    switch ( value )
    {
      case Result::eSuccess : return "Success";
      case Result::eNotReady : return "NotReady";
      case Result::eTimeout : return "Timeout";
      case Result::eEventSet : return "EventSet";
      case Result::eEventReset : return "EventReset";
      case Result::eIncomplete : return "Incomplete";
      case Result::eErrorOutOfHostMemory : return "ErrorOutOfHostMemory";
      case Result::eErrorOutOfDeviceMemory : return "ErrorOutOfDeviceMemory";
      case Result::eErrorInitializationFailed : return "ErrorInitializationFailed";
      case Result::eErrorDeviceLost : return "ErrorDeviceLost";
      case Result::eErrorMemoryMapFailed : return "ErrorMemoryMapFailed";
      case Result::eErrorLayerNotPresent : return "ErrorLayerNotPresent";
      case Result::eErrorExtensionNotPresent : return "ErrorExtensionNotPresent";
      case Result::eErrorFeatureNotPresent : return "ErrorFeatureNotPresent";
      case Result::eErrorIncompatibleDriver : return "ErrorIncompatibleDriver";
      case Result::eErrorTooManyObjects : return "ErrorTooManyObjects";
      case Result::eErrorFormatNotSupported : return "ErrorFormatNotSupported";
      case Result::eErrorFragmentedPool : return "ErrorFragmentedPool";
      case Result::eErrorOutOfPoolMemory : return "ErrorOutOfPoolMemory";
      case Result::eErrorInvalidExternalHandle : return "ErrorInvalidExternalHandle";
      case Result::eErrorSurfaceLostKHR : return "ErrorSurfaceLostKHR";
      case Result::eErrorNativeWindowInUseKHR : return "ErrorNativeWindowInUseKHR";
      case Result::eSuboptimalKHR : return "SuboptimalKHR";
      case Result::eErrorOutOfDateKHR : return "ErrorOutOfDateKHR";
      case Result::eErrorIncompatibleDisplayKHR : return "ErrorIncompatibleDisplayKHR";
      case Result::eErrorValidationFailedEXT : return "ErrorValidationFailedEXT";
      case Result::eErrorInvalidShaderNV : return "ErrorInvalidShaderNV";
      case Result::eErrorInvalidDrmFormatModifierPlaneLayoutEXT : return "ErrorInvalidDrmFormatModifierPlaneLayoutEXT";
      case Result::eErrorFragmentationEXT : return "ErrorFragmentationEXT";
      case Result::eErrorNotPermittedEXT : return "ErrorNotPermittedEXT";
      case Result::eErrorInvalidDeviceAddressEXT : return "ErrorInvalidDeviceAddressEXT";
      case Result::eErrorFullScreenExclusiveModeLostEXT : return "ErrorFullScreenExclusiveModeLostEXT";
      default: return "invalid";
    }
  }

  enum class SamplerAddressMode
  {
    eRepeat = VK_SAMPLER_ADDRESS_MODE_REPEAT,
    eMirroredRepeat = VK_SAMPLER_ADDRESS_MODE_MIRRORED_REPEAT,
    eClampToEdge = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_EDGE,
    eClampToBorder = VK_SAMPLER_ADDRESS_MODE_CLAMP_TO_BORDER,
    eMirrorClampToEdge = VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE,
    eMirrorClampToEdgeKHR = VK_SAMPLER_ADDRESS_MODE_MIRROR_CLAMP_TO_EDGE_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SamplerAddressMode value )
  {
    switch ( value )
    {
      case SamplerAddressMode::eRepeat : return "Repeat";
      case SamplerAddressMode::eMirroredRepeat : return "MirroredRepeat";
      case SamplerAddressMode::eClampToEdge : return "ClampToEdge";
      case SamplerAddressMode::eClampToBorder : return "ClampToBorder";
      case SamplerAddressMode::eMirrorClampToEdge : return "MirrorClampToEdge";
      default: return "invalid";
    }
  }

  enum class SamplerMipmapMode
  {
    eNearest = VK_SAMPLER_MIPMAP_MODE_NEAREST,
    eLinear = VK_SAMPLER_MIPMAP_MODE_LINEAR
  };

  VULKAN_HPP_INLINE std::string to_string( SamplerMipmapMode value )
  {
    switch ( value )
    {
      case SamplerMipmapMode::eNearest : return "Nearest";
      case SamplerMipmapMode::eLinear : return "Linear";
      default: return "invalid";
    }
  }

  enum class SamplerReductionModeEXT
  {
    eWeightedAverage = VK_SAMPLER_REDUCTION_MODE_WEIGHTED_AVERAGE_EXT,
    eMin = VK_SAMPLER_REDUCTION_MODE_MIN_EXT,
    eMax = VK_SAMPLER_REDUCTION_MODE_MAX_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( SamplerReductionModeEXT value )
  {
    switch ( value )
    {
      case SamplerReductionModeEXT::eWeightedAverage : return "WeightedAverage";
      case SamplerReductionModeEXT::eMin : return "Min";
      case SamplerReductionModeEXT::eMax : return "Max";
      default: return "invalid";
    }
  }

  enum class SamplerYcbcrModelConversion
  {
    eRgbIdentity = VK_SAMPLER_YCBCR_MODEL_CONVERSION_RGB_IDENTITY,
    eYcbcrIdentity = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_IDENTITY,
    eYcbcr709 = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_709,
    eYcbcr601 = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_601,
    eYcbcr2020 = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_2020,
    eRgbIdentityKHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_RGB_IDENTITY_KHR,
    eYcbcrIdentityKHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_IDENTITY_KHR,
    eYcbcr709KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_709_KHR,
    eYcbcr601KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_601_KHR,
    eYcbcr2020KHR = VK_SAMPLER_YCBCR_MODEL_CONVERSION_YCBCR_2020_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SamplerYcbcrModelConversion value )
  {
    switch ( value )
    {
      case SamplerYcbcrModelConversion::eRgbIdentity : return "RgbIdentity";
      case SamplerYcbcrModelConversion::eYcbcrIdentity : return "YcbcrIdentity";
      case SamplerYcbcrModelConversion::eYcbcr709 : return "Ycbcr709";
      case SamplerYcbcrModelConversion::eYcbcr601 : return "Ycbcr601";
      case SamplerYcbcrModelConversion::eYcbcr2020 : return "Ycbcr2020";
      default: return "invalid";
    }
  }

  enum class SamplerYcbcrRange
  {
    eItuFull = VK_SAMPLER_YCBCR_RANGE_ITU_FULL,
    eItuNarrow = VK_SAMPLER_YCBCR_RANGE_ITU_NARROW,
    eItuFullKHR = VK_SAMPLER_YCBCR_RANGE_ITU_FULL_KHR,
    eItuNarrowKHR = VK_SAMPLER_YCBCR_RANGE_ITU_NARROW_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SamplerYcbcrRange value )
  {
    switch ( value )
    {
      case SamplerYcbcrRange::eItuFull : return "ItuFull";
      case SamplerYcbcrRange::eItuNarrow : return "ItuNarrow";
      default: return "invalid";
    }
  }

  enum class ScopeNV
  {
    eDevice = VK_SCOPE_DEVICE_NV,
    eWorkgroup = VK_SCOPE_WORKGROUP_NV,
    eSubgroup = VK_SCOPE_SUBGROUP_NV,
    eQueueFamily = VK_SCOPE_QUEUE_FAMILY_NV
  };

  VULKAN_HPP_INLINE std::string to_string( ScopeNV value )
  {
    switch ( value )
    {
      case ScopeNV::eDevice : return "Device";
      case ScopeNV::eWorkgroup : return "Workgroup";
      case ScopeNV::eSubgroup : return "Subgroup";
      case ScopeNV::eQueueFamily : return "QueueFamily";
      default: return "invalid";
    }
  }

  enum class SemaphoreTypeKHR
  {
    eBinary = VK_SEMAPHORE_TYPE_BINARY_KHR,
    eTimeline = VK_SEMAPHORE_TYPE_TIMELINE_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SemaphoreTypeKHR value )
  {
    switch ( value )
    {
      case SemaphoreTypeKHR::eBinary : return "Binary";
      case SemaphoreTypeKHR::eTimeline : return "Timeline";
      default: return "invalid";
    }
  }

  enum class ShaderFloatControlsIndependenceKHR
  {
    e32BitOnly = VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_32_BIT_ONLY_KHR,
    eAll = VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_ALL_KHR,
    eNone = VK_SHADER_FLOAT_CONTROLS_INDEPENDENCE_NONE_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ShaderFloatControlsIndependenceKHR value )
  {
    switch ( value )
    {
      case ShaderFloatControlsIndependenceKHR::e32BitOnly : return "32BitOnly";
      case ShaderFloatControlsIndependenceKHR::eAll : return "All";
      case ShaderFloatControlsIndependenceKHR::eNone : return "None";
      default: return "invalid";
    }
  }

  enum class ShaderInfoTypeAMD
  {
    eStatistics = VK_SHADER_INFO_TYPE_STATISTICS_AMD,
    eBinary = VK_SHADER_INFO_TYPE_BINARY_AMD,
    eDisassembly = VK_SHADER_INFO_TYPE_DISASSEMBLY_AMD
  };

  VULKAN_HPP_INLINE std::string to_string( ShaderInfoTypeAMD value )
  {
    switch ( value )
    {
      case ShaderInfoTypeAMD::eStatistics : return "Statistics";
      case ShaderInfoTypeAMD::eBinary : return "Binary";
      case ShaderInfoTypeAMD::eDisassembly : return "Disassembly";
      default: return "invalid";
    }
  }

  enum class ShadingRatePaletteEntryNV
  {
    eNoInvocations = VK_SHADING_RATE_PALETTE_ENTRY_NO_INVOCATIONS_NV,
    e16InvocationsPerPixel = VK_SHADING_RATE_PALETTE_ENTRY_16_INVOCATIONS_PER_PIXEL_NV,
    e8InvocationsPerPixel = VK_SHADING_RATE_PALETTE_ENTRY_8_INVOCATIONS_PER_PIXEL_NV,
    e4InvocationsPerPixel = VK_SHADING_RATE_PALETTE_ENTRY_4_INVOCATIONS_PER_PIXEL_NV,
    e2InvocationsPerPixel = VK_SHADING_RATE_PALETTE_ENTRY_2_INVOCATIONS_PER_PIXEL_NV,
    e1InvocationPerPixel = VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_PIXEL_NV,
    e1InvocationPer2X1Pixels = VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X1_PIXELS_NV,
    e1InvocationPer1X2Pixels = VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_1X2_PIXELS_NV,
    e1InvocationPer2X2Pixels = VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X2_PIXELS_NV,
    e1InvocationPer4X2Pixels = VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_4X2_PIXELS_NV,
    e1InvocationPer2X4Pixels = VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_2X4_PIXELS_NV,
    e1InvocationPer4X4Pixels = VK_SHADING_RATE_PALETTE_ENTRY_1_INVOCATION_PER_4X4_PIXELS_NV
  };

  VULKAN_HPP_INLINE std::string to_string( ShadingRatePaletteEntryNV value )
  {
    switch ( value )
    {
      case ShadingRatePaletteEntryNV::eNoInvocations : return "NoInvocations";
      case ShadingRatePaletteEntryNV::e16InvocationsPerPixel : return "16InvocationsPerPixel";
      case ShadingRatePaletteEntryNV::e8InvocationsPerPixel : return "8InvocationsPerPixel";
      case ShadingRatePaletteEntryNV::e4InvocationsPerPixel : return "4InvocationsPerPixel";
      case ShadingRatePaletteEntryNV::e2InvocationsPerPixel : return "2InvocationsPerPixel";
      case ShadingRatePaletteEntryNV::e1InvocationPerPixel : return "1InvocationPerPixel";
      case ShadingRatePaletteEntryNV::e1InvocationPer2X1Pixels : return "1InvocationPer2X1Pixels";
      case ShadingRatePaletteEntryNV::e1InvocationPer1X2Pixels : return "1InvocationPer1X2Pixels";
      case ShadingRatePaletteEntryNV::e1InvocationPer2X2Pixels : return "1InvocationPer2X2Pixels";
      case ShadingRatePaletteEntryNV::e1InvocationPer4X2Pixels : return "1InvocationPer4X2Pixels";
      case ShadingRatePaletteEntryNV::e1InvocationPer2X4Pixels : return "1InvocationPer2X4Pixels";
      case ShadingRatePaletteEntryNV::e1InvocationPer4X4Pixels : return "1InvocationPer4X4Pixels";
      default: return "invalid";
    }
  }

  enum class SharingMode
  {
    eExclusive = VK_SHARING_MODE_EXCLUSIVE,
    eConcurrent = VK_SHARING_MODE_CONCURRENT
  };

  VULKAN_HPP_INLINE std::string to_string( SharingMode value )
  {
    switch ( value )
    {
      case SharingMode::eExclusive : return "Exclusive";
      case SharingMode::eConcurrent : return "Concurrent";
      default: return "invalid";
    }
  }

  enum class StencilOp
  {
    eKeep = VK_STENCIL_OP_KEEP,
    eZero = VK_STENCIL_OP_ZERO,
    eReplace = VK_STENCIL_OP_REPLACE,
    eIncrementAndClamp = VK_STENCIL_OP_INCREMENT_AND_CLAMP,
    eDecrementAndClamp = VK_STENCIL_OP_DECREMENT_AND_CLAMP,
    eInvert = VK_STENCIL_OP_INVERT,
    eIncrementAndWrap = VK_STENCIL_OP_INCREMENT_AND_WRAP,
    eDecrementAndWrap = VK_STENCIL_OP_DECREMENT_AND_WRAP
  };

  VULKAN_HPP_INLINE std::string to_string( StencilOp value )
  {
    switch ( value )
    {
      case StencilOp::eKeep : return "Keep";
      case StencilOp::eZero : return "Zero";
      case StencilOp::eReplace : return "Replace";
      case StencilOp::eIncrementAndClamp : return "IncrementAndClamp";
      case StencilOp::eDecrementAndClamp : return "DecrementAndClamp";
      case StencilOp::eInvert : return "Invert";
      case StencilOp::eIncrementAndWrap : return "IncrementAndWrap";
      case StencilOp::eDecrementAndWrap : return "DecrementAndWrap";
      default: return "invalid";
    }
  }

  enum class StructureType
  {
    eApplicationInfo = VK_STRUCTURE_TYPE_APPLICATION_INFO,
    eInstanceCreateInfo = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO,
    eDeviceQueueCreateInfo = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO,
    eDeviceCreateInfo = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO,
    eSubmitInfo = VK_STRUCTURE_TYPE_SUBMIT_INFO,
    eMemoryAllocateInfo = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO,
    eMappedMemoryRange = VK_STRUCTURE_TYPE_MAPPED_MEMORY_RANGE,
    eBindSparseInfo = VK_STRUCTURE_TYPE_BIND_SPARSE_INFO,
    eFenceCreateInfo = VK_STRUCTURE_TYPE_FENCE_CREATE_INFO,
    eSemaphoreCreateInfo = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO,
    eEventCreateInfo = VK_STRUCTURE_TYPE_EVENT_CREATE_INFO,
    eQueryPoolCreateInfo = VK_STRUCTURE_TYPE_QUERY_POOL_CREATE_INFO,
    eBufferCreateInfo = VK_STRUCTURE_TYPE_BUFFER_CREATE_INFO,
    eBufferViewCreateInfo = VK_STRUCTURE_TYPE_BUFFER_VIEW_CREATE_INFO,
    eImageCreateInfo = VK_STRUCTURE_TYPE_IMAGE_CREATE_INFO,
    eImageViewCreateInfo = VK_STRUCTURE_TYPE_IMAGE_VIEW_CREATE_INFO,
    eShaderModuleCreateInfo = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO,
    ePipelineCacheCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_CACHE_CREATE_INFO,
    ePipelineShaderStageCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_CREATE_INFO,
    ePipelineVertexInputStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_STATE_CREATE_INFO,
    ePipelineInputAssemblyStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_INPUT_ASSEMBLY_STATE_CREATE_INFO,
    ePipelineTessellationStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_STATE_CREATE_INFO,
    ePipelineViewportStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_STATE_CREATE_INFO,
    ePipelineRasterizationStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_CREATE_INFO,
    ePipelineMultisampleStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_MULTISAMPLE_STATE_CREATE_INFO,
    ePipelineDepthStencilStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_DEPTH_STENCIL_STATE_CREATE_INFO,
    ePipelineColorBlendStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_STATE_CREATE_INFO,
    ePipelineDynamicStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_DYNAMIC_STATE_CREATE_INFO,
    eGraphicsPipelineCreateInfo = VK_STRUCTURE_TYPE_GRAPHICS_PIPELINE_CREATE_INFO,
    eComputePipelineCreateInfo = VK_STRUCTURE_TYPE_COMPUTE_PIPELINE_CREATE_INFO,
    ePipelineLayoutCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_LAYOUT_CREATE_INFO,
    eSamplerCreateInfo = VK_STRUCTURE_TYPE_SAMPLER_CREATE_INFO,
    eDescriptorSetLayoutCreateInfo = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_CREATE_INFO,
    eDescriptorPoolCreateInfo = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_CREATE_INFO,
    eDescriptorSetAllocateInfo = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_ALLOCATE_INFO,
    eWriteDescriptorSet = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET,
    eCopyDescriptorSet = VK_STRUCTURE_TYPE_COPY_DESCRIPTOR_SET,
    eFramebufferCreateInfo = VK_STRUCTURE_TYPE_FRAMEBUFFER_CREATE_INFO,
    eRenderPassCreateInfo = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO,
    eCommandPoolCreateInfo = VK_STRUCTURE_TYPE_COMMAND_POOL_CREATE_INFO,
    eCommandBufferAllocateInfo = VK_STRUCTURE_TYPE_COMMAND_BUFFER_ALLOCATE_INFO,
    eCommandBufferInheritanceInfo = VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_INFO,
    eCommandBufferBeginInfo = VK_STRUCTURE_TYPE_COMMAND_BUFFER_BEGIN_INFO,
    eRenderPassBeginInfo = VK_STRUCTURE_TYPE_RENDER_PASS_BEGIN_INFO,
    eBufferMemoryBarrier = VK_STRUCTURE_TYPE_BUFFER_MEMORY_BARRIER,
    eImageMemoryBarrier = VK_STRUCTURE_TYPE_IMAGE_MEMORY_BARRIER,
    eMemoryBarrier = VK_STRUCTURE_TYPE_MEMORY_BARRIER,
    eLoaderInstanceCreateInfo = VK_STRUCTURE_TYPE_LOADER_INSTANCE_CREATE_INFO,
    eLoaderDeviceCreateInfo = VK_STRUCTURE_TYPE_LOADER_DEVICE_CREATE_INFO,
    ePhysicalDeviceSubgroupProperties = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_PROPERTIES,
    eBindBufferMemoryInfo = VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_INFO,
    eBindImageMemoryInfo = VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_INFO,
    ePhysicalDevice16BitStorageFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_16BIT_STORAGE_FEATURES,
    eMemoryDedicatedRequirements = VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS,
    eMemoryDedicatedAllocateInfo = VK_STRUCTURE_TYPE_MEMORY_DEDICATED_ALLOCATE_INFO,
    eMemoryAllocateFlagsInfo = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO,
    eDeviceGroupRenderPassBeginInfo = VK_STRUCTURE_TYPE_DEVICE_GROUP_RENDER_PASS_BEGIN_INFO,
    eDeviceGroupCommandBufferBeginInfo = VK_STRUCTURE_TYPE_DEVICE_GROUP_COMMAND_BUFFER_BEGIN_INFO,
    eDeviceGroupSubmitInfo = VK_STRUCTURE_TYPE_DEVICE_GROUP_SUBMIT_INFO,
    eDeviceGroupBindSparseInfo = VK_STRUCTURE_TYPE_DEVICE_GROUP_BIND_SPARSE_INFO,
    eBindBufferMemoryDeviceGroupInfo = VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_DEVICE_GROUP_INFO,
    eBindImageMemoryDeviceGroupInfo = VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_DEVICE_GROUP_INFO,
    ePhysicalDeviceGroupProperties = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GROUP_PROPERTIES,
    eDeviceGroupDeviceCreateInfo = VK_STRUCTURE_TYPE_DEVICE_GROUP_DEVICE_CREATE_INFO,
    eBufferMemoryRequirementsInfo2 = VK_STRUCTURE_TYPE_BUFFER_MEMORY_REQUIREMENTS_INFO_2,
    eImageMemoryRequirementsInfo2 = VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2,
    eImageSparseMemoryRequirementsInfo2 = VK_STRUCTURE_TYPE_IMAGE_SPARSE_MEMORY_REQUIREMENTS_INFO_2,
    eMemoryRequirements2 = VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2,
    eSparseImageMemoryRequirements2 = VK_STRUCTURE_TYPE_SPARSE_IMAGE_MEMORY_REQUIREMENTS_2,
    ePhysicalDeviceFeatures2 = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2,
    ePhysicalDeviceProperties2 = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2,
    eFormatProperties2 = VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_2,
    eImageFormatProperties2 = VK_STRUCTURE_TYPE_IMAGE_FORMAT_PROPERTIES_2,
    ePhysicalDeviceImageFormatInfo2 = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_FORMAT_INFO_2,
    eQueueFamilyProperties2 = VK_STRUCTURE_TYPE_QUEUE_FAMILY_PROPERTIES_2,
    ePhysicalDeviceMemoryProperties2 = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2,
    eSparseImageFormatProperties2 = VK_STRUCTURE_TYPE_SPARSE_IMAGE_FORMAT_PROPERTIES_2,
    ePhysicalDeviceSparseImageFormatInfo2 = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SPARSE_IMAGE_FORMAT_INFO_2,
    ePhysicalDevicePointClippingProperties = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_POINT_CLIPPING_PROPERTIES,
    eRenderPassInputAttachmentAspectCreateInfo = VK_STRUCTURE_TYPE_RENDER_PASS_INPUT_ATTACHMENT_ASPECT_CREATE_INFO,
    eImageViewUsageCreateInfo = VK_STRUCTURE_TYPE_IMAGE_VIEW_USAGE_CREATE_INFO,
    ePipelineTessellationDomainOriginStateCreateInfo = VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_DOMAIN_ORIGIN_STATE_CREATE_INFO,
    eRenderPassMultiviewCreateInfo = VK_STRUCTURE_TYPE_RENDER_PASS_MULTIVIEW_CREATE_INFO,
    ePhysicalDeviceMultiviewFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_FEATURES,
    ePhysicalDeviceMultiviewProperties = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PROPERTIES,
    ePhysicalDeviceVariablePointersFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTERS_FEATURES,
    eProtectedSubmitInfo = VK_STRUCTURE_TYPE_PROTECTED_SUBMIT_INFO,
    ePhysicalDeviceProtectedMemoryFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROTECTED_MEMORY_FEATURES,
    ePhysicalDeviceProtectedMemoryProperties = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROTECTED_MEMORY_PROPERTIES,
    eDeviceQueueInfo2 = VK_STRUCTURE_TYPE_DEVICE_QUEUE_INFO_2,
    eSamplerYcbcrConversionCreateInfo = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_CREATE_INFO,
    eSamplerYcbcrConversionInfo = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_INFO,
    eBindImagePlaneMemoryInfo = VK_STRUCTURE_TYPE_BIND_IMAGE_PLANE_MEMORY_INFO,
    eImagePlaneMemoryRequirementsInfo = VK_STRUCTURE_TYPE_IMAGE_PLANE_MEMORY_REQUIREMENTS_INFO,
    ePhysicalDeviceSamplerYcbcrConversionFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_YCBCR_CONVERSION_FEATURES,
    eSamplerYcbcrConversionImageFormatProperties = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_IMAGE_FORMAT_PROPERTIES,
    eDescriptorUpdateTemplateCreateInfo = VK_STRUCTURE_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_CREATE_INFO,
    ePhysicalDeviceExternalImageFormatInfo = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_IMAGE_FORMAT_INFO,
    eExternalImageFormatProperties = VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES,
    ePhysicalDeviceExternalBufferInfo = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_BUFFER_INFO,
    eExternalBufferProperties = VK_STRUCTURE_TYPE_EXTERNAL_BUFFER_PROPERTIES,
    ePhysicalDeviceIdProperties = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ID_PROPERTIES,
    eExternalMemoryBufferCreateInfo = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO,
    eExternalMemoryImageCreateInfo = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO,
    eExportMemoryAllocateInfo = VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO,
    ePhysicalDeviceExternalFenceInfo = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FENCE_INFO,
    eExternalFenceProperties = VK_STRUCTURE_TYPE_EXTERNAL_FENCE_PROPERTIES,
    eExportFenceCreateInfo = VK_STRUCTURE_TYPE_EXPORT_FENCE_CREATE_INFO,
    eExportSemaphoreCreateInfo = VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO,
    ePhysicalDeviceExternalSemaphoreInfo = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_SEMAPHORE_INFO,
    eExternalSemaphoreProperties = VK_STRUCTURE_TYPE_EXTERNAL_SEMAPHORE_PROPERTIES,
    ePhysicalDeviceMaintenance3Properties = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_3_PROPERTIES,
    eDescriptorSetLayoutSupport = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_SUPPORT,
    ePhysicalDeviceShaderDrawParametersFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DRAW_PARAMETERS_FEATURES,
    eSwapchainCreateInfoKHR = VK_STRUCTURE_TYPE_SWAPCHAIN_CREATE_INFO_KHR,
    ePresentInfoKHR = VK_STRUCTURE_TYPE_PRESENT_INFO_KHR,
    eDeviceGroupPresentCapabilitiesKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_PRESENT_CAPABILITIES_KHR,
    eImageSwapchainCreateInfoKHR = VK_STRUCTURE_TYPE_IMAGE_SWAPCHAIN_CREATE_INFO_KHR,
    eBindImageMemorySwapchainInfoKHR = VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_SWAPCHAIN_INFO_KHR,
    eAcquireNextImageInfoKHR = VK_STRUCTURE_TYPE_ACQUIRE_NEXT_IMAGE_INFO_KHR,
    eDeviceGroupPresentInfoKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_PRESENT_INFO_KHR,
    eDeviceGroupSwapchainCreateInfoKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_SWAPCHAIN_CREATE_INFO_KHR,
    eDisplayModeCreateInfoKHR = VK_STRUCTURE_TYPE_DISPLAY_MODE_CREATE_INFO_KHR,
    eDisplaySurfaceCreateInfoKHR = VK_STRUCTURE_TYPE_DISPLAY_SURFACE_CREATE_INFO_KHR,
    eDisplayPresentInfoKHR = VK_STRUCTURE_TYPE_DISPLAY_PRESENT_INFO_KHR,
    eXlibSurfaceCreateInfoKHR = VK_STRUCTURE_TYPE_XLIB_SURFACE_CREATE_INFO_KHR,
    eXcbSurfaceCreateInfoKHR = VK_STRUCTURE_TYPE_XCB_SURFACE_CREATE_INFO_KHR,
    eWaylandSurfaceCreateInfoKHR = VK_STRUCTURE_TYPE_WAYLAND_SURFACE_CREATE_INFO_KHR,
    eAndroidSurfaceCreateInfoKHR = VK_STRUCTURE_TYPE_ANDROID_SURFACE_CREATE_INFO_KHR,
    eWin32SurfaceCreateInfoKHR = VK_STRUCTURE_TYPE_WIN32_SURFACE_CREATE_INFO_KHR,
    eDebugReportCallbackCreateInfoEXT = VK_STRUCTURE_TYPE_DEBUG_REPORT_CALLBACK_CREATE_INFO_EXT,
    ePipelineRasterizationStateRasterizationOrderAMD = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_RASTERIZATION_ORDER_AMD,
    eDebugMarkerObjectNameInfoEXT = VK_STRUCTURE_TYPE_DEBUG_MARKER_OBJECT_NAME_INFO_EXT,
    eDebugMarkerObjectTagInfoEXT = VK_STRUCTURE_TYPE_DEBUG_MARKER_OBJECT_TAG_INFO_EXT,
    eDebugMarkerMarkerInfoEXT = VK_STRUCTURE_TYPE_DEBUG_MARKER_MARKER_INFO_EXT,
    eDedicatedAllocationImageCreateInfoNV = VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_IMAGE_CREATE_INFO_NV,
    eDedicatedAllocationBufferCreateInfoNV = VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_BUFFER_CREATE_INFO_NV,
    eDedicatedAllocationMemoryAllocateInfoNV = VK_STRUCTURE_TYPE_DEDICATED_ALLOCATION_MEMORY_ALLOCATE_INFO_NV,
    ePhysicalDeviceTransformFeedbackFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TRANSFORM_FEEDBACK_FEATURES_EXT,
    ePhysicalDeviceTransformFeedbackPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TRANSFORM_FEEDBACK_PROPERTIES_EXT,
    ePipelineRasterizationStateStreamCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_STATE_STREAM_CREATE_INFO_EXT,
    eImageViewHandleInfoNVX = VK_STRUCTURE_TYPE_IMAGE_VIEW_HANDLE_INFO_NVX,
    eTextureLodGatherFormatPropertiesAMD = VK_STRUCTURE_TYPE_TEXTURE_LOD_GATHER_FORMAT_PROPERTIES_AMD,
    eStreamDescriptorSurfaceCreateInfoGGP = VK_STRUCTURE_TYPE_STREAM_DESCRIPTOR_SURFACE_CREATE_INFO_GGP,
    ePhysicalDeviceCornerSampledImageFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CORNER_SAMPLED_IMAGE_FEATURES_NV,
    eExternalMemoryImageCreateInfoNV = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO_NV,
    eExportMemoryAllocateInfoNV = VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_NV,
    eImportMemoryWin32HandleInfoNV = VK_STRUCTURE_TYPE_IMPORT_MEMORY_WIN32_HANDLE_INFO_NV,
    eExportMemoryWin32HandleInfoNV = VK_STRUCTURE_TYPE_EXPORT_MEMORY_WIN32_HANDLE_INFO_NV,
    eWin32KeyedMutexAcquireReleaseInfoNV = VK_STRUCTURE_TYPE_WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_NV,
    eValidationFlagsEXT = VK_STRUCTURE_TYPE_VALIDATION_FLAGS_EXT,
    eViSurfaceCreateInfoNN = VK_STRUCTURE_TYPE_VI_SURFACE_CREATE_INFO_NN,
    ePhysicalDeviceTextureCompressionAstcHdrFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXTURE_COMPRESSION_ASTC_HDR_FEATURES_EXT,
    eImageViewAstcDecodeModeEXT = VK_STRUCTURE_TYPE_IMAGE_VIEW_ASTC_DECODE_MODE_EXT,
    ePhysicalDeviceAstcDecodeFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ASTC_DECODE_FEATURES_EXT,
    eImportMemoryWin32HandleInfoKHR = VK_STRUCTURE_TYPE_IMPORT_MEMORY_WIN32_HANDLE_INFO_KHR,
    eExportMemoryWin32HandleInfoKHR = VK_STRUCTURE_TYPE_EXPORT_MEMORY_WIN32_HANDLE_INFO_KHR,
    eMemoryWin32HandlePropertiesKHR = VK_STRUCTURE_TYPE_MEMORY_WIN32_HANDLE_PROPERTIES_KHR,
    eMemoryGetWin32HandleInfoKHR = VK_STRUCTURE_TYPE_MEMORY_GET_WIN32_HANDLE_INFO_KHR,
    eImportMemoryFdInfoKHR = VK_STRUCTURE_TYPE_IMPORT_MEMORY_FD_INFO_KHR,
    eMemoryFdPropertiesKHR = VK_STRUCTURE_TYPE_MEMORY_FD_PROPERTIES_KHR,
    eMemoryGetFdInfoKHR = VK_STRUCTURE_TYPE_MEMORY_GET_FD_INFO_KHR,
    eWin32KeyedMutexAcquireReleaseInfoKHR = VK_STRUCTURE_TYPE_WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_KHR,
    eImportSemaphoreWin32HandleInfoKHR = VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR,
    eExportSemaphoreWin32HandleInfoKHR = VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR,
    eD3D12FenceSubmitInfoKHR = VK_STRUCTURE_TYPE_D3D12_FENCE_SUBMIT_INFO_KHR,
    eSemaphoreGetWin32HandleInfoKHR = VK_STRUCTURE_TYPE_SEMAPHORE_GET_WIN32_HANDLE_INFO_KHR,
    eImportSemaphoreFdInfoKHR = VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_FD_INFO_KHR,
    eSemaphoreGetFdInfoKHR = VK_STRUCTURE_TYPE_SEMAPHORE_GET_FD_INFO_KHR,
    ePhysicalDevicePushDescriptorPropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PUSH_DESCRIPTOR_PROPERTIES_KHR,
    eCommandBufferInheritanceConditionalRenderingInfoEXT = VK_STRUCTURE_TYPE_COMMAND_BUFFER_INHERITANCE_CONDITIONAL_RENDERING_INFO_EXT,
    ePhysicalDeviceConditionalRenderingFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CONDITIONAL_RENDERING_FEATURES_EXT,
    eConditionalRenderingBeginInfoEXT = VK_STRUCTURE_TYPE_CONDITIONAL_RENDERING_BEGIN_INFO_EXT,
    ePhysicalDeviceShaderFloat16Int8FeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_FLOAT16_INT8_FEATURES_KHR,
    ePresentRegionsKHR = VK_STRUCTURE_TYPE_PRESENT_REGIONS_KHR,
    eObjectTableCreateInfoNVX = VK_STRUCTURE_TYPE_OBJECT_TABLE_CREATE_INFO_NVX,
    eIndirectCommandsLayoutCreateInfoNVX = VK_STRUCTURE_TYPE_INDIRECT_COMMANDS_LAYOUT_CREATE_INFO_NVX,
    eCmdProcessCommandsInfoNVX = VK_STRUCTURE_TYPE_CMD_PROCESS_COMMANDS_INFO_NVX,
    eCmdReserveSpaceForCommandsInfoNVX = VK_STRUCTURE_TYPE_CMD_RESERVE_SPACE_FOR_COMMANDS_INFO_NVX,
    eDeviceGeneratedCommandsLimitsNVX = VK_STRUCTURE_TYPE_DEVICE_GENERATED_COMMANDS_LIMITS_NVX,
    eDeviceGeneratedCommandsFeaturesNVX = VK_STRUCTURE_TYPE_DEVICE_GENERATED_COMMANDS_FEATURES_NVX,
    ePipelineViewportWScalingStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_W_SCALING_STATE_CREATE_INFO_NV,
    eSurfaceCapabilities2EXT = VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_2_EXT,
    eDisplayPowerInfoEXT = VK_STRUCTURE_TYPE_DISPLAY_POWER_INFO_EXT,
    eDeviceEventInfoEXT = VK_STRUCTURE_TYPE_DEVICE_EVENT_INFO_EXT,
    eDisplayEventInfoEXT = VK_STRUCTURE_TYPE_DISPLAY_EVENT_INFO_EXT,
    eSwapchainCounterCreateInfoEXT = VK_STRUCTURE_TYPE_SWAPCHAIN_COUNTER_CREATE_INFO_EXT,
    ePresentTimesInfoGOOGLE = VK_STRUCTURE_TYPE_PRESENT_TIMES_INFO_GOOGLE,
    ePhysicalDeviceMultiviewPerViewAttributesPropertiesNVX = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PER_VIEW_ATTRIBUTES_PROPERTIES_NVX,
    ePipelineViewportSwizzleStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_SWIZZLE_STATE_CREATE_INFO_NV,
    ePhysicalDeviceDiscardRectanglePropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DISCARD_RECTANGLE_PROPERTIES_EXT,
    ePipelineDiscardRectangleStateCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_DISCARD_RECTANGLE_STATE_CREATE_INFO_EXT,
    ePhysicalDeviceConservativeRasterizationPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_CONSERVATIVE_RASTERIZATION_PROPERTIES_EXT,
    ePipelineRasterizationConservativeStateCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_CONSERVATIVE_STATE_CREATE_INFO_EXT,
    ePhysicalDeviceDepthClipEnableFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_CLIP_ENABLE_FEATURES_EXT,
    ePipelineRasterizationDepthClipStateCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_DEPTH_CLIP_STATE_CREATE_INFO_EXT,
    eHdrMetadataEXT = VK_STRUCTURE_TYPE_HDR_METADATA_EXT,
    ePhysicalDeviceImagelessFramebufferFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGELESS_FRAMEBUFFER_FEATURES_KHR,
    eFramebufferAttachmentsCreateInfoKHR = VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENTS_CREATE_INFO_KHR,
    eFramebufferAttachmentImageInfoKHR = VK_STRUCTURE_TYPE_FRAMEBUFFER_ATTACHMENT_IMAGE_INFO_KHR,
    eRenderPassAttachmentBeginInfoKHR = VK_STRUCTURE_TYPE_RENDER_PASS_ATTACHMENT_BEGIN_INFO_KHR,
    eAttachmentDescription2KHR = VK_STRUCTURE_TYPE_ATTACHMENT_DESCRIPTION_2_KHR,
    eAttachmentReference2KHR = VK_STRUCTURE_TYPE_ATTACHMENT_REFERENCE_2_KHR,
    eSubpassDescription2KHR = VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_2_KHR,
    eSubpassDependency2KHR = VK_STRUCTURE_TYPE_SUBPASS_DEPENDENCY_2_KHR,
    eRenderPassCreateInfo2KHR = VK_STRUCTURE_TYPE_RENDER_PASS_CREATE_INFO_2_KHR,
    eSubpassBeginInfoKHR = VK_STRUCTURE_TYPE_SUBPASS_BEGIN_INFO_KHR,
    eSubpassEndInfoKHR = VK_STRUCTURE_TYPE_SUBPASS_END_INFO_KHR,
    eSharedPresentSurfaceCapabilitiesKHR = VK_STRUCTURE_TYPE_SHARED_PRESENT_SURFACE_CAPABILITIES_KHR,
    eImportFenceWin32HandleInfoKHR = VK_STRUCTURE_TYPE_IMPORT_FENCE_WIN32_HANDLE_INFO_KHR,
    eExportFenceWin32HandleInfoKHR = VK_STRUCTURE_TYPE_EXPORT_FENCE_WIN32_HANDLE_INFO_KHR,
    eFenceGetWin32HandleInfoKHR = VK_STRUCTURE_TYPE_FENCE_GET_WIN32_HANDLE_INFO_KHR,
    eImportFenceFdInfoKHR = VK_STRUCTURE_TYPE_IMPORT_FENCE_FD_INFO_KHR,
    eFenceGetFdInfoKHR = VK_STRUCTURE_TYPE_FENCE_GET_FD_INFO_KHR,
    ePhysicalDeviceSurfaceInfo2KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SURFACE_INFO_2_KHR,
    eSurfaceCapabilities2KHR = VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_2_KHR,
    eSurfaceFormat2KHR = VK_STRUCTURE_TYPE_SURFACE_FORMAT_2_KHR,
    eDisplayProperties2KHR = VK_STRUCTURE_TYPE_DISPLAY_PROPERTIES_2_KHR,
    eDisplayPlaneProperties2KHR = VK_STRUCTURE_TYPE_DISPLAY_PLANE_PROPERTIES_2_KHR,
    eDisplayModeProperties2KHR = VK_STRUCTURE_TYPE_DISPLAY_MODE_PROPERTIES_2_KHR,
    eDisplayPlaneInfo2KHR = VK_STRUCTURE_TYPE_DISPLAY_PLANE_INFO_2_KHR,
    eDisplayPlaneCapabilities2KHR = VK_STRUCTURE_TYPE_DISPLAY_PLANE_CAPABILITIES_2_KHR,
    eIosSurfaceCreateInfoMVK = VK_STRUCTURE_TYPE_IOS_SURFACE_CREATE_INFO_MVK,
    eMacosSurfaceCreateInfoMVK = VK_STRUCTURE_TYPE_MACOS_SURFACE_CREATE_INFO_MVK,
    eDebugUtilsObjectNameInfoEXT = VK_STRUCTURE_TYPE_DEBUG_UTILS_OBJECT_NAME_INFO_EXT,
    eDebugUtilsObjectTagInfoEXT = VK_STRUCTURE_TYPE_DEBUG_UTILS_OBJECT_TAG_INFO_EXT,
    eDebugUtilsLabelEXT = VK_STRUCTURE_TYPE_DEBUG_UTILS_LABEL_EXT,
    eDebugUtilsMessengerCallbackDataEXT = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CALLBACK_DATA_EXT,
    eDebugUtilsMessengerCreateInfoEXT = VK_STRUCTURE_TYPE_DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT,
    eAndroidHardwareBufferUsageANDROID = VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_USAGE_ANDROID,
    eAndroidHardwareBufferPropertiesANDROID = VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_PROPERTIES_ANDROID,
    eAndroidHardwareBufferFormatPropertiesANDROID = VK_STRUCTURE_TYPE_ANDROID_HARDWARE_BUFFER_FORMAT_PROPERTIES_ANDROID,
    eImportAndroidHardwareBufferInfoANDROID = VK_STRUCTURE_TYPE_IMPORT_ANDROID_HARDWARE_BUFFER_INFO_ANDROID,
    eMemoryGetAndroidHardwareBufferInfoANDROID = VK_STRUCTURE_TYPE_MEMORY_GET_ANDROID_HARDWARE_BUFFER_INFO_ANDROID,
    eExternalFormatANDROID = VK_STRUCTURE_TYPE_EXTERNAL_FORMAT_ANDROID,
    ePhysicalDeviceSamplerFilterMinmaxPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_FILTER_MINMAX_PROPERTIES_EXT,
    eSamplerReductionModeCreateInfoEXT = VK_STRUCTURE_TYPE_SAMPLER_REDUCTION_MODE_CREATE_INFO_EXT,
    ePhysicalDeviceInlineUniformBlockFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_FEATURES_EXT,
    ePhysicalDeviceInlineUniformBlockPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INLINE_UNIFORM_BLOCK_PROPERTIES_EXT,
    eWriteDescriptorSetInlineUniformBlockEXT = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_INLINE_UNIFORM_BLOCK_EXT,
    eDescriptorPoolInlineUniformBlockCreateInfoEXT = VK_STRUCTURE_TYPE_DESCRIPTOR_POOL_INLINE_UNIFORM_BLOCK_CREATE_INFO_EXT,
    eSampleLocationsInfoEXT = VK_STRUCTURE_TYPE_SAMPLE_LOCATIONS_INFO_EXT,
    eRenderPassSampleLocationsBeginInfoEXT = VK_STRUCTURE_TYPE_RENDER_PASS_SAMPLE_LOCATIONS_BEGIN_INFO_EXT,
    ePipelineSampleLocationsStateCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_SAMPLE_LOCATIONS_STATE_CREATE_INFO_EXT,
    ePhysicalDeviceSampleLocationsPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLE_LOCATIONS_PROPERTIES_EXT,
    eMultisamplePropertiesEXT = VK_STRUCTURE_TYPE_MULTISAMPLE_PROPERTIES_EXT,
    eImageFormatListCreateInfoKHR = VK_STRUCTURE_TYPE_IMAGE_FORMAT_LIST_CREATE_INFO_KHR,
    ePhysicalDeviceBlendOperationAdvancedFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BLEND_OPERATION_ADVANCED_FEATURES_EXT,
    ePhysicalDeviceBlendOperationAdvancedPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BLEND_OPERATION_ADVANCED_PROPERTIES_EXT,
    ePipelineColorBlendAdvancedStateCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_COLOR_BLEND_ADVANCED_STATE_CREATE_INFO_EXT,
    ePipelineCoverageToColorStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_TO_COLOR_STATE_CREATE_INFO_NV,
    ePipelineCoverageModulationStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_MODULATION_STATE_CREATE_INFO_NV,
    ePhysicalDeviceShaderSmBuiltinsFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SM_BUILTINS_FEATURES_NV,
    ePhysicalDeviceShaderSmBuiltinsPropertiesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SM_BUILTINS_PROPERTIES_NV,
    eDrmFormatModifierPropertiesListEXT = VK_STRUCTURE_TYPE_DRM_FORMAT_MODIFIER_PROPERTIES_LIST_EXT,
    eDrmFormatModifierPropertiesEXT = VK_STRUCTURE_TYPE_DRM_FORMAT_MODIFIER_PROPERTIES_EXT,
    ePhysicalDeviceImageDrmFormatModifierInfoEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_DRM_FORMAT_MODIFIER_INFO_EXT,
    eImageDrmFormatModifierListCreateInfoEXT = VK_STRUCTURE_TYPE_IMAGE_DRM_FORMAT_MODIFIER_LIST_CREATE_INFO_EXT,
    eImageDrmFormatModifierExplicitCreateInfoEXT = VK_STRUCTURE_TYPE_IMAGE_DRM_FORMAT_MODIFIER_EXPLICIT_CREATE_INFO_EXT,
    eImageDrmFormatModifierPropertiesEXT = VK_STRUCTURE_TYPE_IMAGE_DRM_FORMAT_MODIFIER_PROPERTIES_EXT,
    eValidationCacheCreateInfoEXT = VK_STRUCTURE_TYPE_VALIDATION_CACHE_CREATE_INFO_EXT,
    eShaderModuleValidationCacheCreateInfoEXT = VK_STRUCTURE_TYPE_SHADER_MODULE_VALIDATION_CACHE_CREATE_INFO_EXT,
    eDescriptorSetLayoutBindingFlagsCreateInfoEXT = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_BINDING_FLAGS_CREATE_INFO_EXT,
    ePhysicalDeviceDescriptorIndexingFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_FEATURES_EXT,
    ePhysicalDeviceDescriptorIndexingPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DESCRIPTOR_INDEXING_PROPERTIES_EXT,
    eDescriptorSetVariableDescriptorCountAllocateInfoEXT = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_ALLOCATE_INFO_EXT,
    eDescriptorSetVariableDescriptorCountLayoutSupportEXT = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_VARIABLE_DESCRIPTOR_COUNT_LAYOUT_SUPPORT_EXT,
    ePipelineViewportShadingRateImageStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_SHADING_RATE_IMAGE_STATE_CREATE_INFO_NV,
    ePhysicalDeviceShadingRateImageFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADING_RATE_IMAGE_FEATURES_NV,
    ePhysicalDeviceShadingRateImagePropertiesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADING_RATE_IMAGE_PROPERTIES_NV,
    ePipelineViewportCoarseSampleOrderStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_COARSE_SAMPLE_ORDER_STATE_CREATE_INFO_NV,
    eRayTracingPipelineCreateInfoNV = VK_STRUCTURE_TYPE_RAY_TRACING_PIPELINE_CREATE_INFO_NV,
    eAccelerationStructureCreateInfoNV = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_CREATE_INFO_NV,
    eGeometryNV = VK_STRUCTURE_TYPE_GEOMETRY_NV,
    eGeometryTrianglesNV = VK_STRUCTURE_TYPE_GEOMETRY_TRIANGLES_NV,
    eGeometryAabbNV = VK_STRUCTURE_TYPE_GEOMETRY_AABB_NV,
    eBindAccelerationStructureMemoryInfoNV = VK_STRUCTURE_TYPE_BIND_ACCELERATION_STRUCTURE_MEMORY_INFO_NV,
    eWriteDescriptorSetAccelerationStructureNV = VK_STRUCTURE_TYPE_WRITE_DESCRIPTOR_SET_ACCELERATION_STRUCTURE_NV,
    eAccelerationStructureMemoryRequirementsInfoNV = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_MEMORY_REQUIREMENTS_INFO_NV,
    ePhysicalDeviceRayTracingPropertiesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_RAY_TRACING_PROPERTIES_NV,
    eRayTracingShaderGroupCreateInfoNV = VK_STRUCTURE_TYPE_RAY_TRACING_SHADER_GROUP_CREATE_INFO_NV,
    eAccelerationStructureInfoNV = VK_STRUCTURE_TYPE_ACCELERATION_STRUCTURE_INFO_NV,
    ePhysicalDeviceRepresentativeFragmentTestFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_REPRESENTATIVE_FRAGMENT_TEST_FEATURES_NV,
    ePipelineRepresentativeFragmentTestStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_REPRESENTATIVE_FRAGMENT_TEST_STATE_CREATE_INFO_NV,
    ePhysicalDeviceImageViewImageFormatInfoEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_VIEW_IMAGE_FORMAT_INFO_EXT,
    eFilterCubicImageViewImageFormatPropertiesEXT = VK_STRUCTURE_TYPE_FILTER_CUBIC_IMAGE_VIEW_IMAGE_FORMAT_PROPERTIES_EXT,
    eDeviceQueueGlobalPriorityCreateInfoEXT = VK_STRUCTURE_TYPE_DEVICE_QUEUE_GLOBAL_PRIORITY_CREATE_INFO_EXT,
    ePhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_SUBGROUP_EXTENDED_TYPES_FEATURES_KHR,
    ePhysicalDevice8BitStorageFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_8BIT_STORAGE_FEATURES_KHR,
    eImportMemoryHostPointerInfoEXT = VK_STRUCTURE_TYPE_IMPORT_MEMORY_HOST_POINTER_INFO_EXT,
    eMemoryHostPointerPropertiesEXT = VK_STRUCTURE_TYPE_MEMORY_HOST_POINTER_PROPERTIES_EXT,
    ePhysicalDeviceExternalMemoryHostPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_MEMORY_HOST_PROPERTIES_EXT,
    ePhysicalDeviceShaderAtomicInt64FeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_ATOMIC_INT64_FEATURES_KHR,
    ePhysicalDeviceShaderClockFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CLOCK_FEATURES_KHR,
    ePipelineCompilerControlCreateInfoAMD = VK_STRUCTURE_TYPE_PIPELINE_COMPILER_CONTROL_CREATE_INFO_AMD,
    eCalibratedTimestampInfoEXT = VK_STRUCTURE_TYPE_CALIBRATED_TIMESTAMP_INFO_EXT,
    ePhysicalDeviceShaderCorePropertiesAMD = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_PROPERTIES_AMD,
    eDeviceMemoryOverallocationCreateInfoAMD = VK_STRUCTURE_TYPE_DEVICE_MEMORY_OVERALLOCATION_CREATE_INFO_AMD,
    ePhysicalDeviceVertexAttributeDivisorPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_PROPERTIES_EXT,
    ePipelineVertexInputDivisorStateCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_VERTEX_INPUT_DIVISOR_STATE_CREATE_INFO_EXT,
    ePhysicalDeviceVertexAttributeDivisorFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VERTEX_ATTRIBUTE_DIVISOR_FEATURES_EXT,
    ePresentFrameTokenGGP = VK_STRUCTURE_TYPE_PRESENT_FRAME_TOKEN_GGP,
    ePipelineCreationFeedbackCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_CREATION_FEEDBACK_CREATE_INFO_EXT,
    ePhysicalDeviceDriverPropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DRIVER_PROPERTIES_KHR,
    ePhysicalDeviceFloatControlsPropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FLOAT_CONTROLS_PROPERTIES_KHR,
    ePhysicalDeviceDepthStencilResolvePropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEPTH_STENCIL_RESOLVE_PROPERTIES_KHR,
    eSubpassDescriptionDepthStencilResolveKHR = VK_STRUCTURE_TYPE_SUBPASS_DESCRIPTION_DEPTH_STENCIL_RESOLVE_KHR,
    ePhysicalDeviceComputeShaderDerivativesFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COMPUTE_SHADER_DERIVATIVES_FEATURES_NV,
    ePhysicalDeviceMeshShaderFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_FEATURES_NV,
    ePhysicalDeviceMeshShaderPropertiesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MESH_SHADER_PROPERTIES_NV,
    ePhysicalDeviceFragmentShaderBarycentricFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_BARYCENTRIC_FEATURES_NV,
    ePhysicalDeviceShaderImageFootprintFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_IMAGE_FOOTPRINT_FEATURES_NV,
    ePipelineViewportExclusiveScissorStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_VIEWPORT_EXCLUSIVE_SCISSOR_STATE_CREATE_INFO_NV,
    ePhysicalDeviceExclusiveScissorFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXCLUSIVE_SCISSOR_FEATURES_NV,
    eCheckpointDataNV = VK_STRUCTURE_TYPE_CHECKPOINT_DATA_NV,
    eQueueFamilyCheckpointPropertiesNV = VK_STRUCTURE_TYPE_QUEUE_FAMILY_CHECKPOINT_PROPERTIES_NV,
    ePhysicalDeviceTimelineSemaphoreFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_FEATURES_KHR,
    ePhysicalDeviceTimelineSemaphorePropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TIMELINE_SEMAPHORE_PROPERTIES_KHR,
    eSemaphoreTypeCreateInfoKHR = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO_KHR,
    eTimelineSemaphoreSubmitInfoKHR = VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO_KHR,
    eSemaphoreWaitInfoKHR = VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO_KHR,
    eSemaphoreSignalInfoKHR = VK_STRUCTURE_TYPE_SEMAPHORE_SIGNAL_INFO_KHR,
    ePhysicalDeviceShaderIntegerFunctions2FeaturesINTEL = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_INTEGER_FUNCTIONS_2_FEATURES_INTEL,
    eQueryPoolCreateInfoINTEL = VK_STRUCTURE_TYPE_QUERY_POOL_CREATE_INFO_INTEL,
    eInitializePerformanceApiInfoINTEL = VK_STRUCTURE_TYPE_INITIALIZE_PERFORMANCE_API_INFO_INTEL,
    ePerformanceMarkerInfoINTEL = VK_STRUCTURE_TYPE_PERFORMANCE_MARKER_INFO_INTEL,
    ePerformanceStreamMarkerInfoINTEL = VK_STRUCTURE_TYPE_PERFORMANCE_STREAM_MARKER_INFO_INTEL,
    ePerformanceOverrideInfoINTEL = VK_STRUCTURE_TYPE_PERFORMANCE_OVERRIDE_INFO_INTEL,
    ePerformanceConfigurationAcquireInfoINTEL = VK_STRUCTURE_TYPE_PERFORMANCE_CONFIGURATION_ACQUIRE_INFO_INTEL,
    ePhysicalDeviceVulkanMemoryModelFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VULKAN_MEMORY_MODEL_FEATURES_KHR,
    ePhysicalDevicePciBusInfoPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PCI_BUS_INFO_PROPERTIES_EXT,
    eDisplayNativeHdrSurfaceCapabilitiesAMD = VK_STRUCTURE_TYPE_DISPLAY_NATIVE_HDR_SURFACE_CAPABILITIES_AMD,
    eSwapchainDisplayNativeHdrCreateInfoAMD = VK_STRUCTURE_TYPE_SWAPCHAIN_DISPLAY_NATIVE_HDR_CREATE_INFO_AMD,
    eImagepipeSurfaceCreateInfoFUCHSIA = VK_STRUCTURE_TYPE_IMAGEPIPE_SURFACE_CREATE_INFO_FUCHSIA,
    eMetalSurfaceCreateInfoEXT = VK_STRUCTURE_TYPE_METAL_SURFACE_CREATE_INFO_EXT,
    ePhysicalDeviceFragmentDensityMapFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_FEATURES_EXT,
    ePhysicalDeviceFragmentDensityMapPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_DENSITY_MAP_PROPERTIES_EXT,
    eRenderPassFragmentDensityMapCreateInfoEXT = VK_STRUCTURE_TYPE_RENDER_PASS_FRAGMENT_DENSITY_MAP_CREATE_INFO_EXT,
    ePhysicalDeviceScalarBlockLayoutFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SCALAR_BLOCK_LAYOUT_FEATURES_EXT,
    ePhysicalDeviceSubgroupSizeControlPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_PROPERTIES_EXT,
    ePipelineShaderStageRequiredSubgroupSizeCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_SHADER_STAGE_REQUIRED_SUBGROUP_SIZE_CREATE_INFO_EXT,
    ePhysicalDeviceSubgroupSizeControlFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SUBGROUP_SIZE_CONTROL_FEATURES_EXT,
    ePhysicalDeviceShaderCoreProperties2AMD = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_CORE_PROPERTIES_2_AMD,
    ePhysicalDeviceCoherentMemoryFeaturesAMD = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COHERENT_MEMORY_FEATURES_AMD,
    ePhysicalDeviceMemoryBudgetPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_BUDGET_PROPERTIES_EXT,
    ePhysicalDeviceMemoryPriorityFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PRIORITY_FEATURES_EXT,
    eMemoryPriorityAllocateInfoEXT = VK_STRUCTURE_TYPE_MEMORY_PRIORITY_ALLOCATE_INFO_EXT,
    eSurfaceProtectedCapabilitiesKHR = VK_STRUCTURE_TYPE_SURFACE_PROTECTED_CAPABILITIES_KHR,
    ePhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_DEDICATED_ALLOCATION_IMAGE_ALIASING_FEATURES_NV,
    ePhysicalDeviceBufferDeviceAddressFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_DEVICE_ADDRESS_FEATURES_EXT,
    eBufferDeviceAddressInfoEXT = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_INFO_EXT,
    eBufferDeviceAddressCreateInfoEXT = VK_STRUCTURE_TYPE_BUFFER_DEVICE_ADDRESS_CREATE_INFO_EXT,
    eImageStencilUsageCreateInfoEXT = VK_STRUCTURE_TYPE_IMAGE_STENCIL_USAGE_CREATE_INFO_EXT,
    eValidationFeaturesEXT = VK_STRUCTURE_TYPE_VALIDATION_FEATURES_EXT,
    ePhysicalDeviceCooperativeMatrixFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_FEATURES_NV,
    eCooperativeMatrixPropertiesNV = VK_STRUCTURE_TYPE_COOPERATIVE_MATRIX_PROPERTIES_NV,
    ePhysicalDeviceCooperativeMatrixPropertiesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COOPERATIVE_MATRIX_PROPERTIES_NV,
    ePhysicalDeviceCoverageReductionModeFeaturesNV = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_COVERAGE_REDUCTION_MODE_FEATURES_NV,
    ePipelineCoverageReductionStateCreateInfoNV = VK_STRUCTURE_TYPE_PIPELINE_COVERAGE_REDUCTION_STATE_CREATE_INFO_NV,
    eFramebufferMixedSamplesCombinationNV = VK_STRUCTURE_TYPE_FRAMEBUFFER_MIXED_SAMPLES_COMBINATION_NV,
    ePhysicalDeviceFragmentShaderInterlockFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FRAGMENT_SHADER_INTERLOCK_FEATURES_EXT,
    ePhysicalDeviceYcbcrImageArraysFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_YCBCR_IMAGE_ARRAYS_FEATURES_EXT,
    ePhysicalDeviceUniformBufferStandardLayoutFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_UNIFORM_BUFFER_STANDARD_LAYOUT_FEATURES_KHR,
    eSurfaceFullScreenExclusiveInfoEXT = VK_STRUCTURE_TYPE_SURFACE_FULL_SCREEN_EXCLUSIVE_INFO_EXT,
    eSurfaceCapabilitiesFullScreenExclusiveEXT = VK_STRUCTURE_TYPE_SURFACE_CAPABILITIES_FULL_SCREEN_EXCLUSIVE_EXT,
    eSurfaceFullScreenExclusiveWin32InfoEXT = VK_STRUCTURE_TYPE_SURFACE_FULL_SCREEN_EXCLUSIVE_WIN32_INFO_EXT,
    eHeadlessSurfaceCreateInfoEXT = VK_STRUCTURE_TYPE_HEADLESS_SURFACE_CREATE_INFO_EXT,
    ePhysicalDeviceLineRasterizationFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_FEATURES_EXT,
    ePipelineRasterizationLineStateCreateInfoEXT = VK_STRUCTURE_TYPE_PIPELINE_RASTERIZATION_LINE_STATE_CREATE_INFO_EXT,
    ePhysicalDeviceLineRasterizationPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_LINE_RASTERIZATION_PROPERTIES_EXT,
    ePhysicalDeviceHostQueryResetFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_HOST_QUERY_RESET_FEATURES_EXT,
    ePhysicalDeviceIndexTypeUint8FeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_INDEX_TYPE_UINT8_FEATURES_EXT,
    ePhysicalDevicePipelineExecutablePropertiesFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PIPELINE_EXECUTABLE_PROPERTIES_FEATURES_KHR,
    ePipelineInfoKHR = VK_STRUCTURE_TYPE_PIPELINE_INFO_KHR,
    ePipelineExecutablePropertiesKHR = VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_PROPERTIES_KHR,
    ePipelineExecutableInfoKHR = VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_INFO_KHR,
    ePipelineExecutableStatisticKHR = VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_STATISTIC_KHR,
    ePipelineExecutableInternalRepresentationKHR = VK_STRUCTURE_TYPE_PIPELINE_EXECUTABLE_INTERNAL_REPRESENTATION_KHR,
    ePhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DEMOTE_TO_HELPER_INVOCATION_FEATURES_EXT,
    ePhysicalDeviceTexelBufferAlignmentFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXEL_BUFFER_ALIGNMENT_FEATURES_EXT,
    ePhysicalDeviceTexelBufferAlignmentPropertiesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_TEXEL_BUFFER_ALIGNMENT_PROPERTIES_EXT,
    ePhysicalDeviceVariablePointerFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTER_FEATURES,
    ePhysicalDeviceShaderDrawParameterFeatures = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SHADER_DRAW_PARAMETER_FEATURES,
    eDebugReportCreateInfoEXT = VK_STRUCTURE_TYPE_DEBUG_REPORT_CREATE_INFO_EXT,
    eRenderPassMultiviewCreateInfoKHR = VK_STRUCTURE_TYPE_RENDER_PASS_MULTIVIEW_CREATE_INFO_KHR,
    ePhysicalDeviceMultiviewFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_FEATURES_KHR,
    ePhysicalDeviceMultiviewPropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MULTIVIEW_PROPERTIES_KHR,
    ePhysicalDeviceFeatures2KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FEATURES_2_KHR,
    ePhysicalDeviceProperties2KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_PROPERTIES_2_KHR,
    eFormatProperties2KHR = VK_STRUCTURE_TYPE_FORMAT_PROPERTIES_2_KHR,
    eImageFormatProperties2KHR = VK_STRUCTURE_TYPE_IMAGE_FORMAT_PROPERTIES_2_KHR,
    ePhysicalDeviceImageFormatInfo2KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_IMAGE_FORMAT_INFO_2_KHR,
    eQueueFamilyProperties2KHR = VK_STRUCTURE_TYPE_QUEUE_FAMILY_PROPERTIES_2_KHR,
    ePhysicalDeviceMemoryProperties2KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MEMORY_PROPERTIES_2_KHR,
    eSparseImageFormatProperties2KHR = VK_STRUCTURE_TYPE_SPARSE_IMAGE_FORMAT_PROPERTIES_2_KHR,
    ePhysicalDeviceSparseImageFormatInfo2KHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SPARSE_IMAGE_FORMAT_INFO_2_KHR,
    eMemoryAllocateFlagsInfoKHR = VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_FLAGS_INFO_KHR,
    eDeviceGroupRenderPassBeginInfoKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_RENDER_PASS_BEGIN_INFO_KHR,
    eDeviceGroupCommandBufferBeginInfoKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_COMMAND_BUFFER_BEGIN_INFO_KHR,
    eDeviceGroupSubmitInfoKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_SUBMIT_INFO_KHR,
    eDeviceGroupBindSparseInfoKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_BIND_SPARSE_INFO_KHR,
    eBindBufferMemoryDeviceGroupInfoKHR = VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_DEVICE_GROUP_INFO_KHR,
    eBindImageMemoryDeviceGroupInfoKHR = VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_DEVICE_GROUP_INFO_KHR,
    ePhysicalDeviceGroupPropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_GROUP_PROPERTIES_KHR,
    eDeviceGroupDeviceCreateInfoKHR = VK_STRUCTURE_TYPE_DEVICE_GROUP_DEVICE_CREATE_INFO_KHR,
    ePhysicalDeviceExternalImageFormatInfoKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_IMAGE_FORMAT_INFO_KHR,
    eExternalImageFormatPropertiesKHR = VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES_KHR,
    ePhysicalDeviceExternalBufferInfoKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_BUFFER_INFO_KHR,
    eExternalBufferPropertiesKHR = VK_STRUCTURE_TYPE_EXTERNAL_BUFFER_PROPERTIES_KHR,
    ePhysicalDeviceIdPropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_ID_PROPERTIES_KHR,
    eExternalMemoryBufferCreateInfoKHR = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO_KHR,
    eExternalMemoryImageCreateInfoKHR = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO_KHR,
    eExportMemoryAllocateInfoKHR = VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO_KHR,
    ePhysicalDeviceExternalSemaphoreInfoKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_SEMAPHORE_INFO_KHR,
    eExternalSemaphorePropertiesKHR = VK_STRUCTURE_TYPE_EXTERNAL_SEMAPHORE_PROPERTIES_KHR,
    eExportSemaphoreCreateInfoKHR = VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO_KHR,
    ePhysicalDeviceFloat16Int8FeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_FLOAT16_INT8_FEATURES_KHR,
    ePhysicalDevice16BitStorageFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_16BIT_STORAGE_FEATURES_KHR,
    eDescriptorUpdateTemplateCreateInfoKHR = VK_STRUCTURE_TYPE_DESCRIPTOR_UPDATE_TEMPLATE_CREATE_INFO_KHR,
    ePhysicalDeviceExternalFenceInfoKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_FENCE_INFO_KHR,
    eExternalFencePropertiesKHR = VK_STRUCTURE_TYPE_EXTERNAL_FENCE_PROPERTIES_KHR,
    eExportFenceCreateInfoKHR = VK_STRUCTURE_TYPE_EXPORT_FENCE_CREATE_INFO_KHR,
    ePhysicalDevicePointClippingPropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_POINT_CLIPPING_PROPERTIES_KHR,
    eRenderPassInputAttachmentAspectCreateInfoKHR = VK_STRUCTURE_TYPE_RENDER_PASS_INPUT_ATTACHMENT_ASPECT_CREATE_INFO_KHR,
    eImageViewUsageCreateInfoKHR = VK_STRUCTURE_TYPE_IMAGE_VIEW_USAGE_CREATE_INFO_KHR,
    ePipelineTessellationDomainOriginStateCreateInfoKHR = VK_STRUCTURE_TYPE_PIPELINE_TESSELLATION_DOMAIN_ORIGIN_STATE_CREATE_INFO_KHR,
    ePhysicalDeviceVariablePointerFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTER_FEATURES_KHR,
    ePhysicalDeviceVariablePointersFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_VARIABLE_POINTERS_FEATURES_KHR,
    eMemoryDedicatedRequirementsKHR = VK_STRUCTURE_TYPE_MEMORY_DEDICATED_REQUIREMENTS_KHR,
    eMemoryDedicatedAllocateInfoKHR = VK_STRUCTURE_TYPE_MEMORY_DEDICATED_ALLOCATE_INFO_KHR,
    eBufferMemoryRequirementsInfo2KHR = VK_STRUCTURE_TYPE_BUFFER_MEMORY_REQUIREMENTS_INFO_2_KHR,
    eImageMemoryRequirementsInfo2KHR = VK_STRUCTURE_TYPE_IMAGE_MEMORY_REQUIREMENTS_INFO_2_KHR,
    eImageSparseMemoryRequirementsInfo2KHR = VK_STRUCTURE_TYPE_IMAGE_SPARSE_MEMORY_REQUIREMENTS_INFO_2_KHR,
    eMemoryRequirements2KHR = VK_STRUCTURE_TYPE_MEMORY_REQUIREMENTS_2_KHR,
    eSparseImageMemoryRequirements2KHR = VK_STRUCTURE_TYPE_SPARSE_IMAGE_MEMORY_REQUIREMENTS_2_KHR,
    eSamplerYcbcrConversionCreateInfoKHR = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_CREATE_INFO_KHR,
    eSamplerYcbcrConversionInfoKHR = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_INFO_KHR,
    eBindImagePlaneMemoryInfoKHR = VK_STRUCTURE_TYPE_BIND_IMAGE_PLANE_MEMORY_INFO_KHR,
    eImagePlaneMemoryRequirementsInfoKHR = VK_STRUCTURE_TYPE_IMAGE_PLANE_MEMORY_REQUIREMENTS_INFO_KHR,
    ePhysicalDeviceSamplerYcbcrConversionFeaturesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_SAMPLER_YCBCR_CONVERSION_FEATURES_KHR,
    eSamplerYcbcrConversionImageFormatPropertiesKHR = VK_STRUCTURE_TYPE_SAMPLER_YCBCR_CONVERSION_IMAGE_FORMAT_PROPERTIES_KHR,
    eBindBufferMemoryInfoKHR = VK_STRUCTURE_TYPE_BIND_BUFFER_MEMORY_INFO_KHR,
    eBindImageMemoryInfoKHR = VK_STRUCTURE_TYPE_BIND_IMAGE_MEMORY_INFO_KHR,
    ePhysicalDeviceMaintenance3PropertiesKHR = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_MAINTENANCE_3_PROPERTIES_KHR,
    eDescriptorSetLayoutSupportKHR = VK_STRUCTURE_TYPE_DESCRIPTOR_SET_LAYOUT_SUPPORT_KHR,
    ePhysicalDeviceBufferAddressFeaturesEXT = VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_BUFFER_ADDRESS_FEATURES_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( StructureType value )
  {
    switch ( value )
    {
      case StructureType::eApplicationInfo : return "ApplicationInfo";
      case StructureType::eInstanceCreateInfo : return "InstanceCreateInfo";
      case StructureType::eDeviceQueueCreateInfo : return "DeviceQueueCreateInfo";
      case StructureType::eDeviceCreateInfo : return "DeviceCreateInfo";
      case StructureType::eSubmitInfo : return "SubmitInfo";
      case StructureType::eMemoryAllocateInfo : return "MemoryAllocateInfo";
      case StructureType::eMappedMemoryRange : return "MappedMemoryRange";
      case StructureType::eBindSparseInfo : return "BindSparseInfo";
      case StructureType::eFenceCreateInfo : return "FenceCreateInfo";
      case StructureType::eSemaphoreCreateInfo : return "SemaphoreCreateInfo";
      case StructureType::eEventCreateInfo : return "EventCreateInfo";
      case StructureType::eQueryPoolCreateInfo : return "QueryPoolCreateInfo";
      case StructureType::eBufferCreateInfo : return "BufferCreateInfo";
      case StructureType::eBufferViewCreateInfo : return "BufferViewCreateInfo";
      case StructureType::eImageCreateInfo : return "ImageCreateInfo";
      case StructureType::eImageViewCreateInfo : return "ImageViewCreateInfo";
      case StructureType::eShaderModuleCreateInfo : return "ShaderModuleCreateInfo";
      case StructureType::ePipelineCacheCreateInfo : return "PipelineCacheCreateInfo";
      case StructureType::ePipelineShaderStageCreateInfo : return "PipelineShaderStageCreateInfo";
      case StructureType::ePipelineVertexInputStateCreateInfo : return "PipelineVertexInputStateCreateInfo";
      case StructureType::ePipelineInputAssemblyStateCreateInfo : return "PipelineInputAssemblyStateCreateInfo";
      case StructureType::ePipelineTessellationStateCreateInfo : return "PipelineTessellationStateCreateInfo";
      case StructureType::ePipelineViewportStateCreateInfo : return "PipelineViewportStateCreateInfo";
      case StructureType::ePipelineRasterizationStateCreateInfo : return "PipelineRasterizationStateCreateInfo";
      case StructureType::ePipelineMultisampleStateCreateInfo : return "PipelineMultisampleStateCreateInfo";
      case StructureType::ePipelineDepthStencilStateCreateInfo : return "PipelineDepthStencilStateCreateInfo";
      case StructureType::ePipelineColorBlendStateCreateInfo : return "PipelineColorBlendStateCreateInfo";
      case StructureType::ePipelineDynamicStateCreateInfo : return "PipelineDynamicStateCreateInfo";
      case StructureType::eGraphicsPipelineCreateInfo : return "GraphicsPipelineCreateInfo";
      case StructureType::eComputePipelineCreateInfo : return "ComputePipelineCreateInfo";
      case StructureType::ePipelineLayoutCreateInfo : return "PipelineLayoutCreateInfo";
      case StructureType::eSamplerCreateInfo : return "SamplerCreateInfo";
      case StructureType::eDescriptorSetLayoutCreateInfo : return "DescriptorSetLayoutCreateInfo";
      case StructureType::eDescriptorPoolCreateInfo : return "DescriptorPoolCreateInfo";
      case StructureType::eDescriptorSetAllocateInfo : return "DescriptorSetAllocateInfo";
      case StructureType::eWriteDescriptorSet : return "WriteDescriptorSet";
      case StructureType::eCopyDescriptorSet : return "CopyDescriptorSet";
      case StructureType::eFramebufferCreateInfo : return "FramebufferCreateInfo";
      case StructureType::eRenderPassCreateInfo : return "RenderPassCreateInfo";
      case StructureType::eCommandPoolCreateInfo : return "CommandPoolCreateInfo";
      case StructureType::eCommandBufferAllocateInfo : return "CommandBufferAllocateInfo";
      case StructureType::eCommandBufferInheritanceInfo : return "CommandBufferInheritanceInfo";
      case StructureType::eCommandBufferBeginInfo : return "CommandBufferBeginInfo";
      case StructureType::eRenderPassBeginInfo : return "RenderPassBeginInfo";
      case StructureType::eBufferMemoryBarrier : return "BufferMemoryBarrier";
      case StructureType::eImageMemoryBarrier : return "ImageMemoryBarrier";
      case StructureType::eMemoryBarrier : return "MemoryBarrier";
      case StructureType::eLoaderInstanceCreateInfo : return "LoaderInstanceCreateInfo";
      case StructureType::eLoaderDeviceCreateInfo : return "LoaderDeviceCreateInfo";
      case StructureType::ePhysicalDeviceSubgroupProperties : return "PhysicalDeviceSubgroupProperties";
      case StructureType::eBindBufferMemoryInfo : return "BindBufferMemoryInfo";
      case StructureType::eBindImageMemoryInfo : return "BindImageMemoryInfo";
      case StructureType::ePhysicalDevice16BitStorageFeatures : return "PhysicalDevice16BitStorageFeatures";
      case StructureType::eMemoryDedicatedRequirements : return "MemoryDedicatedRequirements";
      case StructureType::eMemoryDedicatedAllocateInfo : return "MemoryDedicatedAllocateInfo";
      case StructureType::eMemoryAllocateFlagsInfo : return "MemoryAllocateFlagsInfo";
      case StructureType::eDeviceGroupRenderPassBeginInfo : return "DeviceGroupRenderPassBeginInfo";
      case StructureType::eDeviceGroupCommandBufferBeginInfo : return "DeviceGroupCommandBufferBeginInfo";
      case StructureType::eDeviceGroupSubmitInfo : return "DeviceGroupSubmitInfo";
      case StructureType::eDeviceGroupBindSparseInfo : return "DeviceGroupBindSparseInfo";
      case StructureType::eBindBufferMemoryDeviceGroupInfo : return "BindBufferMemoryDeviceGroupInfo";
      case StructureType::eBindImageMemoryDeviceGroupInfo : return "BindImageMemoryDeviceGroupInfo";
      case StructureType::ePhysicalDeviceGroupProperties : return "PhysicalDeviceGroupProperties";
      case StructureType::eDeviceGroupDeviceCreateInfo : return "DeviceGroupDeviceCreateInfo";
      case StructureType::eBufferMemoryRequirementsInfo2 : return "BufferMemoryRequirementsInfo2";
      case StructureType::eImageMemoryRequirementsInfo2 : return "ImageMemoryRequirementsInfo2";
      case StructureType::eImageSparseMemoryRequirementsInfo2 : return "ImageSparseMemoryRequirementsInfo2";
      case StructureType::eMemoryRequirements2 : return "MemoryRequirements2";
      case StructureType::eSparseImageMemoryRequirements2 : return "SparseImageMemoryRequirements2";
      case StructureType::ePhysicalDeviceFeatures2 : return "PhysicalDeviceFeatures2";
      case StructureType::ePhysicalDeviceProperties2 : return "PhysicalDeviceProperties2";
      case StructureType::eFormatProperties2 : return "FormatProperties2";
      case StructureType::eImageFormatProperties2 : return "ImageFormatProperties2";
      case StructureType::ePhysicalDeviceImageFormatInfo2 : return "PhysicalDeviceImageFormatInfo2";
      case StructureType::eQueueFamilyProperties2 : return "QueueFamilyProperties2";
      case StructureType::ePhysicalDeviceMemoryProperties2 : return "PhysicalDeviceMemoryProperties2";
      case StructureType::eSparseImageFormatProperties2 : return "SparseImageFormatProperties2";
      case StructureType::ePhysicalDeviceSparseImageFormatInfo2 : return "PhysicalDeviceSparseImageFormatInfo2";
      case StructureType::ePhysicalDevicePointClippingProperties : return "PhysicalDevicePointClippingProperties";
      case StructureType::eRenderPassInputAttachmentAspectCreateInfo : return "RenderPassInputAttachmentAspectCreateInfo";
      case StructureType::eImageViewUsageCreateInfo : return "ImageViewUsageCreateInfo";
      case StructureType::ePipelineTessellationDomainOriginStateCreateInfo : return "PipelineTessellationDomainOriginStateCreateInfo";
      case StructureType::eRenderPassMultiviewCreateInfo : return "RenderPassMultiviewCreateInfo";
      case StructureType::ePhysicalDeviceMultiviewFeatures : return "PhysicalDeviceMultiviewFeatures";
      case StructureType::ePhysicalDeviceMultiviewProperties : return "PhysicalDeviceMultiviewProperties";
      case StructureType::ePhysicalDeviceVariablePointersFeatures : return "PhysicalDeviceVariablePointersFeatures";
      case StructureType::eProtectedSubmitInfo : return "ProtectedSubmitInfo";
      case StructureType::ePhysicalDeviceProtectedMemoryFeatures : return "PhysicalDeviceProtectedMemoryFeatures";
      case StructureType::ePhysicalDeviceProtectedMemoryProperties : return "PhysicalDeviceProtectedMemoryProperties";
      case StructureType::eDeviceQueueInfo2 : return "DeviceQueueInfo2";
      case StructureType::eSamplerYcbcrConversionCreateInfo : return "SamplerYcbcrConversionCreateInfo";
      case StructureType::eSamplerYcbcrConversionInfo : return "SamplerYcbcrConversionInfo";
      case StructureType::eBindImagePlaneMemoryInfo : return "BindImagePlaneMemoryInfo";
      case StructureType::eImagePlaneMemoryRequirementsInfo : return "ImagePlaneMemoryRequirementsInfo";
      case StructureType::ePhysicalDeviceSamplerYcbcrConversionFeatures : return "PhysicalDeviceSamplerYcbcrConversionFeatures";
      case StructureType::eSamplerYcbcrConversionImageFormatProperties : return "SamplerYcbcrConversionImageFormatProperties";
      case StructureType::eDescriptorUpdateTemplateCreateInfo : return "DescriptorUpdateTemplateCreateInfo";
      case StructureType::ePhysicalDeviceExternalImageFormatInfo : return "PhysicalDeviceExternalImageFormatInfo";
      case StructureType::eExternalImageFormatProperties : return "ExternalImageFormatProperties";
      case StructureType::ePhysicalDeviceExternalBufferInfo : return "PhysicalDeviceExternalBufferInfo";
      case StructureType::eExternalBufferProperties : return "ExternalBufferProperties";
      case StructureType::ePhysicalDeviceIdProperties : return "PhysicalDeviceIdProperties";
      case StructureType::eExternalMemoryBufferCreateInfo : return "ExternalMemoryBufferCreateInfo";
      case StructureType::eExternalMemoryImageCreateInfo : return "ExternalMemoryImageCreateInfo";
      case StructureType::eExportMemoryAllocateInfo : return "ExportMemoryAllocateInfo";
      case StructureType::ePhysicalDeviceExternalFenceInfo : return "PhysicalDeviceExternalFenceInfo";
      case StructureType::eExternalFenceProperties : return "ExternalFenceProperties";
      case StructureType::eExportFenceCreateInfo : return "ExportFenceCreateInfo";
      case StructureType::eExportSemaphoreCreateInfo : return "ExportSemaphoreCreateInfo";
      case StructureType::ePhysicalDeviceExternalSemaphoreInfo : return "PhysicalDeviceExternalSemaphoreInfo";
      case StructureType::eExternalSemaphoreProperties : return "ExternalSemaphoreProperties";
      case StructureType::ePhysicalDeviceMaintenance3Properties : return "PhysicalDeviceMaintenance3Properties";
      case StructureType::eDescriptorSetLayoutSupport : return "DescriptorSetLayoutSupport";
      case StructureType::ePhysicalDeviceShaderDrawParametersFeatures : return "PhysicalDeviceShaderDrawParametersFeatures";
      case StructureType::eSwapchainCreateInfoKHR : return "SwapchainCreateInfoKHR";
      case StructureType::ePresentInfoKHR : return "PresentInfoKHR";
      case StructureType::eDeviceGroupPresentCapabilitiesKHR : return "DeviceGroupPresentCapabilitiesKHR";
      case StructureType::eImageSwapchainCreateInfoKHR : return "ImageSwapchainCreateInfoKHR";
      case StructureType::eBindImageMemorySwapchainInfoKHR : return "BindImageMemorySwapchainInfoKHR";
      case StructureType::eAcquireNextImageInfoKHR : return "AcquireNextImageInfoKHR";
      case StructureType::eDeviceGroupPresentInfoKHR : return "DeviceGroupPresentInfoKHR";
      case StructureType::eDeviceGroupSwapchainCreateInfoKHR : return "DeviceGroupSwapchainCreateInfoKHR";
      case StructureType::eDisplayModeCreateInfoKHR : return "DisplayModeCreateInfoKHR";
      case StructureType::eDisplaySurfaceCreateInfoKHR : return "DisplaySurfaceCreateInfoKHR";
      case StructureType::eDisplayPresentInfoKHR : return "DisplayPresentInfoKHR";
      case StructureType::eXlibSurfaceCreateInfoKHR : return "XlibSurfaceCreateInfoKHR";
      case StructureType::eXcbSurfaceCreateInfoKHR : return "XcbSurfaceCreateInfoKHR";
      case StructureType::eWaylandSurfaceCreateInfoKHR : return "WaylandSurfaceCreateInfoKHR";
      case StructureType::eAndroidSurfaceCreateInfoKHR : return "AndroidSurfaceCreateInfoKHR";
      case StructureType::eWin32SurfaceCreateInfoKHR : return "Win32SurfaceCreateInfoKHR";
      case StructureType::eDebugReportCallbackCreateInfoEXT : return "DebugReportCallbackCreateInfoEXT";
      case StructureType::ePipelineRasterizationStateRasterizationOrderAMD : return "PipelineRasterizationStateRasterizationOrderAMD";
      case StructureType::eDebugMarkerObjectNameInfoEXT : return "DebugMarkerObjectNameInfoEXT";
      case StructureType::eDebugMarkerObjectTagInfoEXT : return "DebugMarkerObjectTagInfoEXT";
      case StructureType::eDebugMarkerMarkerInfoEXT : return "DebugMarkerMarkerInfoEXT";
      case StructureType::eDedicatedAllocationImageCreateInfoNV : return "DedicatedAllocationImageCreateInfoNV";
      case StructureType::eDedicatedAllocationBufferCreateInfoNV : return "DedicatedAllocationBufferCreateInfoNV";
      case StructureType::eDedicatedAllocationMemoryAllocateInfoNV : return "DedicatedAllocationMemoryAllocateInfoNV";
      case StructureType::ePhysicalDeviceTransformFeedbackFeaturesEXT : return "PhysicalDeviceTransformFeedbackFeaturesEXT";
      case StructureType::ePhysicalDeviceTransformFeedbackPropertiesEXT : return "PhysicalDeviceTransformFeedbackPropertiesEXT";
      case StructureType::ePipelineRasterizationStateStreamCreateInfoEXT : return "PipelineRasterizationStateStreamCreateInfoEXT";
      case StructureType::eImageViewHandleInfoNVX : return "ImageViewHandleInfoNVX";
      case StructureType::eTextureLodGatherFormatPropertiesAMD : return "TextureLodGatherFormatPropertiesAMD";
      case StructureType::eStreamDescriptorSurfaceCreateInfoGGP : return "StreamDescriptorSurfaceCreateInfoGGP";
      case StructureType::ePhysicalDeviceCornerSampledImageFeaturesNV : return "PhysicalDeviceCornerSampledImageFeaturesNV";
      case StructureType::eExternalMemoryImageCreateInfoNV : return "ExternalMemoryImageCreateInfoNV";
      case StructureType::eExportMemoryAllocateInfoNV : return "ExportMemoryAllocateInfoNV";
      case StructureType::eImportMemoryWin32HandleInfoNV : return "ImportMemoryWin32HandleInfoNV";
      case StructureType::eExportMemoryWin32HandleInfoNV : return "ExportMemoryWin32HandleInfoNV";
      case StructureType::eWin32KeyedMutexAcquireReleaseInfoNV : return "Win32KeyedMutexAcquireReleaseInfoNV";
      case StructureType::eValidationFlagsEXT : return "ValidationFlagsEXT";
      case StructureType::eViSurfaceCreateInfoNN : return "ViSurfaceCreateInfoNN";
      case StructureType::ePhysicalDeviceTextureCompressionAstcHdrFeaturesEXT : return "PhysicalDeviceTextureCompressionAstcHdrFeaturesEXT";
      case StructureType::eImageViewAstcDecodeModeEXT : return "ImageViewAstcDecodeModeEXT";
      case StructureType::ePhysicalDeviceAstcDecodeFeaturesEXT : return "PhysicalDeviceAstcDecodeFeaturesEXT";
      case StructureType::eImportMemoryWin32HandleInfoKHR : return "ImportMemoryWin32HandleInfoKHR";
      case StructureType::eExportMemoryWin32HandleInfoKHR : return "ExportMemoryWin32HandleInfoKHR";
      case StructureType::eMemoryWin32HandlePropertiesKHR : return "MemoryWin32HandlePropertiesKHR";
      case StructureType::eMemoryGetWin32HandleInfoKHR : return "MemoryGetWin32HandleInfoKHR";
      case StructureType::eImportMemoryFdInfoKHR : return "ImportMemoryFdInfoKHR";
      case StructureType::eMemoryFdPropertiesKHR : return "MemoryFdPropertiesKHR";
      case StructureType::eMemoryGetFdInfoKHR : return "MemoryGetFdInfoKHR";
      case StructureType::eWin32KeyedMutexAcquireReleaseInfoKHR : return "Win32KeyedMutexAcquireReleaseInfoKHR";
      case StructureType::eImportSemaphoreWin32HandleInfoKHR : return "ImportSemaphoreWin32HandleInfoKHR";
      case StructureType::eExportSemaphoreWin32HandleInfoKHR : return "ExportSemaphoreWin32HandleInfoKHR";
      case StructureType::eD3D12FenceSubmitInfoKHR : return "D3D12FenceSubmitInfoKHR";
      case StructureType::eSemaphoreGetWin32HandleInfoKHR : return "SemaphoreGetWin32HandleInfoKHR";
      case StructureType::eImportSemaphoreFdInfoKHR : return "ImportSemaphoreFdInfoKHR";
      case StructureType::eSemaphoreGetFdInfoKHR : return "SemaphoreGetFdInfoKHR";
      case StructureType::ePhysicalDevicePushDescriptorPropertiesKHR : return "PhysicalDevicePushDescriptorPropertiesKHR";
      case StructureType::eCommandBufferInheritanceConditionalRenderingInfoEXT : return "CommandBufferInheritanceConditionalRenderingInfoEXT";
      case StructureType::ePhysicalDeviceConditionalRenderingFeaturesEXT : return "PhysicalDeviceConditionalRenderingFeaturesEXT";
      case StructureType::eConditionalRenderingBeginInfoEXT : return "ConditionalRenderingBeginInfoEXT";
      case StructureType::ePhysicalDeviceShaderFloat16Int8FeaturesKHR : return "PhysicalDeviceShaderFloat16Int8FeaturesKHR";
      case StructureType::ePresentRegionsKHR : return "PresentRegionsKHR";
      case StructureType::eObjectTableCreateInfoNVX : return "ObjectTableCreateInfoNVX";
      case StructureType::eIndirectCommandsLayoutCreateInfoNVX : return "IndirectCommandsLayoutCreateInfoNVX";
      case StructureType::eCmdProcessCommandsInfoNVX : return "CmdProcessCommandsInfoNVX";
      case StructureType::eCmdReserveSpaceForCommandsInfoNVX : return "CmdReserveSpaceForCommandsInfoNVX";
      case StructureType::eDeviceGeneratedCommandsLimitsNVX : return "DeviceGeneratedCommandsLimitsNVX";
      case StructureType::eDeviceGeneratedCommandsFeaturesNVX : return "DeviceGeneratedCommandsFeaturesNVX";
      case StructureType::ePipelineViewportWScalingStateCreateInfoNV : return "PipelineViewportWScalingStateCreateInfoNV";
      case StructureType::eSurfaceCapabilities2EXT : return "SurfaceCapabilities2EXT";
      case StructureType::eDisplayPowerInfoEXT : return "DisplayPowerInfoEXT";
      case StructureType::eDeviceEventInfoEXT : return "DeviceEventInfoEXT";
      case StructureType::eDisplayEventInfoEXT : return "DisplayEventInfoEXT";
      case StructureType::eSwapchainCounterCreateInfoEXT : return "SwapchainCounterCreateInfoEXT";
      case StructureType::ePresentTimesInfoGOOGLE : return "PresentTimesInfoGOOGLE";
      case StructureType::ePhysicalDeviceMultiviewPerViewAttributesPropertiesNVX : return "PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX";
      case StructureType::ePipelineViewportSwizzleStateCreateInfoNV : return "PipelineViewportSwizzleStateCreateInfoNV";
      case StructureType::ePhysicalDeviceDiscardRectanglePropertiesEXT : return "PhysicalDeviceDiscardRectanglePropertiesEXT";
      case StructureType::ePipelineDiscardRectangleStateCreateInfoEXT : return "PipelineDiscardRectangleStateCreateInfoEXT";
      case StructureType::ePhysicalDeviceConservativeRasterizationPropertiesEXT : return "PhysicalDeviceConservativeRasterizationPropertiesEXT";
      case StructureType::ePipelineRasterizationConservativeStateCreateInfoEXT : return "PipelineRasterizationConservativeStateCreateInfoEXT";
      case StructureType::ePhysicalDeviceDepthClipEnableFeaturesEXT : return "PhysicalDeviceDepthClipEnableFeaturesEXT";
      case StructureType::ePipelineRasterizationDepthClipStateCreateInfoEXT : return "PipelineRasterizationDepthClipStateCreateInfoEXT";
      case StructureType::eHdrMetadataEXT : return "HdrMetadataEXT";
      case StructureType::ePhysicalDeviceImagelessFramebufferFeaturesKHR : return "PhysicalDeviceImagelessFramebufferFeaturesKHR";
      case StructureType::eFramebufferAttachmentsCreateInfoKHR : return "FramebufferAttachmentsCreateInfoKHR";
      case StructureType::eFramebufferAttachmentImageInfoKHR : return "FramebufferAttachmentImageInfoKHR";
      case StructureType::eRenderPassAttachmentBeginInfoKHR : return "RenderPassAttachmentBeginInfoKHR";
      case StructureType::eAttachmentDescription2KHR : return "AttachmentDescription2KHR";
      case StructureType::eAttachmentReference2KHR : return "AttachmentReference2KHR";
      case StructureType::eSubpassDescription2KHR : return "SubpassDescription2KHR";
      case StructureType::eSubpassDependency2KHR : return "SubpassDependency2KHR";
      case StructureType::eRenderPassCreateInfo2KHR : return "RenderPassCreateInfo2KHR";
      case StructureType::eSubpassBeginInfoKHR : return "SubpassBeginInfoKHR";
      case StructureType::eSubpassEndInfoKHR : return "SubpassEndInfoKHR";
      case StructureType::eSharedPresentSurfaceCapabilitiesKHR : return "SharedPresentSurfaceCapabilitiesKHR";
      case StructureType::eImportFenceWin32HandleInfoKHR : return "ImportFenceWin32HandleInfoKHR";
      case StructureType::eExportFenceWin32HandleInfoKHR : return "ExportFenceWin32HandleInfoKHR";
      case StructureType::eFenceGetWin32HandleInfoKHR : return "FenceGetWin32HandleInfoKHR";
      case StructureType::eImportFenceFdInfoKHR : return "ImportFenceFdInfoKHR";
      case StructureType::eFenceGetFdInfoKHR : return "FenceGetFdInfoKHR";
      case StructureType::ePhysicalDeviceSurfaceInfo2KHR : return "PhysicalDeviceSurfaceInfo2KHR";
      case StructureType::eSurfaceCapabilities2KHR : return "SurfaceCapabilities2KHR";
      case StructureType::eSurfaceFormat2KHR : return "SurfaceFormat2KHR";
      case StructureType::eDisplayProperties2KHR : return "DisplayProperties2KHR";
      case StructureType::eDisplayPlaneProperties2KHR : return "DisplayPlaneProperties2KHR";
      case StructureType::eDisplayModeProperties2KHR : return "DisplayModeProperties2KHR";
      case StructureType::eDisplayPlaneInfo2KHR : return "DisplayPlaneInfo2KHR";
      case StructureType::eDisplayPlaneCapabilities2KHR : return "DisplayPlaneCapabilities2KHR";
      case StructureType::eIosSurfaceCreateInfoMVK : return "IosSurfaceCreateInfoMVK";
      case StructureType::eMacosSurfaceCreateInfoMVK : return "MacosSurfaceCreateInfoMVK";
      case StructureType::eDebugUtilsObjectNameInfoEXT : return "DebugUtilsObjectNameInfoEXT";
      case StructureType::eDebugUtilsObjectTagInfoEXT : return "DebugUtilsObjectTagInfoEXT";
      case StructureType::eDebugUtilsLabelEXT : return "DebugUtilsLabelEXT";
      case StructureType::eDebugUtilsMessengerCallbackDataEXT : return "DebugUtilsMessengerCallbackDataEXT";
      case StructureType::eDebugUtilsMessengerCreateInfoEXT : return "DebugUtilsMessengerCreateInfoEXT";
      case StructureType::eAndroidHardwareBufferUsageANDROID : return "AndroidHardwareBufferUsageANDROID";
      case StructureType::eAndroidHardwareBufferPropertiesANDROID : return "AndroidHardwareBufferPropertiesANDROID";
      case StructureType::eAndroidHardwareBufferFormatPropertiesANDROID : return "AndroidHardwareBufferFormatPropertiesANDROID";
      case StructureType::eImportAndroidHardwareBufferInfoANDROID : return "ImportAndroidHardwareBufferInfoANDROID";
      case StructureType::eMemoryGetAndroidHardwareBufferInfoANDROID : return "MemoryGetAndroidHardwareBufferInfoANDROID";
      case StructureType::eExternalFormatANDROID : return "ExternalFormatANDROID";
      case StructureType::ePhysicalDeviceSamplerFilterMinmaxPropertiesEXT : return "PhysicalDeviceSamplerFilterMinmaxPropertiesEXT";
      case StructureType::eSamplerReductionModeCreateInfoEXT : return "SamplerReductionModeCreateInfoEXT";
      case StructureType::ePhysicalDeviceInlineUniformBlockFeaturesEXT : return "PhysicalDeviceInlineUniformBlockFeaturesEXT";
      case StructureType::ePhysicalDeviceInlineUniformBlockPropertiesEXT : return "PhysicalDeviceInlineUniformBlockPropertiesEXT";
      case StructureType::eWriteDescriptorSetInlineUniformBlockEXT : return "WriteDescriptorSetInlineUniformBlockEXT";
      case StructureType::eDescriptorPoolInlineUniformBlockCreateInfoEXT : return "DescriptorPoolInlineUniformBlockCreateInfoEXT";
      case StructureType::eSampleLocationsInfoEXT : return "SampleLocationsInfoEXT";
      case StructureType::eRenderPassSampleLocationsBeginInfoEXT : return "RenderPassSampleLocationsBeginInfoEXT";
      case StructureType::ePipelineSampleLocationsStateCreateInfoEXT : return "PipelineSampleLocationsStateCreateInfoEXT";
      case StructureType::ePhysicalDeviceSampleLocationsPropertiesEXT : return "PhysicalDeviceSampleLocationsPropertiesEXT";
      case StructureType::eMultisamplePropertiesEXT : return "MultisamplePropertiesEXT";
      case StructureType::eImageFormatListCreateInfoKHR : return "ImageFormatListCreateInfoKHR";
      case StructureType::ePhysicalDeviceBlendOperationAdvancedFeaturesEXT : return "PhysicalDeviceBlendOperationAdvancedFeaturesEXT";
      case StructureType::ePhysicalDeviceBlendOperationAdvancedPropertiesEXT : return "PhysicalDeviceBlendOperationAdvancedPropertiesEXT";
      case StructureType::ePipelineColorBlendAdvancedStateCreateInfoEXT : return "PipelineColorBlendAdvancedStateCreateInfoEXT";
      case StructureType::ePipelineCoverageToColorStateCreateInfoNV : return "PipelineCoverageToColorStateCreateInfoNV";
      case StructureType::ePipelineCoverageModulationStateCreateInfoNV : return "PipelineCoverageModulationStateCreateInfoNV";
      case StructureType::ePhysicalDeviceShaderSmBuiltinsFeaturesNV : return "PhysicalDeviceShaderSmBuiltinsFeaturesNV";
      case StructureType::ePhysicalDeviceShaderSmBuiltinsPropertiesNV : return "PhysicalDeviceShaderSmBuiltinsPropertiesNV";
      case StructureType::eDrmFormatModifierPropertiesListEXT : return "DrmFormatModifierPropertiesListEXT";
      case StructureType::eDrmFormatModifierPropertiesEXT : return "DrmFormatModifierPropertiesEXT";
      case StructureType::ePhysicalDeviceImageDrmFormatModifierInfoEXT : return "PhysicalDeviceImageDrmFormatModifierInfoEXT";
      case StructureType::eImageDrmFormatModifierListCreateInfoEXT : return "ImageDrmFormatModifierListCreateInfoEXT";
      case StructureType::eImageDrmFormatModifierExplicitCreateInfoEXT : return "ImageDrmFormatModifierExplicitCreateInfoEXT";
      case StructureType::eImageDrmFormatModifierPropertiesEXT : return "ImageDrmFormatModifierPropertiesEXT";
      case StructureType::eValidationCacheCreateInfoEXT : return "ValidationCacheCreateInfoEXT";
      case StructureType::eShaderModuleValidationCacheCreateInfoEXT : return "ShaderModuleValidationCacheCreateInfoEXT";
      case StructureType::eDescriptorSetLayoutBindingFlagsCreateInfoEXT : return "DescriptorSetLayoutBindingFlagsCreateInfoEXT";
      case StructureType::ePhysicalDeviceDescriptorIndexingFeaturesEXT : return "PhysicalDeviceDescriptorIndexingFeaturesEXT";
      case StructureType::ePhysicalDeviceDescriptorIndexingPropertiesEXT : return "PhysicalDeviceDescriptorIndexingPropertiesEXT";
      case StructureType::eDescriptorSetVariableDescriptorCountAllocateInfoEXT : return "DescriptorSetVariableDescriptorCountAllocateInfoEXT";
      case StructureType::eDescriptorSetVariableDescriptorCountLayoutSupportEXT : return "DescriptorSetVariableDescriptorCountLayoutSupportEXT";
      case StructureType::ePipelineViewportShadingRateImageStateCreateInfoNV : return "PipelineViewportShadingRateImageStateCreateInfoNV";
      case StructureType::ePhysicalDeviceShadingRateImageFeaturesNV : return "PhysicalDeviceShadingRateImageFeaturesNV";
      case StructureType::ePhysicalDeviceShadingRateImagePropertiesNV : return "PhysicalDeviceShadingRateImagePropertiesNV";
      case StructureType::ePipelineViewportCoarseSampleOrderStateCreateInfoNV : return "PipelineViewportCoarseSampleOrderStateCreateInfoNV";
      case StructureType::eRayTracingPipelineCreateInfoNV : return "RayTracingPipelineCreateInfoNV";
      case StructureType::eAccelerationStructureCreateInfoNV : return "AccelerationStructureCreateInfoNV";
      case StructureType::eGeometryNV : return "GeometryNV";
      case StructureType::eGeometryTrianglesNV : return "GeometryTrianglesNV";
      case StructureType::eGeometryAabbNV : return "GeometryAabbNV";
      case StructureType::eBindAccelerationStructureMemoryInfoNV : return "BindAccelerationStructureMemoryInfoNV";
      case StructureType::eWriteDescriptorSetAccelerationStructureNV : return "WriteDescriptorSetAccelerationStructureNV";
      case StructureType::eAccelerationStructureMemoryRequirementsInfoNV : return "AccelerationStructureMemoryRequirementsInfoNV";
      case StructureType::ePhysicalDeviceRayTracingPropertiesNV : return "PhysicalDeviceRayTracingPropertiesNV";
      case StructureType::eRayTracingShaderGroupCreateInfoNV : return "RayTracingShaderGroupCreateInfoNV";
      case StructureType::eAccelerationStructureInfoNV : return "AccelerationStructureInfoNV";
      case StructureType::ePhysicalDeviceRepresentativeFragmentTestFeaturesNV : return "PhysicalDeviceRepresentativeFragmentTestFeaturesNV";
      case StructureType::ePipelineRepresentativeFragmentTestStateCreateInfoNV : return "PipelineRepresentativeFragmentTestStateCreateInfoNV";
      case StructureType::ePhysicalDeviceImageViewImageFormatInfoEXT : return "PhysicalDeviceImageViewImageFormatInfoEXT";
      case StructureType::eFilterCubicImageViewImageFormatPropertiesEXT : return "FilterCubicImageViewImageFormatPropertiesEXT";
      case StructureType::eDeviceQueueGlobalPriorityCreateInfoEXT : return "DeviceQueueGlobalPriorityCreateInfoEXT";
      case StructureType::ePhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR : return "PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR";
      case StructureType::ePhysicalDevice8BitStorageFeaturesKHR : return "PhysicalDevice8BitStorageFeaturesKHR";
      case StructureType::eImportMemoryHostPointerInfoEXT : return "ImportMemoryHostPointerInfoEXT";
      case StructureType::eMemoryHostPointerPropertiesEXT : return "MemoryHostPointerPropertiesEXT";
      case StructureType::ePhysicalDeviceExternalMemoryHostPropertiesEXT : return "PhysicalDeviceExternalMemoryHostPropertiesEXT";
      case StructureType::ePhysicalDeviceShaderAtomicInt64FeaturesKHR : return "PhysicalDeviceShaderAtomicInt64FeaturesKHR";
      case StructureType::ePhysicalDeviceShaderClockFeaturesKHR : return "PhysicalDeviceShaderClockFeaturesKHR";
      case StructureType::ePipelineCompilerControlCreateInfoAMD : return "PipelineCompilerControlCreateInfoAMD";
      case StructureType::eCalibratedTimestampInfoEXT : return "CalibratedTimestampInfoEXT";
      case StructureType::ePhysicalDeviceShaderCorePropertiesAMD : return "PhysicalDeviceShaderCorePropertiesAMD";
      case StructureType::eDeviceMemoryOverallocationCreateInfoAMD : return "DeviceMemoryOverallocationCreateInfoAMD";
      case StructureType::ePhysicalDeviceVertexAttributeDivisorPropertiesEXT : return "PhysicalDeviceVertexAttributeDivisorPropertiesEXT";
      case StructureType::ePipelineVertexInputDivisorStateCreateInfoEXT : return "PipelineVertexInputDivisorStateCreateInfoEXT";
      case StructureType::ePhysicalDeviceVertexAttributeDivisorFeaturesEXT : return "PhysicalDeviceVertexAttributeDivisorFeaturesEXT";
      case StructureType::ePresentFrameTokenGGP : return "PresentFrameTokenGGP";
      case StructureType::ePipelineCreationFeedbackCreateInfoEXT : return "PipelineCreationFeedbackCreateInfoEXT";
      case StructureType::ePhysicalDeviceDriverPropertiesKHR : return "PhysicalDeviceDriverPropertiesKHR";
      case StructureType::ePhysicalDeviceFloatControlsPropertiesKHR : return "PhysicalDeviceFloatControlsPropertiesKHR";
      case StructureType::ePhysicalDeviceDepthStencilResolvePropertiesKHR : return "PhysicalDeviceDepthStencilResolvePropertiesKHR";
      case StructureType::eSubpassDescriptionDepthStencilResolveKHR : return "SubpassDescriptionDepthStencilResolveKHR";
      case StructureType::ePhysicalDeviceComputeShaderDerivativesFeaturesNV : return "PhysicalDeviceComputeShaderDerivativesFeaturesNV";
      case StructureType::ePhysicalDeviceMeshShaderFeaturesNV : return "PhysicalDeviceMeshShaderFeaturesNV";
      case StructureType::ePhysicalDeviceMeshShaderPropertiesNV : return "PhysicalDeviceMeshShaderPropertiesNV";
      case StructureType::ePhysicalDeviceFragmentShaderBarycentricFeaturesNV : return "PhysicalDeviceFragmentShaderBarycentricFeaturesNV";
      case StructureType::ePhysicalDeviceShaderImageFootprintFeaturesNV : return "PhysicalDeviceShaderImageFootprintFeaturesNV";
      case StructureType::ePipelineViewportExclusiveScissorStateCreateInfoNV : return "PipelineViewportExclusiveScissorStateCreateInfoNV";
      case StructureType::ePhysicalDeviceExclusiveScissorFeaturesNV : return "PhysicalDeviceExclusiveScissorFeaturesNV";
      case StructureType::eCheckpointDataNV : return "CheckpointDataNV";
      case StructureType::eQueueFamilyCheckpointPropertiesNV : return "QueueFamilyCheckpointPropertiesNV";
      case StructureType::ePhysicalDeviceTimelineSemaphoreFeaturesKHR : return "PhysicalDeviceTimelineSemaphoreFeaturesKHR";
      case StructureType::ePhysicalDeviceTimelineSemaphorePropertiesKHR : return "PhysicalDeviceTimelineSemaphorePropertiesKHR";
      case StructureType::eSemaphoreTypeCreateInfoKHR : return "SemaphoreTypeCreateInfoKHR";
      case StructureType::eTimelineSemaphoreSubmitInfoKHR : return "TimelineSemaphoreSubmitInfoKHR";
      case StructureType::eSemaphoreWaitInfoKHR : return "SemaphoreWaitInfoKHR";
      case StructureType::eSemaphoreSignalInfoKHR : return "SemaphoreSignalInfoKHR";
      case StructureType::ePhysicalDeviceShaderIntegerFunctions2FeaturesINTEL : return "PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL";
      case StructureType::eQueryPoolCreateInfoINTEL : return "QueryPoolCreateInfoINTEL";
      case StructureType::eInitializePerformanceApiInfoINTEL : return "InitializePerformanceApiInfoINTEL";
      case StructureType::ePerformanceMarkerInfoINTEL : return "PerformanceMarkerInfoINTEL";
      case StructureType::ePerformanceStreamMarkerInfoINTEL : return "PerformanceStreamMarkerInfoINTEL";
      case StructureType::ePerformanceOverrideInfoINTEL : return "PerformanceOverrideInfoINTEL";
      case StructureType::ePerformanceConfigurationAcquireInfoINTEL : return "PerformanceConfigurationAcquireInfoINTEL";
      case StructureType::ePhysicalDeviceVulkanMemoryModelFeaturesKHR : return "PhysicalDeviceVulkanMemoryModelFeaturesKHR";
      case StructureType::ePhysicalDevicePciBusInfoPropertiesEXT : return "PhysicalDevicePciBusInfoPropertiesEXT";
      case StructureType::eDisplayNativeHdrSurfaceCapabilitiesAMD : return "DisplayNativeHdrSurfaceCapabilitiesAMD";
      case StructureType::eSwapchainDisplayNativeHdrCreateInfoAMD : return "SwapchainDisplayNativeHdrCreateInfoAMD";
      case StructureType::eImagepipeSurfaceCreateInfoFUCHSIA : return "ImagepipeSurfaceCreateInfoFUCHSIA";
      case StructureType::eMetalSurfaceCreateInfoEXT : return "MetalSurfaceCreateInfoEXT";
      case StructureType::ePhysicalDeviceFragmentDensityMapFeaturesEXT : return "PhysicalDeviceFragmentDensityMapFeaturesEXT";
      case StructureType::ePhysicalDeviceFragmentDensityMapPropertiesEXT : return "PhysicalDeviceFragmentDensityMapPropertiesEXT";
      case StructureType::eRenderPassFragmentDensityMapCreateInfoEXT : return "RenderPassFragmentDensityMapCreateInfoEXT";
      case StructureType::ePhysicalDeviceScalarBlockLayoutFeaturesEXT : return "PhysicalDeviceScalarBlockLayoutFeaturesEXT";
      case StructureType::ePhysicalDeviceSubgroupSizeControlPropertiesEXT : return "PhysicalDeviceSubgroupSizeControlPropertiesEXT";
      case StructureType::ePipelineShaderStageRequiredSubgroupSizeCreateInfoEXT : return "PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT";
      case StructureType::ePhysicalDeviceSubgroupSizeControlFeaturesEXT : return "PhysicalDeviceSubgroupSizeControlFeaturesEXT";
      case StructureType::ePhysicalDeviceShaderCoreProperties2AMD : return "PhysicalDeviceShaderCoreProperties2AMD";
      case StructureType::ePhysicalDeviceCoherentMemoryFeaturesAMD : return "PhysicalDeviceCoherentMemoryFeaturesAMD";
      case StructureType::ePhysicalDeviceMemoryBudgetPropertiesEXT : return "PhysicalDeviceMemoryBudgetPropertiesEXT";
      case StructureType::ePhysicalDeviceMemoryPriorityFeaturesEXT : return "PhysicalDeviceMemoryPriorityFeaturesEXT";
      case StructureType::eMemoryPriorityAllocateInfoEXT : return "MemoryPriorityAllocateInfoEXT";
      case StructureType::eSurfaceProtectedCapabilitiesKHR : return "SurfaceProtectedCapabilitiesKHR";
      case StructureType::ePhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV : return "PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV";
      case StructureType::ePhysicalDeviceBufferDeviceAddressFeaturesEXT : return "PhysicalDeviceBufferDeviceAddressFeaturesEXT";
      case StructureType::eBufferDeviceAddressInfoEXT : return "BufferDeviceAddressInfoEXT";
      case StructureType::eBufferDeviceAddressCreateInfoEXT : return "BufferDeviceAddressCreateInfoEXT";
      case StructureType::eImageStencilUsageCreateInfoEXT : return "ImageStencilUsageCreateInfoEXT";
      case StructureType::eValidationFeaturesEXT : return "ValidationFeaturesEXT";
      case StructureType::ePhysicalDeviceCooperativeMatrixFeaturesNV : return "PhysicalDeviceCooperativeMatrixFeaturesNV";
      case StructureType::eCooperativeMatrixPropertiesNV : return "CooperativeMatrixPropertiesNV";
      case StructureType::ePhysicalDeviceCooperativeMatrixPropertiesNV : return "PhysicalDeviceCooperativeMatrixPropertiesNV";
      case StructureType::ePhysicalDeviceCoverageReductionModeFeaturesNV : return "PhysicalDeviceCoverageReductionModeFeaturesNV";
      case StructureType::ePipelineCoverageReductionStateCreateInfoNV : return "PipelineCoverageReductionStateCreateInfoNV";
      case StructureType::eFramebufferMixedSamplesCombinationNV : return "FramebufferMixedSamplesCombinationNV";
      case StructureType::ePhysicalDeviceFragmentShaderInterlockFeaturesEXT : return "PhysicalDeviceFragmentShaderInterlockFeaturesEXT";
      case StructureType::ePhysicalDeviceYcbcrImageArraysFeaturesEXT : return "PhysicalDeviceYcbcrImageArraysFeaturesEXT";
      case StructureType::ePhysicalDeviceUniformBufferStandardLayoutFeaturesKHR : return "PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR";
      case StructureType::eSurfaceFullScreenExclusiveInfoEXT : return "SurfaceFullScreenExclusiveInfoEXT";
      case StructureType::eSurfaceCapabilitiesFullScreenExclusiveEXT : return "SurfaceCapabilitiesFullScreenExclusiveEXT";
      case StructureType::eSurfaceFullScreenExclusiveWin32InfoEXT : return "SurfaceFullScreenExclusiveWin32InfoEXT";
      case StructureType::eHeadlessSurfaceCreateInfoEXT : return "HeadlessSurfaceCreateInfoEXT";
      case StructureType::ePhysicalDeviceLineRasterizationFeaturesEXT : return "PhysicalDeviceLineRasterizationFeaturesEXT";
      case StructureType::ePipelineRasterizationLineStateCreateInfoEXT : return "PipelineRasterizationLineStateCreateInfoEXT";
      case StructureType::ePhysicalDeviceLineRasterizationPropertiesEXT : return "PhysicalDeviceLineRasterizationPropertiesEXT";
      case StructureType::ePhysicalDeviceHostQueryResetFeaturesEXT : return "PhysicalDeviceHostQueryResetFeaturesEXT";
      case StructureType::ePhysicalDeviceIndexTypeUint8FeaturesEXT : return "PhysicalDeviceIndexTypeUint8FeaturesEXT";
      case StructureType::ePhysicalDevicePipelineExecutablePropertiesFeaturesKHR : return "PhysicalDevicePipelineExecutablePropertiesFeaturesKHR";
      case StructureType::ePipelineInfoKHR : return "PipelineInfoKHR";
      case StructureType::ePipelineExecutablePropertiesKHR : return "PipelineExecutablePropertiesKHR";
      case StructureType::ePipelineExecutableInfoKHR : return "PipelineExecutableInfoKHR";
      case StructureType::ePipelineExecutableStatisticKHR : return "PipelineExecutableStatisticKHR";
      case StructureType::ePipelineExecutableInternalRepresentationKHR : return "PipelineExecutableInternalRepresentationKHR";
      case StructureType::ePhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT : return "PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT";
      case StructureType::ePhysicalDeviceTexelBufferAlignmentFeaturesEXT : return "PhysicalDeviceTexelBufferAlignmentFeaturesEXT";
      case StructureType::ePhysicalDeviceTexelBufferAlignmentPropertiesEXT : return "PhysicalDeviceTexelBufferAlignmentPropertiesEXT";
      default: return "invalid";
    }
  }

  enum class SubpassContents
  {
    eInline = VK_SUBPASS_CONTENTS_INLINE,
    eSecondaryCommandBuffers = VK_SUBPASS_CONTENTS_SECONDARY_COMMAND_BUFFERS
  };

  VULKAN_HPP_INLINE std::string to_string( SubpassContents value )
  {
    switch ( value )
    {
      case SubpassContents::eInline : return "Inline";
      case SubpassContents::eSecondaryCommandBuffers : return "SecondaryCommandBuffers";
      default: return "invalid";
    }
  }

  enum class SystemAllocationScope
  {
    eCommand = VK_SYSTEM_ALLOCATION_SCOPE_COMMAND,
    eObject = VK_SYSTEM_ALLOCATION_SCOPE_OBJECT,
    eCache = VK_SYSTEM_ALLOCATION_SCOPE_CACHE,
    eDevice = VK_SYSTEM_ALLOCATION_SCOPE_DEVICE,
    eInstance = VK_SYSTEM_ALLOCATION_SCOPE_INSTANCE
  };

  VULKAN_HPP_INLINE std::string to_string( SystemAllocationScope value )
  {
    switch ( value )
    {
      case SystemAllocationScope::eCommand : return "Command";
      case SystemAllocationScope::eObject : return "Object";
      case SystemAllocationScope::eCache : return "Cache";
      case SystemAllocationScope::eDevice : return "Device";
      case SystemAllocationScope::eInstance : return "Instance";
      default: return "invalid";
    }
  }

  enum class TessellationDomainOrigin
  {
    eUpperLeft = VK_TESSELLATION_DOMAIN_ORIGIN_UPPER_LEFT,
    eLowerLeft = VK_TESSELLATION_DOMAIN_ORIGIN_LOWER_LEFT,
    eUpperLeftKHR = VK_TESSELLATION_DOMAIN_ORIGIN_UPPER_LEFT_KHR,
    eLowerLeftKHR = VK_TESSELLATION_DOMAIN_ORIGIN_LOWER_LEFT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( TessellationDomainOrigin value )
  {
    switch ( value )
    {
      case TessellationDomainOrigin::eUpperLeft : return "UpperLeft";
      case TessellationDomainOrigin::eLowerLeft : return "LowerLeft";
      default: return "invalid";
    }
  }

  enum class TimeDomainEXT
  {
    eDevice = VK_TIME_DOMAIN_DEVICE_EXT,
    eClockMonotonic = VK_TIME_DOMAIN_CLOCK_MONOTONIC_EXT,
    eClockMonotonicRaw = VK_TIME_DOMAIN_CLOCK_MONOTONIC_RAW_EXT,
    eQueryPerformanceCounter = VK_TIME_DOMAIN_QUERY_PERFORMANCE_COUNTER_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( TimeDomainEXT value )
  {
    switch ( value )
    {
      case TimeDomainEXT::eDevice : return "Device";
      case TimeDomainEXT::eClockMonotonic : return "ClockMonotonic";
      case TimeDomainEXT::eClockMonotonicRaw : return "ClockMonotonicRaw";
      case TimeDomainEXT::eQueryPerformanceCounter : return "QueryPerformanceCounter";
      default: return "invalid";
    }
  }

  enum class ValidationCacheHeaderVersionEXT
  {
    eOne = VK_VALIDATION_CACHE_HEADER_VERSION_ONE_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ValidationCacheHeaderVersionEXT value )
  {
    switch ( value )
    {
      case ValidationCacheHeaderVersionEXT::eOne : return "One";
      default: return "invalid";
    }
  }

  enum class ValidationCheckEXT
  {
    eAll = VK_VALIDATION_CHECK_ALL_EXT,
    eShaders = VK_VALIDATION_CHECK_SHADERS_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ValidationCheckEXT value )
  {
    switch ( value )
    {
      case ValidationCheckEXT::eAll : return "All";
      case ValidationCheckEXT::eShaders : return "Shaders";
      default: return "invalid";
    }
  }

  enum class ValidationFeatureDisableEXT
  {
    eAll = VK_VALIDATION_FEATURE_DISABLE_ALL_EXT,
    eShaders = VK_VALIDATION_FEATURE_DISABLE_SHADERS_EXT,
    eThreadSafety = VK_VALIDATION_FEATURE_DISABLE_THREAD_SAFETY_EXT,
    eApiParameters = VK_VALIDATION_FEATURE_DISABLE_API_PARAMETERS_EXT,
    eObjectLifetimes = VK_VALIDATION_FEATURE_DISABLE_OBJECT_LIFETIMES_EXT,
    eCoreChecks = VK_VALIDATION_FEATURE_DISABLE_CORE_CHECKS_EXT,
    eUniqueHandles = VK_VALIDATION_FEATURE_DISABLE_UNIQUE_HANDLES_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ValidationFeatureDisableEXT value )
  {
    switch ( value )
    {
      case ValidationFeatureDisableEXT::eAll : return "All";
      case ValidationFeatureDisableEXT::eShaders : return "Shaders";
      case ValidationFeatureDisableEXT::eThreadSafety : return "ThreadSafety";
      case ValidationFeatureDisableEXT::eApiParameters : return "ApiParameters";
      case ValidationFeatureDisableEXT::eObjectLifetimes : return "ObjectLifetimes";
      case ValidationFeatureDisableEXT::eCoreChecks : return "CoreChecks";
      case ValidationFeatureDisableEXT::eUniqueHandles : return "UniqueHandles";
      default: return "invalid";
    }
  }

  enum class ValidationFeatureEnableEXT
  {
    eGpuAssisted = VK_VALIDATION_FEATURE_ENABLE_GPU_ASSISTED_EXT,
    eGpuAssistedReserveBindingSlot = VK_VALIDATION_FEATURE_ENABLE_GPU_ASSISTED_RESERVE_BINDING_SLOT_EXT,
    eBestPractices = VK_VALIDATION_FEATURE_ENABLE_BEST_PRACTICES_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ValidationFeatureEnableEXT value )
  {
    switch ( value )
    {
      case ValidationFeatureEnableEXT::eGpuAssisted : return "GpuAssisted";
      case ValidationFeatureEnableEXT::eGpuAssistedReserveBindingSlot : return "GpuAssistedReserveBindingSlot";
      case ValidationFeatureEnableEXT::eBestPractices : return "BestPractices";
      default: return "invalid";
    }
  }

  enum class VendorId
  {
    eVIV = VK_VENDOR_ID_VIV,
    eVSI = VK_VENDOR_ID_VSI,
    eKazan = VK_VENDOR_ID_KAZAN
  };

  VULKAN_HPP_INLINE std::string to_string( VendorId value )
  {
    switch ( value )
    {
      case VendorId::eVIV : return "VIV";
      case VendorId::eVSI : return "VSI";
      case VendorId::eKazan : return "Kazan";
      default: return "invalid";
    }
  }

  enum class VertexInputRate
  {
    eVertex = VK_VERTEX_INPUT_RATE_VERTEX,
    eInstance = VK_VERTEX_INPUT_RATE_INSTANCE
  };

  VULKAN_HPP_INLINE std::string to_string( VertexInputRate value )
  {
    switch ( value )
    {
      case VertexInputRate::eVertex : return "Vertex";
      case VertexInputRate::eInstance : return "Instance";
      default: return "invalid";
    }
  }

  enum class ViewportCoordinateSwizzleNV
  {
    ePositiveX = VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_X_NV,
    eNegativeX = VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_X_NV,
    ePositiveY = VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_Y_NV,
    eNegativeY = VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_Y_NV,
    ePositiveZ = VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_Z_NV,
    eNegativeZ = VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_Z_NV,
    ePositiveW = VK_VIEWPORT_COORDINATE_SWIZZLE_POSITIVE_W_NV,
    eNegativeW = VK_VIEWPORT_COORDINATE_SWIZZLE_NEGATIVE_W_NV
  };

  VULKAN_HPP_INLINE std::string to_string( ViewportCoordinateSwizzleNV value )
  {
    switch ( value )
    {
      case ViewportCoordinateSwizzleNV::ePositiveX : return "PositiveX";
      case ViewportCoordinateSwizzleNV::eNegativeX : return "NegativeX";
      case ViewportCoordinateSwizzleNV::ePositiveY : return "PositiveY";
      case ViewportCoordinateSwizzleNV::eNegativeY : return "NegativeY";
      case ViewportCoordinateSwizzleNV::ePositiveZ : return "PositiveZ";
      case ViewportCoordinateSwizzleNV::eNegativeZ : return "NegativeZ";
      case ViewportCoordinateSwizzleNV::ePositiveW : return "PositiveW";
      case ViewportCoordinateSwizzleNV::eNegativeW : return "NegativeW";
      default: return "invalid";
    }
  }

  template<ObjectType value>
  struct cpp_type
  {
  };

  enum class AccessFlagBits
  {
    eIndirectCommandRead = VK_ACCESS_INDIRECT_COMMAND_READ_BIT,
    eIndexRead = VK_ACCESS_INDEX_READ_BIT,
    eVertexAttributeRead = VK_ACCESS_VERTEX_ATTRIBUTE_READ_BIT,
    eUniformRead = VK_ACCESS_UNIFORM_READ_BIT,
    eInputAttachmentRead = VK_ACCESS_INPUT_ATTACHMENT_READ_BIT,
    eShaderRead = VK_ACCESS_SHADER_READ_BIT,
    eShaderWrite = VK_ACCESS_SHADER_WRITE_BIT,
    eColorAttachmentRead = VK_ACCESS_COLOR_ATTACHMENT_READ_BIT,
    eColorAttachmentWrite = VK_ACCESS_COLOR_ATTACHMENT_WRITE_BIT,
    eDepthStencilAttachmentRead = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_READ_BIT,
    eDepthStencilAttachmentWrite = VK_ACCESS_DEPTH_STENCIL_ATTACHMENT_WRITE_BIT,
    eTransferRead = VK_ACCESS_TRANSFER_READ_BIT,
    eTransferWrite = VK_ACCESS_TRANSFER_WRITE_BIT,
    eHostRead = VK_ACCESS_HOST_READ_BIT,
    eHostWrite = VK_ACCESS_HOST_WRITE_BIT,
    eMemoryRead = VK_ACCESS_MEMORY_READ_BIT,
    eMemoryWrite = VK_ACCESS_MEMORY_WRITE_BIT,
    eTransformFeedbackWriteEXT = VK_ACCESS_TRANSFORM_FEEDBACK_WRITE_BIT_EXT,
    eTransformFeedbackCounterReadEXT = VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_READ_BIT_EXT,
    eTransformFeedbackCounterWriteEXT = VK_ACCESS_TRANSFORM_FEEDBACK_COUNTER_WRITE_BIT_EXT,
    eConditionalRenderingReadEXT = VK_ACCESS_CONDITIONAL_RENDERING_READ_BIT_EXT,
    eCommandProcessReadNVX = VK_ACCESS_COMMAND_PROCESS_READ_BIT_NVX,
    eCommandProcessWriteNVX = VK_ACCESS_COMMAND_PROCESS_WRITE_BIT_NVX,
    eColorAttachmentReadNoncoherentEXT = VK_ACCESS_COLOR_ATTACHMENT_READ_NONCOHERENT_BIT_EXT,
    eShadingRateImageReadNV = VK_ACCESS_SHADING_RATE_IMAGE_READ_BIT_NV,
    eAccelerationStructureReadNV = VK_ACCESS_ACCELERATION_STRUCTURE_READ_BIT_NV,
    eAccelerationStructureWriteNV = VK_ACCESS_ACCELERATION_STRUCTURE_WRITE_BIT_NV,
    eFragmentDensityMapReadEXT = VK_ACCESS_FRAGMENT_DENSITY_MAP_READ_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( AccessFlagBits value )
  {
    switch ( value )
    {
      case AccessFlagBits::eIndirectCommandRead : return "IndirectCommandRead";
      case AccessFlagBits::eIndexRead : return "IndexRead";
      case AccessFlagBits::eVertexAttributeRead : return "VertexAttributeRead";
      case AccessFlagBits::eUniformRead : return "UniformRead";
      case AccessFlagBits::eInputAttachmentRead : return "InputAttachmentRead";
      case AccessFlagBits::eShaderRead : return "ShaderRead";
      case AccessFlagBits::eShaderWrite : return "ShaderWrite";
      case AccessFlagBits::eColorAttachmentRead : return "ColorAttachmentRead";
      case AccessFlagBits::eColorAttachmentWrite : return "ColorAttachmentWrite";
      case AccessFlagBits::eDepthStencilAttachmentRead : return "DepthStencilAttachmentRead";
      case AccessFlagBits::eDepthStencilAttachmentWrite : return "DepthStencilAttachmentWrite";
      case AccessFlagBits::eTransferRead : return "TransferRead";
      case AccessFlagBits::eTransferWrite : return "TransferWrite";
      case AccessFlagBits::eHostRead : return "HostRead";
      case AccessFlagBits::eHostWrite : return "HostWrite";
      case AccessFlagBits::eMemoryRead : return "MemoryRead";
      case AccessFlagBits::eMemoryWrite : return "MemoryWrite";
      case AccessFlagBits::eTransformFeedbackWriteEXT : return "TransformFeedbackWriteEXT";
      case AccessFlagBits::eTransformFeedbackCounterReadEXT : return "TransformFeedbackCounterReadEXT";
      case AccessFlagBits::eTransformFeedbackCounterWriteEXT : return "TransformFeedbackCounterWriteEXT";
      case AccessFlagBits::eConditionalRenderingReadEXT : return "ConditionalRenderingReadEXT";
      case AccessFlagBits::eCommandProcessReadNVX : return "CommandProcessReadNVX";
      case AccessFlagBits::eCommandProcessWriteNVX : return "CommandProcessWriteNVX";
      case AccessFlagBits::eColorAttachmentReadNoncoherentEXT : return "ColorAttachmentReadNoncoherentEXT";
      case AccessFlagBits::eShadingRateImageReadNV : return "ShadingRateImageReadNV";
      case AccessFlagBits::eAccelerationStructureReadNV : return "AccelerationStructureReadNV";
      case AccessFlagBits::eAccelerationStructureWriteNV : return "AccelerationStructureWriteNV";
      case AccessFlagBits::eFragmentDensityMapReadEXT : return "FragmentDensityMapReadEXT";
      default: return "invalid";
    }
  }

  using AccessFlags = Flags<AccessFlagBits, VkAccessFlags>;

  template <> struct FlagTraits<AccessFlagBits>
  {
    enum
    {
      allFlags = VkFlags(AccessFlagBits::eIndirectCommandRead) | VkFlags(AccessFlagBits::eIndexRead) | VkFlags(AccessFlagBits::eVertexAttributeRead) | VkFlags(AccessFlagBits::eUniformRead) | VkFlags(AccessFlagBits::eInputAttachmentRead) | VkFlags(AccessFlagBits::eShaderRead) | VkFlags(AccessFlagBits::eShaderWrite) | VkFlags(AccessFlagBits::eColorAttachmentRead) | VkFlags(AccessFlagBits::eColorAttachmentWrite) | VkFlags(AccessFlagBits::eDepthStencilAttachmentRead) | VkFlags(AccessFlagBits::eDepthStencilAttachmentWrite) | VkFlags(AccessFlagBits::eTransferRead) | VkFlags(AccessFlagBits::eTransferWrite) | VkFlags(AccessFlagBits::eHostRead) | VkFlags(AccessFlagBits::eHostWrite) | VkFlags(AccessFlagBits::eMemoryRead) | VkFlags(AccessFlagBits::eMemoryWrite) | VkFlags(AccessFlagBits::eTransformFeedbackWriteEXT) | VkFlags(AccessFlagBits::eTransformFeedbackCounterReadEXT) | VkFlags(AccessFlagBits::eTransformFeedbackCounterWriteEXT) | VkFlags(AccessFlagBits::eConditionalRenderingReadEXT) | VkFlags(AccessFlagBits::eCommandProcessReadNVX) | VkFlags(AccessFlagBits::eCommandProcessWriteNVX) | VkFlags(AccessFlagBits::eColorAttachmentReadNoncoherentEXT) | VkFlags(AccessFlagBits::eShadingRateImageReadNV) | VkFlags(AccessFlagBits::eAccelerationStructureReadNV) | VkFlags(AccessFlagBits::eAccelerationStructureWriteNV) | VkFlags(AccessFlagBits::eFragmentDensityMapReadEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AccessFlags operator|( AccessFlagBits bit0, AccessFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AccessFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AccessFlags operator&( AccessFlagBits bit0, AccessFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AccessFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AccessFlags operator^( AccessFlagBits bit0, AccessFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AccessFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AccessFlags operator~( AccessFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( AccessFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( AccessFlagBits bit0, AccessFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AccessFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( AccessFlagBits bit0, AccessFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AccessFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( AccessFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & AccessFlagBits::eIndirectCommandRead ) result += "IndirectCommandRead | ";
    if ( value & AccessFlagBits::eIndexRead ) result += "IndexRead | ";
    if ( value & AccessFlagBits::eVertexAttributeRead ) result += "VertexAttributeRead | ";
    if ( value & AccessFlagBits::eUniformRead ) result += "UniformRead | ";
    if ( value & AccessFlagBits::eInputAttachmentRead ) result += "InputAttachmentRead | ";
    if ( value & AccessFlagBits::eShaderRead ) result += "ShaderRead | ";
    if ( value & AccessFlagBits::eShaderWrite ) result += "ShaderWrite | ";
    if ( value & AccessFlagBits::eColorAttachmentRead ) result += "ColorAttachmentRead | ";
    if ( value & AccessFlagBits::eColorAttachmentWrite ) result += "ColorAttachmentWrite | ";
    if ( value & AccessFlagBits::eDepthStencilAttachmentRead ) result += "DepthStencilAttachmentRead | ";
    if ( value & AccessFlagBits::eDepthStencilAttachmentWrite ) result += "DepthStencilAttachmentWrite | ";
    if ( value & AccessFlagBits::eTransferRead ) result += "TransferRead | ";
    if ( value & AccessFlagBits::eTransferWrite ) result += "TransferWrite | ";
    if ( value & AccessFlagBits::eHostRead ) result += "HostRead | ";
    if ( value & AccessFlagBits::eHostWrite ) result += "HostWrite | ";
    if ( value & AccessFlagBits::eMemoryRead ) result += "MemoryRead | ";
    if ( value & AccessFlagBits::eMemoryWrite ) result += "MemoryWrite | ";
    if ( value & AccessFlagBits::eTransformFeedbackWriteEXT ) result += "TransformFeedbackWriteEXT | ";
    if ( value & AccessFlagBits::eTransformFeedbackCounterReadEXT ) result += "TransformFeedbackCounterReadEXT | ";
    if ( value & AccessFlagBits::eTransformFeedbackCounterWriteEXT ) result += "TransformFeedbackCounterWriteEXT | ";
    if ( value & AccessFlagBits::eConditionalRenderingReadEXT ) result += "ConditionalRenderingReadEXT | ";
    if ( value & AccessFlagBits::eCommandProcessReadNVX ) result += "CommandProcessReadNVX | ";
    if ( value & AccessFlagBits::eCommandProcessWriteNVX ) result += "CommandProcessWriteNVX | ";
    if ( value & AccessFlagBits::eColorAttachmentReadNoncoherentEXT ) result += "ColorAttachmentReadNoncoherentEXT | ";
    if ( value & AccessFlagBits::eShadingRateImageReadNV ) result += "ShadingRateImageReadNV | ";
    if ( value & AccessFlagBits::eAccelerationStructureReadNV ) result += "AccelerationStructureReadNV | ";
    if ( value & AccessFlagBits::eAccelerationStructureWriteNV ) result += "AccelerationStructureWriteNV | ";
    if ( value & AccessFlagBits::eFragmentDensityMapReadEXT ) result += "FragmentDensityMapReadEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

#ifdef VK_USE_PLATFORM_ANDROID_KHR
  enum class AndroidSurfaceCreateFlagBitsKHR
  {};

  VULKAN_HPP_INLINE std::string to_string( AndroidSurfaceCreateFlagBitsKHR )
  {
    return "(void)";
  }

  using AndroidSurfaceCreateFlagsKHR = Flags<AndroidSurfaceCreateFlagBitsKHR, VkAndroidSurfaceCreateFlagsKHR>;

  VULKAN_HPP_INLINE std::string to_string( AndroidSurfaceCreateFlagsKHR  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  enum class AttachmentDescriptionFlagBits
  {
    eMayAlias = VK_ATTACHMENT_DESCRIPTION_MAY_ALIAS_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( AttachmentDescriptionFlagBits value )
  {
    switch ( value )
    {
      case AttachmentDescriptionFlagBits::eMayAlias : return "MayAlias";
      default: return "invalid";
    }
  }

  using AttachmentDescriptionFlags = Flags<AttachmentDescriptionFlagBits, VkAttachmentDescriptionFlags>;

  template <> struct FlagTraits<AttachmentDescriptionFlagBits>
  {
    enum
    {
      allFlags = VkFlags(AttachmentDescriptionFlagBits::eMayAlias)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AttachmentDescriptionFlags operator|( AttachmentDescriptionFlagBits bit0, AttachmentDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AttachmentDescriptionFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AttachmentDescriptionFlags operator&( AttachmentDescriptionFlagBits bit0, AttachmentDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AttachmentDescriptionFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AttachmentDescriptionFlags operator^( AttachmentDescriptionFlagBits bit0, AttachmentDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AttachmentDescriptionFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR AttachmentDescriptionFlags operator~( AttachmentDescriptionFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( AttachmentDescriptionFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( AttachmentDescriptionFlagBits bit0, AttachmentDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AttachmentDescriptionFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( AttachmentDescriptionFlagBits bit0, AttachmentDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return AttachmentDescriptionFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( AttachmentDescriptionFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & AttachmentDescriptionFlagBits::eMayAlias ) result += "MayAlias | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class BufferCreateFlagBits
  {
    eSparseBinding = VK_BUFFER_CREATE_SPARSE_BINDING_BIT,
    eSparseResidency = VK_BUFFER_CREATE_SPARSE_RESIDENCY_BIT,
    eSparseAliased = VK_BUFFER_CREATE_SPARSE_ALIASED_BIT,
    eProtected = VK_BUFFER_CREATE_PROTECTED_BIT,
    eDeviceAddressCaptureReplayEXT = VK_BUFFER_CREATE_DEVICE_ADDRESS_CAPTURE_REPLAY_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( BufferCreateFlagBits value )
  {
    switch ( value )
    {
      case BufferCreateFlagBits::eSparseBinding : return "SparseBinding";
      case BufferCreateFlagBits::eSparseResidency : return "SparseResidency";
      case BufferCreateFlagBits::eSparseAliased : return "SparseAliased";
      case BufferCreateFlagBits::eProtected : return "Protected";
      case BufferCreateFlagBits::eDeviceAddressCaptureReplayEXT : return "DeviceAddressCaptureReplayEXT";
      default: return "invalid";
    }
  }

  using BufferCreateFlags = Flags<BufferCreateFlagBits, VkBufferCreateFlags>;

  template <> struct FlagTraits<BufferCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(BufferCreateFlagBits::eSparseBinding) | VkFlags(BufferCreateFlagBits::eSparseResidency) | VkFlags(BufferCreateFlagBits::eSparseAliased) | VkFlags(BufferCreateFlagBits::eProtected) | VkFlags(BufferCreateFlagBits::eDeviceAddressCaptureReplayEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferCreateFlags operator|( BufferCreateFlagBits bit0, BufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferCreateFlags operator&( BufferCreateFlagBits bit0, BufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferCreateFlags operator^( BufferCreateFlagBits bit0, BufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferCreateFlags operator~( BufferCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( BufferCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( BufferCreateFlagBits bit0, BufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( BufferCreateFlagBits bit0, BufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( BufferCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & BufferCreateFlagBits::eSparseBinding ) result += "SparseBinding | ";
    if ( value & BufferCreateFlagBits::eSparseResidency ) result += "SparseResidency | ";
    if ( value & BufferCreateFlagBits::eSparseAliased ) result += "SparseAliased | ";
    if ( value & BufferCreateFlagBits::eProtected ) result += "Protected | ";
    if ( value & BufferCreateFlagBits::eDeviceAddressCaptureReplayEXT ) result += "DeviceAddressCaptureReplayEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class BufferUsageFlagBits
  {
    eTransferSrc = VK_BUFFER_USAGE_TRANSFER_SRC_BIT,
    eTransferDst = VK_BUFFER_USAGE_TRANSFER_DST_BIT,
    eUniformTexelBuffer = VK_BUFFER_USAGE_UNIFORM_TEXEL_BUFFER_BIT,
    eStorageTexelBuffer = VK_BUFFER_USAGE_STORAGE_TEXEL_BUFFER_BIT,
    eUniformBuffer = VK_BUFFER_USAGE_UNIFORM_BUFFER_BIT,
    eStorageBuffer = VK_BUFFER_USAGE_STORAGE_BUFFER_BIT,
    eIndexBuffer = VK_BUFFER_USAGE_INDEX_BUFFER_BIT,
    eVertexBuffer = VK_BUFFER_USAGE_VERTEX_BUFFER_BIT,
    eIndirectBuffer = VK_BUFFER_USAGE_INDIRECT_BUFFER_BIT,
    eTransformFeedbackBufferEXT = VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_BUFFER_BIT_EXT,
    eTransformFeedbackCounterBufferEXT = VK_BUFFER_USAGE_TRANSFORM_FEEDBACK_COUNTER_BUFFER_BIT_EXT,
    eConditionalRenderingEXT = VK_BUFFER_USAGE_CONDITIONAL_RENDERING_BIT_EXT,
    eRayTracingNV = VK_BUFFER_USAGE_RAY_TRACING_BIT_NV,
    eShaderDeviceAddressEXT = VK_BUFFER_USAGE_SHADER_DEVICE_ADDRESS_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( BufferUsageFlagBits value )
  {
    switch ( value )
    {
      case BufferUsageFlagBits::eTransferSrc : return "TransferSrc";
      case BufferUsageFlagBits::eTransferDst : return "TransferDst";
      case BufferUsageFlagBits::eUniformTexelBuffer : return "UniformTexelBuffer";
      case BufferUsageFlagBits::eStorageTexelBuffer : return "StorageTexelBuffer";
      case BufferUsageFlagBits::eUniformBuffer : return "UniformBuffer";
      case BufferUsageFlagBits::eStorageBuffer : return "StorageBuffer";
      case BufferUsageFlagBits::eIndexBuffer : return "IndexBuffer";
      case BufferUsageFlagBits::eVertexBuffer : return "VertexBuffer";
      case BufferUsageFlagBits::eIndirectBuffer : return "IndirectBuffer";
      case BufferUsageFlagBits::eTransformFeedbackBufferEXT : return "TransformFeedbackBufferEXT";
      case BufferUsageFlagBits::eTransformFeedbackCounterBufferEXT : return "TransformFeedbackCounterBufferEXT";
      case BufferUsageFlagBits::eConditionalRenderingEXT : return "ConditionalRenderingEXT";
      case BufferUsageFlagBits::eRayTracingNV : return "RayTracingNV";
      case BufferUsageFlagBits::eShaderDeviceAddressEXT : return "ShaderDeviceAddressEXT";
      default: return "invalid";
    }
  }

  using BufferUsageFlags = Flags<BufferUsageFlagBits, VkBufferUsageFlags>;

  template <> struct FlagTraits<BufferUsageFlagBits>
  {
    enum
    {
      allFlags = VkFlags(BufferUsageFlagBits::eTransferSrc) | VkFlags(BufferUsageFlagBits::eTransferDst) | VkFlags(BufferUsageFlagBits::eUniformTexelBuffer) | VkFlags(BufferUsageFlagBits::eStorageTexelBuffer) | VkFlags(BufferUsageFlagBits::eUniformBuffer) | VkFlags(BufferUsageFlagBits::eStorageBuffer) | VkFlags(BufferUsageFlagBits::eIndexBuffer) | VkFlags(BufferUsageFlagBits::eVertexBuffer) | VkFlags(BufferUsageFlagBits::eIndirectBuffer) | VkFlags(BufferUsageFlagBits::eTransformFeedbackBufferEXT) | VkFlags(BufferUsageFlagBits::eTransformFeedbackCounterBufferEXT) | VkFlags(BufferUsageFlagBits::eConditionalRenderingEXT) | VkFlags(BufferUsageFlagBits::eRayTracingNV) | VkFlags(BufferUsageFlagBits::eShaderDeviceAddressEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferUsageFlags operator|( BufferUsageFlagBits bit0, BufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferUsageFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferUsageFlags operator&( BufferUsageFlagBits bit0, BufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferUsageFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferUsageFlags operator^( BufferUsageFlagBits bit0, BufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferUsageFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BufferUsageFlags operator~( BufferUsageFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( BufferUsageFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( BufferUsageFlagBits bit0, BufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferUsageFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( BufferUsageFlagBits bit0, BufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BufferUsageFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( BufferUsageFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & BufferUsageFlagBits::eTransferSrc ) result += "TransferSrc | ";
    if ( value & BufferUsageFlagBits::eTransferDst ) result += "TransferDst | ";
    if ( value & BufferUsageFlagBits::eUniformTexelBuffer ) result += "UniformTexelBuffer | ";
    if ( value & BufferUsageFlagBits::eStorageTexelBuffer ) result += "StorageTexelBuffer | ";
    if ( value & BufferUsageFlagBits::eUniformBuffer ) result += "UniformBuffer | ";
    if ( value & BufferUsageFlagBits::eStorageBuffer ) result += "StorageBuffer | ";
    if ( value & BufferUsageFlagBits::eIndexBuffer ) result += "IndexBuffer | ";
    if ( value & BufferUsageFlagBits::eVertexBuffer ) result += "VertexBuffer | ";
    if ( value & BufferUsageFlagBits::eIndirectBuffer ) result += "IndirectBuffer | ";
    if ( value & BufferUsageFlagBits::eTransformFeedbackBufferEXT ) result += "TransformFeedbackBufferEXT | ";
    if ( value & BufferUsageFlagBits::eTransformFeedbackCounterBufferEXT ) result += "TransformFeedbackCounterBufferEXT | ";
    if ( value & BufferUsageFlagBits::eConditionalRenderingEXT ) result += "ConditionalRenderingEXT | ";
    if ( value & BufferUsageFlagBits::eRayTracingNV ) result += "RayTracingNV | ";
    if ( value & BufferUsageFlagBits::eShaderDeviceAddressEXT ) result += "ShaderDeviceAddressEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class BufferViewCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( BufferViewCreateFlagBits )
  {
    return "(void)";
  }

  using BufferViewCreateFlags = Flags<BufferViewCreateFlagBits, VkBufferViewCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( BufferViewCreateFlags  )
  {
    return "{}";
  }

  enum class BuildAccelerationStructureFlagBitsNV
  {
    eAllowUpdate = VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_UPDATE_BIT_NV,
    eAllowCompaction = VK_BUILD_ACCELERATION_STRUCTURE_ALLOW_COMPACTION_BIT_NV,
    ePreferFastTrace = VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_TRACE_BIT_NV,
    ePreferFastBuild = VK_BUILD_ACCELERATION_STRUCTURE_PREFER_FAST_BUILD_BIT_NV,
    eLowMemory = VK_BUILD_ACCELERATION_STRUCTURE_LOW_MEMORY_BIT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( BuildAccelerationStructureFlagBitsNV value )
  {
    switch ( value )
    {
      case BuildAccelerationStructureFlagBitsNV::eAllowUpdate : return "AllowUpdate";
      case BuildAccelerationStructureFlagBitsNV::eAllowCompaction : return "AllowCompaction";
      case BuildAccelerationStructureFlagBitsNV::ePreferFastTrace : return "PreferFastTrace";
      case BuildAccelerationStructureFlagBitsNV::ePreferFastBuild : return "PreferFastBuild";
      case BuildAccelerationStructureFlagBitsNV::eLowMemory : return "LowMemory";
      default: return "invalid";
    }
  }

  using BuildAccelerationStructureFlagsNV = Flags<BuildAccelerationStructureFlagBitsNV, VkBuildAccelerationStructureFlagsNV>;

  template <> struct FlagTraits<BuildAccelerationStructureFlagBitsNV>
  {
    enum
    {
      allFlags = VkFlags(BuildAccelerationStructureFlagBitsNV::eAllowUpdate) | VkFlags(BuildAccelerationStructureFlagBitsNV::eAllowCompaction) | VkFlags(BuildAccelerationStructureFlagBitsNV::ePreferFastTrace) | VkFlags(BuildAccelerationStructureFlagBitsNV::ePreferFastBuild) | VkFlags(BuildAccelerationStructureFlagBitsNV::eLowMemory)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BuildAccelerationStructureFlagsNV operator|( BuildAccelerationStructureFlagBitsNV bit0, BuildAccelerationStructureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BuildAccelerationStructureFlagsNV( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BuildAccelerationStructureFlagsNV operator&( BuildAccelerationStructureFlagBitsNV bit0, BuildAccelerationStructureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BuildAccelerationStructureFlagsNV( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BuildAccelerationStructureFlagsNV operator^( BuildAccelerationStructureFlagBitsNV bit0, BuildAccelerationStructureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BuildAccelerationStructureFlagsNV( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR BuildAccelerationStructureFlagsNV operator~( BuildAccelerationStructureFlagBitsNV bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( BuildAccelerationStructureFlagsNV( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( BuildAccelerationStructureFlagBitsNV bit0, BuildAccelerationStructureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BuildAccelerationStructureFlagsNV( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( BuildAccelerationStructureFlagBitsNV bit0, BuildAccelerationStructureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return BuildAccelerationStructureFlagsNV( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( BuildAccelerationStructureFlagsNV value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & BuildAccelerationStructureFlagBitsNV::eAllowUpdate ) result += "AllowUpdate | ";
    if ( value & BuildAccelerationStructureFlagBitsNV::eAllowCompaction ) result += "AllowCompaction | ";
    if ( value & BuildAccelerationStructureFlagBitsNV::ePreferFastTrace ) result += "PreferFastTrace | ";
    if ( value & BuildAccelerationStructureFlagBitsNV::ePreferFastBuild ) result += "PreferFastBuild | ";
    if ( value & BuildAccelerationStructureFlagBitsNV::eLowMemory ) result += "LowMemory | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ColorComponentFlagBits
  {
    eR = VK_COLOR_COMPONENT_R_BIT,
    eG = VK_COLOR_COMPONENT_G_BIT,
    eB = VK_COLOR_COMPONENT_B_BIT,
    eA = VK_COLOR_COMPONENT_A_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( ColorComponentFlagBits value )
  {
    switch ( value )
    {
      case ColorComponentFlagBits::eR : return "R";
      case ColorComponentFlagBits::eG : return "G";
      case ColorComponentFlagBits::eB : return "B";
      case ColorComponentFlagBits::eA : return "A";
      default: return "invalid";
    }
  }

  using ColorComponentFlags = Flags<ColorComponentFlagBits, VkColorComponentFlags>;

  template <> struct FlagTraits<ColorComponentFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ColorComponentFlagBits::eR) | VkFlags(ColorComponentFlagBits::eG) | VkFlags(ColorComponentFlagBits::eB) | VkFlags(ColorComponentFlagBits::eA)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ColorComponentFlags operator|( ColorComponentFlagBits bit0, ColorComponentFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ColorComponentFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ColorComponentFlags operator&( ColorComponentFlagBits bit0, ColorComponentFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ColorComponentFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ColorComponentFlags operator^( ColorComponentFlagBits bit0, ColorComponentFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ColorComponentFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ColorComponentFlags operator~( ColorComponentFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ColorComponentFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ColorComponentFlagBits bit0, ColorComponentFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ColorComponentFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ColorComponentFlagBits bit0, ColorComponentFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ColorComponentFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ColorComponentFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ColorComponentFlagBits::eR ) result += "R | ";
    if ( value & ColorComponentFlagBits::eG ) result += "G | ";
    if ( value & ColorComponentFlagBits::eB ) result += "B | ";
    if ( value & ColorComponentFlagBits::eA ) result += "A | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class CommandBufferResetFlagBits
  {
    eReleaseResources = VK_COMMAND_BUFFER_RESET_RELEASE_RESOURCES_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( CommandBufferResetFlagBits value )
  {
    switch ( value )
    {
      case CommandBufferResetFlagBits::eReleaseResources : return "ReleaseResources";
      default: return "invalid";
    }
  }

  using CommandBufferResetFlags = Flags<CommandBufferResetFlagBits, VkCommandBufferResetFlags>;

  template <> struct FlagTraits<CommandBufferResetFlagBits>
  {
    enum
    {
      allFlags = VkFlags(CommandBufferResetFlagBits::eReleaseResources)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferResetFlags operator|( CommandBufferResetFlagBits bit0, CommandBufferResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferResetFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferResetFlags operator&( CommandBufferResetFlagBits bit0, CommandBufferResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferResetFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferResetFlags operator^( CommandBufferResetFlagBits bit0, CommandBufferResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferResetFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferResetFlags operator~( CommandBufferResetFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( CommandBufferResetFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( CommandBufferResetFlagBits bit0, CommandBufferResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferResetFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( CommandBufferResetFlagBits bit0, CommandBufferResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferResetFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( CommandBufferResetFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & CommandBufferResetFlagBits::eReleaseResources ) result += "ReleaseResources | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class CommandBufferUsageFlagBits
  {
    eOneTimeSubmit = VK_COMMAND_BUFFER_USAGE_ONE_TIME_SUBMIT_BIT,
    eRenderPassContinue = VK_COMMAND_BUFFER_USAGE_RENDER_PASS_CONTINUE_BIT,
    eSimultaneousUse = VK_COMMAND_BUFFER_USAGE_SIMULTANEOUS_USE_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( CommandBufferUsageFlagBits value )
  {
    switch ( value )
    {
      case CommandBufferUsageFlagBits::eOneTimeSubmit : return "OneTimeSubmit";
      case CommandBufferUsageFlagBits::eRenderPassContinue : return "RenderPassContinue";
      case CommandBufferUsageFlagBits::eSimultaneousUse : return "SimultaneousUse";
      default: return "invalid";
    }
  }

  using CommandBufferUsageFlags = Flags<CommandBufferUsageFlagBits, VkCommandBufferUsageFlags>;

  template <> struct FlagTraits<CommandBufferUsageFlagBits>
  {
    enum
    {
      allFlags = VkFlags(CommandBufferUsageFlagBits::eOneTimeSubmit) | VkFlags(CommandBufferUsageFlagBits::eRenderPassContinue) | VkFlags(CommandBufferUsageFlagBits::eSimultaneousUse)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferUsageFlags operator|( CommandBufferUsageFlagBits bit0, CommandBufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferUsageFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferUsageFlags operator&( CommandBufferUsageFlagBits bit0, CommandBufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferUsageFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferUsageFlags operator^( CommandBufferUsageFlagBits bit0, CommandBufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferUsageFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandBufferUsageFlags operator~( CommandBufferUsageFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( CommandBufferUsageFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( CommandBufferUsageFlagBits bit0, CommandBufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferUsageFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( CommandBufferUsageFlagBits bit0, CommandBufferUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandBufferUsageFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( CommandBufferUsageFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & CommandBufferUsageFlagBits::eOneTimeSubmit ) result += "OneTimeSubmit | ";
    if ( value & CommandBufferUsageFlagBits::eRenderPassContinue ) result += "RenderPassContinue | ";
    if ( value & CommandBufferUsageFlagBits::eSimultaneousUse ) result += "SimultaneousUse | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class CommandPoolCreateFlagBits
  {
    eTransient = VK_COMMAND_POOL_CREATE_TRANSIENT_BIT,
    eResetCommandBuffer = VK_COMMAND_POOL_CREATE_RESET_COMMAND_BUFFER_BIT,
    eProtected = VK_COMMAND_POOL_CREATE_PROTECTED_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( CommandPoolCreateFlagBits value )
  {
    switch ( value )
    {
      case CommandPoolCreateFlagBits::eTransient : return "Transient";
      case CommandPoolCreateFlagBits::eResetCommandBuffer : return "ResetCommandBuffer";
      case CommandPoolCreateFlagBits::eProtected : return "Protected";
      default: return "invalid";
    }
  }

  using CommandPoolCreateFlags = Flags<CommandPoolCreateFlagBits, VkCommandPoolCreateFlags>;

  template <> struct FlagTraits<CommandPoolCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(CommandPoolCreateFlagBits::eTransient) | VkFlags(CommandPoolCreateFlagBits::eResetCommandBuffer) | VkFlags(CommandPoolCreateFlagBits::eProtected)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolCreateFlags operator|( CommandPoolCreateFlagBits bit0, CommandPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolCreateFlags operator&( CommandPoolCreateFlagBits bit0, CommandPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolCreateFlags operator^( CommandPoolCreateFlagBits bit0, CommandPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolCreateFlags operator~( CommandPoolCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( CommandPoolCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( CommandPoolCreateFlagBits bit0, CommandPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( CommandPoolCreateFlagBits bit0, CommandPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( CommandPoolCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & CommandPoolCreateFlagBits::eTransient ) result += "Transient | ";
    if ( value & CommandPoolCreateFlagBits::eResetCommandBuffer ) result += "ResetCommandBuffer | ";
    if ( value & CommandPoolCreateFlagBits::eProtected ) result += "Protected | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class CommandPoolResetFlagBits
  {
    eReleaseResources = VK_COMMAND_POOL_RESET_RELEASE_RESOURCES_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( CommandPoolResetFlagBits value )
  {
    switch ( value )
    {
      case CommandPoolResetFlagBits::eReleaseResources : return "ReleaseResources";
      default: return "invalid";
    }
  }

  using CommandPoolResetFlags = Flags<CommandPoolResetFlagBits, VkCommandPoolResetFlags>;

  template <> struct FlagTraits<CommandPoolResetFlagBits>
  {
    enum
    {
      allFlags = VkFlags(CommandPoolResetFlagBits::eReleaseResources)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolResetFlags operator|( CommandPoolResetFlagBits bit0, CommandPoolResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolResetFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolResetFlags operator&( CommandPoolResetFlagBits bit0, CommandPoolResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolResetFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolResetFlags operator^( CommandPoolResetFlagBits bit0, CommandPoolResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolResetFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CommandPoolResetFlags operator~( CommandPoolResetFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( CommandPoolResetFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( CommandPoolResetFlagBits bit0, CommandPoolResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolResetFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( CommandPoolResetFlagBits bit0, CommandPoolResetFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CommandPoolResetFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( CommandPoolResetFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & CommandPoolResetFlagBits::eReleaseResources ) result += "ReleaseResources | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class CommandPoolTrimFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( CommandPoolTrimFlagBits )
  {
    return "(void)";
  }

  using CommandPoolTrimFlags = Flags<CommandPoolTrimFlagBits, VkCommandPoolTrimFlags>;

  using CommandPoolTrimFlagsKHR = CommandPoolTrimFlags;

  VULKAN_HPP_INLINE std::string to_string( CommandPoolTrimFlags  )
  {
    return "{}";
  }

  enum class CompositeAlphaFlagBitsKHR
  {
    eOpaque = VK_COMPOSITE_ALPHA_OPAQUE_BIT_KHR,
    ePreMultiplied = VK_COMPOSITE_ALPHA_PRE_MULTIPLIED_BIT_KHR,
    ePostMultiplied = VK_COMPOSITE_ALPHA_POST_MULTIPLIED_BIT_KHR,
    eInherit = VK_COMPOSITE_ALPHA_INHERIT_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( CompositeAlphaFlagBitsKHR value )
  {
    switch ( value )
    {
      case CompositeAlphaFlagBitsKHR::eOpaque : return "Opaque";
      case CompositeAlphaFlagBitsKHR::ePreMultiplied : return "PreMultiplied";
      case CompositeAlphaFlagBitsKHR::ePostMultiplied : return "PostMultiplied";
      case CompositeAlphaFlagBitsKHR::eInherit : return "Inherit";
      default: return "invalid";
    }
  }

  using CompositeAlphaFlagsKHR = Flags<CompositeAlphaFlagBitsKHR, VkCompositeAlphaFlagsKHR>;

  template <> struct FlagTraits<CompositeAlphaFlagBitsKHR>
  {
    enum
    {
      allFlags = VkFlags(CompositeAlphaFlagBitsKHR::eOpaque) | VkFlags(CompositeAlphaFlagBitsKHR::ePreMultiplied) | VkFlags(CompositeAlphaFlagBitsKHR::ePostMultiplied) | VkFlags(CompositeAlphaFlagBitsKHR::eInherit)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CompositeAlphaFlagsKHR operator|( CompositeAlphaFlagBitsKHR bit0, CompositeAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CompositeAlphaFlagsKHR( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CompositeAlphaFlagsKHR operator&( CompositeAlphaFlagBitsKHR bit0, CompositeAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CompositeAlphaFlagsKHR( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CompositeAlphaFlagsKHR operator^( CompositeAlphaFlagBitsKHR bit0, CompositeAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CompositeAlphaFlagsKHR( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CompositeAlphaFlagsKHR operator~( CompositeAlphaFlagBitsKHR bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( CompositeAlphaFlagsKHR( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( CompositeAlphaFlagBitsKHR bit0, CompositeAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CompositeAlphaFlagsKHR( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( CompositeAlphaFlagBitsKHR bit0, CompositeAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CompositeAlphaFlagsKHR( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( CompositeAlphaFlagsKHR value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & CompositeAlphaFlagBitsKHR::eOpaque ) result += "Opaque | ";
    if ( value & CompositeAlphaFlagBitsKHR::ePreMultiplied ) result += "PreMultiplied | ";
    if ( value & CompositeAlphaFlagBitsKHR::ePostMultiplied ) result += "PostMultiplied | ";
    if ( value & CompositeAlphaFlagBitsKHR::eInherit ) result += "Inherit | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ConditionalRenderingFlagBitsEXT
  {
    eInverted = VK_CONDITIONAL_RENDERING_INVERTED_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ConditionalRenderingFlagBitsEXT value )
  {
    switch ( value )
    {
      case ConditionalRenderingFlagBitsEXT::eInverted : return "Inverted";
      default: return "invalid";
    }
  }

  using ConditionalRenderingFlagsEXT = Flags<ConditionalRenderingFlagBitsEXT, VkConditionalRenderingFlagsEXT>;

  template <> struct FlagTraits<ConditionalRenderingFlagBitsEXT>
  {
    enum
    {
      allFlags = VkFlags(ConditionalRenderingFlagBitsEXT::eInverted)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ConditionalRenderingFlagsEXT operator|( ConditionalRenderingFlagBitsEXT bit0, ConditionalRenderingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ConditionalRenderingFlagsEXT( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ConditionalRenderingFlagsEXT operator&( ConditionalRenderingFlagBitsEXT bit0, ConditionalRenderingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ConditionalRenderingFlagsEXT( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ConditionalRenderingFlagsEXT operator^( ConditionalRenderingFlagBitsEXT bit0, ConditionalRenderingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ConditionalRenderingFlagsEXT( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ConditionalRenderingFlagsEXT operator~( ConditionalRenderingFlagBitsEXT bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ConditionalRenderingFlagsEXT( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ConditionalRenderingFlagBitsEXT bit0, ConditionalRenderingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ConditionalRenderingFlagsEXT( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ConditionalRenderingFlagBitsEXT bit0, ConditionalRenderingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ConditionalRenderingFlagsEXT( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ConditionalRenderingFlagsEXT value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ConditionalRenderingFlagBitsEXT::eInverted ) result += "Inverted | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class CullModeFlagBits
  {
    eNone = VK_CULL_MODE_NONE,
    eFront = VK_CULL_MODE_FRONT_BIT,
    eBack = VK_CULL_MODE_BACK_BIT,
    eFrontAndBack = VK_CULL_MODE_FRONT_AND_BACK
  };

  VULKAN_HPP_INLINE std::string to_string( CullModeFlagBits value )
  {
    switch ( value )
    {
      case CullModeFlagBits::eNone : return "None";
      case CullModeFlagBits::eFront : return "Front";
      case CullModeFlagBits::eBack : return "Back";
      case CullModeFlagBits::eFrontAndBack : return "FrontAndBack";
      default: return "invalid";
    }
  }

  using CullModeFlags = Flags<CullModeFlagBits, VkCullModeFlags>;

  template <> struct FlagTraits<CullModeFlagBits>
  {
    enum
    {
      allFlags = VkFlags(CullModeFlagBits::eNone) | VkFlags(CullModeFlagBits::eFront) | VkFlags(CullModeFlagBits::eBack) | VkFlags(CullModeFlagBits::eFrontAndBack)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CullModeFlags operator|( CullModeFlagBits bit0, CullModeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CullModeFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CullModeFlags operator&( CullModeFlagBits bit0, CullModeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CullModeFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CullModeFlags operator^( CullModeFlagBits bit0, CullModeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CullModeFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR CullModeFlags operator~( CullModeFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( CullModeFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( CullModeFlagBits bit0, CullModeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CullModeFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( CullModeFlagBits bit0, CullModeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return CullModeFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( CullModeFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & CullModeFlagBits::eFront ) result += "Front | ";
    if ( value & CullModeFlagBits::eBack ) result += "Back | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DebugReportFlagBitsEXT
  {
    eInformation = VK_DEBUG_REPORT_INFORMATION_BIT_EXT,
    eWarning = VK_DEBUG_REPORT_WARNING_BIT_EXT,
    ePerformanceWarning = VK_DEBUG_REPORT_PERFORMANCE_WARNING_BIT_EXT,
    eError = VK_DEBUG_REPORT_ERROR_BIT_EXT,
    eDebug = VK_DEBUG_REPORT_DEBUG_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DebugReportFlagBitsEXT value )
  {
    switch ( value )
    {
      case DebugReportFlagBitsEXT::eInformation : return "Information";
      case DebugReportFlagBitsEXT::eWarning : return "Warning";
      case DebugReportFlagBitsEXT::ePerformanceWarning : return "PerformanceWarning";
      case DebugReportFlagBitsEXT::eError : return "Error";
      case DebugReportFlagBitsEXT::eDebug : return "Debug";
      default: return "invalid";
    }
  }

  using DebugReportFlagsEXT = Flags<DebugReportFlagBitsEXT, VkDebugReportFlagsEXT>;

  template <> struct FlagTraits<DebugReportFlagBitsEXT>
  {
    enum
    {
      allFlags = VkFlags(DebugReportFlagBitsEXT::eInformation) | VkFlags(DebugReportFlagBitsEXT::eWarning) | VkFlags(DebugReportFlagBitsEXT::ePerformanceWarning) | VkFlags(DebugReportFlagBitsEXT::eError) | VkFlags(DebugReportFlagBitsEXT::eDebug)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugReportFlagsEXT operator|( DebugReportFlagBitsEXT bit0, DebugReportFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugReportFlagsEXT( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugReportFlagsEXT operator&( DebugReportFlagBitsEXT bit0, DebugReportFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugReportFlagsEXT( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugReportFlagsEXT operator^( DebugReportFlagBitsEXT bit0, DebugReportFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugReportFlagsEXT( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugReportFlagsEXT operator~( DebugReportFlagBitsEXT bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DebugReportFlagsEXT( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DebugReportFlagBitsEXT bit0, DebugReportFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugReportFlagsEXT( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DebugReportFlagBitsEXT bit0, DebugReportFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugReportFlagsEXT( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DebugReportFlagsEXT value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DebugReportFlagBitsEXT::eInformation ) result += "Information | ";
    if ( value & DebugReportFlagBitsEXT::eWarning ) result += "Warning | ";
    if ( value & DebugReportFlagBitsEXT::ePerformanceWarning ) result += "PerformanceWarning | ";
    if ( value & DebugReportFlagBitsEXT::eError ) result += "Error | ";
    if ( value & DebugReportFlagBitsEXT::eDebug ) result += "Debug | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DebugUtilsMessageSeverityFlagBitsEXT
  {
    eVerbose = VK_DEBUG_UTILS_MESSAGE_SEVERITY_VERBOSE_BIT_EXT,
    eInfo = VK_DEBUG_UTILS_MESSAGE_SEVERITY_INFO_BIT_EXT,
    eWarning = VK_DEBUG_UTILS_MESSAGE_SEVERITY_WARNING_BIT_EXT,
    eError = VK_DEBUG_UTILS_MESSAGE_SEVERITY_ERROR_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessageSeverityFlagBitsEXT value )
  {
    switch ( value )
    {
      case DebugUtilsMessageSeverityFlagBitsEXT::eVerbose : return "Verbose";
      case DebugUtilsMessageSeverityFlagBitsEXT::eInfo : return "Info";
      case DebugUtilsMessageSeverityFlagBitsEXT::eWarning : return "Warning";
      case DebugUtilsMessageSeverityFlagBitsEXT::eError : return "Error";
      default: return "invalid";
    }
  }

  using DebugUtilsMessageSeverityFlagsEXT = Flags<DebugUtilsMessageSeverityFlagBitsEXT, VkDebugUtilsMessageSeverityFlagsEXT>;

  template <> struct FlagTraits<DebugUtilsMessageSeverityFlagBitsEXT>
  {
    enum
    {
      allFlags = VkFlags(DebugUtilsMessageSeverityFlagBitsEXT::eVerbose) | VkFlags(DebugUtilsMessageSeverityFlagBitsEXT::eInfo) | VkFlags(DebugUtilsMessageSeverityFlagBitsEXT::eWarning) | VkFlags(DebugUtilsMessageSeverityFlagBitsEXT::eError)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageSeverityFlagsEXT operator|( DebugUtilsMessageSeverityFlagBitsEXT bit0, DebugUtilsMessageSeverityFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageSeverityFlagsEXT( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageSeverityFlagsEXT operator&( DebugUtilsMessageSeverityFlagBitsEXT bit0, DebugUtilsMessageSeverityFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageSeverityFlagsEXT( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageSeverityFlagsEXT operator^( DebugUtilsMessageSeverityFlagBitsEXT bit0, DebugUtilsMessageSeverityFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageSeverityFlagsEXT( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageSeverityFlagsEXT operator~( DebugUtilsMessageSeverityFlagBitsEXT bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DebugUtilsMessageSeverityFlagsEXT( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DebugUtilsMessageSeverityFlagBitsEXT bit0, DebugUtilsMessageSeverityFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageSeverityFlagsEXT( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DebugUtilsMessageSeverityFlagBitsEXT bit0, DebugUtilsMessageSeverityFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageSeverityFlagsEXT( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessageSeverityFlagsEXT value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DebugUtilsMessageSeverityFlagBitsEXT::eVerbose ) result += "Verbose | ";
    if ( value & DebugUtilsMessageSeverityFlagBitsEXT::eInfo ) result += "Info | ";
    if ( value & DebugUtilsMessageSeverityFlagBitsEXT::eWarning ) result += "Warning | ";
    if ( value & DebugUtilsMessageSeverityFlagBitsEXT::eError ) result += "Error | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DebugUtilsMessageTypeFlagBitsEXT
  {
    eGeneral = VK_DEBUG_UTILS_MESSAGE_TYPE_GENERAL_BIT_EXT,
    eValidation = VK_DEBUG_UTILS_MESSAGE_TYPE_VALIDATION_BIT_EXT,
    ePerformance = VK_DEBUG_UTILS_MESSAGE_TYPE_PERFORMANCE_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessageTypeFlagBitsEXT value )
  {
    switch ( value )
    {
      case DebugUtilsMessageTypeFlagBitsEXT::eGeneral : return "General";
      case DebugUtilsMessageTypeFlagBitsEXT::eValidation : return "Validation";
      case DebugUtilsMessageTypeFlagBitsEXT::ePerformance : return "Performance";
      default: return "invalid";
    }
  }

  using DebugUtilsMessageTypeFlagsEXT = Flags<DebugUtilsMessageTypeFlagBitsEXT, VkDebugUtilsMessageTypeFlagsEXT>;

  template <> struct FlagTraits<DebugUtilsMessageTypeFlagBitsEXT>
  {
    enum
    {
      allFlags = VkFlags(DebugUtilsMessageTypeFlagBitsEXT::eGeneral) | VkFlags(DebugUtilsMessageTypeFlagBitsEXT::eValidation) | VkFlags(DebugUtilsMessageTypeFlagBitsEXT::ePerformance)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageTypeFlagsEXT operator|( DebugUtilsMessageTypeFlagBitsEXT bit0, DebugUtilsMessageTypeFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageTypeFlagsEXT( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageTypeFlagsEXT operator&( DebugUtilsMessageTypeFlagBitsEXT bit0, DebugUtilsMessageTypeFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageTypeFlagsEXT( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageTypeFlagsEXT operator^( DebugUtilsMessageTypeFlagBitsEXT bit0, DebugUtilsMessageTypeFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageTypeFlagsEXT( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DebugUtilsMessageTypeFlagsEXT operator~( DebugUtilsMessageTypeFlagBitsEXT bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DebugUtilsMessageTypeFlagsEXT( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DebugUtilsMessageTypeFlagBitsEXT bit0, DebugUtilsMessageTypeFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageTypeFlagsEXT( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DebugUtilsMessageTypeFlagBitsEXT bit0, DebugUtilsMessageTypeFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DebugUtilsMessageTypeFlagsEXT( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessageTypeFlagsEXT value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DebugUtilsMessageTypeFlagBitsEXT::eGeneral ) result += "General | ";
    if ( value & DebugUtilsMessageTypeFlagBitsEXT::eValidation ) result += "Validation | ";
    if ( value & DebugUtilsMessageTypeFlagBitsEXT::ePerformance ) result += "Performance | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DebugUtilsMessengerCallbackDataFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessengerCallbackDataFlagBitsEXT )
  {
    return "(void)";
  }

  using DebugUtilsMessengerCallbackDataFlagsEXT = Flags<DebugUtilsMessengerCallbackDataFlagBitsEXT, VkDebugUtilsMessengerCallbackDataFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessengerCallbackDataFlagsEXT  )
  {
    return "{}";
  }

  enum class DebugUtilsMessengerCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessengerCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using DebugUtilsMessengerCreateFlagsEXT = Flags<DebugUtilsMessengerCreateFlagBitsEXT, VkDebugUtilsMessengerCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( DebugUtilsMessengerCreateFlagsEXT  )
  {
    return "{}";
  }

  enum class DependencyFlagBits
  {
    eByRegion = VK_DEPENDENCY_BY_REGION_BIT,
    eDeviceGroup = VK_DEPENDENCY_DEVICE_GROUP_BIT,
    eViewLocal = VK_DEPENDENCY_VIEW_LOCAL_BIT,
    eViewLocalKHR = VK_DEPENDENCY_VIEW_LOCAL_BIT_KHR,
    eDeviceGroupKHR = VK_DEPENDENCY_DEVICE_GROUP_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( DependencyFlagBits value )
  {
    switch ( value )
    {
      case DependencyFlagBits::eByRegion : return "ByRegion";
      case DependencyFlagBits::eDeviceGroup : return "DeviceGroup";
      case DependencyFlagBits::eViewLocal : return "ViewLocal";
      default: return "invalid";
    }
  }

  using DependencyFlags = Flags<DependencyFlagBits, VkDependencyFlags>;

  template <> struct FlagTraits<DependencyFlagBits>
  {
    enum
    {
      allFlags = VkFlags(DependencyFlagBits::eByRegion) | VkFlags(DependencyFlagBits::eDeviceGroup) | VkFlags(DependencyFlagBits::eViewLocal)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DependencyFlags operator|( DependencyFlagBits bit0, DependencyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DependencyFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DependencyFlags operator&( DependencyFlagBits bit0, DependencyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DependencyFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DependencyFlags operator^( DependencyFlagBits bit0, DependencyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DependencyFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DependencyFlags operator~( DependencyFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DependencyFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DependencyFlagBits bit0, DependencyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DependencyFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DependencyFlagBits bit0, DependencyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DependencyFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DependencyFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DependencyFlagBits::eByRegion ) result += "ByRegion | ";
    if ( value & DependencyFlagBits::eDeviceGroup ) result += "DeviceGroup | ";
    if ( value & DependencyFlagBits::eViewLocal ) result += "ViewLocal | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DescriptorBindingFlagBitsEXT
  {
    eUpdateAfterBind = VK_DESCRIPTOR_BINDING_UPDATE_AFTER_BIND_BIT_EXT,
    eUpdateUnusedWhilePending = VK_DESCRIPTOR_BINDING_UPDATE_UNUSED_WHILE_PENDING_BIT_EXT,
    ePartiallyBound = VK_DESCRIPTOR_BINDING_PARTIALLY_BOUND_BIT_EXT,
    eVariableDescriptorCount = VK_DESCRIPTOR_BINDING_VARIABLE_DESCRIPTOR_COUNT_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DescriptorBindingFlagBitsEXT value )
  {
    switch ( value )
    {
      case DescriptorBindingFlagBitsEXT::eUpdateAfterBind : return "UpdateAfterBind";
      case DescriptorBindingFlagBitsEXT::eUpdateUnusedWhilePending : return "UpdateUnusedWhilePending";
      case DescriptorBindingFlagBitsEXT::ePartiallyBound : return "PartiallyBound";
      case DescriptorBindingFlagBitsEXT::eVariableDescriptorCount : return "VariableDescriptorCount";
      default: return "invalid";
    }
  }

  using DescriptorBindingFlagsEXT = Flags<DescriptorBindingFlagBitsEXT, VkDescriptorBindingFlagsEXT>;

  template <> struct FlagTraits<DescriptorBindingFlagBitsEXT>
  {
    enum
    {
      allFlags = VkFlags(DescriptorBindingFlagBitsEXT::eUpdateAfterBind) | VkFlags(DescriptorBindingFlagBitsEXT::eUpdateUnusedWhilePending) | VkFlags(DescriptorBindingFlagBitsEXT::ePartiallyBound) | VkFlags(DescriptorBindingFlagBitsEXT::eVariableDescriptorCount)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorBindingFlagsEXT operator|( DescriptorBindingFlagBitsEXT bit0, DescriptorBindingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorBindingFlagsEXT( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorBindingFlagsEXT operator&( DescriptorBindingFlagBitsEXT bit0, DescriptorBindingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorBindingFlagsEXT( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorBindingFlagsEXT operator^( DescriptorBindingFlagBitsEXT bit0, DescriptorBindingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorBindingFlagsEXT( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorBindingFlagsEXT operator~( DescriptorBindingFlagBitsEXT bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DescriptorBindingFlagsEXT( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DescriptorBindingFlagBitsEXT bit0, DescriptorBindingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorBindingFlagsEXT( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DescriptorBindingFlagBitsEXT bit0, DescriptorBindingFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorBindingFlagsEXT( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DescriptorBindingFlagsEXT value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DescriptorBindingFlagBitsEXT::eUpdateAfterBind ) result += "UpdateAfterBind | ";
    if ( value & DescriptorBindingFlagBitsEXT::eUpdateUnusedWhilePending ) result += "UpdateUnusedWhilePending | ";
    if ( value & DescriptorBindingFlagBitsEXT::ePartiallyBound ) result += "PartiallyBound | ";
    if ( value & DescriptorBindingFlagBitsEXT::eVariableDescriptorCount ) result += "VariableDescriptorCount | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DescriptorPoolCreateFlagBits
  {
    eFreeDescriptorSet = VK_DESCRIPTOR_POOL_CREATE_FREE_DESCRIPTOR_SET_BIT,
    eUpdateAfterBindEXT = VK_DESCRIPTOR_POOL_CREATE_UPDATE_AFTER_BIND_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DescriptorPoolCreateFlagBits value )
  {
    switch ( value )
    {
      case DescriptorPoolCreateFlagBits::eFreeDescriptorSet : return "FreeDescriptorSet";
      case DescriptorPoolCreateFlagBits::eUpdateAfterBindEXT : return "UpdateAfterBindEXT";
      default: return "invalid";
    }
  }

  using DescriptorPoolCreateFlags = Flags<DescriptorPoolCreateFlagBits, VkDescriptorPoolCreateFlags>;

  template <> struct FlagTraits<DescriptorPoolCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(DescriptorPoolCreateFlagBits::eFreeDescriptorSet) | VkFlags(DescriptorPoolCreateFlagBits::eUpdateAfterBindEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorPoolCreateFlags operator|( DescriptorPoolCreateFlagBits bit0, DescriptorPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorPoolCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorPoolCreateFlags operator&( DescriptorPoolCreateFlagBits bit0, DescriptorPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorPoolCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorPoolCreateFlags operator^( DescriptorPoolCreateFlagBits bit0, DescriptorPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorPoolCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorPoolCreateFlags operator~( DescriptorPoolCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DescriptorPoolCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DescriptorPoolCreateFlagBits bit0, DescriptorPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorPoolCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DescriptorPoolCreateFlagBits bit0, DescriptorPoolCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorPoolCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DescriptorPoolCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DescriptorPoolCreateFlagBits::eFreeDescriptorSet ) result += "FreeDescriptorSet | ";
    if ( value & DescriptorPoolCreateFlagBits::eUpdateAfterBindEXT ) result += "UpdateAfterBindEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DescriptorPoolResetFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( DescriptorPoolResetFlagBits )
  {
    return "(void)";
  }

  using DescriptorPoolResetFlags = Flags<DescriptorPoolResetFlagBits, VkDescriptorPoolResetFlags>;

  VULKAN_HPP_INLINE std::string to_string( DescriptorPoolResetFlags  )
  {
    return "{}";
  }

  enum class DescriptorSetLayoutCreateFlagBits
  {
    ePushDescriptorKHR = VK_DESCRIPTOR_SET_LAYOUT_CREATE_PUSH_DESCRIPTOR_BIT_KHR,
    eUpdateAfterBindPoolEXT = VK_DESCRIPTOR_SET_LAYOUT_CREATE_UPDATE_AFTER_BIND_POOL_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( DescriptorSetLayoutCreateFlagBits value )
  {
    switch ( value )
    {
      case DescriptorSetLayoutCreateFlagBits::ePushDescriptorKHR : return "PushDescriptorKHR";
      case DescriptorSetLayoutCreateFlagBits::eUpdateAfterBindPoolEXT : return "UpdateAfterBindPoolEXT";
      default: return "invalid";
    }
  }

  using DescriptorSetLayoutCreateFlags = Flags<DescriptorSetLayoutCreateFlagBits, VkDescriptorSetLayoutCreateFlags>;

  template <> struct FlagTraits<DescriptorSetLayoutCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(DescriptorSetLayoutCreateFlagBits::ePushDescriptorKHR) | VkFlags(DescriptorSetLayoutCreateFlagBits::eUpdateAfterBindPoolEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorSetLayoutCreateFlags operator|( DescriptorSetLayoutCreateFlagBits bit0, DescriptorSetLayoutCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorSetLayoutCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorSetLayoutCreateFlags operator&( DescriptorSetLayoutCreateFlagBits bit0, DescriptorSetLayoutCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorSetLayoutCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorSetLayoutCreateFlags operator^( DescriptorSetLayoutCreateFlagBits bit0, DescriptorSetLayoutCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorSetLayoutCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DescriptorSetLayoutCreateFlags operator~( DescriptorSetLayoutCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DescriptorSetLayoutCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DescriptorSetLayoutCreateFlagBits bit0, DescriptorSetLayoutCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorSetLayoutCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DescriptorSetLayoutCreateFlagBits bit0, DescriptorSetLayoutCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DescriptorSetLayoutCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DescriptorSetLayoutCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DescriptorSetLayoutCreateFlagBits::ePushDescriptorKHR ) result += "PushDescriptorKHR | ";
    if ( value & DescriptorSetLayoutCreateFlagBits::eUpdateAfterBindPoolEXT ) result += "UpdateAfterBindPoolEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DescriptorUpdateTemplateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( DescriptorUpdateTemplateCreateFlagBits )
  {
    return "(void)";
  }

  using DescriptorUpdateTemplateCreateFlags = Flags<DescriptorUpdateTemplateCreateFlagBits, VkDescriptorUpdateTemplateCreateFlags>;

  using DescriptorUpdateTemplateCreateFlagsKHR = DescriptorUpdateTemplateCreateFlags;

  VULKAN_HPP_INLINE std::string to_string( DescriptorUpdateTemplateCreateFlags  )
  {
    return "{}";
  }

  enum class DeviceCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( DeviceCreateFlagBits )
  {
    return "(void)";
  }

  using DeviceCreateFlags = Flags<DeviceCreateFlagBits, VkDeviceCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( DeviceCreateFlags  )
  {
    return "{}";
  }

  enum class DeviceGroupPresentModeFlagBitsKHR
  {
    eLocal = VK_DEVICE_GROUP_PRESENT_MODE_LOCAL_BIT_KHR,
    eRemote = VK_DEVICE_GROUP_PRESENT_MODE_REMOTE_BIT_KHR,
    eSum = VK_DEVICE_GROUP_PRESENT_MODE_SUM_BIT_KHR,
    eLocalMultiDevice = VK_DEVICE_GROUP_PRESENT_MODE_LOCAL_MULTI_DEVICE_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( DeviceGroupPresentModeFlagBitsKHR value )
  {
    switch ( value )
    {
      case DeviceGroupPresentModeFlagBitsKHR::eLocal : return "Local";
      case DeviceGroupPresentModeFlagBitsKHR::eRemote : return "Remote";
      case DeviceGroupPresentModeFlagBitsKHR::eSum : return "Sum";
      case DeviceGroupPresentModeFlagBitsKHR::eLocalMultiDevice : return "LocalMultiDevice";
      default: return "invalid";
    }
  }

  using DeviceGroupPresentModeFlagsKHR = Flags<DeviceGroupPresentModeFlagBitsKHR, VkDeviceGroupPresentModeFlagsKHR>;

  template <> struct FlagTraits<DeviceGroupPresentModeFlagBitsKHR>
  {
    enum
    {
      allFlags = VkFlags(DeviceGroupPresentModeFlagBitsKHR::eLocal) | VkFlags(DeviceGroupPresentModeFlagBitsKHR::eRemote) | VkFlags(DeviceGroupPresentModeFlagBitsKHR::eSum) | VkFlags(DeviceGroupPresentModeFlagBitsKHR::eLocalMultiDevice)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceGroupPresentModeFlagsKHR operator|( DeviceGroupPresentModeFlagBitsKHR bit0, DeviceGroupPresentModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceGroupPresentModeFlagsKHR( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceGroupPresentModeFlagsKHR operator&( DeviceGroupPresentModeFlagBitsKHR bit0, DeviceGroupPresentModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceGroupPresentModeFlagsKHR( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceGroupPresentModeFlagsKHR operator^( DeviceGroupPresentModeFlagBitsKHR bit0, DeviceGroupPresentModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceGroupPresentModeFlagsKHR( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceGroupPresentModeFlagsKHR operator~( DeviceGroupPresentModeFlagBitsKHR bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DeviceGroupPresentModeFlagsKHR( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DeviceGroupPresentModeFlagBitsKHR bit0, DeviceGroupPresentModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceGroupPresentModeFlagsKHR( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DeviceGroupPresentModeFlagBitsKHR bit0, DeviceGroupPresentModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceGroupPresentModeFlagsKHR( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DeviceGroupPresentModeFlagsKHR value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DeviceGroupPresentModeFlagBitsKHR::eLocal ) result += "Local | ";
    if ( value & DeviceGroupPresentModeFlagBitsKHR::eRemote ) result += "Remote | ";
    if ( value & DeviceGroupPresentModeFlagBitsKHR::eSum ) result += "Sum | ";
    if ( value & DeviceGroupPresentModeFlagBitsKHR::eLocalMultiDevice ) result += "LocalMultiDevice | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DeviceQueueCreateFlagBits
  {
    eProtected = VK_DEVICE_QUEUE_CREATE_PROTECTED_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( DeviceQueueCreateFlagBits value )
  {
    switch ( value )
    {
      case DeviceQueueCreateFlagBits::eProtected : return "Protected";
      default: return "invalid";
    }
  }

  using DeviceQueueCreateFlags = Flags<DeviceQueueCreateFlagBits, VkDeviceQueueCreateFlags>;

  template <> struct FlagTraits<DeviceQueueCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(DeviceQueueCreateFlagBits::eProtected)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceQueueCreateFlags operator|( DeviceQueueCreateFlagBits bit0, DeviceQueueCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceQueueCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceQueueCreateFlags operator&( DeviceQueueCreateFlagBits bit0, DeviceQueueCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceQueueCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceQueueCreateFlags operator^( DeviceQueueCreateFlagBits bit0, DeviceQueueCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceQueueCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DeviceQueueCreateFlags operator~( DeviceQueueCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DeviceQueueCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DeviceQueueCreateFlagBits bit0, DeviceQueueCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceQueueCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DeviceQueueCreateFlagBits bit0, DeviceQueueCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DeviceQueueCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DeviceQueueCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DeviceQueueCreateFlagBits::eProtected ) result += "Protected | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DisplayModeCreateFlagBitsKHR
  {};

  VULKAN_HPP_INLINE std::string to_string( DisplayModeCreateFlagBitsKHR )
  {
    return "(void)";
  }

  using DisplayModeCreateFlagsKHR = Flags<DisplayModeCreateFlagBitsKHR, VkDisplayModeCreateFlagsKHR>;

  VULKAN_HPP_INLINE std::string to_string( DisplayModeCreateFlagsKHR  )
  {
    return "{}";
  }

  enum class DisplayPlaneAlphaFlagBitsKHR
  {
    eOpaque = VK_DISPLAY_PLANE_ALPHA_OPAQUE_BIT_KHR,
    eGlobal = VK_DISPLAY_PLANE_ALPHA_GLOBAL_BIT_KHR,
    ePerPixel = VK_DISPLAY_PLANE_ALPHA_PER_PIXEL_BIT_KHR,
    ePerPixelPremultiplied = VK_DISPLAY_PLANE_ALPHA_PER_PIXEL_PREMULTIPLIED_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( DisplayPlaneAlphaFlagBitsKHR value )
  {
    switch ( value )
    {
      case DisplayPlaneAlphaFlagBitsKHR::eOpaque : return "Opaque";
      case DisplayPlaneAlphaFlagBitsKHR::eGlobal : return "Global";
      case DisplayPlaneAlphaFlagBitsKHR::ePerPixel : return "PerPixel";
      case DisplayPlaneAlphaFlagBitsKHR::ePerPixelPremultiplied : return "PerPixelPremultiplied";
      default: return "invalid";
    }
  }

  using DisplayPlaneAlphaFlagsKHR = Flags<DisplayPlaneAlphaFlagBitsKHR, VkDisplayPlaneAlphaFlagsKHR>;

  template <> struct FlagTraits<DisplayPlaneAlphaFlagBitsKHR>
  {
    enum
    {
      allFlags = VkFlags(DisplayPlaneAlphaFlagBitsKHR::eOpaque) | VkFlags(DisplayPlaneAlphaFlagBitsKHR::eGlobal) | VkFlags(DisplayPlaneAlphaFlagBitsKHR::ePerPixel) | VkFlags(DisplayPlaneAlphaFlagBitsKHR::ePerPixelPremultiplied)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DisplayPlaneAlphaFlagsKHR operator|( DisplayPlaneAlphaFlagBitsKHR bit0, DisplayPlaneAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DisplayPlaneAlphaFlagsKHR( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DisplayPlaneAlphaFlagsKHR operator&( DisplayPlaneAlphaFlagBitsKHR bit0, DisplayPlaneAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DisplayPlaneAlphaFlagsKHR( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DisplayPlaneAlphaFlagsKHR operator^( DisplayPlaneAlphaFlagBitsKHR bit0, DisplayPlaneAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DisplayPlaneAlphaFlagsKHR( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR DisplayPlaneAlphaFlagsKHR operator~( DisplayPlaneAlphaFlagBitsKHR bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( DisplayPlaneAlphaFlagsKHR( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( DisplayPlaneAlphaFlagBitsKHR bit0, DisplayPlaneAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DisplayPlaneAlphaFlagsKHR( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( DisplayPlaneAlphaFlagBitsKHR bit0, DisplayPlaneAlphaFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return DisplayPlaneAlphaFlagsKHR( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( DisplayPlaneAlphaFlagsKHR value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & DisplayPlaneAlphaFlagBitsKHR::eOpaque ) result += "Opaque | ";
    if ( value & DisplayPlaneAlphaFlagBitsKHR::eGlobal ) result += "Global | ";
    if ( value & DisplayPlaneAlphaFlagBitsKHR::ePerPixel ) result += "PerPixel | ";
    if ( value & DisplayPlaneAlphaFlagBitsKHR::ePerPixelPremultiplied ) result += "PerPixelPremultiplied | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class DisplaySurfaceCreateFlagBitsKHR
  {};

  VULKAN_HPP_INLINE std::string to_string( DisplaySurfaceCreateFlagBitsKHR )
  {
    return "(void)";
  }

  using DisplaySurfaceCreateFlagsKHR = Flags<DisplaySurfaceCreateFlagBitsKHR, VkDisplaySurfaceCreateFlagsKHR>;

  VULKAN_HPP_INLINE std::string to_string( DisplaySurfaceCreateFlagsKHR  )
  {
    return "{}";
  }

  enum class EventCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( EventCreateFlagBits )
  {
    return "(void)";
  }

  using EventCreateFlags = Flags<EventCreateFlagBits, VkEventCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( EventCreateFlags  )
  {
    return "{}";
  }

  enum class ExternalFenceFeatureFlagBits
  {
    eExportable = VK_EXTERNAL_FENCE_FEATURE_EXPORTABLE_BIT,
    eImportable = VK_EXTERNAL_FENCE_FEATURE_IMPORTABLE_BIT,
    eExportableKHR = VK_EXTERNAL_FENCE_FEATURE_EXPORTABLE_BIT_KHR,
    eImportableKHR = VK_EXTERNAL_FENCE_FEATURE_IMPORTABLE_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalFenceFeatureFlagBits value )
  {
    switch ( value )
    {
      case ExternalFenceFeatureFlagBits::eExportable : return "Exportable";
      case ExternalFenceFeatureFlagBits::eImportable : return "Importable";
      default: return "invalid";
    }
  }

  using ExternalFenceFeatureFlags = Flags<ExternalFenceFeatureFlagBits, VkExternalFenceFeatureFlags>;

  template <> struct FlagTraits<ExternalFenceFeatureFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ExternalFenceFeatureFlagBits::eExportable) | VkFlags(ExternalFenceFeatureFlagBits::eImportable)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceFeatureFlags operator|( ExternalFenceFeatureFlagBits bit0, ExternalFenceFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceFeatureFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceFeatureFlags operator&( ExternalFenceFeatureFlagBits bit0, ExternalFenceFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceFeatureFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceFeatureFlags operator^( ExternalFenceFeatureFlagBits bit0, ExternalFenceFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceFeatureFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceFeatureFlags operator~( ExternalFenceFeatureFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalFenceFeatureFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalFenceFeatureFlagBits bit0, ExternalFenceFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceFeatureFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalFenceFeatureFlagBits bit0, ExternalFenceFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceFeatureFlags( bit0 ) != bit1;
  }

  using ExternalFenceFeatureFlagsKHR = ExternalFenceFeatureFlags;

  VULKAN_HPP_INLINE std::string to_string( ExternalFenceFeatureFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalFenceFeatureFlagBits::eExportable ) result += "Exportable | ";
    if ( value & ExternalFenceFeatureFlagBits::eImportable ) result += "Importable | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ExternalFenceHandleTypeFlagBits
  {
    eOpaqueFd = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_FD_BIT,
    eOpaqueWin32 = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_BIT,
    eOpaqueWin32Kmt = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
    eSyncFd = VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT,
    eOpaqueFdKHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_FD_BIT_KHR,
    eOpaqueWin32KHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_BIT_KHR,
    eOpaqueWin32KmtKHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_KHR,
    eSyncFdKHR = VK_EXTERNAL_FENCE_HANDLE_TYPE_SYNC_FD_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalFenceHandleTypeFlagBits value )
  {
    switch ( value )
    {
      case ExternalFenceHandleTypeFlagBits::eOpaqueFd : return "OpaqueFd";
      case ExternalFenceHandleTypeFlagBits::eOpaqueWin32 : return "OpaqueWin32";
      case ExternalFenceHandleTypeFlagBits::eOpaqueWin32Kmt : return "OpaqueWin32Kmt";
      case ExternalFenceHandleTypeFlagBits::eSyncFd : return "SyncFd";
      default: return "invalid";
    }
  }

  using ExternalFenceHandleTypeFlags = Flags<ExternalFenceHandleTypeFlagBits, VkExternalFenceHandleTypeFlags>;

  template <> struct FlagTraits<ExternalFenceHandleTypeFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ExternalFenceHandleTypeFlagBits::eOpaqueFd) | VkFlags(ExternalFenceHandleTypeFlagBits::eOpaqueWin32) | VkFlags(ExternalFenceHandleTypeFlagBits::eOpaqueWin32Kmt) | VkFlags(ExternalFenceHandleTypeFlagBits::eSyncFd)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceHandleTypeFlags operator|( ExternalFenceHandleTypeFlagBits bit0, ExternalFenceHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceHandleTypeFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceHandleTypeFlags operator&( ExternalFenceHandleTypeFlagBits bit0, ExternalFenceHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceHandleTypeFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceHandleTypeFlags operator^( ExternalFenceHandleTypeFlagBits bit0, ExternalFenceHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceHandleTypeFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalFenceHandleTypeFlags operator~( ExternalFenceHandleTypeFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalFenceHandleTypeFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalFenceHandleTypeFlagBits bit0, ExternalFenceHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceHandleTypeFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalFenceHandleTypeFlagBits bit0, ExternalFenceHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalFenceHandleTypeFlags( bit0 ) != bit1;
  }

  using ExternalFenceHandleTypeFlagsKHR = ExternalFenceHandleTypeFlags;

  VULKAN_HPP_INLINE std::string to_string( ExternalFenceHandleTypeFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalFenceHandleTypeFlagBits::eOpaqueFd ) result += "OpaqueFd | ";
    if ( value & ExternalFenceHandleTypeFlagBits::eOpaqueWin32 ) result += "OpaqueWin32 | ";
    if ( value & ExternalFenceHandleTypeFlagBits::eOpaqueWin32Kmt ) result += "OpaqueWin32Kmt | ";
    if ( value & ExternalFenceHandleTypeFlagBits::eSyncFd ) result += "SyncFd | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ExternalMemoryFeatureFlagBits
  {
    eDedicatedOnly = VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT,
    eExportable = VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT,
    eImportable = VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT,
    eDedicatedOnlyKHR = VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT_KHR,
    eExportableKHR = VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT_KHR,
    eImportableKHR = VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryFeatureFlagBits value )
  {
    switch ( value )
    {
      case ExternalMemoryFeatureFlagBits::eDedicatedOnly : return "DedicatedOnly";
      case ExternalMemoryFeatureFlagBits::eExportable : return "Exportable";
      case ExternalMemoryFeatureFlagBits::eImportable : return "Importable";
      default: return "invalid";
    }
  }

  using ExternalMemoryFeatureFlags = Flags<ExternalMemoryFeatureFlagBits, VkExternalMemoryFeatureFlags>;

  template <> struct FlagTraits<ExternalMemoryFeatureFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ExternalMemoryFeatureFlagBits::eDedicatedOnly) | VkFlags(ExternalMemoryFeatureFlagBits::eExportable) | VkFlags(ExternalMemoryFeatureFlagBits::eImportable)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlags operator|( ExternalMemoryFeatureFlagBits bit0, ExternalMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlags operator&( ExternalMemoryFeatureFlagBits bit0, ExternalMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlags operator^( ExternalMemoryFeatureFlagBits bit0, ExternalMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlags operator~( ExternalMemoryFeatureFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalMemoryFeatureFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalMemoryFeatureFlagBits bit0, ExternalMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalMemoryFeatureFlagBits bit0, ExternalMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlags( bit0 ) != bit1;
  }

  using ExternalMemoryFeatureFlagsKHR = ExternalMemoryFeatureFlags;

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryFeatureFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalMemoryFeatureFlagBits::eDedicatedOnly ) result += "DedicatedOnly | ";
    if ( value & ExternalMemoryFeatureFlagBits::eExportable ) result += "Exportable | ";
    if ( value & ExternalMemoryFeatureFlagBits::eImportable ) result += "Importable | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ExternalMemoryFeatureFlagBitsNV
  {
    eDedicatedOnly = VK_EXTERNAL_MEMORY_FEATURE_DEDICATED_ONLY_BIT_NV,
    eExportable = VK_EXTERNAL_MEMORY_FEATURE_EXPORTABLE_BIT_NV,
    eImportable = VK_EXTERNAL_MEMORY_FEATURE_IMPORTABLE_BIT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryFeatureFlagBitsNV value )
  {
    switch ( value )
    {
      case ExternalMemoryFeatureFlagBitsNV::eDedicatedOnly : return "DedicatedOnly";
      case ExternalMemoryFeatureFlagBitsNV::eExportable : return "Exportable";
      case ExternalMemoryFeatureFlagBitsNV::eImportable : return "Importable";
      default: return "invalid";
    }
  }

  using ExternalMemoryFeatureFlagsNV = Flags<ExternalMemoryFeatureFlagBitsNV, VkExternalMemoryFeatureFlagsNV>;

  template <> struct FlagTraits<ExternalMemoryFeatureFlagBitsNV>
  {
    enum
    {
      allFlags = VkFlags(ExternalMemoryFeatureFlagBitsNV::eDedicatedOnly) | VkFlags(ExternalMemoryFeatureFlagBitsNV::eExportable) | VkFlags(ExternalMemoryFeatureFlagBitsNV::eImportable)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlagsNV operator|( ExternalMemoryFeatureFlagBitsNV bit0, ExternalMemoryFeatureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlagsNV( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlagsNV operator&( ExternalMemoryFeatureFlagBitsNV bit0, ExternalMemoryFeatureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlagsNV( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlagsNV operator^( ExternalMemoryFeatureFlagBitsNV bit0, ExternalMemoryFeatureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlagsNV( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryFeatureFlagsNV operator~( ExternalMemoryFeatureFlagBitsNV bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalMemoryFeatureFlagsNV( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalMemoryFeatureFlagBitsNV bit0, ExternalMemoryFeatureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlagsNV( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalMemoryFeatureFlagBitsNV bit0, ExternalMemoryFeatureFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryFeatureFlagsNV( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryFeatureFlagsNV value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalMemoryFeatureFlagBitsNV::eDedicatedOnly ) result += "DedicatedOnly | ";
    if ( value & ExternalMemoryFeatureFlagBitsNV::eExportable ) result += "Exportable | ";
    if ( value & ExternalMemoryFeatureFlagBitsNV::eImportable ) result += "Importable | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ExternalMemoryHandleTypeFlagBits
  {
    eOpaqueFd = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT,
    eOpaqueWin32 = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT,
    eOpaqueWin32Kmt = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
    eD3D11Texture = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT,
    eD3D11TextureKmt = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT,
    eD3D12Heap = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP_BIT,
    eD3D12Resource = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT,
    eDmaBufEXT = VK_EXTERNAL_MEMORY_HANDLE_TYPE_DMA_BUF_BIT_EXT,
    eAndroidHardwareBufferANDROID = VK_EXTERNAL_MEMORY_HANDLE_TYPE_ANDROID_HARDWARE_BUFFER_BIT_ANDROID,
    eHostAllocationEXT = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT,
    eHostMappedForeignMemoryEXT = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_MAPPED_FOREIGN_MEMORY_BIT_EXT,
    eOpaqueFdKHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR,
    eOpaqueWin32KHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT_KHR,
    eOpaqueWin32KmtKHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_KHR,
    eD3D11TextureKHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT_KHR,
    eD3D11TextureKmtKHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT_KHR,
    eD3D12HeapKHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP_BIT_KHR,
    eD3D12ResourceKHR = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryHandleTypeFlagBits value )
  {
    switch ( value )
    {
      case ExternalMemoryHandleTypeFlagBits::eOpaqueFd : return "OpaqueFd";
      case ExternalMemoryHandleTypeFlagBits::eOpaqueWin32 : return "OpaqueWin32";
      case ExternalMemoryHandleTypeFlagBits::eOpaqueWin32Kmt : return "OpaqueWin32Kmt";
      case ExternalMemoryHandleTypeFlagBits::eD3D11Texture : return "D3D11Texture";
      case ExternalMemoryHandleTypeFlagBits::eD3D11TextureKmt : return "D3D11TextureKmt";
      case ExternalMemoryHandleTypeFlagBits::eD3D12Heap : return "D3D12Heap";
      case ExternalMemoryHandleTypeFlagBits::eD3D12Resource : return "D3D12Resource";
      case ExternalMemoryHandleTypeFlagBits::eDmaBufEXT : return "DmaBufEXT";
      case ExternalMemoryHandleTypeFlagBits::eAndroidHardwareBufferANDROID : return "AndroidHardwareBufferANDROID";
      case ExternalMemoryHandleTypeFlagBits::eHostAllocationEXT : return "HostAllocationEXT";
      case ExternalMemoryHandleTypeFlagBits::eHostMappedForeignMemoryEXT : return "HostMappedForeignMemoryEXT";
      default: return "invalid";
    }
  }

  using ExternalMemoryHandleTypeFlags = Flags<ExternalMemoryHandleTypeFlagBits, VkExternalMemoryHandleTypeFlags>;

  template <> struct FlagTraits<ExternalMemoryHandleTypeFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ExternalMemoryHandleTypeFlagBits::eOpaqueFd) | VkFlags(ExternalMemoryHandleTypeFlagBits::eOpaqueWin32) | VkFlags(ExternalMemoryHandleTypeFlagBits::eOpaqueWin32Kmt) | VkFlags(ExternalMemoryHandleTypeFlagBits::eD3D11Texture) | VkFlags(ExternalMemoryHandleTypeFlagBits::eD3D11TextureKmt) | VkFlags(ExternalMemoryHandleTypeFlagBits::eD3D12Heap) | VkFlags(ExternalMemoryHandleTypeFlagBits::eD3D12Resource) | VkFlags(ExternalMemoryHandleTypeFlagBits::eDmaBufEXT) | VkFlags(ExternalMemoryHandleTypeFlagBits::eAndroidHardwareBufferANDROID) | VkFlags(ExternalMemoryHandleTypeFlagBits::eHostAllocationEXT) | VkFlags(ExternalMemoryHandleTypeFlagBits::eHostMappedForeignMemoryEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlags operator|( ExternalMemoryHandleTypeFlagBits bit0, ExternalMemoryHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlags operator&( ExternalMemoryHandleTypeFlagBits bit0, ExternalMemoryHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlags operator^( ExternalMemoryHandleTypeFlagBits bit0, ExternalMemoryHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlags operator~( ExternalMemoryHandleTypeFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalMemoryHandleTypeFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalMemoryHandleTypeFlagBits bit0, ExternalMemoryHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalMemoryHandleTypeFlagBits bit0, ExternalMemoryHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlags( bit0 ) != bit1;
  }

  using ExternalMemoryHandleTypeFlagsKHR = ExternalMemoryHandleTypeFlags;

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryHandleTypeFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) result += "OpaqueFd | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eOpaqueWin32 ) result += "OpaqueWin32 | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eOpaqueWin32Kmt ) result += "OpaqueWin32Kmt | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eD3D11Texture ) result += "D3D11Texture | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eD3D11TextureKmt ) result += "D3D11TextureKmt | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eD3D12Heap ) result += "D3D12Heap | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eD3D12Resource ) result += "D3D12Resource | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eDmaBufEXT ) result += "DmaBufEXT | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eAndroidHardwareBufferANDROID ) result += "AndroidHardwareBufferANDROID | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eHostAllocationEXT ) result += "HostAllocationEXT | ";
    if ( value & ExternalMemoryHandleTypeFlagBits::eHostMappedForeignMemoryEXT ) result += "HostMappedForeignMemoryEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ExternalMemoryHandleTypeFlagBitsNV
  {
    eOpaqueWin32 = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT_NV,
    eOpaqueWin32Kmt = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_NV,
    eD3D11Image = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_IMAGE_BIT_NV,
    eD3D11ImageKmt = VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_IMAGE_KMT_BIT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryHandleTypeFlagBitsNV value )
  {
    switch ( value )
    {
      case ExternalMemoryHandleTypeFlagBitsNV::eOpaqueWin32 : return "OpaqueWin32";
      case ExternalMemoryHandleTypeFlagBitsNV::eOpaqueWin32Kmt : return "OpaqueWin32Kmt";
      case ExternalMemoryHandleTypeFlagBitsNV::eD3D11Image : return "D3D11Image";
      case ExternalMemoryHandleTypeFlagBitsNV::eD3D11ImageKmt : return "D3D11ImageKmt";
      default: return "invalid";
    }
  }

  using ExternalMemoryHandleTypeFlagsNV = Flags<ExternalMemoryHandleTypeFlagBitsNV, VkExternalMemoryHandleTypeFlagsNV>;

  template <> struct FlagTraits<ExternalMemoryHandleTypeFlagBitsNV>
  {
    enum
    {
      allFlags = VkFlags(ExternalMemoryHandleTypeFlagBitsNV::eOpaqueWin32) | VkFlags(ExternalMemoryHandleTypeFlagBitsNV::eOpaqueWin32Kmt) | VkFlags(ExternalMemoryHandleTypeFlagBitsNV::eD3D11Image) | VkFlags(ExternalMemoryHandleTypeFlagBitsNV::eD3D11ImageKmt)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlagsNV operator|( ExternalMemoryHandleTypeFlagBitsNV bit0, ExternalMemoryHandleTypeFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlagsNV( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlagsNV operator&( ExternalMemoryHandleTypeFlagBitsNV bit0, ExternalMemoryHandleTypeFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlagsNV( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlagsNV operator^( ExternalMemoryHandleTypeFlagBitsNV bit0, ExternalMemoryHandleTypeFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlagsNV( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalMemoryHandleTypeFlagsNV operator~( ExternalMemoryHandleTypeFlagBitsNV bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalMemoryHandleTypeFlagsNV( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalMemoryHandleTypeFlagBitsNV bit0, ExternalMemoryHandleTypeFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlagsNV( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalMemoryHandleTypeFlagBitsNV bit0, ExternalMemoryHandleTypeFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalMemoryHandleTypeFlagsNV( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ExternalMemoryHandleTypeFlagsNV value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalMemoryHandleTypeFlagBitsNV::eOpaqueWin32 ) result += "OpaqueWin32 | ";
    if ( value & ExternalMemoryHandleTypeFlagBitsNV::eOpaqueWin32Kmt ) result += "OpaqueWin32Kmt | ";
    if ( value & ExternalMemoryHandleTypeFlagBitsNV::eD3D11Image ) result += "D3D11Image | ";
    if ( value & ExternalMemoryHandleTypeFlagBitsNV::eD3D11ImageKmt ) result += "D3D11ImageKmt | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ExternalSemaphoreFeatureFlagBits
  {
    eExportable = VK_EXTERNAL_SEMAPHORE_FEATURE_EXPORTABLE_BIT,
    eImportable = VK_EXTERNAL_SEMAPHORE_FEATURE_IMPORTABLE_BIT,
    eExportableKHR = VK_EXTERNAL_SEMAPHORE_FEATURE_EXPORTABLE_BIT_KHR,
    eImportableKHR = VK_EXTERNAL_SEMAPHORE_FEATURE_IMPORTABLE_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalSemaphoreFeatureFlagBits value )
  {
    switch ( value )
    {
      case ExternalSemaphoreFeatureFlagBits::eExportable : return "Exportable";
      case ExternalSemaphoreFeatureFlagBits::eImportable : return "Importable";
      default: return "invalid";
    }
  }

  using ExternalSemaphoreFeatureFlags = Flags<ExternalSemaphoreFeatureFlagBits, VkExternalSemaphoreFeatureFlags>;

  template <> struct FlagTraits<ExternalSemaphoreFeatureFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ExternalSemaphoreFeatureFlagBits::eExportable) | VkFlags(ExternalSemaphoreFeatureFlagBits::eImportable)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreFeatureFlags operator|( ExternalSemaphoreFeatureFlagBits bit0, ExternalSemaphoreFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreFeatureFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreFeatureFlags operator&( ExternalSemaphoreFeatureFlagBits bit0, ExternalSemaphoreFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreFeatureFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreFeatureFlags operator^( ExternalSemaphoreFeatureFlagBits bit0, ExternalSemaphoreFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreFeatureFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreFeatureFlags operator~( ExternalSemaphoreFeatureFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalSemaphoreFeatureFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalSemaphoreFeatureFlagBits bit0, ExternalSemaphoreFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreFeatureFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalSemaphoreFeatureFlagBits bit0, ExternalSemaphoreFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreFeatureFlags( bit0 ) != bit1;
  }

  using ExternalSemaphoreFeatureFlagsKHR = ExternalSemaphoreFeatureFlags;

  VULKAN_HPP_INLINE std::string to_string( ExternalSemaphoreFeatureFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalSemaphoreFeatureFlagBits::eExportable ) result += "Exportable | ";
    if ( value & ExternalSemaphoreFeatureFlagBits::eImportable ) result += "Importable | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ExternalSemaphoreHandleTypeFlagBits
  {
    eOpaqueFd = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT,
    eOpaqueWin32 = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT,
    eOpaqueWin32Kmt = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT,
    eD3D12Fence = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT,
    eSyncFd = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_SYNC_FD_BIT,
    eOpaqueFdKHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT_KHR,
    eOpaqueWin32KHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT_KHR,
    eOpaqueWin32KmtKHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT_KHR,
    eD3D12FenceKHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT_KHR,
    eSyncFdKHR = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_SYNC_FD_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ExternalSemaphoreHandleTypeFlagBits value )
  {
    switch ( value )
    {
      case ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd : return "OpaqueFd";
      case ExternalSemaphoreHandleTypeFlagBits::eOpaqueWin32 : return "OpaqueWin32";
      case ExternalSemaphoreHandleTypeFlagBits::eOpaqueWin32Kmt : return "OpaqueWin32Kmt";
      case ExternalSemaphoreHandleTypeFlagBits::eD3D12Fence : return "D3D12Fence";
      case ExternalSemaphoreHandleTypeFlagBits::eSyncFd : return "SyncFd";
      default: return "invalid";
    }
  }

  using ExternalSemaphoreHandleTypeFlags = Flags<ExternalSemaphoreHandleTypeFlagBits, VkExternalSemaphoreHandleTypeFlags>;

  template <> struct FlagTraits<ExternalSemaphoreHandleTypeFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd) | VkFlags(ExternalSemaphoreHandleTypeFlagBits::eOpaqueWin32) | VkFlags(ExternalSemaphoreHandleTypeFlagBits::eOpaqueWin32Kmt) | VkFlags(ExternalSemaphoreHandleTypeFlagBits::eD3D12Fence) | VkFlags(ExternalSemaphoreHandleTypeFlagBits::eSyncFd)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreHandleTypeFlags operator|( ExternalSemaphoreHandleTypeFlagBits bit0, ExternalSemaphoreHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreHandleTypeFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreHandleTypeFlags operator&( ExternalSemaphoreHandleTypeFlagBits bit0, ExternalSemaphoreHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreHandleTypeFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreHandleTypeFlags operator^( ExternalSemaphoreHandleTypeFlagBits bit0, ExternalSemaphoreHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreHandleTypeFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ExternalSemaphoreHandleTypeFlags operator~( ExternalSemaphoreHandleTypeFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ExternalSemaphoreHandleTypeFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ExternalSemaphoreHandleTypeFlagBits bit0, ExternalSemaphoreHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreHandleTypeFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ExternalSemaphoreHandleTypeFlagBits bit0, ExternalSemaphoreHandleTypeFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ExternalSemaphoreHandleTypeFlags( bit0 ) != bit1;
  }

  using ExternalSemaphoreHandleTypeFlagsKHR = ExternalSemaphoreHandleTypeFlags;

  VULKAN_HPP_INLINE std::string to_string( ExternalSemaphoreHandleTypeFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd ) result += "OpaqueFd | ";
    if ( value & ExternalSemaphoreHandleTypeFlagBits::eOpaqueWin32 ) result += "OpaqueWin32 | ";
    if ( value & ExternalSemaphoreHandleTypeFlagBits::eOpaqueWin32Kmt ) result += "OpaqueWin32Kmt | ";
    if ( value & ExternalSemaphoreHandleTypeFlagBits::eD3D12Fence ) result += "D3D12Fence | ";
    if ( value & ExternalSemaphoreHandleTypeFlagBits::eSyncFd ) result += "SyncFd | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class FenceCreateFlagBits
  {
    eSignaled = VK_FENCE_CREATE_SIGNALED_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( FenceCreateFlagBits value )
  {
    switch ( value )
    {
      case FenceCreateFlagBits::eSignaled : return "Signaled";
      default: return "invalid";
    }
  }

  using FenceCreateFlags = Flags<FenceCreateFlagBits, VkFenceCreateFlags>;

  template <> struct FlagTraits<FenceCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(FenceCreateFlagBits::eSignaled)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceCreateFlags operator|( FenceCreateFlagBits bit0, FenceCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceCreateFlags operator&( FenceCreateFlagBits bit0, FenceCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceCreateFlags operator^( FenceCreateFlagBits bit0, FenceCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceCreateFlags operator~( FenceCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( FenceCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( FenceCreateFlagBits bit0, FenceCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( FenceCreateFlagBits bit0, FenceCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( FenceCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & FenceCreateFlagBits::eSignaled ) result += "Signaled | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class FenceImportFlagBits
  {
    eTemporary = VK_FENCE_IMPORT_TEMPORARY_BIT,
    eTemporaryKHR = VK_FENCE_IMPORT_TEMPORARY_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( FenceImportFlagBits value )
  {
    switch ( value )
    {
      case FenceImportFlagBits::eTemporary : return "Temporary";
      default: return "invalid";
    }
  }

  using FenceImportFlags = Flags<FenceImportFlagBits, VkFenceImportFlags>;

  template <> struct FlagTraits<FenceImportFlagBits>
  {
    enum
    {
      allFlags = VkFlags(FenceImportFlagBits::eTemporary)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceImportFlags operator|( FenceImportFlagBits bit0, FenceImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceImportFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceImportFlags operator&( FenceImportFlagBits bit0, FenceImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceImportFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceImportFlags operator^( FenceImportFlagBits bit0, FenceImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceImportFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FenceImportFlags operator~( FenceImportFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( FenceImportFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( FenceImportFlagBits bit0, FenceImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceImportFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( FenceImportFlagBits bit0, FenceImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FenceImportFlags( bit0 ) != bit1;
  }

  using FenceImportFlagsKHR = FenceImportFlags;

  VULKAN_HPP_INLINE std::string to_string( FenceImportFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & FenceImportFlagBits::eTemporary ) result += "Temporary | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class FormatFeatureFlagBits
  {
    eSampledImage = VK_FORMAT_FEATURE_SAMPLED_IMAGE_BIT,
    eStorageImage = VK_FORMAT_FEATURE_STORAGE_IMAGE_BIT,
    eStorageImageAtomic = VK_FORMAT_FEATURE_STORAGE_IMAGE_ATOMIC_BIT,
    eUniformTexelBuffer = VK_FORMAT_FEATURE_UNIFORM_TEXEL_BUFFER_BIT,
    eStorageTexelBuffer = VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_BIT,
    eStorageTexelBufferAtomic = VK_FORMAT_FEATURE_STORAGE_TEXEL_BUFFER_ATOMIC_BIT,
    eVertexBuffer = VK_FORMAT_FEATURE_VERTEX_BUFFER_BIT,
    eColorAttachment = VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BIT,
    eColorAttachmentBlend = VK_FORMAT_FEATURE_COLOR_ATTACHMENT_BLEND_BIT,
    eDepthStencilAttachment = VK_FORMAT_FEATURE_DEPTH_STENCIL_ATTACHMENT_BIT,
    eBlitSrc = VK_FORMAT_FEATURE_BLIT_SRC_BIT,
    eBlitDst = VK_FORMAT_FEATURE_BLIT_DST_BIT,
    eSampledImageFilterLinear = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_LINEAR_BIT,
    eTransferSrc = VK_FORMAT_FEATURE_TRANSFER_SRC_BIT,
    eTransferDst = VK_FORMAT_FEATURE_TRANSFER_DST_BIT,
    eMidpointChromaSamples = VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT,
    eSampledImageYcbcrConversionLinearFilter = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT,
    eSampledImageYcbcrConversionSeparateReconstructionFilter = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT,
    eSampledImageYcbcrConversionChromaReconstructionExplicit = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT,
    eSampledImageYcbcrConversionChromaReconstructionExplicitForceable = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT,
    eDisjoint = VK_FORMAT_FEATURE_DISJOINT_BIT,
    eCositedChromaSamples = VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT,
    eSampledImageFilterCubicIMG = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_IMG,
    eSampledImageFilterMinmaxEXT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_MINMAX_BIT_EXT,
    eFragmentDensityMapEXT = VK_FORMAT_FEATURE_FRAGMENT_DENSITY_MAP_BIT_EXT,
    eTransferSrcKHR = VK_FORMAT_FEATURE_TRANSFER_SRC_BIT_KHR,
    eTransferDstKHR = VK_FORMAT_FEATURE_TRANSFER_DST_BIT_KHR,
    eMidpointChromaSamplesKHR = VK_FORMAT_FEATURE_MIDPOINT_CHROMA_SAMPLES_BIT_KHR,
    eSampledImageYcbcrConversionLinearFilterKHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_LINEAR_FILTER_BIT_KHR,
    eSampledImageYcbcrConversionSeparateReconstructionFilterKHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_SEPARATE_RECONSTRUCTION_FILTER_BIT_KHR,
    eSampledImageYcbcrConversionChromaReconstructionExplicitKHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_BIT_KHR,
    eSampledImageYcbcrConversionChromaReconstructionExplicitForceableKHR = VK_FORMAT_FEATURE_SAMPLED_IMAGE_YCBCR_CONVERSION_CHROMA_RECONSTRUCTION_EXPLICIT_FORCEABLE_BIT_KHR,
    eDisjointKHR = VK_FORMAT_FEATURE_DISJOINT_BIT_KHR,
    eCositedChromaSamplesKHR = VK_FORMAT_FEATURE_COSITED_CHROMA_SAMPLES_BIT_KHR,
    eSampledImageFilterCubicEXT = VK_FORMAT_FEATURE_SAMPLED_IMAGE_FILTER_CUBIC_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( FormatFeatureFlagBits value )
  {
    switch ( value )
    {
      case FormatFeatureFlagBits::eSampledImage : return "SampledImage";
      case FormatFeatureFlagBits::eStorageImage : return "StorageImage";
      case FormatFeatureFlagBits::eStorageImageAtomic : return "StorageImageAtomic";
      case FormatFeatureFlagBits::eUniformTexelBuffer : return "UniformTexelBuffer";
      case FormatFeatureFlagBits::eStorageTexelBuffer : return "StorageTexelBuffer";
      case FormatFeatureFlagBits::eStorageTexelBufferAtomic : return "StorageTexelBufferAtomic";
      case FormatFeatureFlagBits::eVertexBuffer : return "VertexBuffer";
      case FormatFeatureFlagBits::eColorAttachment : return "ColorAttachment";
      case FormatFeatureFlagBits::eColorAttachmentBlend : return "ColorAttachmentBlend";
      case FormatFeatureFlagBits::eDepthStencilAttachment : return "DepthStencilAttachment";
      case FormatFeatureFlagBits::eBlitSrc : return "BlitSrc";
      case FormatFeatureFlagBits::eBlitDst : return "BlitDst";
      case FormatFeatureFlagBits::eSampledImageFilterLinear : return "SampledImageFilterLinear";
      case FormatFeatureFlagBits::eTransferSrc : return "TransferSrc";
      case FormatFeatureFlagBits::eTransferDst : return "TransferDst";
      case FormatFeatureFlagBits::eMidpointChromaSamples : return "MidpointChromaSamples";
      case FormatFeatureFlagBits::eSampledImageYcbcrConversionLinearFilter : return "SampledImageYcbcrConversionLinearFilter";
      case FormatFeatureFlagBits::eSampledImageYcbcrConversionSeparateReconstructionFilter : return "SampledImageYcbcrConversionSeparateReconstructionFilter";
      case FormatFeatureFlagBits::eSampledImageYcbcrConversionChromaReconstructionExplicit : return "SampledImageYcbcrConversionChromaReconstructionExplicit";
      case FormatFeatureFlagBits::eSampledImageYcbcrConversionChromaReconstructionExplicitForceable : return "SampledImageYcbcrConversionChromaReconstructionExplicitForceable";
      case FormatFeatureFlagBits::eDisjoint : return "Disjoint";
      case FormatFeatureFlagBits::eCositedChromaSamples : return "CositedChromaSamples";
      case FormatFeatureFlagBits::eSampledImageFilterCubicIMG : return "SampledImageFilterCubicIMG";
      case FormatFeatureFlagBits::eSampledImageFilterMinmaxEXT : return "SampledImageFilterMinmaxEXT";
      case FormatFeatureFlagBits::eFragmentDensityMapEXT : return "FragmentDensityMapEXT";
      default: return "invalid";
    }
  }

  using FormatFeatureFlags = Flags<FormatFeatureFlagBits, VkFormatFeatureFlags>;

  template <> struct FlagTraits<FormatFeatureFlagBits>
  {
    enum
    {
      allFlags = VkFlags(FormatFeatureFlagBits::eSampledImage) | VkFlags(FormatFeatureFlagBits::eStorageImage) | VkFlags(FormatFeatureFlagBits::eStorageImageAtomic) | VkFlags(FormatFeatureFlagBits::eUniformTexelBuffer) | VkFlags(FormatFeatureFlagBits::eStorageTexelBuffer) | VkFlags(FormatFeatureFlagBits::eStorageTexelBufferAtomic) | VkFlags(FormatFeatureFlagBits::eVertexBuffer) | VkFlags(FormatFeatureFlagBits::eColorAttachment) | VkFlags(FormatFeatureFlagBits::eColorAttachmentBlend) | VkFlags(FormatFeatureFlagBits::eDepthStencilAttachment) | VkFlags(FormatFeatureFlagBits::eBlitSrc) | VkFlags(FormatFeatureFlagBits::eBlitDst) | VkFlags(FormatFeatureFlagBits::eSampledImageFilterLinear) | VkFlags(FormatFeatureFlagBits::eTransferSrc) | VkFlags(FormatFeatureFlagBits::eTransferDst) | VkFlags(FormatFeatureFlagBits::eMidpointChromaSamples) | VkFlags(FormatFeatureFlagBits::eSampledImageYcbcrConversionLinearFilter) | VkFlags(FormatFeatureFlagBits::eSampledImageYcbcrConversionSeparateReconstructionFilter) | VkFlags(FormatFeatureFlagBits::eSampledImageYcbcrConversionChromaReconstructionExplicit) | VkFlags(FormatFeatureFlagBits::eSampledImageYcbcrConversionChromaReconstructionExplicitForceable) | VkFlags(FormatFeatureFlagBits::eDisjoint) | VkFlags(FormatFeatureFlagBits::eCositedChromaSamples) | VkFlags(FormatFeatureFlagBits::eSampledImageFilterCubicIMG) | VkFlags(FormatFeatureFlagBits::eSampledImageFilterMinmaxEXT) | VkFlags(FormatFeatureFlagBits::eFragmentDensityMapEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FormatFeatureFlags operator|( FormatFeatureFlagBits bit0, FormatFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FormatFeatureFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FormatFeatureFlags operator&( FormatFeatureFlagBits bit0, FormatFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FormatFeatureFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FormatFeatureFlags operator^( FormatFeatureFlagBits bit0, FormatFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FormatFeatureFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FormatFeatureFlags operator~( FormatFeatureFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( FormatFeatureFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( FormatFeatureFlagBits bit0, FormatFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FormatFeatureFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( FormatFeatureFlagBits bit0, FormatFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FormatFeatureFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( FormatFeatureFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & FormatFeatureFlagBits::eSampledImage ) result += "SampledImage | ";
    if ( value & FormatFeatureFlagBits::eStorageImage ) result += "StorageImage | ";
    if ( value & FormatFeatureFlagBits::eStorageImageAtomic ) result += "StorageImageAtomic | ";
    if ( value & FormatFeatureFlagBits::eUniformTexelBuffer ) result += "UniformTexelBuffer | ";
    if ( value & FormatFeatureFlagBits::eStorageTexelBuffer ) result += "StorageTexelBuffer | ";
    if ( value & FormatFeatureFlagBits::eStorageTexelBufferAtomic ) result += "StorageTexelBufferAtomic | ";
    if ( value & FormatFeatureFlagBits::eVertexBuffer ) result += "VertexBuffer | ";
    if ( value & FormatFeatureFlagBits::eColorAttachment ) result += "ColorAttachment | ";
    if ( value & FormatFeatureFlagBits::eColorAttachmentBlend ) result += "ColorAttachmentBlend | ";
    if ( value & FormatFeatureFlagBits::eDepthStencilAttachment ) result += "DepthStencilAttachment | ";
    if ( value & FormatFeatureFlagBits::eBlitSrc ) result += "BlitSrc | ";
    if ( value & FormatFeatureFlagBits::eBlitDst ) result += "BlitDst | ";
    if ( value & FormatFeatureFlagBits::eSampledImageFilterLinear ) result += "SampledImageFilterLinear | ";
    if ( value & FormatFeatureFlagBits::eTransferSrc ) result += "TransferSrc | ";
    if ( value & FormatFeatureFlagBits::eTransferDst ) result += "TransferDst | ";
    if ( value & FormatFeatureFlagBits::eMidpointChromaSamples ) result += "MidpointChromaSamples | ";
    if ( value & FormatFeatureFlagBits::eSampledImageYcbcrConversionLinearFilter ) result += "SampledImageYcbcrConversionLinearFilter | ";
    if ( value & FormatFeatureFlagBits::eSampledImageYcbcrConversionSeparateReconstructionFilter ) result += "SampledImageYcbcrConversionSeparateReconstructionFilter | ";
    if ( value & FormatFeatureFlagBits::eSampledImageYcbcrConversionChromaReconstructionExplicit ) result += "SampledImageYcbcrConversionChromaReconstructionExplicit | ";
    if ( value & FormatFeatureFlagBits::eSampledImageYcbcrConversionChromaReconstructionExplicitForceable ) result += "SampledImageYcbcrConversionChromaReconstructionExplicitForceable | ";
    if ( value & FormatFeatureFlagBits::eDisjoint ) result += "Disjoint | ";
    if ( value & FormatFeatureFlagBits::eCositedChromaSamples ) result += "CositedChromaSamples | ";
    if ( value & FormatFeatureFlagBits::eSampledImageFilterCubicIMG ) result += "SampledImageFilterCubicIMG | ";
    if ( value & FormatFeatureFlagBits::eSampledImageFilterMinmaxEXT ) result += "SampledImageFilterMinmaxEXT | ";
    if ( value & FormatFeatureFlagBits::eFragmentDensityMapEXT ) result += "FragmentDensityMapEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class FramebufferCreateFlagBits
  {
    eImagelessKHR = VK_FRAMEBUFFER_CREATE_IMAGELESS_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( FramebufferCreateFlagBits value )
  {
    switch ( value )
    {
      case FramebufferCreateFlagBits::eImagelessKHR : return "ImagelessKHR";
      default: return "invalid";
    }
  }

  using FramebufferCreateFlags = Flags<FramebufferCreateFlagBits, VkFramebufferCreateFlags>;

  template <> struct FlagTraits<FramebufferCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(FramebufferCreateFlagBits::eImagelessKHR)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FramebufferCreateFlags operator|( FramebufferCreateFlagBits bit0, FramebufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FramebufferCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FramebufferCreateFlags operator&( FramebufferCreateFlagBits bit0, FramebufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FramebufferCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FramebufferCreateFlags operator^( FramebufferCreateFlagBits bit0, FramebufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FramebufferCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR FramebufferCreateFlags operator~( FramebufferCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( FramebufferCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( FramebufferCreateFlagBits bit0, FramebufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FramebufferCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( FramebufferCreateFlagBits bit0, FramebufferCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return FramebufferCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( FramebufferCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & FramebufferCreateFlagBits::eImagelessKHR ) result += "ImagelessKHR | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class GeometryFlagBitsNV
  {
    eOpaque = VK_GEOMETRY_OPAQUE_BIT_NV,
    eNoDuplicateAnyHitInvocation = VK_GEOMETRY_NO_DUPLICATE_ANY_HIT_INVOCATION_BIT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( GeometryFlagBitsNV value )
  {
    switch ( value )
    {
      case GeometryFlagBitsNV::eOpaque : return "Opaque";
      case GeometryFlagBitsNV::eNoDuplicateAnyHitInvocation : return "NoDuplicateAnyHitInvocation";
      default: return "invalid";
    }
  }

  using GeometryFlagsNV = Flags<GeometryFlagBitsNV, VkGeometryFlagsNV>;

  template <> struct FlagTraits<GeometryFlagBitsNV>
  {
    enum
    {
      allFlags = VkFlags(GeometryFlagBitsNV::eOpaque) | VkFlags(GeometryFlagBitsNV::eNoDuplicateAnyHitInvocation)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryFlagsNV operator|( GeometryFlagBitsNV bit0, GeometryFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryFlagsNV( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryFlagsNV operator&( GeometryFlagBitsNV bit0, GeometryFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryFlagsNV( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryFlagsNV operator^( GeometryFlagBitsNV bit0, GeometryFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryFlagsNV( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryFlagsNV operator~( GeometryFlagBitsNV bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( GeometryFlagsNV( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( GeometryFlagBitsNV bit0, GeometryFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryFlagsNV( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( GeometryFlagBitsNV bit0, GeometryFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryFlagsNV( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( GeometryFlagsNV value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & GeometryFlagBitsNV::eOpaque ) result += "Opaque | ";
    if ( value & GeometryFlagBitsNV::eNoDuplicateAnyHitInvocation ) result += "NoDuplicateAnyHitInvocation | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class GeometryInstanceFlagBitsNV
  {
    eTriangleCullDisable = VK_GEOMETRY_INSTANCE_TRIANGLE_CULL_DISABLE_BIT_NV,
    eTriangleFrontCounterclockwise = VK_GEOMETRY_INSTANCE_TRIANGLE_FRONT_COUNTERCLOCKWISE_BIT_NV,
    eForceOpaque = VK_GEOMETRY_INSTANCE_FORCE_OPAQUE_BIT_NV,
    eForceNoOpaque = VK_GEOMETRY_INSTANCE_FORCE_NO_OPAQUE_BIT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( GeometryInstanceFlagBitsNV value )
  {
    switch ( value )
    {
      case GeometryInstanceFlagBitsNV::eTriangleCullDisable : return "TriangleCullDisable";
      case GeometryInstanceFlagBitsNV::eTriangleFrontCounterclockwise : return "TriangleFrontCounterclockwise";
      case GeometryInstanceFlagBitsNV::eForceOpaque : return "ForceOpaque";
      case GeometryInstanceFlagBitsNV::eForceNoOpaque : return "ForceNoOpaque";
      default: return "invalid";
    }
  }

  using GeometryInstanceFlagsNV = Flags<GeometryInstanceFlagBitsNV, VkGeometryInstanceFlagsNV>;

  template <> struct FlagTraits<GeometryInstanceFlagBitsNV>
  {
    enum
    {
      allFlags = VkFlags(GeometryInstanceFlagBitsNV::eTriangleCullDisable) | VkFlags(GeometryInstanceFlagBitsNV::eTriangleFrontCounterclockwise) | VkFlags(GeometryInstanceFlagBitsNV::eForceOpaque) | VkFlags(GeometryInstanceFlagBitsNV::eForceNoOpaque)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryInstanceFlagsNV operator|( GeometryInstanceFlagBitsNV bit0, GeometryInstanceFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryInstanceFlagsNV( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryInstanceFlagsNV operator&( GeometryInstanceFlagBitsNV bit0, GeometryInstanceFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryInstanceFlagsNV( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryInstanceFlagsNV operator^( GeometryInstanceFlagBitsNV bit0, GeometryInstanceFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryInstanceFlagsNV( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR GeometryInstanceFlagsNV operator~( GeometryInstanceFlagBitsNV bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( GeometryInstanceFlagsNV( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( GeometryInstanceFlagBitsNV bit0, GeometryInstanceFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryInstanceFlagsNV( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( GeometryInstanceFlagBitsNV bit0, GeometryInstanceFlagBitsNV bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return GeometryInstanceFlagsNV( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( GeometryInstanceFlagsNV value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & GeometryInstanceFlagBitsNV::eTriangleCullDisable ) result += "TriangleCullDisable | ";
    if ( value & GeometryInstanceFlagBitsNV::eTriangleFrontCounterclockwise ) result += "TriangleFrontCounterclockwise | ";
    if ( value & GeometryInstanceFlagBitsNV::eForceOpaque ) result += "ForceOpaque | ";
    if ( value & GeometryInstanceFlagBitsNV::eForceNoOpaque ) result += "ForceNoOpaque | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class HeadlessSurfaceCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( HeadlessSurfaceCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using HeadlessSurfaceCreateFlagsEXT = Flags<HeadlessSurfaceCreateFlagBitsEXT, VkHeadlessSurfaceCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( HeadlessSurfaceCreateFlagsEXT  )
  {
    return "{}";
  }

#ifdef VK_USE_PLATFORM_IOS_MVK
  enum class IOSSurfaceCreateFlagBitsMVK
  {};

  VULKAN_HPP_INLINE std::string to_string( IOSSurfaceCreateFlagBitsMVK )
  {
    return "(void)";
  }

  using IOSSurfaceCreateFlagsMVK = Flags<IOSSurfaceCreateFlagBitsMVK, VkIOSSurfaceCreateFlagsMVK>;

  VULKAN_HPP_INLINE std::string to_string( IOSSurfaceCreateFlagsMVK  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_IOS_MVK*/

  enum class ImageAspectFlagBits
  {
    eColor = VK_IMAGE_ASPECT_COLOR_BIT,
    eDepth = VK_IMAGE_ASPECT_DEPTH_BIT,
    eStencil = VK_IMAGE_ASPECT_STENCIL_BIT,
    eMetadata = VK_IMAGE_ASPECT_METADATA_BIT,
    ePlane0 = VK_IMAGE_ASPECT_PLANE_0_BIT,
    ePlane1 = VK_IMAGE_ASPECT_PLANE_1_BIT,
    ePlane2 = VK_IMAGE_ASPECT_PLANE_2_BIT,
    eMemoryPlane0EXT = VK_IMAGE_ASPECT_MEMORY_PLANE_0_BIT_EXT,
    eMemoryPlane1EXT = VK_IMAGE_ASPECT_MEMORY_PLANE_1_BIT_EXT,
    eMemoryPlane2EXT = VK_IMAGE_ASPECT_MEMORY_PLANE_2_BIT_EXT,
    eMemoryPlane3EXT = VK_IMAGE_ASPECT_MEMORY_PLANE_3_BIT_EXT,
    ePlane0KHR = VK_IMAGE_ASPECT_PLANE_0_BIT_KHR,
    ePlane1KHR = VK_IMAGE_ASPECT_PLANE_1_BIT_KHR,
    ePlane2KHR = VK_IMAGE_ASPECT_PLANE_2_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ImageAspectFlagBits value )
  {
    switch ( value )
    {
      case ImageAspectFlagBits::eColor : return "Color";
      case ImageAspectFlagBits::eDepth : return "Depth";
      case ImageAspectFlagBits::eStencil : return "Stencil";
      case ImageAspectFlagBits::eMetadata : return "Metadata";
      case ImageAspectFlagBits::ePlane0 : return "Plane0";
      case ImageAspectFlagBits::ePlane1 : return "Plane1";
      case ImageAspectFlagBits::ePlane2 : return "Plane2";
      case ImageAspectFlagBits::eMemoryPlane0EXT : return "MemoryPlane0EXT";
      case ImageAspectFlagBits::eMemoryPlane1EXT : return "MemoryPlane1EXT";
      case ImageAspectFlagBits::eMemoryPlane2EXT : return "MemoryPlane2EXT";
      case ImageAspectFlagBits::eMemoryPlane3EXT : return "MemoryPlane3EXT";
      default: return "invalid";
    }
  }

  using ImageAspectFlags = Flags<ImageAspectFlagBits, VkImageAspectFlags>;

  template <> struct FlagTraits<ImageAspectFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ImageAspectFlagBits::eColor) | VkFlags(ImageAspectFlagBits::eDepth) | VkFlags(ImageAspectFlagBits::eStencil) | VkFlags(ImageAspectFlagBits::eMetadata) | VkFlags(ImageAspectFlagBits::ePlane0) | VkFlags(ImageAspectFlagBits::ePlane1) | VkFlags(ImageAspectFlagBits::ePlane2) | VkFlags(ImageAspectFlagBits::eMemoryPlane0EXT) | VkFlags(ImageAspectFlagBits::eMemoryPlane1EXT) | VkFlags(ImageAspectFlagBits::eMemoryPlane2EXT) | VkFlags(ImageAspectFlagBits::eMemoryPlane3EXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageAspectFlags operator|( ImageAspectFlagBits bit0, ImageAspectFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageAspectFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageAspectFlags operator&( ImageAspectFlagBits bit0, ImageAspectFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageAspectFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageAspectFlags operator^( ImageAspectFlagBits bit0, ImageAspectFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageAspectFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageAspectFlags operator~( ImageAspectFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ImageAspectFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ImageAspectFlagBits bit0, ImageAspectFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageAspectFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ImageAspectFlagBits bit0, ImageAspectFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageAspectFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ImageAspectFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ImageAspectFlagBits::eColor ) result += "Color | ";
    if ( value & ImageAspectFlagBits::eDepth ) result += "Depth | ";
    if ( value & ImageAspectFlagBits::eStencil ) result += "Stencil | ";
    if ( value & ImageAspectFlagBits::eMetadata ) result += "Metadata | ";
    if ( value & ImageAspectFlagBits::ePlane0 ) result += "Plane0 | ";
    if ( value & ImageAspectFlagBits::ePlane1 ) result += "Plane1 | ";
    if ( value & ImageAspectFlagBits::ePlane2 ) result += "Plane2 | ";
    if ( value & ImageAspectFlagBits::eMemoryPlane0EXT ) result += "MemoryPlane0EXT | ";
    if ( value & ImageAspectFlagBits::eMemoryPlane1EXT ) result += "MemoryPlane1EXT | ";
    if ( value & ImageAspectFlagBits::eMemoryPlane2EXT ) result += "MemoryPlane2EXT | ";
    if ( value & ImageAspectFlagBits::eMemoryPlane3EXT ) result += "MemoryPlane3EXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ImageCreateFlagBits
  {
    eSparseBinding = VK_IMAGE_CREATE_SPARSE_BINDING_BIT,
    eSparseResidency = VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT,
    eSparseAliased = VK_IMAGE_CREATE_SPARSE_ALIASED_BIT,
    eMutableFormat = VK_IMAGE_CREATE_MUTABLE_FORMAT_BIT,
    eCubeCompatible = VK_IMAGE_CREATE_CUBE_COMPATIBLE_BIT,
    eAlias = VK_IMAGE_CREATE_ALIAS_BIT,
    eSplitInstanceBindRegions = VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT,
    e2DArrayCompatible = VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT,
    eBlockTexelViewCompatible = VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT,
    eExtendedUsage = VK_IMAGE_CREATE_EXTENDED_USAGE_BIT,
    eProtected = VK_IMAGE_CREATE_PROTECTED_BIT,
    eDisjoint = VK_IMAGE_CREATE_DISJOINT_BIT,
    eCornerSampledNV = VK_IMAGE_CREATE_CORNER_SAMPLED_BIT_NV,
    eSampleLocationsCompatibleDepthEXT = VK_IMAGE_CREATE_SAMPLE_LOCATIONS_COMPATIBLE_DEPTH_BIT_EXT,
    eSubsampledEXT = VK_IMAGE_CREATE_SUBSAMPLED_BIT_EXT,
    eSplitInstanceBindRegionsKHR = VK_IMAGE_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT_KHR,
    e2DArrayCompatibleKHR = VK_IMAGE_CREATE_2D_ARRAY_COMPATIBLE_BIT_KHR,
    eBlockTexelViewCompatibleKHR = VK_IMAGE_CREATE_BLOCK_TEXEL_VIEW_COMPATIBLE_BIT_KHR,
    eExtendedUsageKHR = VK_IMAGE_CREATE_EXTENDED_USAGE_BIT_KHR,
    eDisjointKHR = VK_IMAGE_CREATE_DISJOINT_BIT_KHR,
    eAliasKHR = VK_IMAGE_CREATE_ALIAS_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ImageCreateFlagBits value )
  {
    switch ( value )
    {
      case ImageCreateFlagBits::eSparseBinding : return "SparseBinding";
      case ImageCreateFlagBits::eSparseResidency : return "SparseResidency";
      case ImageCreateFlagBits::eSparseAliased : return "SparseAliased";
      case ImageCreateFlagBits::eMutableFormat : return "MutableFormat";
      case ImageCreateFlagBits::eCubeCompatible : return "CubeCompatible";
      case ImageCreateFlagBits::eAlias : return "Alias";
      case ImageCreateFlagBits::eSplitInstanceBindRegions : return "SplitInstanceBindRegions";
      case ImageCreateFlagBits::e2DArrayCompatible : return "2DArrayCompatible";
      case ImageCreateFlagBits::eBlockTexelViewCompatible : return "BlockTexelViewCompatible";
      case ImageCreateFlagBits::eExtendedUsage : return "ExtendedUsage";
      case ImageCreateFlagBits::eProtected : return "Protected";
      case ImageCreateFlagBits::eDisjoint : return "Disjoint";
      case ImageCreateFlagBits::eCornerSampledNV : return "CornerSampledNV";
      case ImageCreateFlagBits::eSampleLocationsCompatibleDepthEXT : return "SampleLocationsCompatibleDepthEXT";
      case ImageCreateFlagBits::eSubsampledEXT : return "SubsampledEXT";
      default: return "invalid";
    }
  }

  using ImageCreateFlags = Flags<ImageCreateFlagBits, VkImageCreateFlags>;

  template <> struct FlagTraits<ImageCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ImageCreateFlagBits::eSparseBinding) | VkFlags(ImageCreateFlagBits::eSparseResidency) | VkFlags(ImageCreateFlagBits::eSparseAliased) | VkFlags(ImageCreateFlagBits::eMutableFormat) | VkFlags(ImageCreateFlagBits::eCubeCompatible) | VkFlags(ImageCreateFlagBits::eAlias) | VkFlags(ImageCreateFlagBits::eSplitInstanceBindRegions) | VkFlags(ImageCreateFlagBits::e2DArrayCompatible) | VkFlags(ImageCreateFlagBits::eBlockTexelViewCompatible) | VkFlags(ImageCreateFlagBits::eExtendedUsage) | VkFlags(ImageCreateFlagBits::eProtected) | VkFlags(ImageCreateFlagBits::eDisjoint) | VkFlags(ImageCreateFlagBits::eCornerSampledNV) | VkFlags(ImageCreateFlagBits::eSampleLocationsCompatibleDepthEXT) | VkFlags(ImageCreateFlagBits::eSubsampledEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageCreateFlags operator|( ImageCreateFlagBits bit0, ImageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageCreateFlags operator&( ImageCreateFlagBits bit0, ImageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageCreateFlags operator^( ImageCreateFlagBits bit0, ImageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageCreateFlags operator~( ImageCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ImageCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ImageCreateFlagBits bit0, ImageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ImageCreateFlagBits bit0, ImageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ImageCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ImageCreateFlagBits::eSparseBinding ) result += "SparseBinding | ";
    if ( value & ImageCreateFlagBits::eSparseResidency ) result += "SparseResidency | ";
    if ( value & ImageCreateFlagBits::eSparseAliased ) result += "SparseAliased | ";
    if ( value & ImageCreateFlagBits::eMutableFormat ) result += "MutableFormat | ";
    if ( value & ImageCreateFlagBits::eCubeCompatible ) result += "CubeCompatible | ";
    if ( value & ImageCreateFlagBits::eAlias ) result += "Alias | ";
    if ( value & ImageCreateFlagBits::eSplitInstanceBindRegions ) result += "SplitInstanceBindRegions | ";
    if ( value & ImageCreateFlagBits::e2DArrayCompatible ) result += "2DArrayCompatible | ";
    if ( value & ImageCreateFlagBits::eBlockTexelViewCompatible ) result += "BlockTexelViewCompatible | ";
    if ( value & ImageCreateFlagBits::eExtendedUsage ) result += "ExtendedUsage | ";
    if ( value & ImageCreateFlagBits::eProtected ) result += "Protected | ";
    if ( value & ImageCreateFlagBits::eDisjoint ) result += "Disjoint | ";
    if ( value & ImageCreateFlagBits::eCornerSampledNV ) result += "CornerSampledNV | ";
    if ( value & ImageCreateFlagBits::eSampleLocationsCompatibleDepthEXT ) result += "SampleLocationsCompatibleDepthEXT | ";
    if ( value & ImageCreateFlagBits::eSubsampledEXT ) result += "SubsampledEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

#ifdef VK_USE_PLATFORM_FUCHSIA
  enum class ImagePipeSurfaceCreateFlagBitsFUCHSIA
  {};

  VULKAN_HPP_INLINE std::string to_string( ImagePipeSurfaceCreateFlagBitsFUCHSIA )
  {
    return "(void)";
  }

  using ImagePipeSurfaceCreateFlagsFUCHSIA = Flags<ImagePipeSurfaceCreateFlagBitsFUCHSIA, VkImagePipeSurfaceCreateFlagsFUCHSIA>;

  VULKAN_HPP_INLINE std::string to_string( ImagePipeSurfaceCreateFlagsFUCHSIA  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_FUCHSIA*/

  enum class ImageUsageFlagBits
  {
    eTransferSrc = VK_IMAGE_USAGE_TRANSFER_SRC_BIT,
    eTransferDst = VK_IMAGE_USAGE_TRANSFER_DST_BIT,
    eSampled = VK_IMAGE_USAGE_SAMPLED_BIT,
    eStorage = VK_IMAGE_USAGE_STORAGE_BIT,
    eColorAttachment = VK_IMAGE_USAGE_COLOR_ATTACHMENT_BIT,
    eDepthStencilAttachment = VK_IMAGE_USAGE_DEPTH_STENCIL_ATTACHMENT_BIT,
    eTransientAttachment = VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT,
    eInputAttachment = VK_IMAGE_USAGE_INPUT_ATTACHMENT_BIT,
    eShadingRateImageNV = VK_IMAGE_USAGE_SHADING_RATE_IMAGE_BIT_NV,
    eFragmentDensityMapEXT = VK_IMAGE_USAGE_FRAGMENT_DENSITY_MAP_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ImageUsageFlagBits value )
  {
    switch ( value )
    {
      case ImageUsageFlagBits::eTransferSrc : return "TransferSrc";
      case ImageUsageFlagBits::eTransferDst : return "TransferDst";
      case ImageUsageFlagBits::eSampled : return "Sampled";
      case ImageUsageFlagBits::eStorage : return "Storage";
      case ImageUsageFlagBits::eColorAttachment : return "ColorAttachment";
      case ImageUsageFlagBits::eDepthStencilAttachment : return "DepthStencilAttachment";
      case ImageUsageFlagBits::eTransientAttachment : return "TransientAttachment";
      case ImageUsageFlagBits::eInputAttachment : return "InputAttachment";
      case ImageUsageFlagBits::eShadingRateImageNV : return "ShadingRateImageNV";
      case ImageUsageFlagBits::eFragmentDensityMapEXT : return "FragmentDensityMapEXT";
      default: return "invalid";
    }
  }

  using ImageUsageFlags = Flags<ImageUsageFlagBits, VkImageUsageFlags>;

  template <> struct FlagTraits<ImageUsageFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ImageUsageFlagBits::eTransferSrc) | VkFlags(ImageUsageFlagBits::eTransferDst) | VkFlags(ImageUsageFlagBits::eSampled) | VkFlags(ImageUsageFlagBits::eStorage) | VkFlags(ImageUsageFlagBits::eColorAttachment) | VkFlags(ImageUsageFlagBits::eDepthStencilAttachment) | VkFlags(ImageUsageFlagBits::eTransientAttachment) | VkFlags(ImageUsageFlagBits::eInputAttachment) | VkFlags(ImageUsageFlagBits::eShadingRateImageNV) | VkFlags(ImageUsageFlagBits::eFragmentDensityMapEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageUsageFlags operator|( ImageUsageFlagBits bit0, ImageUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageUsageFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageUsageFlags operator&( ImageUsageFlagBits bit0, ImageUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageUsageFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageUsageFlags operator^( ImageUsageFlagBits bit0, ImageUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageUsageFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageUsageFlags operator~( ImageUsageFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ImageUsageFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ImageUsageFlagBits bit0, ImageUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageUsageFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ImageUsageFlagBits bit0, ImageUsageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageUsageFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ImageUsageFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ImageUsageFlagBits::eTransferSrc ) result += "TransferSrc | ";
    if ( value & ImageUsageFlagBits::eTransferDst ) result += "TransferDst | ";
    if ( value & ImageUsageFlagBits::eSampled ) result += "Sampled | ";
    if ( value & ImageUsageFlagBits::eStorage ) result += "Storage | ";
    if ( value & ImageUsageFlagBits::eColorAttachment ) result += "ColorAttachment | ";
    if ( value & ImageUsageFlagBits::eDepthStencilAttachment ) result += "DepthStencilAttachment | ";
    if ( value & ImageUsageFlagBits::eTransientAttachment ) result += "TransientAttachment | ";
    if ( value & ImageUsageFlagBits::eInputAttachment ) result += "InputAttachment | ";
    if ( value & ImageUsageFlagBits::eShadingRateImageNV ) result += "ShadingRateImageNV | ";
    if ( value & ImageUsageFlagBits::eFragmentDensityMapEXT ) result += "FragmentDensityMapEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ImageViewCreateFlagBits
  {
    eFragmentDensityMapDynamicEXT = VK_IMAGE_VIEW_CREATE_FRAGMENT_DENSITY_MAP_DYNAMIC_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( ImageViewCreateFlagBits value )
  {
    switch ( value )
    {
      case ImageViewCreateFlagBits::eFragmentDensityMapDynamicEXT : return "FragmentDensityMapDynamicEXT";
      default: return "invalid";
    }
  }

  using ImageViewCreateFlags = Flags<ImageViewCreateFlagBits, VkImageViewCreateFlags>;

  template <> struct FlagTraits<ImageViewCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ImageViewCreateFlagBits::eFragmentDensityMapDynamicEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageViewCreateFlags operator|( ImageViewCreateFlagBits bit0, ImageViewCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageViewCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageViewCreateFlags operator&( ImageViewCreateFlagBits bit0, ImageViewCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageViewCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageViewCreateFlags operator^( ImageViewCreateFlagBits bit0, ImageViewCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageViewCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ImageViewCreateFlags operator~( ImageViewCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ImageViewCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ImageViewCreateFlagBits bit0, ImageViewCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageViewCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ImageViewCreateFlagBits bit0, ImageViewCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ImageViewCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ImageViewCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ImageViewCreateFlagBits::eFragmentDensityMapDynamicEXT ) result += "FragmentDensityMapDynamicEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class IndirectCommandsLayoutUsageFlagBitsNVX
  {
    eUnorderedSequences = VK_INDIRECT_COMMANDS_LAYOUT_USAGE_UNORDERED_SEQUENCES_BIT_NVX,
    eSparseSequences = VK_INDIRECT_COMMANDS_LAYOUT_USAGE_SPARSE_SEQUENCES_BIT_NVX,
    eEmptyExecutions = VK_INDIRECT_COMMANDS_LAYOUT_USAGE_EMPTY_EXECUTIONS_BIT_NVX,
    eIndexedSequences = VK_INDIRECT_COMMANDS_LAYOUT_USAGE_INDEXED_SEQUENCES_BIT_NVX
  };

  VULKAN_HPP_INLINE std::string to_string( IndirectCommandsLayoutUsageFlagBitsNVX value )
  {
    switch ( value )
    {
      case IndirectCommandsLayoutUsageFlagBitsNVX::eUnorderedSequences : return "UnorderedSequences";
      case IndirectCommandsLayoutUsageFlagBitsNVX::eSparseSequences : return "SparseSequences";
      case IndirectCommandsLayoutUsageFlagBitsNVX::eEmptyExecutions : return "EmptyExecutions";
      case IndirectCommandsLayoutUsageFlagBitsNVX::eIndexedSequences : return "IndexedSequences";
      default: return "invalid";
    }
  }

  using IndirectCommandsLayoutUsageFlagsNVX = Flags<IndirectCommandsLayoutUsageFlagBitsNVX, VkIndirectCommandsLayoutUsageFlagsNVX>;

  template <> struct FlagTraits<IndirectCommandsLayoutUsageFlagBitsNVX>
  {
    enum
    {
      allFlags = VkFlags(IndirectCommandsLayoutUsageFlagBitsNVX::eUnorderedSequences) | VkFlags(IndirectCommandsLayoutUsageFlagBitsNVX::eSparseSequences) | VkFlags(IndirectCommandsLayoutUsageFlagBitsNVX::eEmptyExecutions) | VkFlags(IndirectCommandsLayoutUsageFlagBitsNVX::eIndexedSequences)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutUsageFlagsNVX operator|( IndirectCommandsLayoutUsageFlagBitsNVX bit0, IndirectCommandsLayoutUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return IndirectCommandsLayoutUsageFlagsNVX( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutUsageFlagsNVX operator&( IndirectCommandsLayoutUsageFlagBitsNVX bit0, IndirectCommandsLayoutUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return IndirectCommandsLayoutUsageFlagsNVX( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutUsageFlagsNVX operator^( IndirectCommandsLayoutUsageFlagBitsNVX bit0, IndirectCommandsLayoutUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return IndirectCommandsLayoutUsageFlagsNVX( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutUsageFlagsNVX operator~( IndirectCommandsLayoutUsageFlagBitsNVX bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( IndirectCommandsLayoutUsageFlagsNVX( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( IndirectCommandsLayoutUsageFlagBitsNVX bit0, IndirectCommandsLayoutUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return IndirectCommandsLayoutUsageFlagsNVX( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( IndirectCommandsLayoutUsageFlagBitsNVX bit0, IndirectCommandsLayoutUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return IndirectCommandsLayoutUsageFlagsNVX( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( IndirectCommandsLayoutUsageFlagsNVX value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & IndirectCommandsLayoutUsageFlagBitsNVX::eUnorderedSequences ) result += "UnorderedSequences | ";
    if ( value & IndirectCommandsLayoutUsageFlagBitsNVX::eSparseSequences ) result += "SparseSequences | ";
    if ( value & IndirectCommandsLayoutUsageFlagBitsNVX::eEmptyExecutions ) result += "EmptyExecutions | ";
    if ( value & IndirectCommandsLayoutUsageFlagBitsNVX::eIndexedSequences ) result += "IndexedSequences | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class InstanceCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( InstanceCreateFlagBits )
  {
    return "(void)";
  }

  using InstanceCreateFlags = Flags<InstanceCreateFlagBits, VkInstanceCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( InstanceCreateFlags  )
  {
    return "{}";
  }

#ifdef VK_USE_PLATFORM_MACOS_MVK
  enum class MacOSSurfaceCreateFlagBitsMVK
  {};

  VULKAN_HPP_INLINE std::string to_string( MacOSSurfaceCreateFlagBitsMVK )
  {
    return "(void)";
  }

  using MacOSSurfaceCreateFlagsMVK = Flags<MacOSSurfaceCreateFlagBitsMVK, VkMacOSSurfaceCreateFlagsMVK>;

  VULKAN_HPP_INLINE std::string to_string( MacOSSurfaceCreateFlagsMVK  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_MACOS_MVK*/

  enum class MemoryAllocateFlagBits
  {
    eDeviceMask = VK_MEMORY_ALLOCATE_DEVICE_MASK_BIT,
    eDeviceMaskKHR = VK_MEMORY_ALLOCATE_DEVICE_MASK_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( MemoryAllocateFlagBits value )
  {
    switch ( value )
    {
      case MemoryAllocateFlagBits::eDeviceMask : return "DeviceMask";
      default: return "invalid";
    }
  }

  using MemoryAllocateFlags = Flags<MemoryAllocateFlagBits, VkMemoryAllocateFlags>;

  template <> struct FlagTraits<MemoryAllocateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(MemoryAllocateFlagBits::eDeviceMask)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryAllocateFlags operator|( MemoryAllocateFlagBits bit0, MemoryAllocateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryAllocateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryAllocateFlags operator&( MemoryAllocateFlagBits bit0, MemoryAllocateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryAllocateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryAllocateFlags operator^( MemoryAllocateFlagBits bit0, MemoryAllocateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryAllocateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryAllocateFlags operator~( MemoryAllocateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( MemoryAllocateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( MemoryAllocateFlagBits bit0, MemoryAllocateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryAllocateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( MemoryAllocateFlagBits bit0, MemoryAllocateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryAllocateFlags( bit0 ) != bit1;
  }

  using MemoryAllocateFlagsKHR = MemoryAllocateFlags;

  VULKAN_HPP_INLINE std::string to_string( MemoryAllocateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & MemoryAllocateFlagBits::eDeviceMask ) result += "DeviceMask | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class MemoryHeapFlagBits
  {
    eDeviceLocal = VK_MEMORY_HEAP_DEVICE_LOCAL_BIT,
    eMultiInstance = VK_MEMORY_HEAP_MULTI_INSTANCE_BIT,
    eMultiInstanceKHR = VK_MEMORY_HEAP_MULTI_INSTANCE_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( MemoryHeapFlagBits value )
  {
    switch ( value )
    {
      case MemoryHeapFlagBits::eDeviceLocal : return "DeviceLocal";
      case MemoryHeapFlagBits::eMultiInstance : return "MultiInstance";
      default: return "invalid";
    }
  }

  using MemoryHeapFlags = Flags<MemoryHeapFlagBits, VkMemoryHeapFlags>;

  template <> struct FlagTraits<MemoryHeapFlagBits>
  {
    enum
    {
      allFlags = VkFlags(MemoryHeapFlagBits::eDeviceLocal) | VkFlags(MemoryHeapFlagBits::eMultiInstance)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryHeapFlags operator|( MemoryHeapFlagBits bit0, MemoryHeapFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryHeapFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryHeapFlags operator&( MemoryHeapFlagBits bit0, MemoryHeapFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryHeapFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryHeapFlags operator^( MemoryHeapFlagBits bit0, MemoryHeapFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryHeapFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryHeapFlags operator~( MemoryHeapFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( MemoryHeapFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( MemoryHeapFlagBits bit0, MemoryHeapFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryHeapFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( MemoryHeapFlagBits bit0, MemoryHeapFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryHeapFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( MemoryHeapFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & MemoryHeapFlagBits::eDeviceLocal ) result += "DeviceLocal | ";
    if ( value & MemoryHeapFlagBits::eMultiInstance ) result += "MultiInstance | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class MemoryMapFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( MemoryMapFlagBits )
  {
    return "(void)";
  }

  using MemoryMapFlags = Flags<MemoryMapFlagBits, VkMemoryMapFlags>;

  VULKAN_HPP_INLINE std::string to_string( MemoryMapFlags  )
  {
    return "{}";
  }

  enum class MemoryPropertyFlagBits
  {
    eDeviceLocal = VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT,
    eHostVisible = VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT,
    eHostCoherent = VK_MEMORY_PROPERTY_HOST_COHERENT_BIT,
    eHostCached = VK_MEMORY_PROPERTY_HOST_CACHED_BIT,
    eLazilyAllocated = VK_MEMORY_PROPERTY_LAZILY_ALLOCATED_BIT,
    eProtected = VK_MEMORY_PROPERTY_PROTECTED_BIT,
    eDeviceCoherentAMD = VK_MEMORY_PROPERTY_DEVICE_COHERENT_BIT_AMD,
    eDeviceUncachedAMD = VK_MEMORY_PROPERTY_DEVICE_UNCACHED_BIT_AMD
  };

  VULKAN_HPP_INLINE std::string to_string( MemoryPropertyFlagBits value )
  {
    switch ( value )
    {
      case MemoryPropertyFlagBits::eDeviceLocal : return "DeviceLocal";
      case MemoryPropertyFlagBits::eHostVisible : return "HostVisible";
      case MemoryPropertyFlagBits::eHostCoherent : return "HostCoherent";
      case MemoryPropertyFlagBits::eHostCached : return "HostCached";
      case MemoryPropertyFlagBits::eLazilyAllocated : return "LazilyAllocated";
      case MemoryPropertyFlagBits::eProtected : return "Protected";
      case MemoryPropertyFlagBits::eDeviceCoherentAMD : return "DeviceCoherentAMD";
      case MemoryPropertyFlagBits::eDeviceUncachedAMD : return "DeviceUncachedAMD";
      default: return "invalid";
    }
  }

  using MemoryPropertyFlags = Flags<MemoryPropertyFlagBits, VkMemoryPropertyFlags>;

  template <> struct FlagTraits<MemoryPropertyFlagBits>
  {
    enum
    {
      allFlags = VkFlags(MemoryPropertyFlagBits::eDeviceLocal) | VkFlags(MemoryPropertyFlagBits::eHostVisible) | VkFlags(MemoryPropertyFlagBits::eHostCoherent) | VkFlags(MemoryPropertyFlagBits::eHostCached) | VkFlags(MemoryPropertyFlagBits::eLazilyAllocated) | VkFlags(MemoryPropertyFlagBits::eProtected) | VkFlags(MemoryPropertyFlagBits::eDeviceCoherentAMD) | VkFlags(MemoryPropertyFlagBits::eDeviceUncachedAMD)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryPropertyFlags operator|( MemoryPropertyFlagBits bit0, MemoryPropertyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryPropertyFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryPropertyFlags operator&( MemoryPropertyFlagBits bit0, MemoryPropertyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryPropertyFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryPropertyFlags operator^( MemoryPropertyFlagBits bit0, MemoryPropertyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryPropertyFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR MemoryPropertyFlags operator~( MemoryPropertyFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( MemoryPropertyFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( MemoryPropertyFlagBits bit0, MemoryPropertyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryPropertyFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( MemoryPropertyFlagBits bit0, MemoryPropertyFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return MemoryPropertyFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( MemoryPropertyFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & MemoryPropertyFlagBits::eDeviceLocal ) result += "DeviceLocal | ";
    if ( value & MemoryPropertyFlagBits::eHostVisible ) result += "HostVisible | ";
    if ( value & MemoryPropertyFlagBits::eHostCoherent ) result += "HostCoherent | ";
    if ( value & MemoryPropertyFlagBits::eHostCached ) result += "HostCached | ";
    if ( value & MemoryPropertyFlagBits::eLazilyAllocated ) result += "LazilyAllocated | ";
    if ( value & MemoryPropertyFlagBits::eProtected ) result += "Protected | ";
    if ( value & MemoryPropertyFlagBits::eDeviceCoherentAMD ) result += "DeviceCoherentAMD | ";
    if ( value & MemoryPropertyFlagBits::eDeviceUncachedAMD ) result += "DeviceUncachedAMD | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

#ifdef VK_USE_PLATFORM_METAL_EXT
  enum class MetalSurfaceCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( MetalSurfaceCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using MetalSurfaceCreateFlagsEXT = Flags<MetalSurfaceCreateFlagBitsEXT, VkMetalSurfaceCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( MetalSurfaceCreateFlagsEXT  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_METAL_EXT*/

  enum class ObjectEntryUsageFlagBitsNVX
  {
    eGraphics = VK_OBJECT_ENTRY_USAGE_GRAPHICS_BIT_NVX,
    eCompute = VK_OBJECT_ENTRY_USAGE_COMPUTE_BIT_NVX
  };

  VULKAN_HPP_INLINE std::string to_string( ObjectEntryUsageFlagBitsNVX value )
  {
    switch ( value )
    {
      case ObjectEntryUsageFlagBitsNVX::eGraphics : return "Graphics";
      case ObjectEntryUsageFlagBitsNVX::eCompute : return "Compute";
      default: return "invalid";
    }
  }

  using ObjectEntryUsageFlagsNVX = Flags<ObjectEntryUsageFlagBitsNVX, VkObjectEntryUsageFlagsNVX>;

  template <> struct FlagTraits<ObjectEntryUsageFlagBitsNVX>
  {
    enum
    {
      allFlags = VkFlags(ObjectEntryUsageFlagBitsNVX::eGraphics) | VkFlags(ObjectEntryUsageFlagBitsNVX::eCompute)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ObjectEntryUsageFlagsNVX operator|( ObjectEntryUsageFlagBitsNVX bit0, ObjectEntryUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ObjectEntryUsageFlagsNVX( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ObjectEntryUsageFlagsNVX operator&( ObjectEntryUsageFlagBitsNVX bit0, ObjectEntryUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ObjectEntryUsageFlagsNVX( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ObjectEntryUsageFlagsNVX operator^( ObjectEntryUsageFlagBitsNVX bit0, ObjectEntryUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ObjectEntryUsageFlagsNVX( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ObjectEntryUsageFlagsNVX operator~( ObjectEntryUsageFlagBitsNVX bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ObjectEntryUsageFlagsNVX( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ObjectEntryUsageFlagBitsNVX bit0, ObjectEntryUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ObjectEntryUsageFlagsNVX( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ObjectEntryUsageFlagBitsNVX bit0, ObjectEntryUsageFlagBitsNVX bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ObjectEntryUsageFlagsNVX( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ObjectEntryUsageFlagsNVX value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ObjectEntryUsageFlagBitsNVX::eGraphics ) result += "Graphics | ";
    if ( value & ObjectEntryUsageFlagBitsNVX::eCompute ) result += "Compute | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class PeerMemoryFeatureFlagBits
  {
    eCopySrc = VK_PEER_MEMORY_FEATURE_COPY_SRC_BIT,
    eCopyDst = VK_PEER_MEMORY_FEATURE_COPY_DST_BIT,
    eGenericSrc = VK_PEER_MEMORY_FEATURE_GENERIC_SRC_BIT,
    eGenericDst = VK_PEER_MEMORY_FEATURE_GENERIC_DST_BIT,
    eCopySrcKHR = VK_PEER_MEMORY_FEATURE_COPY_SRC_BIT_KHR,
    eCopyDstKHR = VK_PEER_MEMORY_FEATURE_COPY_DST_BIT_KHR,
    eGenericSrcKHR = VK_PEER_MEMORY_FEATURE_GENERIC_SRC_BIT_KHR,
    eGenericDstKHR = VK_PEER_MEMORY_FEATURE_GENERIC_DST_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( PeerMemoryFeatureFlagBits value )
  {
    switch ( value )
    {
      case PeerMemoryFeatureFlagBits::eCopySrc : return "CopySrc";
      case PeerMemoryFeatureFlagBits::eCopyDst : return "CopyDst";
      case PeerMemoryFeatureFlagBits::eGenericSrc : return "GenericSrc";
      case PeerMemoryFeatureFlagBits::eGenericDst : return "GenericDst";
      default: return "invalid";
    }
  }

  using PeerMemoryFeatureFlags = Flags<PeerMemoryFeatureFlagBits, VkPeerMemoryFeatureFlags>;

  template <> struct FlagTraits<PeerMemoryFeatureFlagBits>
  {
    enum
    {
      allFlags = VkFlags(PeerMemoryFeatureFlagBits::eCopySrc) | VkFlags(PeerMemoryFeatureFlagBits::eCopyDst) | VkFlags(PeerMemoryFeatureFlagBits::eGenericSrc) | VkFlags(PeerMemoryFeatureFlagBits::eGenericDst)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PeerMemoryFeatureFlags operator|( PeerMemoryFeatureFlagBits bit0, PeerMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PeerMemoryFeatureFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PeerMemoryFeatureFlags operator&( PeerMemoryFeatureFlagBits bit0, PeerMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PeerMemoryFeatureFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PeerMemoryFeatureFlags operator^( PeerMemoryFeatureFlagBits bit0, PeerMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PeerMemoryFeatureFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PeerMemoryFeatureFlags operator~( PeerMemoryFeatureFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( PeerMemoryFeatureFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( PeerMemoryFeatureFlagBits bit0, PeerMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PeerMemoryFeatureFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( PeerMemoryFeatureFlagBits bit0, PeerMemoryFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PeerMemoryFeatureFlags( bit0 ) != bit1;
  }

  using PeerMemoryFeatureFlagsKHR = PeerMemoryFeatureFlags;

  VULKAN_HPP_INLINE std::string to_string( PeerMemoryFeatureFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & PeerMemoryFeatureFlagBits::eCopySrc ) result += "CopySrc | ";
    if ( value & PeerMemoryFeatureFlagBits::eCopyDst ) result += "CopyDst | ";
    if ( value & PeerMemoryFeatureFlagBits::eGenericSrc ) result += "GenericSrc | ";
    if ( value & PeerMemoryFeatureFlagBits::eGenericDst ) result += "GenericDst | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class PipelineCacheCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineCacheCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineCacheCreateFlags = Flags<PipelineCacheCreateFlagBits, VkPipelineCacheCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineCacheCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineColorBlendStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineColorBlendStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineColorBlendStateCreateFlags = Flags<PipelineColorBlendStateCreateFlagBits, VkPipelineColorBlendStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineColorBlendStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineCompilerControlFlagBitsAMD
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineCompilerControlFlagBitsAMD )
  {
    return "(void)";
  }

  using PipelineCompilerControlFlagsAMD = Flags<PipelineCompilerControlFlagBitsAMD, VkPipelineCompilerControlFlagsAMD>;

  VULKAN_HPP_INLINE std::string to_string( PipelineCompilerControlFlagsAMD  )
  {
    return "{}";
  }

  enum class PipelineCoverageModulationStateCreateFlagBitsNV
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineCoverageModulationStateCreateFlagBitsNV )
  {
    return "(void)";
  }

  using PipelineCoverageModulationStateCreateFlagsNV = Flags<PipelineCoverageModulationStateCreateFlagBitsNV, VkPipelineCoverageModulationStateCreateFlagsNV>;

  VULKAN_HPP_INLINE std::string to_string( PipelineCoverageModulationStateCreateFlagsNV  )
  {
    return "{}";
  }

  enum class PipelineCoverageReductionStateCreateFlagBitsNV
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineCoverageReductionStateCreateFlagBitsNV )
  {
    return "(void)";
  }

  using PipelineCoverageReductionStateCreateFlagsNV = Flags<PipelineCoverageReductionStateCreateFlagBitsNV, VkPipelineCoverageReductionStateCreateFlagsNV>;

  VULKAN_HPP_INLINE std::string to_string( PipelineCoverageReductionStateCreateFlagsNV  )
  {
    return "{}";
  }

  enum class PipelineCoverageToColorStateCreateFlagBitsNV
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineCoverageToColorStateCreateFlagBitsNV )
  {
    return "(void)";
  }

  using PipelineCoverageToColorStateCreateFlagsNV = Flags<PipelineCoverageToColorStateCreateFlagBitsNV, VkPipelineCoverageToColorStateCreateFlagsNV>;

  VULKAN_HPP_INLINE std::string to_string( PipelineCoverageToColorStateCreateFlagsNV  )
  {
    return "{}";
  }

  enum class PipelineCreateFlagBits
  {
    eDisableOptimization = VK_PIPELINE_CREATE_DISABLE_OPTIMIZATION_BIT,
    eAllowDerivatives = VK_PIPELINE_CREATE_ALLOW_DERIVATIVES_BIT,
    eDerivative = VK_PIPELINE_CREATE_DERIVATIVE_BIT,
    eViewIndexFromDeviceIndex = VK_PIPELINE_CREATE_VIEW_INDEX_FROM_DEVICE_INDEX_BIT,
    eDispatchBase = VK_PIPELINE_CREATE_DISPATCH_BASE,
    eDeferCompileNV = VK_PIPELINE_CREATE_DEFER_COMPILE_BIT_NV,
    eCaptureStatisticsKHR = VK_PIPELINE_CREATE_CAPTURE_STATISTICS_BIT_KHR,
    eCaptureInternalRepresentationsKHR = VK_PIPELINE_CREATE_CAPTURE_INTERNAL_REPRESENTATIONS_BIT_KHR,
    eViewIndexFromDeviceIndexKHR = VK_PIPELINE_CREATE_VIEW_INDEX_FROM_DEVICE_INDEX_BIT_KHR,
    eDispatchBaseKHR = VK_PIPELINE_CREATE_DISPATCH_BASE_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( PipelineCreateFlagBits value )
  {
    switch ( value )
    {
      case PipelineCreateFlagBits::eDisableOptimization : return "DisableOptimization";
      case PipelineCreateFlagBits::eAllowDerivatives : return "AllowDerivatives";
      case PipelineCreateFlagBits::eDerivative : return "Derivative";
      case PipelineCreateFlagBits::eViewIndexFromDeviceIndex : return "ViewIndexFromDeviceIndex";
      case PipelineCreateFlagBits::eDispatchBase : return "DispatchBase";
      case PipelineCreateFlagBits::eDeferCompileNV : return "DeferCompileNV";
      case PipelineCreateFlagBits::eCaptureStatisticsKHR : return "CaptureStatisticsKHR";
      case PipelineCreateFlagBits::eCaptureInternalRepresentationsKHR : return "CaptureInternalRepresentationsKHR";
      default: return "invalid";
    }
  }

  using PipelineCreateFlags = Flags<PipelineCreateFlagBits, VkPipelineCreateFlags>;

  template <> struct FlagTraits<PipelineCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(PipelineCreateFlagBits::eDisableOptimization) | VkFlags(PipelineCreateFlagBits::eAllowDerivatives) | VkFlags(PipelineCreateFlagBits::eDerivative) | VkFlags(PipelineCreateFlagBits::eViewIndexFromDeviceIndex) | VkFlags(PipelineCreateFlagBits::eDispatchBase) | VkFlags(PipelineCreateFlagBits::eDeferCompileNV) | VkFlags(PipelineCreateFlagBits::eCaptureStatisticsKHR) | VkFlags(PipelineCreateFlagBits::eCaptureInternalRepresentationsKHR)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreateFlags operator|( PipelineCreateFlagBits bit0, PipelineCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreateFlags operator&( PipelineCreateFlagBits bit0, PipelineCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreateFlags operator^( PipelineCreateFlagBits bit0, PipelineCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreateFlags operator~( PipelineCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( PipelineCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( PipelineCreateFlagBits bit0, PipelineCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( PipelineCreateFlagBits bit0, PipelineCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( PipelineCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & PipelineCreateFlagBits::eDisableOptimization ) result += "DisableOptimization | ";
    if ( value & PipelineCreateFlagBits::eAllowDerivatives ) result += "AllowDerivatives | ";
    if ( value & PipelineCreateFlagBits::eDerivative ) result += "Derivative | ";
    if ( value & PipelineCreateFlagBits::eViewIndexFromDeviceIndex ) result += "ViewIndexFromDeviceIndex | ";
    if ( value & PipelineCreateFlagBits::eDispatchBase ) result += "DispatchBase | ";
    if ( value & PipelineCreateFlagBits::eDeferCompileNV ) result += "DeferCompileNV | ";
    if ( value & PipelineCreateFlagBits::eCaptureStatisticsKHR ) result += "CaptureStatisticsKHR | ";
    if ( value & PipelineCreateFlagBits::eCaptureInternalRepresentationsKHR ) result += "CaptureInternalRepresentationsKHR | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class PipelineCreationFeedbackFlagBitsEXT
  {
    eValid = VK_PIPELINE_CREATION_FEEDBACK_VALID_BIT_EXT,
    eApplicationPipelineCacheHit = VK_PIPELINE_CREATION_FEEDBACK_APPLICATION_PIPELINE_CACHE_HIT_BIT_EXT,
    eBasePipelineAcceleration = VK_PIPELINE_CREATION_FEEDBACK_BASE_PIPELINE_ACCELERATION_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( PipelineCreationFeedbackFlagBitsEXT value )
  {
    switch ( value )
    {
      case PipelineCreationFeedbackFlagBitsEXT::eValid : return "Valid";
      case PipelineCreationFeedbackFlagBitsEXT::eApplicationPipelineCacheHit : return "ApplicationPipelineCacheHit";
      case PipelineCreationFeedbackFlagBitsEXT::eBasePipelineAcceleration : return "BasePipelineAcceleration";
      default: return "invalid";
    }
  }

  using PipelineCreationFeedbackFlagsEXT = Flags<PipelineCreationFeedbackFlagBitsEXT, VkPipelineCreationFeedbackFlagsEXT>;

  template <> struct FlagTraits<PipelineCreationFeedbackFlagBitsEXT>
  {
    enum
    {
      allFlags = VkFlags(PipelineCreationFeedbackFlagBitsEXT::eValid) | VkFlags(PipelineCreationFeedbackFlagBitsEXT::eApplicationPipelineCacheHit) | VkFlags(PipelineCreationFeedbackFlagBitsEXT::eBasePipelineAcceleration)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreationFeedbackFlagsEXT operator|( PipelineCreationFeedbackFlagBitsEXT bit0, PipelineCreationFeedbackFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreationFeedbackFlagsEXT( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreationFeedbackFlagsEXT operator&( PipelineCreationFeedbackFlagBitsEXT bit0, PipelineCreationFeedbackFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreationFeedbackFlagsEXT( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreationFeedbackFlagsEXT operator^( PipelineCreationFeedbackFlagBitsEXT bit0, PipelineCreationFeedbackFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreationFeedbackFlagsEXT( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineCreationFeedbackFlagsEXT operator~( PipelineCreationFeedbackFlagBitsEXT bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( PipelineCreationFeedbackFlagsEXT( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( PipelineCreationFeedbackFlagBitsEXT bit0, PipelineCreationFeedbackFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreationFeedbackFlagsEXT( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( PipelineCreationFeedbackFlagBitsEXT bit0, PipelineCreationFeedbackFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineCreationFeedbackFlagsEXT( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( PipelineCreationFeedbackFlagsEXT value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & PipelineCreationFeedbackFlagBitsEXT::eValid ) result += "Valid | ";
    if ( value & PipelineCreationFeedbackFlagBitsEXT::eApplicationPipelineCacheHit ) result += "ApplicationPipelineCacheHit | ";
    if ( value & PipelineCreationFeedbackFlagBitsEXT::eBasePipelineAcceleration ) result += "BasePipelineAcceleration | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class PipelineDepthStencilStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineDepthStencilStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineDepthStencilStateCreateFlags = Flags<PipelineDepthStencilStateCreateFlagBits, VkPipelineDepthStencilStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineDepthStencilStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineDiscardRectangleStateCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineDiscardRectangleStateCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using PipelineDiscardRectangleStateCreateFlagsEXT = Flags<PipelineDiscardRectangleStateCreateFlagBitsEXT, VkPipelineDiscardRectangleStateCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( PipelineDiscardRectangleStateCreateFlagsEXT  )
  {
    return "{}";
  }

  enum class PipelineDynamicStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineDynamicStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineDynamicStateCreateFlags = Flags<PipelineDynamicStateCreateFlagBits, VkPipelineDynamicStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineDynamicStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineInputAssemblyStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineInputAssemblyStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineInputAssemblyStateCreateFlags = Flags<PipelineInputAssemblyStateCreateFlagBits, VkPipelineInputAssemblyStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineInputAssemblyStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineLayoutCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineLayoutCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineLayoutCreateFlags = Flags<PipelineLayoutCreateFlagBits, VkPipelineLayoutCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineLayoutCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineMultisampleStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineMultisampleStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineMultisampleStateCreateFlags = Flags<PipelineMultisampleStateCreateFlagBits, VkPipelineMultisampleStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineMultisampleStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineRasterizationConservativeStateCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationConservativeStateCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using PipelineRasterizationConservativeStateCreateFlagsEXT = Flags<PipelineRasterizationConservativeStateCreateFlagBitsEXT, VkPipelineRasterizationConservativeStateCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationConservativeStateCreateFlagsEXT  )
  {
    return "{}";
  }

  enum class PipelineRasterizationDepthClipStateCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationDepthClipStateCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using PipelineRasterizationDepthClipStateCreateFlagsEXT = Flags<PipelineRasterizationDepthClipStateCreateFlagBitsEXT, VkPipelineRasterizationDepthClipStateCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationDepthClipStateCreateFlagsEXT  )
  {
    return "{}";
  }

  enum class PipelineRasterizationStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineRasterizationStateCreateFlags = Flags<PipelineRasterizationStateCreateFlagBits, VkPipelineRasterizationStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineRasterizationStateStreamCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationStateStreamCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using PipelineRasterizationStateStreamCreateFlagsEXT = Flags<PipelineRasterizationStateStreamCreateFlagBitsEXT, VkPipelineRasterizationStateStreamCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( PipelineRasterizationStateStreamCreateFlagsEXT  )
  {
    return "{}";
  }

  enum class PipelineShaderStageCreateFlagBits
  {
    eAllowVaryingSubgroupSizeEXT = VK_PIPELINE_SHADER_STAGE_CREATE_ALLOW_VARYING_SUBGROUP_SIZE_BIT_EXT,
    eRequireFullSubgroupsEXT = VK_PIPELINE_SHADER_STAGE_CREATE_REQUIRE_FULL_SUBGROUPS_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( PipelineShaderStageCreateFlagBits value )
  {
    switch ( value )
    {
      case PipelineShaderStageCreateFlagBits::eAllowVaryingSubgroupSizeEXT : return "AllowVaryingSubgroupSizeEXT";
      case PipelineShaderStageCreateFlagBits::eRequireFullSubgroupsEXT : return "RequireFullSubgroupsEXT";
      default: return "invalid";
    }
  }

  using PipelineShaderStageCreateFlags = Flags<PipelineShaderStageCreateFlagBits, VkPipelineShaderStageCreateFlags>;

  template <> struct FlagTraits<PipelineShaderStageCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(PipelineShaderStageCreateFlagBits::eAllowVaryingSubgroupSizeEXT) | VkFlags(PipelineShaderStageCreateFlagBits::eRequireFullSubgroupsEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineShaderStageCreateFlags operator|( PipelineShaderStageCreateFlagBits bit0, PipelineShaderStageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineShaderStageCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineShaderStageCreateFlags operator&( PipelineShaderStageCreateFlagBits bit0, PipelineShaderStageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineShaderStageCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineShaderStageCreateFlags operator^( PipelineShaderStageCreateFlagBits bit0, PipelineShaderStageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineShaderStageCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineShaderStageCreateFlags operator~( PipelineShaderStageCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( PipelineShaderStageCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( PipelineShaderStageCreateFlagBits bit0, PipelineShaderStageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineShaderStageCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( PipelineShaderStageCreateFlagBits bit0, PipelineShaderStageCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineShaderStageCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( PipelineShaderStageCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & PipelineShaderStageCreateFlagBits::eAllowVaryingSubgroupSizeEXT ) result += "AllowVaryingSubgroupSizeEXT | ";
    if ( value & PipelineShaderStageCreateFlagBits::eRequireFullSubgroupsEXT ) result += "RequireFullSubgroupsEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class PipelineStageFlagBits
  {
    eTopOfPipe = VK_PIPELINE_STAGE_TOP_OF_PIPE_BIT,
    eDrawIndirect = VK_PIPELINE_STAGE_DRAW_INDIRECT_BIT,
    eVertexInput = VK_PIPELINE_STAGE_VERTEX_INPUT_BIT,
    eVertexShader = VK_PIPELINE_STAGE_VERTEX_SHADER_BIT,
    eTessellationControlShader = VK_PIPELINE_STAGE_TESSELLATION_CONTROL_SHADER_BIT,
    eTessellationEvaluationShader = VK_PIPELINE_STAGE_TESSELLATION_EVALUATION_SHADER_BIT,
    eGeometryShader = VK_PIPELINE_STAGE_GEOMETRY_SHADER_BIT,
    eFragmentShader = VK_PIPELINE_STAGE_FRAGMENT_SHADER_BIT,
    eEarlyFragmentTests = VK_PIPELINE_STAGE_EARLY_FRAGMENT_TESTS_BIT,
    eLateFragmentTests = VK_PIPELINE_STAGE_LATE_FRAGMENT_TESTS_BIT,
    eColorAttachmentOutput = VK_PIPELINE_STAGE_COLOR_ATTACHMENT_OUTPUT_BIT,
    eComputeShader = VK_PIPELINE_STAGE_COMPUTE_SHADER_BIT,
    eTransfer = VK_PIPELINE_STAGE_TRANSFER_BIT,
    eBottomOfPipe = VK_PIPELINE_STAGE_BOTTOM_OF_PIPE_BIT,
    eHost = VK_PIPELINE_STAGE_HOST_BIT,
    eAllGraphics = VK_PIPELINE_STAGE_ALL_GRAPHICS_BIT,
    eAllCommands = VK_PIPELINE_STAGE_ALL_COMMANDS_BIT,
    eTransformFeedbackEXT = VK_PIPELINE_STAGE_TRANSFORM_FEEDBACK_BIT_EXT,
    eConditionalRenderingEXT = VK_PIPELINE_STAGE_CONDITIONAL_RENDERING_BIT_EXT,
    eCommandProcessNVX = VK_PIPELINE_STAGE_COMMAND_PROCESS_BIT_NVX,
    eShadingRateImageNV = VK_PIPELINE_STAGE_SHADING_RATE_IMAGE_BIT_NV,
    eRayTracingShaderNV = VK_PIPELINE_STAGE_RAY_TRACING_SHADER_BIT_NV,
    eAccelerationStructureBuildNV = VK_PIPELINE_STAGE_ACCELERATION_STRUCTURE_BUILD_BIT_NV,
    eTaskShaderNV = VK_PIPELINE_STAGE_TASK_SHADER_BIT_NV,
    eMeshShaderNV = VK_PIPELINE_STAGE_MESH_SHADER_BIT_NV,
    eFragmentDensityProcessEXT = VK_PIPELINE_STAGE_FRAGMENT_DENSITY_PROCESS_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( PipelineStageFlagBits value )
  {
    switch ( value )
    {
      case PipelineStageFlagBits::eTopOfPipe : return "TopOfPipe";
      case PipelineStageFlagBits::eDrawIndirect : return "DrawIndirect";
      case PipelineStageFlagBits::eVertexInput : return "VertexInput";
      case PipelineStageFlagBits::eVertexShader : return "VertexShader";
      case PipelineStageFlagBits::eTessellationControlShader : return "TessellationControlShader";
      case PipelineStageFlagBits::eTessellationEvaluationShader : return "TessellationEvaluationShader";
      case PipelineStageFlagBits::eGeometryShader : return "GeometryShader";
      case PipelineStageFlagBits::eFragmentShader : return "FragmentShader";
      case PipelineStageFlagBits::eEarlyFragmentTests : return "EarlyFragmentTests";
      case PipelineStageFlagBits::eLateFragmentTests : return "LateFragmentTests";
      case PipelineStageFlagBits::eColorAttachmentOutput : return "ColorAttachmentOutput";
      case PipelineStageFlagBits::eComputeShader : return "ComputeShader";
      case PipelineStageFlagBits::eTransfer : return "Transfer";
      case PipelineStageFlagBits::eBottomOfPipe : return "BottomOfPipe";
      case PipelineStageFlagBits::eHost : return "Host";
      case PipelineStageFlagBits::eAllGraphics : return "AllGraphics";
      case PipelineStageFlagBits::eAllCommands : return "AllCommands";
      case PipelineStageFlagBits::eTransformFeedbackEXT : return "TransformFeedbackEXT";
      case PipelineStageFlagBits::eConditionalRenderingEXT : return "ConditionalRenderingEXT";
      case PipelineStageFlagBits::eCommandProcessNVX : return "CommandProcessNVX";
      case PipelineStageFlagBits::eShadingRateImageNV : return "ShadingRateImageNV";
      case PipelineStageFlagBits::eRayTracingShaderNV : return "RayTracingShaderNV";
      case PipelineStageFlagBits::eAccelerationStructureBuildNV : return "AccelerationStructureBuildNV";
      case PipelineStageFlagBits::eTaskShaderNV : return "TaskShaderNV";
      case PipelineStageFlagBits::eMeshShaderNV : return "MeshShaderNV";
      case PipelineStageFlagBits::eFragmentDensityProcessEXT : return "FragmentDensityProcessEXT";
      default: return "invalid";
    }
  }

  using PipelineStageFlags = Flags<PipelineStageFlagBits, VkPipelineStageFlags>;

  template <> struct FlagTraits<PipelineStageFlagBits>
  {
    enum
    {
      allFlags = VkFlags(PipelineStageFlagBits::eTopOfPipe) | VkFlags(PipelineStageFlagBits::eDrawIndirect) | VkFlags(PipelineStageFlagBits::eVertexInput) | VkFlags(PipelineStageFlagBits::eVertexShader) | VkFlags(PipelineStageFlagBits::eTessellationControlShader) | VkFlags(PipelineStageFlagBits::eTessellationEvaluationShader) | VkFlags(PipelineStageFlagBits::eGeometryShader) | VkFlags(PipelineStageFlagBits::eFragmentShader) | VkFlags(PipelineStageFlagBits::eEarlyFragmentTests) | VkFlags(PipelineStageFlagBits::eLateFragmentTests) | VkFlags(PipelineStageFlagBits::eColorAttachmentOutput) | VkFlags(PipelineStageFlagBits::eComputeShader) | VkFlags(PipelineStageFlagBits::eTransfer) | VkFlags(PipelineStageFlagBits::eBottomOfPipe) | VkFlags(PipelineStageFlagBits::eHost) | VkFlags(PipelineStageFlagBits::eAllGraphics) | VkFlags(PipelineStageFlagBits::eAllCommands) | VkFlags(PipelineStageFlagBits::eTransformFeedbackEXT) | VkFlags(PipelineStageFlagBits::eConditionalRenderingEXT) | VkFlags(PipelineStageFlagBits::eCommandProcessNVX) | VkFlags(PipelineStageFlagBits::eShadingRateImageNV) | VkFlags(PipelineStageFlagBits::eRayTracingShaderNV) | VkFlags(PipelineStageFlagBits::eAccelerationStructureBuildNV) | VkFlags(PipelineStageFlagBits::eTaskShaderNV) | VkFlags(PipelineStageFlagBits::eMeshShaderNV) | VkFlags(PipelineStageFlagBits::eFragmentDensityProcessEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineStageFlags operator|( PipelineStageFlagBits bit0, PipelineStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineStageFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineStageFlags operator&( PipelineStageFlagBits bit0, PipelineStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineStageFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineStageFlags operator^( PipelineStageFlagBits bit0, PipelineStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineStageFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR PipelineStageFlags operator~( PipelineStageFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( PipelineStageFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( PipelineStageFlagBits bit0, PipelineStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineStageFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( PipelineStageFlagBits bit0, PipelineStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return PipelineStageFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( PipelineStageFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & PipelineStageFlagBits::eTopOfPipe ) result += "TopOfPipe | ";
    if ( value & PipelineStageFlagBits::eDrawIndirect ) result += "DrawIndirect | ";
    if ( value & PipelineStageFlagBits::eVertexInput ) result += "VertexInput | ";
    if ( value & PipelineStageFlagBits::eVertexShader ) result += "VertexShader | ";
    if ( value & PipelineStageFlagBits::eTessellationControlShader ) result += "TessellationControlShader | ";
    if ( value & PipelineStageFlagBits::eTessellationEvaluationShader ) result += "TessellationEvaluationShader | ";
    if ( value & PipelineStageFlagBits::eGeometryShader ) result += "GeometryShader | ";
    if ( value & PipelineStageFlagBits::eFragmentShader ) result += "FragmentShader | ";
    if ( value & PipelineStageFlagBits::eEarlyFragmentTests ) result += "EarlyFragmentTests | ";
    if ( value & PipelineStageFlagBits::eLateFragmentTests ) result += "LateFragmentTests | ";
    if ( value & PipelineStageFlagBits::eColorAttachmentOutput ) result += "ColorAttachmentOutput | ";
    if ( value & PipelineStageFlagBits::eComputeShader ) result += "ComputeShader | ";
    if ( value & PipelineStageFlagBits::eTransfer ) result += "Transfer | ";
    if ( value & PipelineStageFlagBits::eBottomOfPipe ) result += "BottomOfPipe | ";
    if ( value & PipelineStageFlagBits::eHost ) result += "Host | ";
    if ( value & PipelineStageFlagBits::eAllGraphics ) result += "AllGraphics | ";
    if ( value & PipelineStageFlagBits::eAllCommands ) result += "AllCommands | ";
    if ( value & PipelineStageFlagBits::eTransformFeedbackEXT ) result += "TransformFeedbackEXT | ";
    if ( value & PipelineStageFlagBits::eConditionalRenderingEXT ) result += "ConditionalRenderingEXT | ";
    if ( value & PipelineStageFlagBits::eCommandProcessNVX ) result += "CommandProcessNVX | ";
    if ( value & PipelineStageFlagBits::eShadingRateImageNV ) result += "ShadingRateImageNV | ";
    if ( value & PipelineStageFlagBits::eRayTracingShaderNV ) result += "RayTracingShaderNV | ";
    if ( value & PipelineStageFlagBits::eAccelerationStructureBuildNV ) result += "AccelerationStructureBuildNV | ";
    if ( value & PipelineStageFlagBits::eTaskShaderNV ) result += "TaskShaderNV | ";
    if ( value & PipelineStageFlagBits::eMeshShaderNV ) result += "MeshShaderNV | ";
    if ( value & PipelineStageFlagBits::eFragmentDensityProcessEXT ) result += "FragmentDensityProcessEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class PipelineTessellationStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineTessellationStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineTessellationStateCreateFlags = Flags<PipelineTessellationStateCreateFlagBits, VkPipelineTessellationStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineTessellationStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineVertexInputStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineVertexInputStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineVertexInputStateCreateFlags = Flags<PipelineVertexInputStateCreateFlagBits, VkPipelineVertexInputStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineVertexInputStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineViewportStateCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineViewportStateCreateFlagBits )
  {
    return "(void)";
  }

  using PipelineViewportStateCreateFlags = Flags<PipelineViewportStateCreateFlagBits, VkPipelineViewportStateCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( PipelineViewportStateCreateFlags  )
  {
    return "{}";
  }

  enum class PipelineViewportSwizzleStateCreateFlagBitsNV
  {};

  VULKAN_HPP_INLINE std::string to_string( PipelineViewportSwizzleStateCreateFlagBitsNV )
  {
    return "(void)";
  }

  using PipelineViewportSwizzleStateCreateFlagsNV = Flags<PipelineViewportSwizzleStateCreateFlagBitsNV, VkPipelineViewportSwizzleStateCreateFlagsNV>;

  VULKAN_HPP_INLINE std::string to_string( PipelineViewportSwizzleStateCreateFlagsNV  )
  {
    return "{}";
  }

  enum class QueryControlFlagBits
  {
    ePrecise = VK_QUERY_CONTROL_PRECISE_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( QueryControlFlagBits value )
  {
    switch ( value )
    {
      case QueryControlFlagBits::ePrecise : return "Precise";
      default: return "invalid";
    }
  }

  using QueryControlFlags = Flags<QueryControlFlagBits, VkQueryControlFlags>;

  template <> struct FlagTraits<QueryControlFlagBits>
  {
    enum
    {
      allFlags = VkFlags(QueryControlFlagBits::ePrecise)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryControlFlags operator|( QueryControlFlagBits bit0, QueryControlFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryControlFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryControlFlags operator&( QueryControlFlagBits bit0, QueryControlFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryControlFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryControlFlags operator^( QueryControlFlagBits bit0, QueryControlFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryControlFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryControlFlags operator~( QueryControlFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( QueryControlFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( QueryControlFlagBits bit0, QueryControlFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryControlFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( QueryControlFlagBits bit0, QueryControlFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryControlFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( QueryControlFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & QueryControlFlagBits::ePrecise ) result += "Precise | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class QueryPipelineStatisticFlagBits
  {
    eInputAssemblyVertices = VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_VERTICES_BIT,
    eInputAssemblyPrimitives = VK_QUERY_PIPELINE_STATISTIC_INPUT_ASSEMBLY_PRIMITIVES_BIT,
    eVertexShaderInvocations = VK_QUERY_PIPELINE_STATISTIC_VERTEX_SHADER_INVOCATIONS_BIT,
    eGeometryShaderInvocations = VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_INVOCATIONS_BIT,
    eGeometryShaderPrimitives = VK_QUERY_PIPELINE_STATISTIC_GEOMETRY_SHADER_PRIMITIVES_BIT,
    eClippingInvocations = VK_QUERY_PIPELINE_STATISTIC_CLIPPING_INVOCATIONS_BIT,
    eClippingPrimitives = VK_QUERY_PIPELINE_STATISTIC_CLIPPING_PRIMITIVES_BIT,
    eFragmentShaderInvocations = VK_QUERY_PIPELINE_STATISTIC_FRAGMENT_SHADER_INVOCATIONS_BIT,
    eTessellationControlShaderPatches = VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_CONTROL_SHADER_PATCHES_BIT,
    eTessellationEvaluationShaderInvocations = VK_QUERY_PIPELINE_STATISTIC_TESSELLATION_EVALUATION_SHADER_INVOCATIONS_BIT,
    eComputeShaderInvocations = VK_QUERY_PIPELINE_STATISTIC_COMPUTE_SHADER_INVOCATIONS_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( QueryPipelineStatisticFlagBits value )
  {
    switch ( value )
    {
      case QueryPipelineStatisticFlagBits::eInputAssemblyVertices : return "InputAssemblyVertices";
      case QueryPipelineStatisticFlagBits::eInputAssemblyPrimitives : return "InputAssemblyPrimitives";
      case QueryPipelineStatisticFlagBits::eVertexShaderInvocations : return "VertexShaderInvocations";
      case QueryPipelineStatisticFlagBits::eGeometryShaderInvocations : return "GeometryShaderInvocations";
      case QueryPipelineStatisticFlagBits::eGeometryShaderPrimitives : return "GeometryShaderPrimitives";
      case QueryPipelineStatisticFlagBits::eClippingInvocations : return "ClippingInvocations";
      case QueryPipelineStatisticFlagBits::eClippingPrimitives : return "ClippingPrimitives";
      case QueryPipelineStatisticFlagBits::eFragmentShaderInvocations : return "FragmentShaderInvocations";
      case QueryPipelineStatisticFlagBits::eTessellationControlShaderPatches : return "TessellationControlShaderPatches";
      case QueryPipelineStatisticFlagBits::eTessellationEvaluationShaderInvocations : return "TessellationEvaluationShaderInvocations";
      case QueryPipelineStatisticFlagBits::eComputeShaderInvocations : return "ComputeShaderInvocations";
      default: return "invalid";
    }
  }

  using QueryPipelineStatisticFlags = Flags<QueryPipelineStatisticFlagBits, VkQueryPipelineStatisticFlags>;

  template <> struct FlagTraits<QueryPipelineStatisticFlagBits>
  {
    enum
    {
      allFlags = VkFlags(QueryPipelineStatisticFlagBits::eInputAssemblyVertices) | VkFlags(QueryPipelineStatisticFlagBits::eInputAssemblyPrimitives) | VkFlags(QueryPipelineStatisticFlagBits::eVertexShaderInvocations) | VkFlags(QueryPipelineStatisticFlagBits::eGeometryShaderInvocations) | VkFlags(QueryPipelineStatisticFlagBits::eGeometryShaderPrimitives) | VkFlags(QueryPipelineStatisticFlagBits::eClippingInvocations) | VkFlags(QueryPipelineStatisticFlagBits::eClippingPrimitives) | VkFlags(QueryPipelineStatisticFlagBits::eFragmentShaderInvocations) | VkFlags(QueryPipelineStatisticFlagBits::eTessellationControlShaderPatches) | VkFlags(QueryPipelineStatisticFlagBits::eTessellationEvaluationShaderInvocations) | VkFlags(QueryPipelineStatisticFlagBits::eComputeShaderInvocations)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryPipelineStatisticFlags operator|( QueryPipelineStatisticFlagBits bit0, QueryPipelineStatisticFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryPipelineStatisticFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryPipelineStatisticFlags operator&( QueryPipelineStatisticFlagBits bit0, QueryPipelineStatisticFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryPipelineStatisticFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryPipelineStatisticFlags operator^( QueryPipelineStatisticFlagBits bit0, QueryPipelineStatisticFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryPipelineStatisticFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryPipelineStatisticFlags operator~( QueryPipelineStatisticFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( QueryPipelineStatisticFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( QueryPipelineStatisticFlagBits bit0, QueryPipelineStatisticFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryPipelineStatisticFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( QueryPipelineStatisticFlagBits bit0, QueryPipelineStatisticFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryPipelineStatisticFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( QueryPipelineStatisticFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & QueryPipelineStatisticFlagBits::eInputAssemblyVertices ) result += "InputAssemblyVertices | ";
    if ( value & QueryPipelineStatisticFlagBits::eInputAssemblyPrimitives ) result += "InputAssemblyPrimitives | ";
    if ( value & QueryPipelineStatisticFlagBits::eVertexShaderInvocations ) result += "VertexShaderInvocations | ";
    if ( value & QueryPipelineStatisticFlagBits::eGeometryShaderInvocations ) result += "GeometryShaderInvocations | ";
    if ( value & QueryPipelineStatisticFlagBits::eGeometryShaderPrimitives ) result += "GeometryShaderPrimitives | ";
    if ( value & QueryPipelineStatisticFlagBits::eClippingInvocations ) result += "ClippingInvocations | ";
    if ( value & QueryPipelineStatisticFlagBits::eClippingPrimitives ) result += "ClippingPrimitives | ";
    if ( value & QueryPipelineStatisticFlagBits::eFragmentShaderInvocations ) result += "FragmentShaderInvocations | ";
    if ( value & QueryPipelineStatisticFlagBits::eTessellationControlShaderPatches ) result += "TessellationControlShaderPatches | ";
    if ( value & QueryPipelineStatisticFlagBits::eTessellationEvaluationShaderInvocations ) result += "TessellationEvaluationShaderInvocations | ";
    if ( value & QueryPipelineStatisticFlagBits::eComputeShaderInvocations ) result += "ComputeShaderInvocations | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class QueryPoolCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( QueryPoolCreateFlagBits )
  {
    return "(void)";
  }

  using QueryPoolCreateFlags = Flags<QueryPoolCreateFlagBits, VkQueryPoolCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( QueryPoolCreateFlags  )
  {
    return "{}";
  }

  enum class QueryResultFlagBits
  {
    e64 = VK_QUERY_RESULT_64_BIT,
    eWait = VK_QUERY_RESULT_WAIT_BIT,
    eWithAvailability = VK_QUERY_RESULT_WITH_AVAILABILITY_BIT,
    ePartial = VK_QUERY_RESULT_PARTIAL_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( QueryResultFlagBits value )
  {
    switch ( value )
    {
      case QueryResultFlagBits::e64 : return "64";
      case QueryResultFlagBits::eWait : return "Wait";
      case QueryResultFlagBits::eWithAvailability : return "WithAvailability";
      case QueryResultFlagBits::ePartial : return "Partial";
      default: return "invalid";
    }
  }

  using QueryResultFlags = Flags<QueryResultFlagBits, VkQueryResultFlags>;

  template <> struct FlagTraits<QueryResultFlagBits>
  {
    enum
    {
      allFlags = VkFlags(QueryResultFlagBits::e64) | VkFlags(QueryResultFlagBits::eWait) | VkFlags(QueryResultFlagBits::eWithAvailability) | VkFlags(QueryResultFlagBits::ePartial)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryResultFlags operator|( QueryResultFlagBits bit0, QueryResultFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryResultFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryResultFlags operator&( QueryResultFlagBits bit0, QueryResultFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryResultFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryResultFlags operator^( QueryResultFlagBits bit0, QueryResultFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryResultFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueryResultFlags operator~( QueryResultFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( QueryResultFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( QueryResultFlagBits bit0, QueryResultFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryResultFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( QueryResultFlagBits bit0, QueryResultFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueryResultFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( QueryResultFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & QueryResultFlagBits::e64 ) result += "64 | ";
    if ( value & QueryResultFlagBits::eWait ) result += "Wait | ";
    if ( value & QueryResultFlagBits::eWithAvailability ) result += "WithAvailability | ";
    if ( value & QueryResultFlagBits::ePartial ) result += "Partial | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class QueueFlagBits
  {
    eGraphics = VK_QUEUE_GRAPHICS_BIT,
    eCompute = VK_QUEUE_COMPUTE_BIT,
    eTransfer = VK_QUEUE_TRANSFER_BIT,
    eSparseBinding = VK_QUEUE_SPARSE_BINDING_BIT,
    eProtected = VK_QUEUE_PROTECTED_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( QueueFlagBits value )
  {
    switch ( value )
    {
      case QueueFlagBits::eGraphics : return "Graphics";
      case QueueFlagBits::eCompute : return "Compute";
      case QueueFlagBits::eTransfer : return "Transfer";
      case QueueFlagBits::eSparseBinding : return "SparseBinding";
      case QueueFlagBits::eProtected : return "Protected";
      default: return "invalid";
    }
  }

  using QueueFlags = Flags<QueueFlagBits, VkQueueFlags>;

  template <> struct FlagTraits<QueueFlagBits>
  {
    enum
    {
      allFlags = VkFlags(QueueFlagBits::eGraphics) | VkFlags(QueueFlagBits::eCompute) | VkFlags(QueueFlagBits::eTransfer) | VkFlags(QueueFlagBits::eSparseBinding) | VkFlags(QueueFlagBits::eProtected)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueueFlags operator|( QueueFlagBits bit0, QueueFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueueFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueueFlags operator&( QueueFlagBits bit0, QueueFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueueFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueueFlags operator^( QueueFlagBits bit0, QueueFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueueFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR QueueFlags operator~( QueueFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( QueueFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( QueueFlagBits bit0, QueueFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueueFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( QueueFlagBits bit0, QueueFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return QueueFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( QueueFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & QueueFlagBits::eGraphics ) result += "Graphics | ";
    if ( value & QueueFlagBits::eCompute ) result += "Compute | ";
    if ( value & QueueFlagBits::eTransfer ) result += "Transfer | ";
    if ( value & QueueFlagBits::eSparseBinding ) result += "SparseBinding | ";
    if ( value & QueueFlagBits::eProtected ) result += "Protected | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class RenderPassCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( RenderPassCreateFlagBits )
  {
    return "(void)";
  }

  using RenderPassCreateFlags = Flags<RenderPassCreateFlagBits, VkRenderPassCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( RenderPassCreateFlags  )
  {
    return "{}";
  }

  enum class ResolveModeFlagBitsKHR
  {
    eNone = VK_RESOLVE_MODE_NONE_KHR,
    eSampleZero = VK_RESOLVE_MODE_SAMPLE_ZERO_BIT_KHR,
    eAverage = VK_RESOLVE_MODE_AVERAGE_BIT_KHR,
    eMin = VK_RESOLVE_MODE_MIN_BIT_KHR,
    eMax = VK_RESOLVE_MODE_MAX_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( ResolveModeFlagBitsKHR value )
  {
    switch ( value )
    {
      case ResolveModeFlagBitsKHR::eNone : return "None";
      case ResolveModeFlagBitsKHR::eSampleZero : return "SampleZero";
      case ResolveModeFlagBitsKHR::eAverage : return "Average";
      case ResolveModeFlagBitsKHR::eMin : return "Min";
      case ResolveModeFlagBitsKHR::eMax : return "Max";
      default: return "invalid";
    }
  }

  using ResolveModeFlagsKHR = Flags<ResolveModeFlagBitsKHR, VkResolveModeFlagsKHR>;

  template <> struct FlagTraits<ResolveModeFlagBitsKHR>
  {
    enum
    {
      allFlags = VkFlags(ResolveModeFlagBitsKHR::eNone) | VkFlags(ResolveModeFlagBitsKHR::eSampleZero) | VkFlags(ResolveModeFlagBitsKHR::eAverage) | VkFlags(ResolveModeFlagBitsKHR::eMin) | VkFlags(ResolveModeFlagBitsKHR::eMax)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ResolveModeFlagsKHR operator|( ResolveModeFlagBitsKHR bit0, ResolveModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ResolveModeFlagsKHR( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ResolveModeFlagsKHR operator&( ResolveModeFlagBitsKHR bit0, ResolveModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ResolveModeFlagsKHR( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ResolveModeFlagsKHR operator^( ResolveModeFlagBitsKHR bit0, ResolveModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ResolveModeFlagsKHR( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ResolveModeFlagsKHR operator~( ResolveModeFlagBitsKHR bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ResolveModeFlagsKHR( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ResolveModeFlagBitsKHR bit0, ResolveModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ResolveModeFlagsKHR( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ResolveModeFlagBitsKHR bit0, ResolveModeFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ResolveModeFlagsKHR( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ResolveModeFlagsKHR value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ResolveModeFlagBitsKHR::eSampleZero ) result += "SampleZero | ";
    if ( value & ResolveModeFlagBitsKHR::eAverage ) result += "Average | ";
    if ( value & ResolveModeFlagBitsKHR::eMin ) result += "Min | ";
    if ( value & ResolveModeFlagBitsKHR::eMax ) result += "Max | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SampleCountFlagBits
  {
    e1 = VK_SAMPLE_COUNT_1_BIT,
    e2 = VK_SAMPLE_COUNT_2_BIT,
    e4 = VK_SAMPLE_COUNT_4_BIT,
    e8 = VK_SAMPLE_COUNT_8_BIT,
    e16 = VK_SAMPLE_COUNT_16_BIT,
    e32 = VK_SAMPLE_COUNT_32_BIT,
    e64 = VK_SAMPLE_COUNT_64_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( SampleCountFlagBits value )
  {
    switch ( value )
    {
      case SampleCountFlagBits::e1 : return "1";
      case SampleCountFlagBits::e2 : return "2";
      case SampleCountFlagBits::e4 : return "4";
      case SampleCountFlagBits::e8 : return "8";
      case SampleCountFlagBits::e16 : return "16";
      case SampleCountFlagBits::e32 : return "32";
      case SampleCountFlagBits::e64 : return "64";
      default: return "invalid";
    }
  }

  using SampleCountFlags = Flags<SampleCountFlagBits, VkSampleCountFlags>;

  template <> struct FlagTraits<SampleCountFlagBits>
  {
    enum
    {
      allFlags = VkFlags(SampleCountFlagBits::e1) | VkFlags(SampleCountFlagBits::e2) | VkFlags(SampleCountFlagBits::e4) | VkFlags(SampleCountFlagBits::e8) | VkFlags(SampleCountFlagBits::e16) | VkFlags(SampleCountFlagBits::e32) | VkFlags(SampleCountFlagBits::e64)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SampleCountFlags operator|( SampleCountFlagBits bit0, SampleCountFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SampleCountFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SampleCountFlags operator&( SampleCountFlagBits bit0, SampleCountFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SampleCountFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SampleCountFlags operator^( SampleCountFlagBits bit0, SampleCountFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SampleCountFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SampleCountFlags operator~( SampleCountFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SampleCountFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SampleCountFlagBits bit0, SampleCountFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SampleCountFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SampleCountFlagBits bit0, SampleCountFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SampleCountFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SampleCountFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SampleCountFlagBits::e1 ) result += "1 | ";
    if ( value & SampleCountFlagBits::e2 ) result += "2 | ";
    if ( value & SampleCountFlagBits::e4 ) result += "4 | ";
    if ( value & SampleCountFlagBits::e8 ) result += "8 | ";
    if ( value & SampleCountFlagBits::e16 ) result += "16 | ";
    if ( value & SampleCountFlagBits::e32 ) result += "32 | ";
    if ( value & SampleCountFlagBits::e64 ) result += "64 | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SamplerCreateFlagBits
  {
    eSubsampledEXT = VK_SAMPLER_CREATE_SUBSAMPLED_BIT_EXT,
    eSubsampledCoarseReconstructionEXT = VK_SAMPLER_CREATE_SUBSAMPLED_COARSE_RECONSTRUCTION_BIT_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( SamplerCreateFlagBits value )
  {
    switch ( value )
    {
      case SamplerCreateFlagBits::eSubsampledEXT : return "SubsampledEXT";
      case SamplerCreateFlagBits::eSubsampledCoarseReconstructionEXT : return "SubsampledCoarseReconstructionEXT";
      default: return "invalid";
    }
  }

  using SamplerCreateFlags = Flags<SamplerCreateFlagBits, VkSamplerCreateFlags>;

  template <> struct FlagTraits<SamplerCreateFlagBits>
  {
    enum
    {
      allFlags = VkFlags(SamplerCreateFlagBits::eSubsampledEXT) | VkFlags(SamplerCreateFlagBits::eSubsampledCoarseReconstructionEXT)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SamplerCreateFlags operator|( SamplerCreateFlagBits bit0, SamplerCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SamplerCreateFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SamplerCreateFlags operator&( SamplerCreateFlagBits bit0, SamplerCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SamplerCreateFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SamplerCreateFlags operator^( SamplerCreateFlagBits bit0, SamplerCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SamplerCreateFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SamplerCreateFlags operator~( SamplerCreateFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SamplerCreateFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SamplerCreateFlagBits bit0, SamplerCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SamplerCreateFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SamplerCreateFlagBits bit0, SamplerCreateFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SamplerCreateFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SamplerCreateFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SamplerCreateFlagBits::eSubsampledEXT ) result += "SubsampledEXT | ";
    if ( value & SamplerCreateFlagBits::eSubsampledCoarseReconstructionEXT ) result += "SubsampledCoarseReconstructionEXT | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SemaphoreCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( SemaphoreCreateFlagBits )
  {
    return "(void)";
  }

  using SemaphoreCreateFlags = Flags<SemaphoreCreateFlagBits, VkSemaphoreCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( SemaphoreCreateFlags  )
  {
    return "{}";
  }

  enum class SemaphoreImportFlagBits
  {
    eTemporary = VK_SEMAPHORE_IMPORT_TEMPORARY_BIT,
    eTemporaryKHR = VK_SEMAPHORE_IMPORT_TEMPORARY_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SemaphoreImportFlagBits value )
  {
    switch ( value )
    {
      case SemaphoreImportFlagBits::eTemporary : return "Temporary";
      default: return "invalid";
    }
  }

  using SemaphoreImportFlags = Flags<SemaphoreImportFlagBits, VkSemaphoreImportFlags>;

  template <> struct FlagTraits<SemaphoreImportFlagBits>
  {
    enum
    {
      allFlags = VkFlags(SemaphoreImportFlagBits::eTemporary)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreImportFlags operator|( SemaphoreImportFlagBits bit0, SemaphoreImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreImportFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreImportFlags operator&( SemaphoreImportFlagBits bit0, SemaphoreImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreImportFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreImportFlags operator^( SemaphoreImportFlagBits bit0, SemaphoreImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreImportFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreImportFlags operator~( SemaphoreImportFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SemaphoreImportFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SemaphoreImportFlagBits bit0, SemaphoreImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreImportFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SemaphoreImportFlagBits bit0, SemaphoreImportFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreImportFlags( bit0 ) != bit1;
  }

  using SemaphoreImportFlagsKHR = SemaphoreImportFlags;

  VULKAN_HPP_INLINE std::string to_string( SemaphoreImportFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SemaphoreImportFlagBits::eTemporary ) result += "Temporary | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SemaphoreWaitFlagBitsKHR
  {
    eAny = VK_SEMAPHORE_WAIT_ANY_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SemaphoreWaitFlagBitsKHR value )
  {
    switch ( value )
    {
      case SemaphoreWaitFlagBitsKHR::eAny : return "Any";
      default: return "invalid";
    }
  }

  using SemaphoreWaitFlagsKHR = Flags<SemaphoreWaitFlagBitsKHR, VkSemaphoreWaitFlagsKHR>;

  template <> struct FlagTraits<SemaphoreWaitFlagBitsKHR>
  {
    enum
    {
      allFlags = VkFlags(SemaphoreWaitFlagBitsKHR::eAny)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreWaitFlagsKHR operator|( SemaphoreWaitFlagBitsKHR bit0, SemaphoreWaitFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreWaitFlagsKHR( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreWaitFlagsKHR operator&( SemaphoreWaitFlagBitsKHR bit0, SemaphoreWaitFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreWaitFlagsKHR( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreWaitFlagsKHR operator^( SemaphoreWaitFlagBitsKHR bit0, SemaphoreWaitFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreWaitFlagsKHR( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SemaphoreWaitFlagsKHR operator~( SemaphoreWaitFlagBitsKHR bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SemaphoreWaitFlagsKHR( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SemaphoreWaitFlagBitsKHR bit0, SemaphoreWaitFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreWaitFlagsKHR( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SemaphoreWaitFlagBitsKHR bit0, SemaphoreWaitFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SemaphoreWaitFlagsKHR( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SemaphoreWaitFlagsKHR value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SemaphoreWaitFlagBitsKHR::eAny ) result += "Any | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ShaderCorePropertiesFlagBitsAMD
  {};

  VULKAN_HPP_INLINE std::string to_string( ShaderCorePropertiesFlagBitsAMD )
  {
    return "(void)";
  }

  using ShaderCorePropertiesFlagsAMD = Flags<ShaderCorePropertiesFlagBitsAMD, VkShaderCorePropertiesFlagsAMD>;

  VULKAN_HPP_INLINE std::string to_string( ShaderCorePropertiesFlagsAMD  )
  {
    return "{}";
  }

  enum class ShaderModuleCreateFlagBits
  {};

  VULKAN_HPP_INLINE std::string to_string( ShaderModuleCreateFlagBits )
  {
    return "(void)";
  }

  using ShaderModuleCreateFlags = Flags<ShaderModuleCreateFlagBits, VkShaderModuleCreateFlags>;

  VULKAN_HPP_INLINE std::string to_string( ShaderModuleCreateFlags  )
  {
    return "{}";
  }

  enum class ShaderStageFlagBits
  {
    eVertex = VK_SHADER_STAGE_VERTEX_BIT,
    eTessellationControl = VK_SHADER_STAGE_TESSELLATION_CONTROL_BIT,
    eTessellationEvaluation = VK_SHADER_STAGE_TESSELLATION_EVALUATION_BIT,
    eGeometry = VK_SHADER_STAGE_GEOMETRY_BIT,
    eFragment = VK_SHADER_STAGE_FRAGMENT_BIT,
    eCompute = VK_SHADER_STAGE_COMPUTE_BIT,
    eAllGraphics = VK_SHADER_STAGE_ALL_GRAPHICS,
    eAll = VK_SHADER_STAGE_ALL,
    eRaygenNV = VK_SHADER_STAGE_RAYGEN_BIT_NV,
    eAnyHitNV = VK_SHADER_STAGE_ANY_HIT_BIT_NV,
    eClosestHitNV = VK_SHADER_STAGE_CLOSEST_HIT_BIT_NV,
    eMissNV = VK_SHADER_STAGE_MISS_BIT_NV,
    eIntersectionNV = VK_SHADER_STAGE_INTERSECTION_BIT_NV,
    eCallableNV = VK_SHADER_STAGE_CALLABLE_BIT_NV,
    eTaskNV = VK_SHADER_STAGE_TASK_BIT_NV,
    eMeshNV = VK_SHADER_STAGE_MESH_BIT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( ShaderStageFlagBits value )
  {
    switch ( value )
    {
      case ShaderStageFlagBits::eVertex : return "Vertex";
      case ShaderStageFlagBits::eTessellationControl : return "TessellationControl";
      case ShaderStageFlagBits::eTessellationEvaluation : return "TessellationEvaluation";
      case ShaderStageFlagBits::eGeometry : return "Geometry";
      case ShaderStageFlagBits::eFragment : return "Fragment";
      case ShaderStageFlagBits::eCompute : return "Compute";
      case ShaderStageFlagBits::eAllGraphics : return "AllGraphics";
      case ShaderStageFlagBits::eAll : return "All";
      case ShaderStageFlagBits::eRaygenNV : return "RaygenNV";
      case ShaderStageFlagBits::eAnyHitNV : return "AnyHitNV";
      case ShaderStageFlagBits::eClosestHitNV : return "ClosestHitNV";
      case ShaderStageFlagBits::eMissNV : return "MissNV";
      case ShaderStageFlagBits::eIntersectionNV : return "IntersectionNV";
      case ShaderStageFlagBits::eCallableNV : return "CallableNV";
      case ShaderStageFlagBits::eTaskNV : return "TaskNV";
      case ShaderStageFlagBits::eMeshNV : return "MeshNV";
      default: return "invalid";
    }
  }

  using ShaderStageFlags = Flags<ShaderStageFlagBits, VkShaderStageFlags>;

  template <> struct FlagTraits<ShaderStageFlagBits>
  {
    enum
    {
      allFlags = VkFlags(ShaderStageFlagBits::eVertex) | VkFlags(ShaderStageFlagBits::eTessellationControl) | VkFlags(ShaderStageFlagBits::eTessellationEvaluation) | VkFlags(ShaderStageFlagBits::eGeometry) | VkFlags(ShaderStageFlagBits::eFragment) | VkFlags(ShaderStageFlagBits::eCompute) | VkFlags(ShaderStageFlagBits::eAllGraphics) | VkFlags(ShaderStageFlagBits::eAll) | VkFlags(ShaderStageFlagBits::eRaygenNV) | VkFlags(ShaderStageFlagBits::eAnyHitNV) | VkFlags(ShaderStageFlagBits::eClosestHitNV) | VkFlags(ShaderStageFlagBits::eMissNV) | VkFlags(ShaderStageFlagBits::eIntersectionNV) | VkFlags(ShaderStageFlagBits::eCallableNV) | VkFlags(ShaderStageFlagBits::eTaskNV) | VkFlags(ShaderStageFlagBits::eMeshNV)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ShaderStageFlags operator|( ShaderStageFlagBits bit0, ShaderStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ShaderStageFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ShaderStageFlags operator&( ShaderStageFlagBits bit0, ShaderStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ShaderStageFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ShaderStageFlags operator^( ShaderStageFlagBits bit0, ShaderStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ShaderStageFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR ShaderStageFlags operator~( ShaderStageFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( ShaderStageFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( ShaderStageFlagBits bit0, ShaderStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ShaderStageFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( ShaderStageFlagBits bit0, ShaderStageFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return ShaderStageFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( ShaderStageFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & ShaderStageFlagBits::eVertex ) result += "Vertex | ";
    if ( value & ShaderStageFlagBits::eTessellationControl ) result += "TessellationControl | ";
    if ( value & ShaderStageFlagBits::eTessellationEvaluation ) result += "TessellationEvaluation | ";
    if ( value & ShaderStageFlagBits::eGeometry ) result += "Geometry | ";
    if ( value & ShaderStageFlagBits::eFragment ) result += "Fragment | ";
    if ( value & ShaderStageFlagBits::eCompute ) result += "Compute | ";
    if ( value & ShaderStageFlagBits::eRaygenNV ) result += "RaygenNV | ";
    if ( value & ShaderStageFlagBits::eAnyHitNV ) result += "AnyHitNV | ";
    if ( value & ShaderStageFlagBits::eClosestHitNV ) result += "ClosestHitNV | ";
    if ( value & ShaderStageFlagBits::eMissNV ) result += "MissNV | ";
    if ( value & ShaderStageFlagBits::eIntersectionNV ) result += "IntersectionNV | ";
    if ( value & ShaderStageFlagBits::eCallableNV ) result += "CallableNV | ";
    if ( value & ShaderStageFlagBits::eTaskNV ) result += "TaskNV | ";
    if ( value & ShaderStageFlagBits::eMeshNV ) result += "MeshNV | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SparseImageFormatFlagBits
  {
    eSingleMiptail = VK_SPARSE_IMAGE_FORMAT_SINGLE_MIPTAIL_BIT,
    eAlignedMipSize = VK_SPARSE_IMAGE_FORMAT_ALIGNED_MIP_SIZE_BIT,
    eNonstandardBlockSize = VK_SPARSE_IMAGE_FORMAT_NONSTANDARD_BLOCK_SIZE_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( SparseImageFormatFlagBits value )
  {
    switch ( value )
    {
      case SparseImageFormatFlagBits::eSingleMiptail : return "SingleMiptail";
      case SparseImageFormatFlagBits::eAlignedMipSize : return "AlignedMipSize";
      case SparseImageFormatFlagBits::eNonstandardBlockSize : return "NonstandardBlockSize";
      default: return "invalid";
    }
  }

  using SparseImageFormatFlags = Flags<SparseImageFormatFlagBits, VkSparseImageFormatFlags>;

  template <> struct FlagTraits<SparseImageFormatFlagBits>
  {
    enum
    {
      allFlags = VkFlags(SparseImageFormatFlagBits::eSingleMiptail) | VkFlags(SparseImageFormatFlagBits::eAlignedMipSize) | VkFlags(SparseImageFormatFlagBits::eNonstandardBlockSize)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseImageFormatFlags operator|( SparseImageFormatFlagBits bit0, SparseImageFormatFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseImageFormatFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseImageFormatFlags operator&( SparseImageFormatFlagBits bit0, SparseImageFormatFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseImageFormatFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseImageFormatFlags operator^( SparseImageFormatFlagBits bit0, SparseImageFormatFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseImageFormatFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseImageFormatFlags operator~( SparseImageFormatFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SparseImageFormatFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SparseImageFormatFlagBits bit0, SparseImageFormatFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseImageFormatFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SparseImageFormatFlagBits bit0, SparseImageFormatFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseImageFormatFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SparseImageFormatFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SparseImageFormatFlagBits::eSingleMiptail ) result += "SingleMiptail | ";
    if ( value & SparseImageFormatFlagBits::eAlignedMipSize ) result += "AlignedMipSize | ";
    if ( value & SparseImageFormatFlagBits::eNonstandardBlockSize ) result += "NonstandardBlockSize | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SparseMemoryBindFlagBits
  {
    eMetadata = VK_SPARSE_MEMORY_BIND_METADATA_BIT
  };

  VULKAN_HPP_INLINE std::string to_string( SparseMemoryBindFlagBits value )
  {
    switch ( value )
    {
      case SparseMemoryBindFlagBits::eMetadata : return "Metadata";
      default: return "invalid";
    }
  }

  using SparseMemoryBindFlags = Flags<SparseMemoryBindFlagBits, VkSparseMemoryBindFlags>;

  template <> struct FlagTraits<SparseMemoryBindFlagBits>
  {
    enum
    {
      allFlags = VkFlags(SparseMemoryBindFlagBits::eMetadata)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseMemoryBindFlags operator|( SparseMemoryBindFlagBits bit0, SparseMemoryBindFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseMemoryBindFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseMemoryBindFlags operator&( SparseMemoryBindFlagBits bit0, SparseMemoryBindFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseMemoryBindFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseMemoryBindFlags operator^( SparseMemoryBindFlagBits bit0, SparseMemoryBindFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseMemoryBindFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SparseMemoryBindFlags operator~( SparseMemoryBindFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SparseMemoryBindFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SparseMemoryBindFlagBits bit0, SparseMemoryBindFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseMemoryBindFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SparseMemoryBindFlagBits bit0, SparseMemoryBindFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SparseMemoryBindFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SparseMemoryBindFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SparseMemoryBindFlagBits::eMetadata ) result += "Metadata | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class StencilFaceFlagBits
  {
    eFront = VK_STENCIL_FACE_FRONT_BIT,
    eBack = VK_STENCIL_FACE_BACK_BIT,
    eFrontAndBack = VK_STENCIL_FACE_FRONT_AND_BACK,
    eVkStencilFrontAndBack = VK_STENCIL_FRONT_AND_BACK
  };

  VULKAN_HPP_INLINE std::string to_string( StencilFaceFlagBits value )
  {
    switch ( value )
    {
      case StencilFaceFlagBits::eFront : return "Front";
      case StencilFaceFlagBits::eBack : return "Back";
      case StencilFaceFlagBits::eFrontAndBack : return "FrontAndBack";
      default: return "invalid";
    }
  }

  using StencilFaceFlags = Flags<StencilFaceFlagBits, VkStencilFaceFlags>;

  template <> struct FlagTraits<StencilFaceFlagBits>
  {
    enum
    {
      allFlags = VkFlags(StencilFaceFlagBits::eFront) | VkFlags(StencilFaceFlagBits::eBack) | VkFlags(StencilFaceFlagBits::eFrontAndBack)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR StencilFaceFlags operator|( StencilFaceFlagBits bit0, StencilFaceFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return StencilFaceFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR StencilFaceFlags operator&( StencilFaceFlagBits bit0, StencilFaceFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return StencilFaceFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR StencilFaceFlags operator^( StencilFaceFlagBits bit0, StencilFaceFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return StencilFaceFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR StencilFaceFlags operator~( StencilFaceFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( StencilFaceFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( StencilFaceFlagBits bit0, StencilFaceFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return StencilFaceFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( StencilFaceFlagBits bit0, StencilFaceFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return StencilFaceFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( StencilFaceFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & StencilFaceFlagBits::eFront ) result += "Front | ";
    if ( value & StencilFaceFlagBits::eBack ) result += "Back | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

#ifdef VK_USE_PLATFORM_GGP
  enum class StreamDescriptorSurfaceCreateFlagBitsGGP
  {};

  VULKAN_HPP_INLINE std::string to_string( StreamDescriptorSurfaceCreateFlagBitsGGP )
  {
    return "(void)";
  }

  using StreamDescriptorSurfaceCreateFlagsGGP = Flags<StreamDescriptorSurfaceCreateFlagBitsGGP, VkStreamDescriptorSurfaceCreateFlagsGGP>;

  VULKAN_HPP_INLINE std::string to_string( StreamDescriptorSurfaceCreateFlagsGGP  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_GGP*/

  enum class SubgroupFeatureFlagBits
  {
    eBasic = VK_SUBGROUP_FEATURE_BASIC_BIT,
    eVote = VK_SUBGROUP_FEATURE_VOTE_BIT,
    eArithmetic = VK_SUBGROUP_FEATURE_ARITHMETIC_BIT,
    eBallot = VK_SUBGROUP_FEATURE_BALLOT_BIT,
    eShuffle = VK_SUBGROUP_FEATURE_SHUFFLE_BIT,
    eShuffleRelative = VK_SUBGROUP_FEATURE_SHUFFLE_RELATIVE_BIT,
    eClustered = VK_SUBGROUP_FEATURE_CLUSTERED_BIT,
    eQuad = VK_SUBGROUP_FEATURE_QUAD_BIT,
    ePartitionedNV = VK_SUBGROUP_FEATURE_PARTITIONED_BIT_NV
  };

  VULKAN_HPP_INLINE std::string to_string( SubgroupFeatureFlagBits value )
  {
    switch ( value )
    {
      case SubgroupFeatureFlagBits::eBasic : return "Basic";
      case SubgroupFeatureFlagBits::eVote : return "Vote";
      case SubgroupFeatureFlagBits::eArithmetic : return "Arithmetic";
      case SubgroupFeatureFlagBits::eBallot : return "Ballot";
      case SubgroupFeatureFlagBits::eShuffle : return "Shuffle";
      case SubgroupFeatureFlagBits::eShuffleRelative : return "ShuffleRelative";
      case SubgroupFeatureFlagBits::eClustered : return "Clustered";
      case SubgroupFeatureFlagBits::eQuad : return "Quad";
      case SubgroupFeatureFlagBits::ePartitionedNV : return "PartitionedNV";
      default: return "invalid";
    }
  }

  using SubgroupFeatureFlags = Flags<SubgroupFeatureFlagBits, VkSubgroupFeatureFlags>;

  template <> struct FlagTraits<SubgroupFeatureFlagBits>
  {
    enum
    {
      allFlags = VkFlags(SubgroupFeatureFlagBits::eBasic) | VkFlags(SubgroupFeatureFlagBits::eVote) | VkFlags(SubgroupFeatureFlagBits::eArithmetic) | VkFlags(SubgroupFeatureFlagBits::eBallot) | VkFlags(SubgroupFeatureFlagBits::eShuffle) | VkFlags(SubgroupFeatureFlagBits::eShuffleRelative) | VkFlags(SubgroupFeatureFlagBits::eClustered) | VkFlags(SubgroupFeatureFlagBits::eQuad) | VkFlags(SubgroupFeatureFlagBits::ePartitionedNV)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubgroupFeatureFlags operator|( SubgroupFeatureFlagBits bit0, SubgroupFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubgroupFeatureFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubgroupFeatureFlags operator&( SubgroupFeatureFlagBits bit0, SubgroupFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubgroupFeatureFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubgroupFeatureFlags operator^( SubgroupFeatureFlagBits bit0, SubgroupFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubgroupFeatureFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubgroupFeatureFlags operator~( SubgroupFeatureFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SubgroupFeatureFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SubgroupFeatureFlagBits bit0, SubgroupFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubgroupFeatureFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SubgroupFeatureFlagBits bit0, SubgroupFeatureFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubgroupFeatureFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SubgroupFeatureFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SubgroupFeatureFlagBits::eBasic ) result += "Basic | ";
    if ( value & SubgroupFeatureFlagBits::eVote ) result += "Vote | ";
    if ( value & SubgroupFeatureFlagBits::eArithmetic ) result += "Arithmetic | ";
    if ( value & SubgroupFeatureFlagBits::eBallot ) result += "Ballot | ";
    if ( value & SubgroupFeatureFlagBits::eShuffle ) result += "Shuffle | ";
    if ( value & SubgroupFeatureFlagBits::eShuffleRelative ) result += "ShuffleRelative | ";
    if ( value & SubgroupFeatureFlagBits::eClustered ) result += "Clustered | ";
    if ( value & SubgroupFeatureFlagBits::eQuad ) result += "Quad | ";
    if ( value & SubgroupFeatureFlagBits::ePartitionedNV ) result += "PartitionedNV | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SubpassDescriptionFlagBits
  {
    ePerViewAttributesNVX = VK_SUBPASS_DESCRIPTION_PER_VIEW_ATTRIBUTES_BIT_NVX,
    ePerViewPositionXOnlyNVX = VK_SUBPASS_DESCRIPTION_PER_VIEW_POSITION_X_ONLY_BIT_NVX
  };

  VULKAN_HPP_INLINE std::string to_string( SubpassDescriptionFlagBits value )
  {
    switch ( value )
    {
      case SubpassDescriptionFlagBits::ePerViewAttributesNVX : return "PerViewAttributesNVX";
      case SubpassDescriptionFlagBits::ePerViewPositionXOnlyNVX : return "PerViewPositionXOnlyNVX";
      default: return "invalid";
    }
  }

  using SubpassDescriptionFlags = Flags<SubpassDescriptionFlagBits, VkSubpassDescriptionFlags>;

  template <> struct FlagTraits<SubpassDescriptionFlagBits>
  {
    enum
    {
      allFlags = VkFlags(SubpassDescriptionFlagBits::ePerViewAttributesNVX) | VkFlags(SubpassDescriptionFlagBits::ePerViewPositionXOnlyNVX)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubpassDescriptionFlags operator|( SubpassDescriptionFlagBits bit0, SubpassDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubpassDescriptionFlags( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubpassDescriptionFlags operator&( SubpassDescriptionFlagBits bit0, SubpassDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubpassDescriptionFlags( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubpassDescriptionFlags operator^( SubpassDescriptionFlagBits bit0, SubpassDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubpassDescriptionFlags( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SubpassDescriptionFlags operator~( SubpassDescriptionFlagBits bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SubpassDescriptionFlags( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SubpassDescriptionFlagBits bit0, SubpassDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubpassDescriptionFlags( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SubpassDescriptionFlagBits bit0, SubpassDescriptionFlagBits bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SubpassDescriptionFlags( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SubpassDescriptionFlags value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SubpassDescriptionFlagBits::ePerViewAttributesNVX ) result += "PerViewAttributesNVX | ";
    if ( value & SubpassDescriptionFlagBits::ePerViewPositionXOnlyNVX ) result += "PerViewPositionXOnlyNVX | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SurfaceCounterFlagBitsEXT
  {
    eVblank = VK_SURFACE_COUNTER_VBLANK_EXT
  };

  VULKAN_HPP_INLINE std::string to_string( SurfaceCounterFlagBitsEXT value )
  {
    switch ( value )
    {
      case SurfaceCounterFlagBitsEXT::eVblank : return "Vblank";
      default: return "invalid";
    }
  }

  using SurfaceCounterFlagsEXT = Flags<SurfaceCounterFlagBitsEXT, VkSurfaceCounterFlagsEXT>;

  template <> struct FlagTraits<SurfaceCounterFlagBitsEXT>
  {
    enum
    {
      allFlags = VkFlags(SurfaceCounterFlagBitsEXT::eVblank)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceCounterFlagsEXT operator|( SurfaceCounterFlagBitsEXT bit0, SurfaceCounterFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceCounterFlagsEXT( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceCounterFlagsEXT operator&( SurfaceCounterFlagBitsEXT bit0, SurfaceCounterFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceCounterFlagsEXT( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceCounterFlagsEXT operator^( SurfaceCounterFlagBitsEXT bit0, SurfaceCounterFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceCounterFlagsEXT( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceCounterFlagsEXT operator~( SurfaceCounterFlagBitsEXT bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SurfaceCounterFlagsEXT( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SurfaceCounterFlagBitsEXT bit0, SurfaceCounterFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceCounterFlagsEXT( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SurfaceCounterFlagBitsEXT bit0, SurfaceCounterFlagBitsEXT bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceCounterFlagsEXT( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SurfaceCounterFlagsEXT value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SurfaceCounterFlagBitsEXT::eVblank ) result += "Vblank | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SurfaceTransformFlagBitsKHR
  {
    eIdentity = VK_SURFACE_TRANSFORM_IDENTITY_BIT_KHR,
    eRotate90 = VK_SURFACE_TRANSFORM_ROTATE_90_BIT_KHR,
    eRotate180 = VK_SURFACE_TRANSFORM_ROTATE_180_BIT_KHR,
    eRotate270 = VK_SURFACE_TRANSFORM_ROTATE_270_BIT_KHR,
    eHorizontalMirror = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_BIT_KHR,
    eHorizontalMirrorRotate90 = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_90_BIT_KHR,
    eHorizontalMirrorRotate180 = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_180_BIT_KHR,
    eHorizontalMirrorRotate270 = VK_SURFACE_TRANSFORM_HORIZONTAL_MIRROR_ROTATE_270_BIT_KHR,
    eInherit = VK_SURFACE_TRANSFORM_INHERIT_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SurfaceTransformFlagBitsKHR value )
  {
    switch ( value )
    {
      case SurfaceTransformFlagBitsKHR::eIdentity : return "Identity";
      case SurfaceTransformFlagBitsKHR::eRotate90 : return "Rotate90";
      case SurfaceTransformFlagBitsKHR::eRotate180 : return "Rotate180";
      case SurfaceTransformFlagBitsKHR::eRotate270 : return "Rotate270";
      case SurfaceTransformFlagBitsKHR::eHorizontalMirror : return "HorizontalMirror";
      case SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate90 : return "HorizontalMirrorRotate90";
      case SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate180 : return "HorizontalMirrorRotate180";
      case SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate270 : return "HorizontalMirrorRotate270";
      case SurfaceTransformFlagBitsKHR::eInherit : return "Inherit";
      default: return "invalid";
    }
  }

  using SurfaceTransformFlagsKHR = Flags<SurfaceTransformFlagBitsKHR, VkSurfaceTransformFlagsKHR>;

  template <> struct FlagTraits<SurfaceTransformFlagBitsKHR>
  {
    enum
    {
      allFlags = VkFlags(SurfaceTransformFlagBitsKHR::eIdentity) | VkFlags(SurfaceTransformFlagBitsKHR::eRotate90) | VkFlags(SurfaceTransformFlagBitsKHR::eRotate180) | VkFlags(SurfaceTransformFlagBitsKHR::eRotate270) | VkFlags(SurfaceTransformFlagBitsKHR::eHorizontalMirror) | VkFlags(SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate90) | VkFlags(SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate180) | VkFlags(SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate270) | VkFlags(SurfaceTransformFlagBitsKHR::eInherit)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceTransformFlagsKHR operator|( SurfaceTransformFlagBitsKHR bit0, SurfaceTransformFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceTransformFlagsKHR( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceTransformFlagsKHR operator&( SurfaceTransformFlagBitsKHR bit0, SurfaceTransformFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceTransformFlagsKHR( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceTransformFlagsKHR operator^( SurfaceTransformFlagBitsKHR bit0, SurfaceTransformFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceTransformFlagsKHR( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SurfaceTransformFlagsKHR operator~( SurfaceTransformFlagBitsKHR bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SurfaceTransformFlagsKHR( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SurfaceTransformFlagBitsKHR bit0, SurfaceTransformFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceTransformFlagsKHR( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SurfaceTransformFlagBitsKHR bit0, SurfaceTransformFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SurfaceTransformFlagsKHR( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SurfaceTransformFlagsKHR value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SurfaceTransformFlagBitsKHR::eIdentity ) result += "Identity | ";
    if ( value & SurfaceTransformFlagBitsKHR::eRotate90 ) result += "Rotate90 | ";
    if ( value & SurfaceTransformFlagBitsKHR::eRotate180 ) result += "Rotate180 | ";
    if ( value & SurfaceTransformFlagBitsKHR::eRotate270 ) result += "Rotate270 | ";
    if ( value & SurfaceTransformFlagBitsKHR::eHorizontalMirror ) result += "HorizontalMirror | ";
    if ( value & SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate90 ) result += "HorizontalMirrorRotate90 | ";
    if ( value & SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate180 ) result += "HorizontalMirrorRotate180 | ";
    if ( value & SurfaceTransformFlagBitsKHR::eHorizontalMirrorRotate270 ) result += "HorizontalMirrorRotate270 | ";
    if ( value & SurfaceTransformFlagBitsKHR::eInherit ) result += "Inherit | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class SwapchainCreateFlagBitsKHR
  {
    eSplitInstanceBindRegions = VK_SWAPCHAIN_CREATE_SPLIT_INSTANCE_BIND_REGIONS_BIT_KHR,
    eProtected = VK_SWAPCHAIN_CREATE_PROTECTED_BIT_KHR,
    eMutableFormat = VK_SWAPCHAIN_CREATE_MUTABLE_FORMAT_BIT_KHR
  };

  VULKAN_HPP_INLINE std::string to_string( SwapchainCreateFlagBitsKHR value )
  {
    switch ( value )
    {
      case SwapchainCreateFlagBitsKHR::eSplitInstanceBindRegions : return "SplitInstanceBindRegions";
      case SwapchainCreateFlagBitsKHR::eProtected : return "Protected";
      case SwapchainCreateFlagBitsKHR::eMutableFormat : return "MutableFormat";
      default: return "invalid";
    }
  }

  using SwapchainCreateFlagsKHR = Flags<SwapchainCreateFlagBitsKHR, VkSwapchainCreateFlagsKHR>;

  template <> struct FlagTraits<SwapchainCreateFlagBitsKHR>
  {
    enum
    {
      allFlags = VkFlags(SwapchainCreateFlagBitsKHR::eSplitInstanceBindRegions) | VkFlags(SwapchainCreateFlagBitsKHR::eProtected) | VkFlags(SwapchainCreateFlagBitsKHR::eMutableFormat)
    };
  };

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SwapchainCreateFlagsKHR operator|( SwapchainCreateFlagBitsKHR bit0, SwapchainCreateFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SwapchainCreateFlagsKHR( bit0 ) | bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SwapchainCreateFlagsKHR operator&( SwapchainCreateFlagBitsKHR bit0, SwapchainCreateFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SwapchainCreateFlagsKHR( bit0 ) & bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SwapchainCreateFlagsKHR operator^( SwapchainCreateFlagBitsKHR bit0, SwapchainCreateFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SwapchainCreateFlagsKHR( bit0 ) ^ bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR SwapchainCreateFlagsKHR operator~( SwapchainCreateFlagBitsKHR bits ) VULKAN_HPP_NOEXCEPT
  {
    return ~( SwapchainCreateFlagsKHR( bits ) );
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator==( SwapchainCreateFlagBitsKHR bit0, SwapchainCreateFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SwapchainCreateFlagsKHR( bit0 ) == bit1;
  }

  VULKAN_HPP_INLINE VULKAN_HPP_CONSTEXPR bool operator!=( SwapchainCreateFlagBitsKHR bit0, SwapchainCreateFlagBitsKHR bit1 ) VULKAN_HPP_NOEXCEPT
  {
    return SwapchainCreateFlagsKHR( bit0 ) != bit1;
  }

  VULKAN_HPP_INLINE std::string to_string( SwapchainCreateFlagsKHR value  )
  {
    if ( !value ) return "{}";
    std::string result;

    if ( value & SwapchainCreateFlagBitsKHR::eSplitInstanceBindRegions ) result += "SplitInstanceBindRegions | ";
    if ( value & SwapchainCreateFlagBitsKHR::eProtected ) result += "Protected | ";
    if ( value & SwapchainCreateFlagBitsKHR::eMutableFormat ) result += "MutableFormat | ";
    return "{ " + result.substr(0, result.size() - 3) + " }";
  }

  enum class ValidationCacheCreateFlagBitsEXT
  {};

  VULKAN_HPP_INLINE std::string to_string( ValidationCacheCreateFlagBitsEXT )
  {
    return "(void)";
  }

  using ValidationCacheCreateFlagsEXT = Flags<ValidationCacheCreateFlagBitsEXT, VkValidationCacheCreateFlagsEXT>;

  VULKAN_HPP_INLINE std::string to_string( ValidationCacheCreateFlagsEXT  )
  {
    return "{}";
  }

#ifdef VK_USE_PLATFORM_VI_NN
  enum class ViSurfaceCreateFlagBitsNN
  {};

  VULKAN_HPP_INLINE std::string to_string( ViSurfaceCreateFlagBitsNN )
  {
    return "(void)";
  }

  using ViSurfaceCreateFlagsNN = Flags<ViSurfaceCreateFlagBitsNN, VkViSurfaceCreateFlagsNN>;

  VULKAN_HPP_INLINE std::string to_string( ViSurfaceCreateFlagsNN  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_VI_NN*/

#ifdef VK_USE_PLATFORM_WAYLAND_KHR
  enum class WaylandSurfaceCreateFlagBitsKHR
  {};

  VULKAN_HPP_INLINE std::string to_string( WaylandSurfaceCreateFlagBitsKHR )
  {
    return "(void)";
  }

  using WaylandSurfaceCreateFlagsKHR = Flags<WaylandSurfaceCreateFlagBitsKHR, VkWaylandSurfaceCreateFlagsKHR>;

  VULKAN_HPP_INLINE std::string to_string( WaylandSurfaceCreateFlagsKHR  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  enum class Win32SurfaceCreateFlagBitsKHR
  {};

  VULKAN_HPP_INLINE std::string to_string( Win32SurfaceCreateFlagBitsKHR )
  {
    return "(void)";
  }

  using Win32SurfaceCreateFlagsKHR = Flags<Win32SurfaceCreateFlagBitsKHR, VkWin32SurfaceCreateFlagsKHR>;

  VULKAN_HPP_INLINE std::string to_string( Win32SurfaceCreateFlagsKHR  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_XCB_KHR
  enum class XcbSurfaceCreateFlagBitsKHR
  {};

  VULKAN_HPP_INLINE std::string to_string( XcbSurfaceCreateFlagBitsKHR )
  {
    return "(void)";
  }

  using XcbSurfaceCreateFlagsKHR = Flags<XcbSurfaceCreateFlagBitsKHR, VkXcbSurfaceCreateFlagsKHR>;

  VULKAN_HPP_INLINE std::string to_string( XcbSurfaceCreateFlagsKHR  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR
  enum class XlibSurfaceCreateFlagBitsKHR
  {};

  VULKAN_HPP_INLINE std::string to_string( XlibSurfaceCreateFlagBitsKHR )
  {
    return "(void)";
  }

  using XlibSurfaceCreateFlagsKHR = Flags<XlibSurfaceCreateFlagBitsKHR, VkXlibSurfaceCreateFlagsKHR>;

  VULKAN_HPP_INLINE std::string to_string( XlibSurfaceCreateFlagsKHR  )
  {
    return "{}";
  }
#endif /*VK_USE_PLATFORM_XLIB_KHR*/
} // namespace VULKAN_HPP_NAMESPACE

namespace std
{
  template <>
  struct is_error_code_enum<VULKAN_HPP_NAMESPACE::Result> : public true_type
  {};
}

namespace VULKAN_HPP_NAMESPACE
{
#ifndef VULKAN_HPP_NO_EXCEPTIONS
  class ErrorCategoryImpl : public std::error_category
  {
    public:
    virtual const char* name() const VULKAN_HPP_NOEXCEPT override { return VULKAN_HPP_NAMESPACE_STRING"::Result"; }
    virtual std::string message(int ev) const override { return to_string(static_cast<Result>(ev)); }
  };

  class Error
  {
    public:
    Error() VULKAN_HPP_NOEXCEPT = default;
    Error(const Error&) VULKAN_HPP_NOEXCEPT = default;
    virtual ~Error() VULKAN_HPP_NOEXCEPT = default;

    virtual const char* what() const VULKAN_HPP_NOEXCEPT = 0;
  };

  class LogicError : public Error, public std::logic_error
  {
    public:
    explicit LogicError( const std::string& what )
      : Error(), std::logic_error(what) {}
    explicit LogicError( char const * what )
      : Error(), std::logic_error(what) {}

    virtual const char* what() const VULKAN_HPP_NOEXCEPT { return std::logic_error::what(); }
  };

  class SystemError : public Error, public std::system_error
  {
    public:
    SystemError( std::error_code ec )
      : Error(), std::system_error(ec) {}
    SystemError( std::error_code ec, std::string const& what )
      : Error(), std::system_error(ec, what) {}
    SystemError( std::error_code ec, char const * what )
      : Error(), std::system_error(ec, what) {}
    SystemError( int ev, std::error_category const& ecat )
      : Error(), std::system_error(ev, ecat) {}
    SystemError( int ev, std::error_category const& ecat, std::string const& what)
      : Error(), std::system_error(ev, ecat, what) {}
    SystemError( int ev, std::error_category const& ecat, char const * what)
      : Error(), std::system_error(ev, ecat, what) {}

    virtual const char* what() const VULKAN_HPP_NOEXCEPT { return std::system_error::what(); }
  };

  VULKAN_HPP_INLINE const std::error_category& errorCategory() VULKAN_HPP_NOEXCEPT
  {
    static ErrorCategoryImpl instance;
    return instance;
  }

  VULKAN_HPP_INLINE std::error_code make_error_code(Result e) VULKAN_HPP_NOEXCEPT
  {
    return std::error_code(static_cast<int>(e), errorCategory());
  }

  VULKAN_HPP_INLINE std::error_condition make_error_condition(Result e) VULKAN_HPP_NOEXCEPT
  {
    return std::error_condition(static_cast<int>(e), errorCategory());
  }

  class OutOfHostMemoryError : public SystemError
  {
  public:
    OutOfHostMemoryError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorOutOfHostMemory ), message ) {}
    OutOfHostMemoryError( char const * message )
      : SystemError( make_error_code( Result::eErrorOutOfHostMemory ), message ) {}
  };

  class OutOfDeviceMemoryError : public SystemError
  {
  public:
    OutOfDeviceMemoryError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorOutOfDeviceMemory ), message ) {}
    OutOfDeviceMemoryError( char const * message )
      : SystemError( make_error_code( Result::eErrorOutOfDeviceMemory ), message ) {}
  };

  class InitializationFailedError : public SystemError
  {
  public:
    InitializationFailedError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorInitializationFailed ), message ) {}
    InitializationFailedError( char const * message )
      : SystemError( make_error_code( Result::eErrorInitializationFailed ), message ) {}
  };

  class DeviceLostError : public SystemError
  {
  public:
    DeviceLostError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorDeviceLost ), message ) {}
    DeviceLostError( char const * message )
      : SystemError( make_error_code( Result::eErrorDeviceLost ), message ) {}
  };

  class MemoryMapFailedError : public SystemError
  {
  public:
    MemoryMapFailedError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorMemoryMapFailed ), message ) {}
    MemoryMapFailedError( char const * message )
      : SystemError( make_error_code( Result::eErrorMemoryMapFailed ), message ) {}
  };

  class LayerNotPresentError : public SystemError
  {
  public:
    LayerNotPresentError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorLayerNotPresent ), message ) {}
    LayerNotPresentError( char const * message )
      : SystemError( make_error_code( Result::eErrorLayerNotPresent ), message ) {}
  };

  class ExtensionNotPresentError : public SystemError
  {
  public:
    ExtensionNotPresentError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorExtensionNotPresent ), message ) {}
    ExtensionNotPresentError( char const * message )
      : SystemError( make_error_code( Result::eErrorExtensionNotPresent ), message ) {}
  };

  class FeatureNotPresentError : public SystemError
  {
  public:
    FeatureNotPresentError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorFeatureNotPresent ), message ) {}
    FeatureNotPresentError( char const * message )
      : SystemError( make_error_code( Result::eErrorFeatureNotPresent ), message ) {}
  };

  class IncompatibleDriverError : public SystemError
  {
  public:
    IncompatibleDriverError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorIncompatibleDriver ), message ) {}
    IncompatibleDriverError( char const * message )
      : SystemError( make_error_code( Result::eErrorIncompatibleDriver ), message ) {}
  };

  class TooManyObjectsError : public SystemError
  {
  public:
    TooManyObjectsError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorTooManyObjects ), message ) {}
    TooManyObjectsError( char const * message )
      : SystemError( make_error_code( Result::eErrorTooManyObjects ), message ) {}
  };

  class FormatNotSupportedError : public SystemError
  {
  public:
    FormatNotSupportedError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorFormatNotSupported ), message ) {}
    FormatNotSupportedError( char const * message )
      : SystemError( make_error_code( Result::eErrorFormatNotSupported ), message ) {}
  };

  class FragmentedPoolError : public SystemError
  {
  public:
    FragmentedPoolError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorFragmentedPool ), message ) {}
    FragmentedPoolError( char const * message )
      : SystemError( make_error_code( Result::eErrorFragmentedPool ), message ) {}
  };

  class OutOfPoolMemoryError : public SystemError
  {
  public:
    OutOfPoolMemoryError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorOutOfPoolMemory ), message ) {}
    OutOfPoolMemoryError( char const * message )
      : SystemError( make_error_code( Result::eErrorOutOfPoolMemory ), message ) {}
  };

  class InvalidExternalHandleError : public SystemError
  {
  public:
    InvalidExternalHandleError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorInvalidExternalHandle ), message ) {}
    InvalidExternalHandleError( char const * message )
      : SystemError( make_error_code( Result::eErrorInvalidExternalHandle ), message ) {}
  };

  class SurfaceLostKHRError : public SystemError
  {
  public:
    SurfaceLostKHRError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorSurfaceLostKHR ), message ) {}
    SurfaceLostKHRError( char const * message )
      : SystemError( make_error_code( Result::eErrorSurfaceLostKHR ), message ) {}
  };

  class NativeWindowInUseKHRError : public SystemError
  {
  public:
    NativeWindowInUseKHRError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorNativeWindowInUseKHR ), message ) {}
    NativeWindowInUseKHRError( char const * message )
      : SystemError( make_error_code( Result::eErrorNativeWindowInUseKHR ), message ) {}
  };

  class OutOfDateKHRError : public SystemError
  {
  public:
    OutOfDateKHRError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorOutOfDateKHR ), message ) {}
    OutOfDateKHRError( char const * message )
      : SystemError( make_error_code( Result::eErrorOutOfDateKHR ), message ) {}
  };

  class IncompatibleDisplayKHRError : public SystemError
  {
  public:
    IncompatibleDisplayKHRError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorIncompatibleDisplayKHR ), message ) {}
    IncompatibleDisplayKHRError( char const * message )
      : SystemError( make_error_code( Result::eErrorIncompatibleDisplayKHR ), message ) {}
  };

  class ValidationFailedEXTError : public SystemError
  {
  public:
    ValidationFailedEXTError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorValidationFailedEXT ), message ) {}
    ValidationFailedEXTError( char const * message )
      : SystemError( make_error_code( Result::eErrorValidationFailedEXT ), message ) {}
  };

  class InvalidShaderNVError : public SystemError
  {
  public:
    InvalidShaderNVError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorInvalidShaderNV ), message ) {}
    InvalidShaderNVError( char const * message )
      : SystemError( make_error_code( Result::eErrorInvalidShaderNV ), message ) {}
  };

  class InvalidDrmFormatModifierPlaneLayoutEXTError : public SystemError
  {
  public:
    InvalidDrmFormatModifierPlaneLayoutEXTError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorInvalidDrmFormatModifierPlaneLayoutEXT ), message ) {}
    InvalidDrmFormatModifierPlaneLayoutEXTError( char const * message )
      : SystemError( make_error_code( Result::eErrorInvalidDrmFormatModifierPlaneLayoutEXT ), message ) {}
  };

  class FragmentationEXTError : public SystemError
  {
  public:
    FragmentationEXTError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorFragmentationEXT ), message ) {}
    FragmentationEXTError( char const * message )
      : SystemError( make_error_code( Result::eErrorFragmentationEXT ), message ) {}
  };

  class NotPermittedEXTError : public SystemError
  {
  public:
    NotPermittedEXTError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorNotPermittedEXT ), message ) {}
    NotPermittedEXTError( char const * message )
      : SystemError( make_error_code( Result::eErrorNotPermittedEXT ), message ) {}
  };

  class InvalidDeviceAddressEXTError : public SystemError
  {
  public:
    InvalidDeviceAddressEXTError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorInvalidDeviceAddressEXT ), message ) {}
    InvalidDeviceAddressEXTError( char const * message )
      : SystemError( make_error_code( Result::eErrorInvalidDeviceAddressEXT ), message ) {}
  };

  class FullScreenExclusiveModeLostEXTError : public SystemError
  {
  public:
    FullScreenExclusiveModeLostEXTError( std::string const& message )
      : SystemError( make_error_code( Result::eErrorFullScreenExclusiveModeLostEXT ), message ) {}
    FullScreenExclusiveModeLostEXTError( char const * message )
      : SystemError( make_error_code( Result::eErrorFullScreenExclusiveModeLostEXT ), message ) {}
  };

  VULKAN_HPP_INLINE void throwResultException( Result result, char const * message )
  {
    switch ( result )
    {
      case Result::eErrorOutOfHostMemory: throw OutOfHostMemoryError( message );
      case Result::eErrorOutOfDeviceMemory: throw OutOfDeviceMemoryError( message );
      case Result::eErrorInitializationFailed: throw InitializationFailedError( message );
      case Result::eErrorDeviceLost: throw DeviceLostError( message );
      case Result::eErrorMemoryMapFailed: throw MemoryMapFailedError( message );
      case Result::eErrorLayerNotPresent: throw LayerNotPresentError( message );
      case Result::eErrorExtensionNotPresent: throw ExtensionNotPresentError( message );
      case Result::eErrorFeatureNotPresent: throw FeatureNotPresentError( message );
      case Result::eErrorIncompatibleDriver: throw IncompatibleDriverError( message );
      case Result::eErrorTooManyObjects: throw TooManyObjectsError( message );
      case Result::eErrorFormatNotSupported: throw FormatNotSupportedError( message );
      case Result::eErrorFragmentedPool: throw FragmentedPoolError( message );
      case Result::eErrorOutOfPoolMemory: throw OutOfPoolMemoryError( message );
      case Result::eErrorInvalidExternalHandle: throw InvalidExternalHandleError( message );
      case Result::eErrorSurfaceLostKHR: throw SurfaceLostKHRError( message );
      case Result::eErrorNativeWindowInUseKHR: throw NativeWindowInUseKHRError( message );
      case Result::eErrorOutOfDateKHR: throw OutOfDateKHRError( message );
      case Result::eErrorIncompatibleDisplayKHR: throw IncompatibleDisplayKHRError( message );
      case Result::eErrorValidationFailedEXT: throw ValidationFailedEXTError( message );
      case Result::eErrorInvalidShaderNV: throw InvalidShaderNVError( message );
      case Result::eErrorInvalidDrmFormatModifierPlaneLayoutEXT: throw InvalidDrmFormatModifierPlaneLayoutEXTError( message );
      case Result::eErrorFragmentationEXT: throw FragmentationEXTError( message );
      case Result::eErrorNotPermittedEXT: throw NotPermittedEXTError( message );
      case Result::eErrorInvalidDeviceAddressEXT: throw InvalidDeviceAddressEXTError( message );
      case Result::eErrorFullScreenExclusiveModeLostEXT: throw FullScreenExclusiveModeLostEXTError( message );
      default: throw SystemError( make_error_code( result ) );
    }
  }
#endif

  template <typename T> void ignore(T const&) VULKAN_HPP_NOEXCEPT {}

  template <typename T>
  struct ResultValue
  {
#ifdef VULKAN_HPP_HAS_NOEXCEPT
    ResultValue( Result r, T & v ) VULKAN_HPP_NOEXCEPT(VULKAN_HPP_NOEXCEPT(T(v)))
#else
    ResultValue( Result r, T & v )
#endif
      : result( r )
      , value( v )
    {}

#ifdef VULKAN_HPP_HAS_NOEXCEPT
    ResultValue( Result r, T && v ) VULKAN_HPP_NOEXCEPT(VULKAN_HPP_NOEXCEPT(T(std::move(v))))
#else
    ResultValue( Result r, T && v )
#endif
      : result( r )
      , value( std::move( v ) )
    {}

    Result  result;
    T       value;

    operator std::tuple<Result&, T&>() VULKAN_HPP_NOEXCEPT { return std::tuple<Result&, T&>(result, value); }
  };

  template <typename T>
  struct ResultValueType
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    typedef ResultValue<T>  type;
#else
    typedef T               type;
#endif
  };

  template <>
  struct ResultValueType<void>
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    typedef Result type;
#else
    typedef void   type;
#endif
  };

  VULKAN_HPP_INLINE ResultValueType<void>::type createResultValue( Result result, char const * message )
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    ignore(message);
    VULKAN_HPP_ASSERT( result == Result::eSuccess );
    return result;
#else
    if ( result != Result::eSuccess )
    {
      throwResultException( result, message );
    }
#endif
  }

  template <typename T>
  VULKAN_HPP_INLINE typename ResultValueType<T>::type createResultValue( Result result, T & data, char const * message )
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    ignore(message);
    VULKAN_HPP_ASSERT( result == Result::eSuccess );
    return ResultValue<T>( result, std::move( data ) );
#else
    if ( result != Result::eSuccess )
    {
      throwResultException( result, message );
    }
    return std::move( data );
#endif
  }

  VULKAN_HPP_INLINE Result createResultValue( Result result, char const * message, std::initializer_list<Result> successCodes )
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    ignore(message);
    VULKAN_HPP_ASSERT( std::find( successCodes.begin(), successCodes.end(), result ) != successCodes.end() );
#else
    if ( std::find( successCodes.begin(), successCodes.end(), result ) == successCodes.end() )
    {
      throwResultException( result, message );
    }
#endif
    return result;
  }

  template <typename T>
  VULKAN_HPP_INLINE ResultValue<T> createResultValue( Result result, T & data, char const * message, std::initializer_list<Result> successCodes )
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    ignore(message);
    VULKAN_HPP_ASSERT( std::find( successCodes.begin(), successCodes.end(), result ) != successCodes.end() );
#else
    if ( std::find( successCodes.begin(), successCodes.end(), result ) == successCodes.end() )
    {
      throwResultException( result, message );
    }
#endif
    return ResultValue<T>( result, data );
  }

#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template <typename T, typename D>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<T,D>>::type createResultValue( Result result, T & data, char const * message, typename UniqueHandleTraits<T,D>::deleter const& deleter )
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    ignore(message);
    VULKAN_HPP_ASSERT( result == Result::eSuccess );
    return ResultValue<UniqueHandle<T,D>>( result, UniqueHandle<T,D>(data, deleter) );
#else
    if ( result != Result::eSuccess )
    {
      throwResultException( result, message );
    }
    return UniqueHandle<T,D>(data, deleter);
#endif
  }
#endif

  struct AccelerationStructureCreateInfoNV;
  struct AccelerationStructureInfoNV;
  struct AccelerationStructureMemoryRequirementsInfoNV;
  struct AcquireNextImageInfoKHR;
  struct AllocationCallbacks;
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  struct AndroidHardwareBufferFormatPropertiesANDROID;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  struct AndroidHardwareBufferPropertiesANDROID;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  struct AndroidHardwareBufferUsageANDROID;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  struct AndroidSurfaceCreateInfoKHR;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
  struct ApplicationInfo;
  struct AttachmentDescription;
  struct AttachmentDescription2KHR;
  struct AttachmentReference;
  struct AttachmentReference2KHR;
  struct AttachmentSampleLocationsEXT;
  struct BaseInStructure;
  struct BaseOutStructure;
  struct BindAccelerationStructureMemoryInfoNV;
  struct BindBufferMemoryDeviceGroupInfo;
  using BindBufferMemoryDeviceGroupInfoKHR = BindBufferMemoryDeviceGroupInfo;
  struct BindBufferMemoryInfo;
  using BindBufferMemoryInfoKHR = BindBufferMemoryInfo;
  struct BindImageMemoryDeviceGroupInfo;
  using BindImageMemoryDeviceGroupInfoKHR = BindImageMemoryDeviceGroupInfo;
  struct BindImageMemoryInfo;
  using BindImageMemoryInfoKHR = BindImageMemoryInfo;
  struct BindImageMemorySwapchainInfoKHR;
  struct BindImagePlaneMemoryInfo;
  using BindImagePlaneMemoryInfoKHR = BindImagePlaneMemoryInfo;
  struct BindSparseInfo;
  struct BufferCopy;
  struct BufferCreateInfo;
  struct BufferDeviceAddressCreateInfoEXT;
  struct BufferDeviceAddressInfoEXT;
  struct BufferImageCopy;
  struct BufferMemoryBarrier;
  struct BufferMemoryRequirementsInfo2;
  using BufferMemoryRequirementsInfo2KHR = BufferMemoryRequirementsInfo2;
  struct BufferViewCreateInfo;
  struct CalibratedTimestampInfoEXT;
  struct CheckpointDataNV;
  struct ClearAttachment;
  union ClearColorValue;
  struct ClearDepthStencilValue;
  struct ClearRect;
  union ClearValue;
  struct CmdProcessCommandsInfoNVX;
  struct CmdReserveSpaceForCommandsInfoNVX;
  struct CoarseSampleLocationNV;
  struct CoarseSampleOrderCustomNV;
  struct CommandBufferAllocateInfo;
  struct CommandBufferBeginInfo;
  struct CommandBufferInheritanceConditionalRenderingInfoEXT;
  struct CommandBufferInheritanceInfo;
  struct CommandPoolCreateInfo;
  struct ComponentMapping;
  struct ComputePipelineCreateInfo;
  struct ConditionalRenderingBeginInfoEXT;
  struct ConformanceVersionKHR;
  struct CooperativeMatrixPropertiesNV;
  struct CopyDescriptorSet;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct D3D12FenceSubmitInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct DebugMarkerMarkerInfoEXT;
  struct DebugMarkerObjectNameInfoEXT;
  struct DebugMarkerObjectTagInfoEXT;
  struct DebugReportCallbackCreateInfoEXT;
  struct DebugUtilsLabelEXT;
  struct DebugUtilsMessengerCallbackDataEXT;
  struct DebugUtilsMessengerCreateInfoEXT;
  struct DebugUtilsObjectNameInfoEXT;
  struct DebugUtilsObjectTagInfoEXT;
  struct DedicatedAllocationBufferCreateInfoNV;
  struct DedicatedAllocationImageCreateInfoNV;
  struct DedicatedAllocationMemoryAllocateInfoNV;
  struct DescriptorBufferInfo;
  struct DescriptorImageInfo;
  struct DescriptorPoolCreateInfo;
  struct DescriptorPoolInlineUniformBlockCreateInfoEXT;
  struct DescriptorPoolSize;
  struct DescriptorSetAllocateInfo;
  struct DescriptorSetLayoutBinding;
  struct DescriptorSetLayoutBindingFlagsCreateInfoEXT;
  struct DescriptorSetLayoutCreateInfo;
  struct DescriptorSetLayoutSupport;
  using DescriptorSetLayoutSupportKHR = DescriptorSetLayoutSupport;
  struct DescriptorSetVariableDescriptorCountAllocateInfoEXT;
  struct DescriptorSetVariableDescriptorCountLayoutSupportEXT;
  struct DescriptorUpdateTemplateCreateInfo;
  using DescriptorUpdateTemplateCreateInfoKHR = DescriptorUpdateTemplateCreateInfo;
  struct DescriptorUpdateTemplateEntry;
  using DescriptorUpdateTemplateEntryKHR = DescriptorUpdateTemplateEntry;
  struct DeviceCreateInfo;
  struct DeviceEventInfoEXT;
  struct DeviceGeneratedCommandsFeaturesNVX;
  struct DeviceGeneratedCommandsLimitsNVX;
  struct DeviceGroupBindSparseInfo;
  using DeviceGroupBindSparseInfoKHR = DeviceGroupBindSparseInfo;
  struct DeviceGroupCommandBufferBeginInfo;
  using DeviceGroupCommandBufferBeginInfoKHR = DeviceGroupCommandBufferBeginInfo;
  struct DeviceGroupDeviceCreateInfo;
  using DeviceGroupDeviceCreateInfoKHR = DeviceGroupDeviceCreateInfo;
  struct DeviceGroupPresentCapabilitiesKHR;
  struct DeviceGroupPresentInfoKHR;
  struct DeviceGroupRenderPassBeginInfo;
  using DeviceGroupRenderPassBeginInfoKHR = DeviceGroupRenderPassBeginInfo;
  struct DeviceGroupSubmitInfo;
  using DeviceGroupSubmitInfoKHR = DeviceGroupSubmitInfo;
  struct DeviceGroupSwapchainCreateInfoKHR;
  struct DeviceMemoryOverallocationCreateInfoAMD;
  struct DeviceQueueCreateInfo;
  struct DeviceQueueGlobalPriorityCreateInfoEXT;
  struct DeviceQueueInfo2;
  struct DispatchIndirectCommand;
  struct DisplayEventInfoEXT;
  struct DisplayModeCreateInfoKHR;
  struct DisplayModeParametersKHR;
  struct DisplayModeProperties2KHR;
  struct DisplayModePropertiesKHR;
  struct DisplayNativeHdrSurfaceCapabilitiesAMD;
  struct DisplayPlaneCapabilities2KHR;
  struct DisplayPlaneCapabilitiesKHR;
  struct DisplayPlaneInfo2KHR;
  struct DisplayPlaneProperties2KHR;
  struct DisplayPlanePropertiesKHR;
  struct DisplayPowerInfoEXT;
  struct DisplayPresentInfoKHR;
  struct DisplayProperties2KHR;
  struct DisplayPropertiesKHR;
  struct DisplaySurfaceCreateInfoKHR;
  struct DrawIndexedIndirectCommand;
  struct DrawIndirectCommand;
  struct DrawMeshTasksIndirectCommandNV;
  struct DrmFormatModifierPropertiesEXT;
  struct DrmFormatModifierPropertiesListEXT;
  struct EventCreateInfo;
  struct ExportFenceCreateInfo;
  using ExportFenceCreateInfoKHR = ExportFenceCreateInfo;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ExportFenceWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct ExportMemoryAllocateInfo;
  using ExportMemoryAllocateInfoKHR = ExportMemoryAllocateInfo;
  struct ExportMemoryAllocateInfoNV;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ExportMemoryWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ExportMemoryWin32HandleInfoNV;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct ExportSemaphoreCreateInfo;
  using ExportSemaphoreCreateInfoKHR = ExportSemaphoreCreateInfo;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ExportSemaphoreWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct ExtensionProperties;
  struct Extent2D;
  struct Extent3D;
  struct ExternalBufferProperties;
  using ExternalBufferPropertiesKHR = ExternalBufferProperties;
  struct ExternalFenceProperties;
  using ExternalFencePropertiesKHR = ExternalFenceProperties;
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  struct ExternalFormatANDROID;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
  struct ExternalImageFormatProperties;
  using ExternalImageFormatPropertiesKHR = ExternalImageFormatProperties;
  struct ExternalImageFormatPropertiesNV;
  struct ExternalMemoryBufferCreateInfo;
  using ExternalMemoryBufferCreateInfoKHR = ExternalMemoryBufferCreateInfo;
  struct ExternalMemoryImageCreateInfo;
  using ExternalMemoryImageCreateInfoKHR = ExternalMemoryImageCreateInfo;
  struct ExternalMemoryImageCreateInfoNV;
  struct ExternalMemoryProperties;
  using ExternalMemoryPropertiesKHR = ExternalMemoryProperties;
  struct ExternalSemaphoreProperties;
  using ExternalSemaphorePropertiesKHR = ExternalSemaphoreProperties;
  struct FenceCreateInfo;
  struct FenceGetFdInfoKHR;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct FenceGetWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct FilterCubicImageViewImageFormatPropertiesEXT;
  struct FormatProperties;
  struct FormatProperties2;
  using FormatProperties2KHR = FormatProperties2;
  struct FramebufferAttachmentImageInfoKHR;
  struct FramebufferAttachmentsCreateInfoKHR;
  struct FramebufferCreateInfo;
  struct FramebufferMixedSamplesCombinationNV;
  struct GeometryAABBNV;
  struct GeometryDataNV;
  struct GeometryNV;
  struct GeometryTrianglesNV;
  struct GraphicsPipelineCreateInfo;
  struct HdrMetadataEXT;
  struct HeadlessSurfaceCreateInfoEXT;
#ifdef VK_USE_PLATFORM_IOS_MVK
  struct IOSSurfaceCreateInfoMVK;
#endif /*VK_USE_PLATFORM_IOS_MVK*/
  struct ImageBlit;
  struct ImageCopy;
  struct ImageCreateInfo;
  struct ImageDrmFormatModifierExplicitCreateInfoEXT;
  struct ImageDrmFormatModifierListCreateInfoEXT;
  struct ImageDrmFormatModifierPropertiesEXT;
  struct ImageFormatListCreateInfoKHR;
  struct ImageFormatProperties;
  struct ImageFormatProperties2;
  using ImageFormatProperties2KHR = ImageFormatProperties2;
  struct ImageMemoryBarrier;
  struct ImageMemoryRequirementsInfo2;
  using ImageMemoryRequirementsInfo2KHR = ImageMemoryRequirementsInfo2;
#ifdef VK_USE_PLATFORM_FUCHSIA
  struct ImagePipeSurfaceCreateInfoFUCHSIA;
#endif /*VK_USE_PLATFORM_FUCHSIA*/
  struct ImagePlaneMemoryRequirementsInfo;
  using ImagePlaneMemoryRequirementsInfoKHR = ImagePlaneMemoryRequirementsInfo;
  struct ImageResolve;
  struct ImageSparseMemoryRequirementsInfo2;
  using ImageSparseMemoryRequirementsInfo2KHR = ImageSparseMemoryRequirementsInfo2;
  struct ImageStencilUsageCreateInfoEXT;
  struct ImageSubresource;
  struct ImageSubresourceLayers;
  struct ImageSubresourceRange;
  struct ImageSwapchainCreateInfoKHR;
  struct ImageViewASTCDecodeModeEXT;
  struct ImageViewCreateInfo;
  struct ImageViewHandleInfoNVX;
  struct ImageViewUsageCreateInfo;
  using ImageViewUsageCreateInfoKHR = ImageViewUsageCreateInfo;
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  struct ImportAndroidHardwareBufferInfoANDROID;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
  struct ImportFenceFdInfoKHR;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ImportFenceWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct ImportMemoryFdInfoKHR;
  struct ImportMemoryHostPointerInfoEXT;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ImportMemoryWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ImportMemoryWin32HandleInfoNV;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct ImportSemaphoreFdInfoKHR;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct ImportSemaphoreWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct IndirectCommandsLayoutCreateInfoNVX;
  struct IndirectCommandsLayoutTokenNVX;
  struct IndirectCommandsTokenNVX;
  struct InitializePerformanceApiInfoINTEL;
  struct InputAttachmentAspectReference;
  using InputAttachmentAspectReferenceKHR = InputAttachmentAspectReference;
  struct InstanceCreateInfo;
  struct LayerProperties;
#ifdef VK_USE_PLATFORM_MACOS_MVK
  struct MacOSSurfaceCreateInfoMVK;
#endif /*VK_USE_PLATFORM_MACOS_MVK*/
  struct MappedMemoryRange;
  struct MemoryAllocateFlagsInfo;
  using MemoryAllocateFlagsInfoKHR = MemoryAllocateFlagsInfo;
  struct MemoryAllocateInfo;
  struct MemoryBarrier;
  struct MemoryDedicatedAllocateInfo;
  using MemoryDedicatedAllocateInfoKHR = MemoryDedicatedAllocateInfo;
  struct MemoryDedicatedRequirements;
  using MemoryDedicatedRequirementsKHR = MemoryDedicatedRequirements;
  struct MemoryFdPropertiesKHR;
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  struct MemoryGetAndroidHardwareBufferInfoANDROID;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
  struct MemoryGetFdInfoKHR;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct MemoryGetWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct MemoryHeap;
  struct MemoryHostPointerPropertiesEXT;
  struct MemoryPriorityAllocateInfoEXT;
  struct MemoryRequirements;
  struct MemoryRequirements2;
  using MemoryRequirements2KHR = MemoryRequirements2;
  struct MemoryType;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct MemoryWin32HandlePropertiesKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_METAL_EXT
  struct MetalSurfaceCreateInfoEXT;
#endif /*VK_USE_PLATFORM_METAL_EXT*/
  struct MultisamplePropertiesEXT;
  struct ObjectTableCreateInfoNVX;
  struct ObjectTableDescriptorSetEntryNVX;
  struct ObjectTableEntryNVX;
  struct ObjectTableIndexBufferEntryNVX;
  struct ObjectTablePipelineEntryNVX;
  struct ObjectTablePushConstantEntryNVX;
  struct ObjectTableVertexBufferEntryNVX;
  struct Offset2D;
  struct Offset3D;
  struct PastPresentationTimingGOOGLE;
  struct PerformanceConfigurationAcquireInfoINTEL;
  struct PerformanceMarkerInfoINTEL;
  struct PerformanceOverrideInfoINTEL;
  struct PerformanceStreamMarkerInfoINTEL;
  union PerformanceValueDataINTEL;
  struct PerformanceValueINTEL;
  struct PhysicalDevice16BitStorageFeatures;
  using PhysicalDevice16BitStorageFeaturesKHR = PhysicalDevice16BitStorageFeatures;
  struct PhysicalDevice8BitStorageFeaturesKHR;
  struct PhysicalDeviceASTCDecodeFeaturesEXT;
  struct PhysicalDeviceBlendOperationAdvancedFeaturesEXT;
  struct PhysicalDeviceBlendOperationAdvancedPropertiesEXT;
  struct PhysicalDeviceBufferDeviceAddressFeaturesEXT;
  using PhysicalDeviceBufferAddressFeaturesEXT = PhysicalDeviceBufferDeviceAddressFeaturesEXT;
  struct PhysicalDeviceCoherentMemoryFeaturesAMD;
  struct PhysicalDeviceComputeShaderDerivativesFeaturesNV;
  struct PhysicalDeviceConditionalRenderingFeaturesEXT;
  struct PhysicalDeviceConservativeRasterizationPropertiesEXT;
  struct PhysicalDeviceCooperativeMatrixFeaturesNV;
  struct PhysicalDeviceCooperativeMatrixPropertiesNV;
  struct PhysicalDeviceCornerSampledImageFeaturesNV;
  struct PhysicalDeviceCoverageReductionModeFeaturesNV;
  struct PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV;
  struct PhysicalDeviceDepthClipEnableFeaturesEXT;
  struct PhysicalDeviceDepthStencilResolvePropertiesKHR;
  struct PhysicalDeviceDescriptorIndexingFeaturesEXT;
  struct PhysicalDeviceDescriptorIndexingPropertiesEXT;
  struct PhysicalDeviceDiscardRectanglePropertiesEXT;
  struct PhysicalDeviceDriverPropertiesKHR;
  struct PhysicalDeviceExclusiveScissorFeaturesNV;
  struct PhysicalDeviceExternalBufferInfo;
  using PhysicalDeviceExternalBufferInfoKHR = PhysicalDeviceExternalBufferInfo;
  struct PhysicalDeviceExternalFenceInfo;
  using PhysicalDeviceExternalFenceInfoKHR = PhysicalDeviceExternalFenceInfo;
  struct PhysicalDeviceExternalImageFormatInfo;
  using PhysicalDeviceExternalImageFormatInfoKHR = PhysicalDeviceExternalImageFormatInfo;
  struct PhysicalDeviceExternalMemoryHostPropertiesEXT;
  struct PhysicalDeviceExternalSemaphoreInfo;
  using PhysicalDeviceExternalSemaphoreInfoKHR = PhysicalDeviceExternalSemaphoreInfo;
  struct PhysicalDeviceFeatures;
  struct PhysicalDeviceFeatures2;
  using PhysicalDeviceFeatures2KHR = PhysicalDeviceFeatures2;
  struct PhysicalDeviceFloatControlsPropertiesKHR;
  struct PhysicalDeviceFragmentDensityMapFeaturesEXT;
  struct PhysicalDeviceFragmentDensityMapPropertiesEXT;
  struct PhysicalDeviceFragmentShaderBarycentricFeaturesNV;
  struct PhysicalDeviceFragmentShaderInterlockFeaturesEXT;
  struct PhysicalDeviceGroupProperties;
  using PhysicalDeviceGroupPropertiesKHR = PhysicalDeviceGroupProperties;
  struct PhysicalDeviceHostQueryResetFeaturesEXT;
  struct PhysicalDeviceIDProperties;
  using PhysicalDeviceIDPropertiesKHR = PhysicalDeviceIDProperties;
  struct PhysicalDeviceImageDrmFormatModifierInfoEXT;
  struct PhysicalDeviceImageFormatInfo2;
  using PhysicalDeviceImageFormatInfo2KHR = PhysicalDeviceImageFormatInfo2;
  struct PhysicalDeviceImageViewImageFormatInfoEXT;
  struct PhysicalDeviceImagelessFramebufferFeaturesKHR;
  struct PhysicalDeviceIndexTypeUint8FeaturesEXT;
  struct PhysicalDeviceInlineUniformBlockFeaturesEXT;
  struct PhysicalDeviceInlineUniformBlockPropertiesEXT;
  struct PhysicalDeviceLimits;
  struct PhysicalDeviceLineRasterizationFeaturesEXT;
  struct PhysicalDeviceLineRasterizationPropertiesEXT;
  struct PhysicalDeviceMaintenance3Properties;
  using PhysicalDeviceMaintenance3PropertiesKHR = PhysicalDeviceMaintenance3Properties;
  struct PhysicalDeviceMemoryBudgetPropertiesEXT;
  struct PhysicalDeviceMemoryPriorityFeaturesEXT;
  struct PhysicalDeviceMemoryProperties;
  struct PhysicalDeviceMemoryProperties2;
  using PhysicalDeviceMemoryProperties2KHR = PhysicalDeviceMemoryProperties2;
  struct PhysicalDeviceMeshShaderFeaturesNV;
  struct PhysicalDeviceMeshShaderPropertiesNV;
  struct PhysicalDeviceMultiviewFeatures;
  using PhysicalDeviceMultiviewFeaturesKHR = PhysicalDeviceMultiviewFeatures;
  struct PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX;
  struct PhysicalDeviceMultiviewProperties;
  using PhysicalDeviceMultiviewPropertiesKHR = PhysicalDeviceMultiviewProperties;
  struct PhysicalDevicePCIBusInfoPropertiesEXT;
  struct PhysicalDevicePipelineExecutablePropertiesFeaturesKHR;
  struct PhysicalDevicePointClippingProperties;
  using PhysicalDevicePointClippingPropertiesKHR = PhysicalDevicePointClippingProperties;
  struct PhysicalDeviceProperties;
  struct PhysicalDeviceProperties2;
  using PhysicalDeviceProperties2KHR = PhysicalDeviceProperties2;
  struct PhysicalDeviceProtectedMemoryFeatures;
  struct PhysicalDeviceProtectedMemoryProperties;
  struct PhysicalDevicePushDescriptorPropertiesKHR;
  struct PhysicalDeviceRayTracingPropertiesNV;
  struct PhysicalDeviceRepresentativeFragmentTestFeaturesNV;
  struct PhysicalDeviceSampleLocationsPropertiesEXT;
  struct PhysicalDeviceSamplerFilterMinmaxPropertiesEXT;
  struct PhysicalDeviceSamplerYcbcrConversionFeatures;
  using PhysicalDeviceSamplerYcbcrConversionFeaturesKHR = PhysicalDeviceSamplerYcbcrConversionFeatures;
  struct PhysicalDeviceScalarBlockLayoutFeaturesEXT;
  struct PhysicalDeviceShaderAtomicInt64FeaturesKHR;
  struct PhysicalDeviceShaderClockFeaturesKHR;
  struct PhysicalDeviceShaderCoreProperties2AMD;
  struct PhysicalDeviceShaderCorePropertiesAMD;
  struct PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT;
  struct PhysicalDeviceShaderDrawParametersFeatures;
  using PhysicalDeviceShaderDrawParameterFeatures = PhysicalDeviceShaderDrawParametersFeatures;
  struct PhysicalDeviceShaderFloat16Int8FeaturesKHR;
  using PhysicalDeviceFloat16Int8FeaturesKHR = PhysicalDeviceShaderFloat16Int8FeaturesKHR;
  struct PhysicalDeviceShaderImageFootprintFeaturesNV;
  struct PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL;
  struct PhysicalDeviceShaderSMBuiltinsFeaturesNV;
  struct PhysicalDeviceShaderSMBuiltinsPropertiesNV;
  struct PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR;
  struct PhysicalDeviceShadingRateImageFeaturesNV;
  struct PhysicalDeviceShadingRateImagePropertiesNV;
  struct PhysicalDeviceSparseImageFormatInfo2;
  using PhysicalDeviceSparseImageFormatInfo2KHR = PhysicalDeviceSparseImageFormatInfo2;
  struct PhysicalDeviceSparseProperties;
  struct PhysicalDeviceSubgroupProperties;
  struct PhysicalDeviceSubgroupSizeControlFeaturesEXT;
  struct PhysicalDeviceSubgroupSizeControlPropertiesEXT;
  struct PhysicalDeviceSurfaceInfo2KHR;
  struct PhysicalDeviceTexelBufferAlignmentFeaturesEXT;
  struct PhysicalDeviceTexelBufferAlignmentPropertiesEXT;
  struct PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT;
  struct PhysicalDeviceTimelineSemaphoreFeaturesKHR;
  struct PhysicalDeviceTimelineSemaphorePropertiesKHR;
  struct PhysicalDeviceTransformFeedbackFeaturesEXT;
  struct PhysicalDeviceTransformFeedbackPropertiesEXT;
  struct PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR;
  struct PhysicalDeviceVariablePointersFeatures;
  using PhysicalDeviceVariablePointersFeaturesKHR = PhysicalDeviceVariablePointersFeatures;
  using PhysicalDeviceVariablePointerFeaturesKHR = PhysicalDeviceVariablePointersFeatures;
  using PhysicalDeviceVariablePointerFeatures = PhysicalDeviceVariablePointersFeatures;
  struct PhysicalDeviceVertexAttributeDivisorFeaturesEXT;
  struct PhysicalDeviceVertexAttributeDivisorPropertiesEXT;
  struct PhysicalDeviceVulkanMemoryModelFeaturesKHR;
  struct PhysicalDeviceYcbcrImageArraysFeaturesEXT;
  struct PipelineCacheCreateInfo;
  struct PipelineColorBlendAdvancedStateCreateInfoEXT;
  struct PipelineColorBlendAttachmentState;
  struct PipelineColorBlendStateCreateInfo;
  struct PipelineCompilerControlCreateInfoAMD;
  struct PipelineCoverageModulationStateCreateInfoNV;
  struct PipelineCoverageReductionStateCreateInfoNV;
  struct PipelineCoverageToColorStateCreateInfoNV;
  struct PipelineCreationFeedbackCreateInfoEXT;
  struct PipelineCreationFeedbackEXT;
  struct PipelineDepthStencilStateCreateInfo;
  struct PipelineDiscardRectangleStateCreateInfoEXT;
  struct PipelineDynamicStateCreateInfo;
  struct PipelineExecutableInfoKHR;
  struct PipelineExecutableInternalRepresentationKHR;
  struct PipelineExecutablePropertiesKHR;
  struct PipelineExecutableStatisticKHR;
  union PipelineExecutableStatisticValueKHR;
  struct PipelineInfoKHR;
  struct PipelineInputAssemblyStateCreateInfo;
  struct PipelineLayoutCreateInfo;
  struct PipelineMultisampleStateCreateInfo;
  struct PipelineRasterizationConservativeStateCreateInfoEXT;
  struct PipelineRasterizationDepthClipStateCreateInfoEXT;
  struct PipelineRasterizationLineStateCreateInfoEXT;
  struct PipelineRasterizationStateCreateInfo;
  struct PipelineRasterizationStateRasterizationOrderAMD;
  struct PipelineRasterizationStateStreamCreateInfoEXT;
  struct PipelineRepresentativeFragmentTestStateCreateInfoNV;
  struct PipelineSampleLocationsStateCreateInfoEXT;
  struct PipelineShaderStageCreateInfo;
  struct PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT;
  struct PipelineTessellationDomainOriginStateCreateInfo;
  using PipelineTessellationDomainOriginStateCreateInfoKHR = PipelineTessellationDomainOriginStateCreateInfo;
  struct PipelineTessellationStateCreateInfo;
  struct PipelineVertexInputDivisorStateCreateInfoEXT;
  struct PipelineVertexInputStateCreateInfo;
  struct PipelineViewportCoarseSampleOrderStateCreateInfoNV;
  struct PipelineViewportExclusiveScissorStateCreateInfoNV;
  struct PipelineViewportShadingRateImageStateCreateInfoNV;
  struct PipelineViewportStateCreateInfo;
  struct PipelineViewportSwizzleStateCreateInfoNV;
  struct PipelineViewportWScalingStateCreateInfoNV;
#ifdef VK_USE_PLATFORM_GGP
  struct PresentFrameTokenGGP;
#endif /*VK_USE_PLATFORM_GGP*/
  struct PresentInfoKHR;
  struct PresentRegionKHR;
  struct PresentRegionsKHR;
  struct PresentTimeGOOGLE;
  struct PresentTimesInfoGOOGLE;
  struct ProtectedSubmitInfo;
  struct PushConstantRange;
  struct QueryPoolCreateInfo;
  struct QueryPoolCreateInfoINTEL;
  struct QueueFamilyCheckpointPropertiesNV;
  struct QueueFamilyProperties;
  struct QueueFamilyProperties2;
  using QueueFamilyProperties2KHR = QueueFamilyProperties2;
  struct RayTracingPipelineCreateInfoNV;
  struct RayTracingShaderGroupCreateInfoNV;
  struct Rect2D;
  struct RectLayerKHR;
  struct RefreshCycleDurationGOOGLE;
  struct RenderPassAttachmentBeginInfoKHR;
  struct RenderPassBeginInfo;
  struct RenderPassCreateInfo;
  struct RenderPassCreateInfo2KHR;
  struct RenderPassFragmentDensityMapCreateInfoEXT;
  struct RenderPassInputAttachmentAspectCreateInfo;
  using RenderPassInputAttachmentAspectCreateInfoKHR = RenderPassInputAttachmentAspectCreateInfo;
  struct RenderPassMultiviewCreateInfo;
  using RenderPassMultiviewCreateInfoKHR = RenderPassMultiviewCreateInfo;
  struct RenderPassSampleLocationsBeginInfoEXT;
  struct SampleLocationEXT;
  struct SampleLocationsInfoEXT;
  struct SamplerCreateInfo;
  struct SamplerReductionModeCreateInfoEXT;
  struct SamplerYcbcrConversionCreateInfo;
  using SamplerYcbcrConversionCreateInfoKHR = SamplerYcbcrConversionCreateInfo;
  struct SamplerYcbcrConversionImageFormatProperties;
  using SamplerYcbcrConversionImageFormatPropertiesKHR = SamplerYcbcrConversionImageFormatProperties;
  struct SamplerYcbcrConversionInfo;
  using SamplerYcbcrConversionInfoKHR = SamplerYcbcrConversionInfo;
  struct SemaphoreCreateInfo;
  struct SemaphoreGetFdInfoKHR;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct SemaphoreGetWin32HandleInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct SemaphoreSignalInfoKHR;
  struct SemaphoreTypeCreateInfoKHR;
  struct SemaphoreWaitInfoKHR;
  struct ShaderModuleCreateInfo;
  struct ShaderModuleValidationCacheCreateInfoEXT;
  struct ShaderResourceUsageAMD;
  struct ShaderStatisticsInfoAMD;
  struct ShadingRatePaletteNV;
  struct SharedPresentSurfaceCapabilitiesKHR;
  struct SparseBufferMemoryBindInfo;
  struct SparseImageFormatProperties;
  struct SparseImageFormatProperties2;
  using SparseImageFormatProperties2KHR = SparseImageFormatProperties2;
  struct SparseImageMemoryBind;
  struct SparseImageMemoryBindInfo;
  struct SparseImageMemoryRequirements;
  struct SparseImageMemoryRequirements2;
  using SparseImageMemoryRequirements2KHR = SparseImageMemoryRequirements2;
  struct SparseImageOpaqueMemoryBindInfo;
  struct SparseMemoryBind;
  struct SpecializationInfo;
  struct SpecializationMapEntry;
  struct StencilOpState;
#ifdef VK_USE_PLATFORM_GGP
  struct StreamDescriptorSurfaceCreateInfoGGP;
#endif /*VK_USE_PLATFORM_GGP*/
  struct SubmitInfo;
  struct SubpassBeginInfoKHR;
  struct SubpassDependency;
  struct SubpassDependency2KHR;
  struct SubpassDescription;
  struct SubpassDescription2KHR;
  struct SubpassDescriptionDepthStencilResolveKHR;
  struct SubpassEndInfoKHR;
  struct SubpassSampleLocationsEXT;
  struct SubresourceLayout;
  struct SurfaceCapabilities2EXT;
  struct SurfaceCapabilities2KHR;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct SurfaceCapabilitiesFullScreenExclusiveEXT;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct SurfaceCapabilitiesKHR;
  struct SurfaceFormat2KHR;
  struct SurfaceFormatKHR;
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct SurfaceFullScreenExclusiveInfoEXT;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct SurfaceFullScreenExclusiveWin32InfoEXT;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct SurfaceProtectedCapabilitiesKHR;
  struct SwapchainCounterCreateInfoEXT;
  struct SwapchainCreateInfoKHR;
  struct SwapchainDisplayNativeHdrCreateInfoAMD;
  struct TextureLODGatherFormatPropertiesAMD;
  struct TimelineSemaphoreSubmitInfoKHR;
  struct ValidationCacheCreateInfoEXT;
  struct ValidationFeaturesEXT;
  struct ValidationFlagsEXT;
  struct VertexInputAttributeDescription;
  struct VertexInputBindingDescription;
  struct VertexInputBindingDivisorDescriptionEXT;
#ifdef VK_USE_PLATFORM_VI_NN
  struct ViSurfaceCreateInfoNN;
#endif /*VK_USE_PLATFORM_VI_NN*/
  struct Viewport;
  struct ViewportSwizzleNV;
  struct ViewportWScalingNV;
#ifdef VK_USE_PLATFORM_WAYLAND_KHR
  struct WaylandSurfaceCreateInfoKHR;
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct Win32KeyedMutexAcquireReleaseInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct Win32KeyedMutexAcquireReleaseInfoNV;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  struct Win32SurfaceCreateInfoKHR;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  struct WriteDescriptorSet;
  struct WriteDescriptorSetAccelerationStructureNV;
  struct WriteDescriptorSetInlineUniformBlockEXT;
  struct XYColorEXT;
#ifdef VK_USE_PLATFORM_XCB_KHR
  struct XcbSurfaceCreateInfoKHR;
#endif /*VK_USE_PLATFORM_XCB_KHR*/
#ifdef VK_USE_PLATFORM_XLIB_KHR
  struct XlibSurfaceCreateInfoKHR;
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

  class SurfaceKHR
  {
  public:
    using CType = VkSurfaceKHR;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eSurfaceKHR;

  public:
    VULKAN_HPP_CONSTEXPR SurfaceKHR() VULKAN_HPP_NOEXCEPT
      : m_surfaceKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR SurfaceKHR( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_surfaceKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT SurfaceKHR( VkSurfaceKHR surfaceKHR ) VULKAN_HPP_NOEXCEPT
      : m_surfaceKHR( surfaceKHR )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    SurfaceKHR & operator=(VkSurfaceKHR surfaceKHR) VULKAN_HPP_NOEXCEPT
    {
      m_surfaceKHR = surfaceKHR;
      return *this;
    }
#endif

    SurfaceKHR & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_surfaceKHR = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( SurfaceKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_surfaceKHR == rhs.m_surfaceKHR;
    }

    bool operator!=(SurfaceKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_surfaceKHR != rhs.m_surfaceKHR;
    }

    bool operator<(SurfaceKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_surfaceKHR < rhs.m_surfaceKHR;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkSurfaceKHR() const VULKAN_HPP_NOEXCEPT
    {
      return m_surfaceKHR;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_surfaceKHR != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_surfaceKHR == VK_NULL_HANDLE;
    }

  private:
    VkSurfaceKHR m_surfaceKHR;
  };
  static_assert( sizeof( SurfaceKHR ) == sizeof( VkSurfaceKHR ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eSurfaceKHR>
  {
    using type = SurfaceKHR;
  };

  class DebugReportCallbackEXT
  {
  public:
    using CType = VkDebugReportCallbackEXT;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDebugReportCallbackEXT;

  public:
    VULKAN_HPP_CONSTEXPR DebugReportCallbackEXT() VULKAN_HPP_NOEXCEPT
      : m_debugReportCallbackEXT(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DebugReportCallbackEXT( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_debugReportCallbackEXT(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DebugReportCallbackEXT( VkDebugReportCallbackEXT debugReportCallbackEXT ) VULKAN_HPP_NOEXCEPT
      : m_debugReportCallbackEXT( debugReportCallbackEXT )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DebugReportCallbackEXT & operator=(VkDebugReportCallbackEXT debugReportCallbackEXT) VULKAN_HPP_NOEXCEPT
    {
      m_debugReportCallbackEXT = debugReportCallbackEXT;
      return *this;
    }
#endif

    DebugReportCallbackEXT & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_debugReportCallbackEXT = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DebugReportCallbackEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_debugReportCallbackEXT == rhs.m_debugReportCallbackEXT;
    }

    bool operator!=(DebugReportCallbackEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_debugReportCallbackEXT != rhs.m_debugReportCallbackEXT;
    }

    bool operator<(DebugReportCallbackEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_debugReportCallbackEXT < rhs.m_debugReportCallbackEXT;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDebugReportCallbackEXT() const VULKAN_HPP_NOEXCEPT
    {
      return m_debugReportCallbackEXT;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_debugReportCallbackEXT != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_debugReportCallbackEXT == VK_NULL_HANDLE;
    }

  private:
    VkDebugReportCallbackEXT m_debugReportCallbackEXT;
  };
  static_assert( sizeof( DebugReportCallbackEXT ) == sizeof( VkDebugReportCallbackEXT ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDebugReportCallbackEXT>
  {
    using type = DebugReportCallbackEXT;
  };

  class DebugUtilsMessengerEXT
  {
  public:
    using CType = VkDebugUtilsMessengerEXT;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDebugUtilsMessengerEXT;

  public:
    VULKAN_HPP_CONSTEXPR DebugUtilsMessengerEXT() VULKAN_HPP_NOEXCEPT
      : m_debugUtilsMessengerEXT(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DebugUtilsMessengerEXT( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_debugUtilsMessengerEXT(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DebugUtilsMessengerEXT( VkDebugUtilsMessengerEXT debugUtilsMessengerEXT ) VULKAN_HPP_NOEXCEPT
      : m_debugUtilsMessengerEXT( debugUtilsMessengerEXT )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DebugUtilsMessengerEXT & operator=(VkDebugUtilsMessengerEXT debugUtilsMessengerEXT) VULKAN_HPP_NOEXCEPT
    {
      m_debugUtilsMessengerEXT = debugUtilsMessengerEXT;
      return *this;
    }
#endif

    DebugUtilsMessengerEXT & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_debugUtilsMessengerEXT = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DebugUtilsMessengerEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_debugUtilsMessengerEXT == rhs.m_debugUtilsMessengerEXT;
    }

    bool operator!=(DebugUtilsMessengerEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_debugUtilsMessengerEXT != rhs.m_debugUtilsMessengerEXT;
    }

    bool operator<(DebugUtilsMessengerEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_debugUtilsMessengerEXT < rhs.m_debugUtilsMessengerEXT;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDebugUtilsMessengerEXT() const VULKAN_HPP_NOEXCEPT
    {
      return m_debugUtilsMessengerEXT;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_debugUtilsMessengerEXT != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_debugUtilsMessengerEXT == VK_NULL_HANDLE;
    }

  private:
    VkDebugUtilsMessengerEXT m_debugUtilsMessengerEXT;
  };
  static_assert( sizeof( DebugUtilsMessengerEXT ) == sizeof( VkDebugUtilsMessengerEXT ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDebugUtilsMessengerEXT>
  {
    using type = DebugUtilsMessengerEXT;
  };

  class DisplayKHR
  {
  public:
    using CType = VkDisplayKHR;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDisplayKHR;

  public:
    VULKAN_HPP_CONSTEXPR DisplayKHR() VULKAN_HPP_NOEXCEPT
      : m_displayKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DisplayKHR( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_displayKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DisplayKHR( VkDisplayKHR displayKHR ) VULKAN_HPP_NOEXCEPT
      : m_displayKHR( displayKHR )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DisplayKHR & operator=(VkDisplayKHR displayKHR) VULKAN_HPP_NOEXCEPT
    {
      m_displayKHR = displayKHR;
      return *this;
    }
#endif

    DisplayKHR & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_displayKHR = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DisplayKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_displayKHR == rhs.m_displayKHR;
    }

    bool operator!=(DisplayKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_displayKHR != rhs.m_displayKHR;
    }

    bool operator<(DisplayKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_displayKHR < rhs.m_displayKHR;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDisplayKHR() const VULKAN_HPP_NOEXCEPT
    {
      return m_displayKHR;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_displayKHR != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_displayKHR == VK_NULL_HANDLE;
    }

  private:
    VkDisplayKHR m_displayKHR;
  };
  static_assert( sizeof( DisplayKHR ) == sizeof( VkDisplayKHR ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDisplayKHR>
  {
    using type = DisplayKHR;
  };

  class SwapchainKHR
  {
  public:
    using CType = VkSwapchainKHR;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eSwapchainKHR;

  public:
    VULKAN_HPP_CONSTEXPR SwapchainKHR() VULKAN_HPP_NOEXCEPT
      : m_swapchainKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR SwapchainKHR( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_swapchainKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT SwapchainKHR( VkSwapchainKHR swapchainKHR ) VULKAN_HPP_NOEXCEPT
      : m_swapchainKHR( swapchainKHR )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    SwapchainKHR & operator=(VkSwapchainKHR swapchainKHR) VULKAN_HPP_NOEXCEPT
    {
      m_swapchainKHR = swapchainKHR;
      return *this;
    }
#endif

    SwapchainKHR & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_swapchainKHR = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( SwapchainKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_swapchainKHR == rhs.m_swapchainKHR;
    }

    bool operator!=(SwapchainKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_swapchainKHR != rhs.m_swapchainKHR;
    }

    bool operator<(SwapchainKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_swapchainKHR < rhs.m_swapchainKHR;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkSwapchainKHR() const VULKAN_HPP_NOEXCEPT
    {
      return m_swapchainKHR;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_swapchainKHR != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_swapchainKHR == VK_NULL_HANDLE;
    }

  private:
    VkSwapchainKHR m_swapchainKHR;
  };
  static_assert( sizeof( SwapchainKHR ) == sizeof( VkSwapchainKHR ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eSwapchainKHR>
  {
    using type = SwapchainKHR;
  };

  class Semaphore
  {
  public:
    using CType = VkSemaphore;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eSemaphore;

  public:
    VULKAN_HPP_CONSTEXPR Semaphore() VULKAN_HPP_NOEXCEPT
      : m_semaphore(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Semaphore( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_semaphore(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Semaphore( VkSemaphore semaphore ) VULKAN_HPP_NOEXCEPT
      : m_semaphore( semaphore )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Semaphore & operator=(VkSemaphore semaphore) VULKAN_HPP_NOEXCEPT
    {
      m_semaphore = semaphore;
      return *this;
    }
#endif

    Semaphore & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_semaphore = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Semaphore const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_semaphore == rhs.m_semaphore;
    }

    bool operator!=(Semaphore const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_semaphore != rhs.m_semaphore;
    }

    bool operator<(Semaphore const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_semaphore < rhs.m_semaphore;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkSemaphore() const VULKAN_HPP_NOEXCEPT
    {
      return m_semaphore;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_semaphore != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_semaphore == VK_NULL_HANDLE;
    }

  private:
    VkSemaphore m_semaphore;
  };
  static_assert( sizeof( Semaphore ) == sizeof( VkSemaphore ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eSemaphore>
  {
    using type = Semaphore;
  };

  class Fence
  {
  public:
    using CType = VkFence;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eFence;

  public:
    VULKAN_HPP_CONSTEXPR Fence() VULKAN_HPP_NOEXCEPT
      : m_fence(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Fence( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_fence(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Fence( VkFence fence ) VULKAN_HPP_NOEXCEPT
      : m_fence( fence )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Fence & operator=(VkFence fence) VULKAN_HPP_NOEXCEPT
    {
      m_fence = fence;
      return *this;
    }
#endif

    Fence & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_fence = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Fence const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_fence == rhs.m_fence;
    }

    bool operator!=(Fence const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_fence != rhs.m_fence;
    }

    bool operator<(Fence const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_fence < rhs.m_fence;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkFence() const VULKAN_HPP_NOEXCEPT
    {
      return m_fence;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_fence != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_fence == VK_NULL_HANDLE;
    }

  private:
    VkFence m_fence;
  };
  static_assert( sizeof( Fence ) == sizeof( VkFence ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eFence>
  {
    using type = Fence;
  };

  class PerformanceConfigurationINTEL
  {
  public:
    using CType = VkPerformanceConfigurationINTEL;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::ePerformanceConfigurationINTEL;

  public:
    VULKAN_HPP_CONSTEXPR PerformanceConfigurationINTEL() VULKAN_HPP_NOEXCEPT
      : m_performanceConfigurationINTEL(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR PerformanceConfigurationINTEL( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_performanceConfigurationINTEL(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT PerformanceConfigurationINTEL( VkPerformanceConfigurationINTEL performanceConfigurationINTEL ) VULKAN_HPP_NOEXCEPT
      : m_performanceConfigurationINTEL( performanceConfigurationINTEL )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    PerformanceConfigurationINTEL & operator=(VkPerformanceConfigurationINTEL performanceConfigurationINTEL) VULKAN_HPP_NOEXCEPT
    {
      m_performanceConfigurationINTEL = performanceConfigurationINTEL;
      return *this;
    }
#endif

    PerformanceConfigurationINTEL & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_performanceConfigurationINTEL = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( PerformanceConfigurationINTEL const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_performanceConfigurationINTEL == rhs.m_performanceConfigurationINTEL;
    }

    bool operator!=(PerformanceConfigurationINTEL const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_performanceConfigurationINTEL != rhs.m_performanceConfigurationINTEL;
    }

    bool operator<(PerformanceConfigurationINTEL const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_performanceConfigurationINTEL < rhs.m_performanceConfigurationINTEL;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkPerformanceConfigurationINTEL() const VULKAN_HPP_NOEXCEPT
    {
      return m_performanceConfigurationINTEL;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_performanceConfigurationINTEL != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_performanceConfigurationINTEL == VK_NULL_HANDLE;
    }

  private:
    VkPerformanceConfigurationINTEL m_performanceConfigurationINTEL;
  };
  static_assert( sizeof( PerformanceConfigurationINTEL ) == sizeof( VkPerformanceConfigurationINTEL ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::ePerformanceConfigurationINTEL>
  {
    using type = PerformanceConfigurationINTEL;
  };

  class QueryPool
  {
  public:
    using CType = VkQueryPool;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eQueryPool;

  public:
    VULKAN_HPP_CONSTEXPR QueryPool() VULKAN_HPP_NOEXCEPT
      : m_queryPool(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR QueryPool( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_queryPool(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT QueryPool( VkQueryPool queryPool ) VULKAN_HPP_NOEXCEPT
      : m_queryPool( queryPool )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    QueryPool & operator=(VkQueryPool queryPool) VULKAN_HPP_NOEXCEPT
    {
      m_queryPool = queryPool;
      return *this;
    }
#endif

    QueryPool & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_queryPool = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( QueryPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_queryPool == rhs.m_queryPool;
    }

    bool operator!=(QueryPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_queryPool != rhs.m_queryPool;
    }

    bool operator<(QueryPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_queryPool < rhs.m_queryPool;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkQueryPool() const VULKAN_HPP_NOEXCEPT
    {
      return m_queryPool;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_queryPool != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_queryPool == VK_NULL_HANDLE;
    }

  private:
    VkQueryPool m_queryPool;
  };
  static_assert( sizeof( QueryPool ) == sizeof( VkQueryPool ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eQueryPool>
  {
    using type = QueryPool;
  };

  class Buffer
  {
  public:
    using CType = VkBuffer;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eBuffer;

  public:
    VULKAN_HPP_CONSTEXPR Buffer() VULKAN_HPP_NOEXCEPT
      : m_buffer(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Buffer( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_buffer(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Buffer( VkBuffer buffer ) VULKAN_HPP_NOEXCEPT
      : m_buffer( buffer )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Buffer & operator=(VkBuffer buffer) VULKAN_HPP_NOEXCEPT
    {
      m_buffer = buffer;
      return *this;
    }
#endif

    Buffer & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_buffer = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Buffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_buffer == rhs.m_buffer;
    }

    bool operator!=(Buffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_buffer != rhs.m_buffer;
    }

    bool operator<(Buffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_buffer < rhs.m_buffer;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkBuffer() const VULKAN_HPP_NOEXCEPT
    {
      return m_buffer;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_buffer != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_buffer == VK_NULL_HANDLE;
    }

  private:
    VkBuffer m_buffer;
  };
  static_assert( sizeof( Buffer ) == sizeof( VkBuffer ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eBuffer>
  {
    using type = Buffer;
  };

  class PipelineLayout
  {
  public:
    using CType = VkPipelineLayout;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::ePipelineLayout;

  public:
    VULKAN_HPP_CONSTEXPR PipelineLayout() VULKAN_HPP_NOEXCEPT
      : m_pipelineLayout(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR PipelineLayout( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_pipelineLayout(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT PipelineLayout( VkPipelineLayout pipelineLayout ) VULKAN_HPP_NOEXCEPT
      : m_pipelineLayout( pipelineLayout )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    PipelineLayout & operator=(VkPipelineLayout pipelineLayout) VULKAN_HPP_NOEXCEPT
    {
      m_pipelineLayout = pipelineLayout;
      return *this;
    }
#endif

    PipelineLayout & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_pipelineLayout = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( PipelineLayout const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineLayout == rhs.m_pipelineLayout;
    }

    bool operator!=(PipelineLayout const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineLayout != rhs.m_pipelineLayout;
    }

    bool operator<(PipelineLayout const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineLayout < rhs.m_pipelineLayout;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkPipelineLayout() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineLayout;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineLayout != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineLayout == VK_NULL_HANDLE;
    }

  private:
    VkPipelineLayout m_pipelineLayout;
  };
  static_assert( sizeof( PipelineLayout ) == sizeof( VkPipelineLayout ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::ePipelineLayout>
  {
    using type = PipelineLayout;
  };

  class DescriptorSet
  {
  public:
    using CType = VkDescriptorSet;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDescriptorSet;

  public:
    VULKAN_HPP_CONSTEXPR DescriptorSet() VULKAN_HPP_NOEXCEPT
      : m_descriptorSet(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DescriptorSet( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_descriptorSet(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DescriptorSet( VkDescriptorSet descriptorSet ) VULKAN_HPP_NOEXCEPT
      : m_descriptorSet( descriptorSet )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DescriptorSet & operator=(VkDescriptorSet descriptorSet) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorSet = descriptorSet;
      return *this;
    }
#endif

    DescriptorSet & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorSet = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DescriptorSet const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSet == rhs.m_descriptorSet;
    }

    bool operator!=(DescriptorSet const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSet != rhs.m_descriptorSet;
    }

    bool operator<(DescriptorSet const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSet < rhs.m_descriptorSet;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDescriptorSet() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSet;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSet != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSet == VK_NULL_HANDLE;
    }

  private:
    VkDescriptorSet m_descriptorSet;
  };
  static_assert( sizeof( DescriptorSet ) == sizeof( VkDescriptorSet ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDescriptorSet>
  {
    using type = DescriptorSet;
  };

  class Pipeline
  {
  public:
    using CType = VkPipeline;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::ePipeline;

  public:
    VULKAN_HPP_CONSTEXPR Pipeline() VULKAN_HPP_NOEXCEPT
      : m_pipeline(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Pipeline( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_pipeline(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Pipeline( VkPipeline pipeline ) VULKAN_HPP_NOEXCEPT
      : m_pipeline( pipeline )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Pipeline & operator=(VkPipeline pipeline) VULKAN_HPP_NOEXCEPT
    {
      m_pipeline = pipeline;
      return *this;
    }
#endif

    Pipeline & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_pipeline = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Pipeline const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipeline == rhs.m_pipeline;
    }

    bool operator!=(Pipeline const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipeline != rhs.m_pipeline;
    }

    bool operator<(Pipeline const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipeline < rhs.m_pipeline;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkPipeline() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipeline;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipeline != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipeline == VK_NULL_HANDLE;
    }

  private:
    VkPipeline m_pipeline;
  };
  static_assert( sizeof( Pipeline ) == sizeof( VkPipeline ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::ePipeline>
  {
    using type = Pipeline;
  };

  class ImageView
  {
  public:
    using CType = VkImageView;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eImageView;

  public:
    VULKAN_HPP_CONSTEXPR ImageView() VULKAN_HPP_NOEXCEPT
      : m_imageView(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR ImageView( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_imageView(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT ImageView( VkImageView imageView ) VULKAN_HPP_NOEXCEPT
      : m_imageView( imageView )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    ImageView & operator=(VkImageView imageView) VULKAN_HPP_NOEXCEPT
    {
      m_imageView = imageView;
      return *this;
    }
#endif

    ImageView & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_imageView = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( ImageView const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_imageView == rhs.m_imageView;
    }

    bool operator!=(ImageView const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_imageView != rhs.m_imageView;
    }

    bool operator<(ImageView const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_imageView < rhs.m_imageView;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkImageView() const VULKAN_HPP_NOEXCEPT
    {
      return m_imageView;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_imageView != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_imageView == VK_NULL_HANDLE;
    }

  private:
    VkImageView m_imageView;
  };
  static_assert( sizeof( ImageView ) == sizeof( VkImageView ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eImageView>
  {
    using type = ImageView;
  };

  class Image
  {
  public:
    using CType = VkImage;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eImage;

  public:
    VULKAN_HPP_CONSTEXPR Image() VULKAN_HPP_NOEXCEPT
      : m_image(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Image( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_image(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Image( VkImage image ) VULKAN_HPP_NOEXCEPT
      : m_image( image )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Image & operator=(VkImage image) VULKAN_HPP_NOEXCEPT
    {
      m_image = image;
      return *this;
    }
#endif

    Image & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_image = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Image const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_image == rhs.m_image;
    }

    bool operator!=(Image const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_image != rhs.m_image;
    }

    bool operator<(Image const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_image < rhs.m_image;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkImage() const VULKAN_HPP_NOEXCEPT
    {
      return m_image;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_image != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_image == VK_NULL_HANDLE;
    }

  private:
    VkImage m_image;
  };
  static_assert( sizeof( Image ) == sizeof( VkImage ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eImage>
  {
    using type = Image;
  };

  class AccelerationStructureNV
  {
  public:
    using CType = VkAccelerationStructureNV;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eAccelerationStructureNV;

  public:
    VULKAN_HPP_CONSTEXPR AccelerationStructureNV() VULKAN_HPP_NOEXCEPT
      : m_accelerationStructureNV(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR AccelerationStructureNV( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_accelerationStructureNV(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT AccelerationStructureNV( VkAccelerationStructureNV accelerationStructureNV ) VULKAN_HPP_NOEXCEPT
      : m_accelerationStructureNV( accelerationStructureNV )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    AccelerationStructureNV & operator=(VkAccelerationStructureNV accelerationStructureNV) VULKAN_HPP_NOEXCEPT
    {
      m_accelerationStructureNV = accelerationStructureNV;
      return *this;
    }
#endif

    AccelerationStructureNV & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_accelerationStructureNV = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( AccelerationStructureNV const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_accelerationStructureNV == rhs.m_accelerationStructureNV;
    }

    bool operator!=(AccelerationStructureNV const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_accelerationStructureNV != rhs.m_accelerationStructureNV;
    }

    bool operator<(AccelerationStructureNV const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_accelerationStructureNV < rhs.m_accelerationStructureNV;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkAccelerationStructureNV() const VULKAN_HPP_NOEXCEPT
    {
      return m_accelerationStructureNV;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_accelerationStructureNV != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_accelerationStructureNV == VK_NULL_HANDLE;
    }

  private:
    VkAccelerationStructureNV m_accelerationStructureNV;
  };
  static_assert( sizeof( AccelerationStructureNV ) == sizeof( VkAccelerationStructureNV ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eAccelerationStructureNV>
  {
    using type = AccelerationStructureNV;
  };

  class DescriptorUpdateTemplate
  {
  public:
    using CType = VkDescriptorUpdateTemplate;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDescriptorUpdateTemplate;

  public:
    VULKAN_HPP_CONSTEXPR DescriptorUpdateTemplate() VULKAN_HPP_NOEXCEPT
      : m_descriptorUpdateTemplate(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DescriptorUpdateTemplate( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_descriptorUpdateTemplate(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DescriptorUpdateTemplate( VkDescriptorUpdateTemplate descriptorUpdateTemplate ) VULKAN_HPP_NOEXCEPT
      : m_descriptorUpdateTemplate( descriptorUpdateTemplate )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DescriptorUpdateTemplate & operator=(VkDescriptorUpdateTemplate descriptorUpdateTemplate) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorUpdateTemplate = descriptorUpdateTemplate;
      return *this;
    }
#endif

    DescriptorUpdateTemplate & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorUpdateTemplate = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DescriptorUpdateTemplate const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorUpdateTemplate == rhs.m_descriptorUpdateTemplate;
    }

    bool operator!=(DescriptorUpdateTemplate const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorUpdateTemplate != rhs.m_descriptorUpdateTemplate;
    }

    bool operator<(DescriptorUpdateTemplate const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorUpdateTemplate < rhs.m_descriptorUpdateTemplate;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDescriptorUpdateTemplate() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorUpdateTemplate;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorUpdateTemplate != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorUpdateTemplate == VK_NULL_HANDLE;
    }

  private:
    VkDescriptorUpdateTemplate m_descriptorUpdateTemplate;
  };
  static_assert( sizeof( DescriptorUpdateTemplate ) == sizeof( VkDescriptorUpdateTemplate ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDescriptorUpdateTemplate>
  {
    using type = DescriptorUpdateTemplate;
  };
  using DescriptorUpdateTemplateKHR = DescriptorUpdateTemplate;

  class Event
  {
  public:
    using CType = VkEvent;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eEvent;

  public:
    VULKAN_HPP_CONSTEXPR Event() VULKAN_HPP_NOEXCEPT
      : m_event(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Event( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_event(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Event( VkEvent event ) VULKAN_HPP_NOEXCEPT
      : m_event( event )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Event & operator=(VkEvent event) VULKAN_HPP_NOEXCEPT
    {
      m_event = event;
      return *this;
    }
#endif

    Event & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_event = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Event const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_event == rhs.m_event;
    }

    bool operator!=(Event const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_event != rhs.m_event;
    }

    bool operator<(Event const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_event < rhs.m_event;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkEvent() const VULKAN_HPP_NOEXCEPT
    {
      return m_event;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_event != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_event == VK_NULL_HANDLE;
    }

  private:
    VkEvent m_event;
  };
  static_assert( sizeof( Event ) == sizeof( VkEvent ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eEvent>
  {
    using type = Event;
  };

  class CommandBuffer
  {
  public:
    using CType = VkCommandBuffer;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eCommandBuffer;

  public:
    VULKAN_HPP_CONSTEXPR CommandBuffer() VULKAN_HPP_NOEXCEPT
      : m_commandBuffer(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR CommandBuffer( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_commandBuffer(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT CommandBuffer( VkCommandBuffer commandBuffer ) VULKAN_HPP_NOEXCEPT
      : m_commandBuffer( commandBuffer )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    CommandBuffer & operator=(VkCommandBuffer commandBuffer) VULKAN_HPP_NOEXCEPT
    {
      m_commandBuffer = commandBuffer;
      return *this;
    }
#endif

    CommandBuffer & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_commandBuffer = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( CommandBuffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_commandBuffer == rhs.m_commandBuffer;
    }

    bool operator!=(CommandBuffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_commandBuffer != rhs.m_commandBuffer;
    }

    bool operator<(CommandBuffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_commandBuffer < rhs.m_commandBuffer;
    }

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result begin( const vk::CommandBufferBeginInfo* pBeginInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type begin( const CommandBufferBeginInfo & beginInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginConditionalRenderingEXT( const vk::ConditionalRenderingBeginInfoEXT* pConditionalRenderingBegin, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginConditionalRenderingEXT( const ConditionalRenderingBeginInfoEXT & conditionalRenderingBegin, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginQuery( vk::QueryPool queryPool, uint32_t query, vk::QueryControlFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginQueryIndexedEXT( vk::QueryPool queryPool, uint32_t query, vk::QueryControlFlags flags, uint32_t index, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginRenderPass( const vk::RenderPassBeginInfo* pRenderPassBegin, vk::SubpassContents contents, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginRenderPass( const RenderPassBeginInfo & renderPassBegin, vk::SubpassContents contents, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginRenderPass2KHR( const vk::RenderPassBeginInfo* pRenderPassBegin, const vk::SubpassBeginInfoKHR* pSubpassBeginInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginRenderPass2KHR( const RenderPassBeginInfo & renderPassBegin, const SubpassBeginInfoKHR & subpassBeginInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginTransformFeedbackEXT( uint32_t firstCounterBuffer, uint32_t counterBufferCount, const vk::Buffer* pCounterBuffers, const vk::DeviceSize* pCounterBufferOffsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginTransformFeedbackEXT( uint32_t firstCounterBuffer, ArrayProxy<const vk::Buffer> counterBuffers, ArrayProxy<const vk::DeviceSize> counterBufferOffsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindDescriptorSets( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t firstSet, uint32_t descriptorSetCount, const vk::DescriptorSet* pDescriptorSets, uint32_t dynamicOffsetCount, const uint32_t* pDynamicOffsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindDescriptorSets( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t firstSet, ArrayProxy<const vk::DescriptorSet> descriptorSets, ArrayProxy<const uint32_t> dynamicOffsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindIndexBuffer( vk::Buffer buffer, vk::DeviceSize offset, vk::IndexType indexType, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindPipeline( vk::PipelineBindPoint pipelineBindPoint, vk::Pipeline pipeline, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindShadingRateImageNV( vk::ImageView imageView, vk::ImageLayout imageLayout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindTransformFeedbackBuffersEXT( uint32_t firstBinding, uint32_t bindingCount, const vk::Buffer* pBuffers, const vk::DeviceSize* pOffsets, const vk::DeviceSize* pSizes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindTransformFeedbackBuffersEXT( uint32_t firstBinding, ArrayProxy<const vk::Buffer> buffers, ArrayProxy<const vk::DeviceSize> offsets, ArrayProxy<const vk::DeviceSize> sizes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindVertexBuffers( uint32_t firstBinding, uint32_t bindingCount, const vk::Buffer* pBuffers, const vk::DeviceSize* pOffsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void bindVertexBuffers( uint32_t firstBinding, ArrayProxy<const vk::Buffer> buffers, ArrayProxy<const vk::DeviceSize> offsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void blitImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::ImageBlit* pRegions, vk::Filter filter, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void blitImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::ImageBlit> regions, vk::Filter filter, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void buildAccelerationStructureNV( const vk::AccelerationStructureInfoNV* pInfo, vk::Buffer instanceData, vk::DeviceSize instanceOffset, vk::Bool32 update, vk::AccelerationStructureNV dst, vk::AccelerationStructureNV src, vk::Buffer scratch, vk::DeviceSize scratchOffset, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void buildAccelerationStructureNV( const AccelerationStructureInfoNV & info, vk::Buffer instanceData, vk::DeviceSize instanceOffset, vk::Bool32 update, vk::AccelerationStructureNV dst, vk::AccelerationStructureNV src, vk::Buffer scratch, vk::DeviceSize scratchOffset, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void clearAttachments( uint32_t attachmentCount, const vk::ClearAttachment* pAttachments, uint32_t rectCount, const vk::ClearRect* pRects, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void clearAttachments( ArrayProxy<const vk::ClearAttachment> attachments, ArrayProxy<const vk::ClearRect> rects, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void clearColorImage( vk::Image image, vk::ImageLayout imageLayout, const vk::ClearColorValue* pColor, uint32_t rangeCount, const vk::ImageSubresourceRange* pRanges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void clearColorImage( vk::Image image, vk::ImageLayout imageLayout, const ClearColorValue & color, ArrayProxy<const vk::ImageSubresourceRange> ranges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void clearDepthStencilImage( vk::Image image, vk::ImageLayout imageLayout, const vk::ClearDepthStencilValue* pDepthStencil, uint32_t rangeCount, const vk::ImageSubresourceRange* pRanges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void clearDepthStencilImage( vk::Image image, vk::ImageLayout imageLayout, const ClearDepthStencilValue & depthStencil, ArrayProxy<const vk::ImageSubresourceRange> ranges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyAccelerationStructureNV( vk::AccelerationStructureNV dst, vk::AccelerationStructureNV src, vk::CopyAccelerationStructureModeNV mode, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyBuffer( vk::Buffer srcBuffer, vk::Buffer dstBuffer, uint32_t regionCount, const vk::BufferCopy* pRegions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyBuffer( vk::Buffer srcBuffer, vk::Buffer dstBuffer, ArrayProxy<const vk::BufferCopy> regions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyBufferToImage( vk::Buffer srcBuffer, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::BufferImageCopy* pRegions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyBufferToImage( vk::Buffer srcBuffer, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::BufferImageCopy> regions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::ImageCopy* pRegions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::ImageCopy> regions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyImageToBuffer( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Buffer dstBuffer, uint32_t regionCount, const vk::BufferImageCopy* pRegions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyImageToBuffer( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Buffer dstBuffer, ArrayProxy<const vk::BufferImageCopy> regions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void copyQueryPoolResults( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize stride, vk::QueryResultFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void debugMarkerBeginEXT( const vk::DebugMarkerMarkerInfoEXT* pMarkerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void debugMarkerBeginEXT( const DebugMarkerMarkerInfoEXT & markerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void debugMarkerEndEXT(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void debugMarkerInsertEXT( const vk::DebugMarkerMarkerInfoEXT* pMarkerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void debugMarkerInsertEXT( const DebugMarkerMarkerInfoEXT & markerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void dispatch( uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void dispatchBase( uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void dispatchBaseKHR( uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void dispatchIndirect( vk::Buffer buffer, vk::DeviceSize offset, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void draw( uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndexed( uint32_t indexCount, uint32_t instanceCount, uint32_t firstIndex, int32_t vertexOffset, uint32_t firstInstance, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndexedIndirect( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndexedIndirectCountAMD( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndexedIndirectCountKHR( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndirect( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndirectByteCountEXT( uint32_t instanceCount, uint32_t firstInstance, vk::Buffer counterBuffer, vk::DeviceSize counterBufferOffset, uint32_t counterOffset, uint32_t vertexStride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndirectCountAMD( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawIndirectCountKHR( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawMeshTasksIndirectCountNV( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawMeshTasksIndirectNV( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void drawMeshTasksNV( uint32_t taskCount, uint32_t firstTask, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endConditionalRenderingEXT(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endDebugUtilsLabelEXT(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endQuery( vk::QueryPool queryPool, uint32_t query, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endQueryIndexedEXT( vk::QueryPool queryPool, uint32_t query, uint32_t index, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endRenderPass(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endRenderPass2KHR( const vk::SubpassEndInfoKHR* pSubpassEndInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endRenderPass2KHR( const SubpassEndInfoKHR & subpassEndInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endTransformFeedbackEXT( uint32_t firstCounterBuffer, uint32_t counterBufferCount, const vk::Buffer* pCounterBuffers, const vk::DeviceSize* pCounterBufferOffsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endTransformFeedbackEXT( uint32_t firstCounterBuffer, ArrayProxy<const vk::Buffer> counterBuffers, ArrayProxy<const vk::DeviceSize> counterBufferOffsets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void executeCommands( uint32_t commandBufferCount, const vk::CommandBuffer* pCommandBuffers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void executeCommands( ArrayProxy<const vk::CommandBuffer> commandBuffers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void fillBuffer( vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize size, uint32_t data, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void insertDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void insertDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void nextSubpass( vk::SubpassContents contents, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void nextSubpass2KHR( const vk::SubpassBeginInfoKHR* pSubpassBeginInfo, const vk::SubpassEndInfoKHR* pSubpassEndInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void nextSubpass2KHR( const SubpassBeginInfoKHR & subpassBeginInfo, const SubpassEndInfoKHR & subpassEndInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void pipelineBarrier( vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, vk::DependencyFlags dependencyFlags, uint32_t memoryBarrierCount, const vk::MemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const vk::BufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const vk::ImageMemoryBarrier* pImageMemoryBarriers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void pipelineBarrier( vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, vk::DependencyFlags dependencyFlags, ArrayProxy<const vk::MemoryBarrier> memoryBarriers, ArrayProxy<const vk::BufferMemoryBarrier> bufferMemoryBarriers, ArrayProxy<const vk::ImageMemoryBarrier> imageMemoryBarriers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void processCommandsNVX( const vk::CmdProcessCommandsInfoNVX* pProcessCommandsInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void processCommandsNVX( const CmdProcessCommandsInfoNVX & processCommandsInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void pushConstants( vk::PipelineLayout layout, vk::ShaderStageFlags stageFlags, uint32_t offset, uint32_t size, const void* pValues, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename T, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void pushConstants( vk::PipelineLayout layout, vk::ShaderStageFlags stageFlags, uint32_t offset, ArrayProxy<const T> values, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void pushDescriptorSetKHR( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t set, uint32_t descriptorWriteCount, const vk::WriteDescriptorSet* pDescriptorWrites, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void pushDescriptorSetKHR( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t set, ArrayProxy<const vk::WriteDescriptorSet> descriptorWrites, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void pushDescriptorSetWithTemplateKHR( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, vk::PipelineLayout layout, uint32_t set, const void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void reserveSpaceForCommandsNVX( const vk::CmdReserveSpaceForCommandsInfoNVX* pReserveSpaceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void reserveSpaceForCommandsNVX( const CmdReserveSpaceForCommandsInfoNVX & reserveSpaceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void resetEvent( vk::Event event, vk::PipelineStageFlags stageMask, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void resetQueryPool( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void resolveImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::ImageResolve* pRegions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void resolveImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::ImageResolve> regions, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setBlendConstants( const float blendConstants[4], Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setCheckpointNV( const void* pCheckpointMarker, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setCoarseSampleOrderNV( vk::CoarseSampleOrderTypeNV sampleOrderType, uint32_t customSampleOrderCount, const vk::CoarseSampleOrderCustomNV* pCustomSampleOrders, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setCoarseSampleOrderNV( vk::CoarseSampleOrderTypeNV sampleOrderType, ArrayProxy<const vk::CoarseSampleOrderCustomNV> customSampleOrders, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setDepthBias( float depthBiasConstantFactor, float depthBiasClamp, float depthBiasSlopeFactor, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setDepthBounds( float minDepthBounds, float maxDepthBounds, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setDeviceMask( uint32_t deviceMask, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setDeviceMaskKHR( uint32_t deviceMask, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setDiscardRectangleEXT( uint32_t firstDiscardRectangle, uint32_t discardRectangleCount, const vk::Rect2D* pDiscardRectangles, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setDiscardRectangleEXT( uint32_t firstDiscardRectangle, ArrayProxy<const vk::Rect2D> discardRectangles, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setEvent( vk::Event event, vk::PipelineStageFlags stageMask, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setExclusiveScissorNV( uint32_t firstExclusiveScissor, uint32_t exclusiveScissorCount, const vk::Rect2D* pExclusiveScissors, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setExclusiveScissorNV( uint32_t firstExclusiveScissor, ArrayProxy<const vk::Rect2D> exclusiveScissors, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setLineStippleEXT( uint32_t lineStippleFactor, uint16_t lineStipplePattern, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setLineWidth( float lineWidth, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result setPerformanceMarkerINTEL( const vk::PerformanceMarkerInfoINTEL* pMarkerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type setPerformanceMarkerINTEL( const PerformanceMarkerInfoINTEL & markerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result setPerformanceOverrideINTEL( const vk::PerformanceOverrideInfoINTEL* pOverrideInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type setPerformanceOverrideINTEL( const PerformanceOverrideInfoINTEL & overrideInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result setPerformanceStreamMarkerINTEL( const vk::PerformanceStreamMarkerInfoINTEL* pMarkerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type setPerformanceStreamMarkerINTEL( const PerformanceStreamMarkerInfoINTEL & markerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setSampleLocationsEXT( const vk::SampleLocationsInfoEXT* pSampleLocationsInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setSampleLocationsEXT( const SampleLocationsInfoEXT & sampleLocationsInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setScissor( uint32_t firstScissor, uint32_t scissorCount, const vk::Rect2D* pScissors, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setScissor( uint32_t firstScissor, ArrayProxy<const vk::Rect2D> scissors, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setStencilCompareMask( vk::StencilFaceFlags faceMask, uint32_t compareMask, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setStencilReference( vk::StencilFaceFlags faceMask, uint32_t reference, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setStencilWriteMask( vk::StencilFaceFlags faceMask, uint32_t writeMask, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setViewport( uint32_t firstViewport, uint32_t viewportCount, const vk::Viewport* pViewports, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setViewport( uint32_t firstViewport, ArrayProxy<const vk::Viewport> viewports, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setViewportShadingRatePaletteNV( uint32_t firstViewport, uint32_t viewportCount, const vk::ShadingRatePaletteNV* pShadingRatePalettes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setViewportShadingRatePaletteNV( uint32_t firstViewport, ArrayProxy<const vk::ShadingRatePaletteNV> shadingRatePalettes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setViewportWScalingNV( uint32_t firstViewport, uint32_t viewportCount, const vk::ViewportWScalingNV* pViewportWScalings, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setViewportWScalingNV( uint32_t firstViewport, ArrayProxy<const vk::ViewportWScalingNV> viewportWScalings, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void traceRaysNV( vk::Buffer raygenShaderBindingTableBuffer, vk::DeviceSize raygenShaderBindingOffset, vk::Buffer missShaderBindingTableBuffer, vk::DeviceSize missShaderBindingOffset, vk::DeviceSize missShaderBindingStride, vk::Buffer hitShaderBindingTableBuffer, vk::DeviceSize hitShaderBindingOffset, vk::DeviceSize hitShaderBindingStride, vk::Buffer callableShaderBindingTableBuffer, vk::DeviceSize callableShaderBindingOffset, vk::DeviceSize callableShaderBindingStride, uint32_t width, uint32_t height, uint32_t depth, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void updateBuffer( vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize dataSize, const void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename T, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void updateBuffer( vk::Buffer dstBuffer, vk::DeviceSize dstOffset, ArrayProxy<const T> data, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void waitEvents( uint32_t eventCount, const vk::Event* pEvents, vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, uint32_t memoryBarrierCount, const vk::MemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const vk::BufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const vk::ImageMemoryBarrier* pImageMemoryBarriers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void waitEvents( ArrayProxy<const vk::Event> events, vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, ArrayProxy<const vk::MemoryBarrier> memoryBarriers, ArrayProxy<const vk::BufferMemoryBarrier> bufferMemoryBarriers, ArrayProxy<const vk::ImageMemoryBarrier> imageMemoryBarriers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void writeAccelerationStructuresPropertiesNV( uint32_t accelerationStructureCount, const vk::AccelerationStructureNV* pAccelerationStructures, vk::QueryType queryType, vk::QueryPool queryPool, uint32_t firstQuery, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void writeAccelerationStructuresPropertiesNV( ArrayProxy<const vk::AccelerationStructureNV> accelerationStructures, vk::QueryType queryType, vk::QueryPool queryPool, uint32_t firstQuery, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void writeBufferMarkerAMD( vk::PipelineStageFlagBits pipelineStage, vk::Buffer dstBuffer, vk::DeviceSize dstOffset, uint32_t marker, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void writeTimestamp( vk::PipelineStageFlagBits pipelineStage, vk::QueryPool queryPool, uint32_t query, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result end(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type end(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result reset( vk::CommandBufferResetFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type reset( vk::CommandBufferResetFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkCommandBuffer() const VULKAN_HPP_NOEXCEPT
    {
      return m_commandBuffer;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_commandBuffer != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_commandBuffer == VK_NULL_HANDLE;
    }

  private:
    VkCommandBuffer m_commandBuffer;
  };
  static_assert( sizeof( CommandBuffer ) == sizeof( VkCommandBuffer ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eCommandBuffer>
  {
    using type = CommandBuffer;
  };

  class DeviceMemory
  {
  public:
    using CType = VkDeviceMemory;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDeviceMemory;

  public:
    VULKAN_HPP_CONSTEXPR DeviceMemory() VULKAN_HPP_NOEXCEPT
      : m_deviceMemory(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DeviceMemory( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_deviceMemory(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DeviceMemory( VkDeviceMemory deviceMemory ) VULKAN_HPP_NOEXCEPT
      : m_deviceMemory( deviceMemory )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DeviceMemory & operator=(VkDeviceMemory deviceMemory) VULKAN_HPP_NOEXCEPT
    {
      m_deviceMemory = deviceMemory;
      return *this;
    }
#endif

    DeviceMemory & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_deviceMemory = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DeviceMemory const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_deviceMemory == rhs.m_deviceMemory;
    }

    bool operator!=(DeviceMemory const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_deviceMemory != rhs.m_deviceMemory;
    }

    bool operator<(DeviceMemory const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_deviceMemory < rhs.m_deviceMemory;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDeviceMemory() const VULKAN_HPP_NOEXCEPT
    {
      return m_deviceMemory;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_deviceMemory != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_deviceMemory == VK_NULL_HANDLE;
    }

  private:
    VkDeviceMemory m_deviceMemory;
  };
  static_assert( sizeof( DeviceMemory ) == sizeof( VkDeviceMemory ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDeviceMemory>
  {
    using type = DeviceMemory;
  };

  class BufferView
  {
  public:
    using CType = VkBufferView;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eBufferView;

  public:
    VULKAN_HPP_CONSTEXPR BufferView() VULKAN_HPP_NOEXCEPT
      : m_bufferView(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR BufferView( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_bufferView(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT BufferView( VkBufferView bufferView ) VULKAN_HPP_NOEXCEPT
      : m_bufferView( bufferView )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    BufferView & operator=(VkBufferView bufferView) VULKAN_HPP_NOEXCEPT
    {
      m_bufferView = bufferView;
      return *this;
    }
#endif

    BufferView & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_bufferView = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( BufferView const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_bufferView == rhs.m_bufferView;
    }

    bool operator!=(BufferView const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_bufferView != rhs.m_bufferView;
    }

    bool operator<(BufferView const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_bufferView < rhs.m_bufferView;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkBufferView() const VULKAN_HPP_NOEXCEPT
    {
      return m_bufferView;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_bufferView != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_bufferView == VK_NULL_HANDLE;
    }

  private:
    VkBufferView m_bufferView;
  };
  static_assert( sizeof( BufferView ) == sizeof( VkBufferView ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eBufferView>
  {
    using type = BufferView;
  };

  class CommandPool
  {
  public:
    using CType = VkCommandPool;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eCommandPool;

  public:
    VULKAN_HPP_CONSTEXPR CommandPool() VULKAN_HPP_NOEXCEPT
      : m_commandPool(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR CommandPool( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_commandPool(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT CommandPool( VkCommandPool commandPool ) VULKAN_HPP_NOEXCEPT
      : m_commandPool( commandPool )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    CommandPool & operator=(VkCommandPool commandPool) VULKAN_HPP_NOEXCEPT
    {
      m_commandPool = commandPool;
      return *this;
    }
#endif

    CommandPool & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_commandPool = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( CommandPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_commandPool == rhs.m_commandPool;
    }

    bool operator!=(CommandPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_commandPool != rhs.m_commandPool;
    }

    bool operator<(CommandPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_commandPool < rhs.m_commandPool;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkCommandPool() const VULKAN_HPP_NOEXCEPT
    {
      return m_commandPool;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_commandPool != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_commandPool == VK_NULL_HANDLE;
    }

  private:
    VkCommandPool m_commandPool;
  };
  static_assert( sizeof( CommandPool ) == sizeof( VkCommandPool ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eCommandPool>
  {
    using type = CommandPool;
  };

  class PipelineCache
  {
  public:
    using CType = VkPipelineCache;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::ePipelineCache;

  public:
    VULKAN_HPP_CONSTEXPR PipelineCache() VULKAN_HPP_NOEXCEPT
      : m_pipelineCache(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR PipelineCache( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_pipelineCache(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT PipelineCache( VkPipelineCache pipelineCache ) VULKAN_HPP_NOEXCEPT
      : m_pipelineCache( pipelineCache )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    PipelineCache & operator=(VkPipelineCache pipelineCache) VULKAN_HPP_NOEXCEPT
    {
      m_pipelineCache = pipelineCache;
      return *this;
    }
#endif

    PipelineCache & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_pipelineCache = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( PipelineCache const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineCache == rhs.m_pipelineCache;
    }

    bool operator!=(PipelineCache const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineCache != rhs.m_pipelineCache;
    }

    bool operator<(PipelineCache const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineCache < rhs.m_pipelineCache;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkPipelineCache() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineCache;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineCache != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_pipelineCache == VK_NULL_HANDLE;
    }

  private:
    VkPipelineCache m_pipelineCache;
  };
  static_assert( sizeof( PipelineCache ) == sizeof( VkPipelineCache ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::ePipelineCache>
  {
    using type = PipelineCache;
  };

  class DescriptorPool
  {
  public:
    using CType = VkDescriptorPool;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDescriptorPool;

  public:
    VULKAN_HPP_CONSTEXPR DescriptorPool() VULKAN_HPP_NOEXCEPT
      : m_descriptorPool(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DescriptorPool( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_descriptorPool(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DescriptorPool( VkDescriptorPool descriptorPool ) VULKAN_HPP_NOEXCEPT
      : m_descriptorPool( descriptorPool )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DescriptorPool & operator=(VkDescriptorPool descriptorPool) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorPool = descriptorPool;
      return *this;
    }
#endif

    DescriptorPool & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorPool = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DescriptorPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorPool == rhs.m_descriptorPool;
    }

    bool operator!=(DescriptorPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorPool != rhs.m_descriptorPool;
    }

    bool operator<(DescriptorPool const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorPool < rhs.m_descriptorPool;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDescriptorPool() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorPool;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorPool != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorPool == VK_NULL_HANDLE;
    }

  private:
    VkDescriptorPool m_descriptorPool;
  };
  static_assert( sizeof( DescriptorPool ) == sizeof( VkDescriptorPool ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDescriptorPool>
  {
    using type = DescriptorPool;
  };

  class DescriptorSetLayout
  {
  public:
    using CType = VkDescriptorSetLayout;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDescriptorSetLayout;

  public:
    VULKAN_HPP_CONSTEXPR DescriptorSetLayout() VULKAN_HPP_NOEXCEPT
      : m_descriptorSetLayout(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DescriptorSetLayout( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_descriptorSetLayout(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DescriptorSetLayout( VkDescriptorSetLayout descriptorSetLayout ) VULKAN_HPP_NOEXCEPT
      : m_descriptorSetLayout( descriptorSetLayout )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DescriptorSetLayout & operator=(VkDescriptorSetLayout descriptorSetLayout) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorSetLayout = descriptorSetLayout;
      return *this;
    }
#endif

    DescriptorSetLayout & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_descriptorSetLayout = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DescriptorSetLayout const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSetLayout == rhs.m_descriptorSetLayout;
    }

    bool operator!=(DescriptorSetLayout const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSetLayout != rhs.m_descriptorSetLayout;
    }

    bool operator<(DescriptorSetLayout const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSetLayout < rhs.m_descriptorSetLayout;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDescriptorSetLayout() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSetLayout;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSetLayout != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_descriptorSetLayout == VK_NULL_HANDLE;
    }

  private:
    VkDescriptorSetLayout m_descriptorSetLayout;
  };
  static_assert( sizeof( DescriptorSetLayout ) == sizeof( VkDescriptorSetLayout ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDescriptorSetLayout>
  {
    using type = DescriptorSetLayout;
  };

  class Framebuffer
  {
  public:
    using CType = VkFramebuffer;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eFramebuffer;

  public:
    VULKAN_HPP_CONSTEXPR Framebuffer() VULKAN_HPP_NOEXCEPT
      : m_framebuffer(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Framebuffer( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_framebuffer(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Framebuffer( VkFramebuffer framebuffer ) VULKAN_HPP_NOEXCEPT
      : m_framebuffer( framebuffer )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Framebuffer & operator=(VkFramebuffer framebuffer) VULKAN_HPP_NOEXCEPT
    {
      m_framebuffer = framebuffer;
      return *this;
    }
#endif

    Framebuffer & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_framebuffer = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Framebuffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_framebuffer == rhs.m_framebuffer;
    }

    bool operator!=(Framebuffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_framebuffer != rhs.m_framebuffer;
    }

    bool operator<(Framebuffer const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_framebuffer < rhs.m_framebuffer;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkFramebuffer() const VULKAN_HPP_NOEXCEPT
    {
      return m_framebuffer;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_framebuffer != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_framebuffer == VK_NULL_HANDLE;
    }

  private:
    VkFramebuffer m_framebuffer;
  };
  static_assert( sizeof( Framebuffer ) == sizeof( VkFramebuffer ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eFramebuffer>
  {
    using type = Framebuffer;
  };

  class IndirectCommandsLayoutNVX
  {
  public:
    using CType = VkIndirectCommandsLayoutNVX;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eIndirectCommandsLayoutNVX;

  public:
    VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutNVX() VULKAN_HPP_NOEXCEPT
      : m_indirectCommandsLayoutNVX(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutNVX( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_indirectCommandsLayoutNVX(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT IndirectCommandsLayoutNVX( VkIndirectCommandsLayoutNVX indirectCommandsLayoutNVX ) VULKAN_HPP_NOEXCEPT
      : m_indirectCommandsLayoutNVX( indirectCommandsLayoutNVX )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    IndirectCommandsLayoutNVX & operator=(VkIndirectCommandsLayoutNVX indirectCommandsLayoutNVX) VULKAN_HPP_NOEXCEPT
    {
      m_indirectCommandsLayoutNVX = indirectCommandsLayoutNVX;
      return *this;
    }
#endif

    IndirectCommandsLayoutNVX & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_indirectCommandsLayoutNVX = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( IndirectCommandsLayoutNVX const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_indirectCommandsLayoutNVX == rhs.m_indirectCommandsLayoutNVX;
    }

    bool operator!=(IndirectCommandsLayoutNVX const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_indirectCommandsLayoutNVX != rhs.m_indirectCommandsLayoutNVX;
    }

    bool operator<(IndirectCommandsLayoutNVX const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_indirectCommandsLayoutNVX < rhs.m_indirectCommandsLayoutNVX;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkIndirectCommandsLayoutNVX() const VULKAN_HPP_NOEXCEPT
    {
      return m_indirectCommandsLayoutNVX;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_indirectCommandsLayoutNVX != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_indirectCommandsLayoutNVX == VK_NULL_HANDLE;
    }

  private:
    VkIndirectCommandsLayoutNVX m_indirectCommandsLayoutNVX;
  };
  static_assert( sizeof( IndirectCommandsLayoutNVX ) == sizeof( VkIndirectCommandsLayoutNVX ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eIndirectCommandsLayoutNVX>
  {
    using type = IndirectCommandsLayoutNVX;
  };

  class ObjectTableNVX
  {
  public:
    using CType = VkObjectTableNVX;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eObjectTableNVX;

  public:
    VULKAN_HPP_CONSTEXPR ObjectTableNVX() VULKAN_HPP_NOEXCEPT
      : m_objectTableNVX(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR ObjectTableNVX( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_objectTableNVX(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT ObjectTableNVX( VkObjectTableNVX objectTableNVX ) VULKAN_HPP_NOEXCEPT
      : m_objectTableNVX( objectTableNVX )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    ObjectTableNVX & operator=(VkObjectTableNVX objectTableNVX) VULKAN_HPP_NOEXCEPT
    {
      m_objectTableNVX = objectTableNVX;
      return *this;
    }
#endif

    ObjectTableNVX & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_objectTableNVX = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( ObjectTableNVX const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_objectTableNVX == rhs.m_objectTableNVX;
    }

    bool operator!=(ObjectTableNVX const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_objectTableNVX != rhs.m_objectTableNVX;
    }

    bool operator<(ObjectTableNVX const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_objectTableNVX < rhs.m_objectTableNVX;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkObjectTableNVX() const VULKAN_HPP_NOEXCEPT
    {
      return m_objectTableNVX;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_objectTableNVX != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_objectTableNVX == VK_NULL_HANDLE;
    }

  private:
    VkObjectTableNVX m_objectTableNVX;
  };
  static_assert( sizeof( ObjectTableNVX ) == sizeof( VkObjectTableNVX ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eObjectTableNVX>
  {
    using type = ObjectTableNVX;
  };

  class RenderPass
  {
  public:
    using CType = VkRenderPass;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eRenderPass;

  public:
    VULKAN_HPP_CONSTEXPR RenderPass() VULKAN_HPP_NOEXCEPT
      : m_renderPass(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR RenderPass( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_renderPass(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT RenderPass( VkRenderPass renderPass ) VULKAN_HPP_NOEXCEPT
      : m_renderPass( renderPass )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    RenderPass & operator=(VkRenderPass renderPass) VULKAN_HPP_NOEXCEPT
    {
      m_renderPass = renderPass;
      return *this;
    }
#endif

    RenderPass & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_renderPass = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( RenderPass const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_renderPass == rhs.m_renderPass;
    }

    bool operator!=(RenderPass const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_renderPass != rhs.m_renderPass;
    }

    bool operator<(RenderPass const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_renderPass < rhs.m_renderPass;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkRenderPass() const VULKAN_HPP_NOEXCEPT
    {
      return m_renderPass;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_renderPass != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_renderPass == VK_NULL_HANDLE;
    }

  private:
    VkRenderPass m_renderPass;
  };
  static_assert( sizeof( RenderPass ) == sizeof( VkRenderPass ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eRenderPass>
  {
    using type = RenderPass;
  };

  class Sampler
  {
  public:
    using CType = VkSampler;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eSampler;

  public:
    VULKAN_HPP_CONSTEXPR Sampler() VULKAN_HPP_NOEXCEPT
      : m_sampler(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Sampler( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_sampler(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Sampler( VkSampler sampler ) VULKAN_HPP_NOEXCEPT
      : m_sampler( sampler )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Sampler & operator=(VkSampler sampler) VULKAN_HPP_NOEXCEPT
    {
      m_sampler = sampler;
      return *this;
    }
#endif

    Sampler & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_sampler = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Sampler const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_sampler == rhs.m_sampler;
    }

    bool operator!=(Sampler const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_sampler != rhs.m_sampler;
    }

    bool operator<(Sampler const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_sampler < rhs.m_sampler;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkSampler() const VULKAN_HPP_NOEXCEPT
    {
      return m_sampler;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_sampler != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_sampler == VK_NULL_HANDLE;
    }

  private:
    VkSampler m_sampler;
  };
  static_assert( sizeof( Sampler ) == sizeof( VkSampler ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eSampler>
  {
    using type = Sampler;
  };

  class SamplerYcbcrConversion
  {
  public:
    using CType = VkSamplerYcbcrConversion;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eSamplerYcbcrConversion;

  public:
    VULKAN_HPP_CONSTEXPR SamplerYcbcrConversion() VULKAN_HPP_NOEXCEPT
      : m_samplerYcbcrConversion(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR SamplerYcbcrConversion( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_samplerYcbcrConversion(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT SamplerYcbcrConversion( VkSamplerYcbcrConversion samplerYcbcrConversion ) VULKAN_HPP_NOEXCEPT
      : m_samplerYcbcrConversion( samplerYcbcrConversion )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    SamplerYcbcrConversion & operator=(VkSamplerYcbcrConversion samplerYcbcrConversion) VULKAN_HPP_NOEXCEPT
    {
      m_samplerYcbcrConversion = samplerYcbcrConversion;
      return *this;
    }
#endif

    SamplerYcbcrConversion & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_samplerYcbcrConversion = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( SamplerYcbcrConversion const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_samplerYcbcrConversion == rhs.m_samplerYcbcrConversion;
    }

    bool operator!=(SamplerYcbcrConversion const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_samplerYcbcrConversion != rhs.m_samplerYcbcrConversion;
    }

    bool operator<(SamplerYcbcrConversion const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_samplerYcbcrConversion < rhs.m_samplerYcbcrConversion;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkSamplerYcbcrConversion() const VULKAN_HPP_NOEXCEPT
    {
      return m_samplerYcbcrConversion;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_samplerYcbcrConversion != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_samplerYcbcrConversion == VK_NULL_HANDLE;
    }

  private:
    VkSamplerYcbcrConversion m_samplerYcbcrConversion;
  };
  static_assert( sizeof( SamplerYcbcrConversion ) == sizeof( VkSamplerYcbcrConversion ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eSamplerYcbcrConversion>
  {
    using type = SamplerYcbcrConversion;
  };
  using SamplerYcbcrConversionKHR = SamplerYcbcrConversion;

  class ShaderModule
  {
  public:
    using CType = VkShaderModule;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eShaderModule;

  public:
    VULKAN_HPP_CONSTEXPR ShaderModule() VULKAN_HPP_NOEXCEPT
      : m_shaderModule(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR ShaderModule( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_shaderModule(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT ShaderModule( VkShaderModule shaderModule ) VULKAN_HPP_NOEXCEPT
      : m_shaderModule( shaderModule )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    ShaderModule & operator=(VkShaderModule shaderModule) VULKAN_HPP_NOEXCEPT
    {
      m_shaderModule = shaderModule;
      return *this;
    }
#endif

    ShaderModule & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_shaderModule = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( ShaderModule const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_shaderModule == rhs.m_shaderModule;
    }

    bool operator!=(ShaderModule const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_shaderModule != rhs.m_shaderModule;
    }

    bool operator<(ShaderModule const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_shaderModule < rhs.m_shaderModule;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkShaderModule() const VULKAN_HPP_NOEXCEPT
    {
      return m_shaderModule;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_shaderModule != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_shaderModule == VK_NULL_HANDLE;
    }

  private:
    VkShaderModule m_shaderModule;
  };
  static_assert( sizeof( ShaderModule ) == sizeof( VkShaderModule ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eShaderModule>
  {
    using type = ShaderModule;
  };

  class ValidationCacheEXT
  {
  public:
    using CType = VkValidationCacheEXT;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eValidationCacheEXT;

  public:
    VULKAN_HPP_CONSTEXPR ValidationCacheEXT() VULKAN_HPP_NOEXCEPT
      : m_validationCacheEXT(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR ValidationCacheEXT( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_validationCacheEXT(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT ValidationCacheEXT( VkValidationCacheEXT validationCacheEXT ) VULKAN_HPP_NOEXCEPT
      : m_validationCacheEXT( validationCacheEXT )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    ValidationCacheEXT & operator=(VkValidationCacheEXT validationCacheEXT) VULKAN_HPP_NOEXCEPT
    {
      m_validationCacheEXT = validationCacheEXT;
      return *this;
    }
#endif

    ValidationCacheEXT & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_validationCacheEXT = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( ValidationCacheEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_validationCacheEXT == rhs.m_validationCacheEXT;
    }

    bool operator!=(ValidationCacheEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_validationCacheEXT != rhs.m_validationCacheEXT;
    }

    bool operator<(ValidationCacheEXT const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_validationCacheEXT < rhs.m_validationCacheEXT;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkValidationCacheEXT() const VULKAN_HPP_NOEXCEPT
    {
      return m_validationCacheEXT;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_validationCacheEXT != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_validationCacheEXT == VK_NULL_HANDLE;
    }

  private:
    VkValidationCacheEXT m_validationCacheEXT;
  };
  static_assert( sizeof( ValidationCacheEXT ) == sizeof( VkValidationCacheEXT ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eValidationCacheEXT>
  {
    using type = ValidationCacheEXT;
  };

  class Queue
  {
  public:
    using CType = VkQueue;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eQueue;

  public:
    VULKAN_HPP_CONSTEXPR Queue() VULKAN_HPP_NOEXCEPT
      : m_queue(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Queue( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_queue(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Queue( VkQueue queue ) VULKAN_HPP_NOEXCEPT
      : m_queue( queue )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Queue & operator=(VkQueue queue) VULKAN_HPP_NOEXCEPT
    {
      m_queue = queue;
      return *this;
    }
#endif

    Queue & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_queue = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Queue const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_queue == rhs.m_queue;
    }

    bool operator!=(Queue const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_queue != rhs.m_queue;
    }

    bool operator<(Queue const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_queue < rhs.m_queue;
    }

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getCheckpointDataNV( uint32_t* pCheckpointDataCount, vk::CheckpointDataNV* pCheckpointData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<CheckpointDataNV>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<CheckpointDataNV,Allocator> getCheckpointDataNV(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<CheckpointDataNV>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<CheckpointDataNV,Allocator> getCheckpointDataNV(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void beginDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindSparse( uint32_t bindInfoCount, const vk::BindSparseInfo* pBindInfo, vk::Fence fence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindSparse( ArrayProxy<const vk::BindSparseInfo> bindInfo, vk::Fence fence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void endDebugUtilsLabelEXT(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void insertDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void insertDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result presentKHR( const vk::PresentInfoKHR* pPresentInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result presentKHR( const PresentInfoKHR & presentInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result setPerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type setPerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result submit( uint32_t submitCount, const vk::SubmitInfo* pSubmits, vk::Fence fence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type submit( ArrayProxy<const vk::SubmitInfo> submits, vk::Fence fence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result waitIdle(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type waitIdle(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkQueue() const VULKAN_HPP_NOEXCEPT
    {
      return m_queue;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_queue != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_queue == VK_NULL_HANDLE;
    }

  private:
    VkQueue m_queue;
  };
  static_assert( sizeof( Queue ) == sizeof( VkQueue ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eQueue>
  {
    using type = Queue;
  };

#ifndef VULKAN_HPP_NO_SMART_HANDLE
  class Device;
  template <typename Dispatch> class UniqueHandleTraits<AccelerationStructureNV, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueAccelerationStructureNV = UniqueHandle<AccelerationStructureNV, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Buffer, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueBuffer = UniqueHandle<Buffer, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<BufferView, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueBufferView = UniqueHandle<BufferView, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<CommandBuffer, Dispatch> { public: using deleter = PoolFree<Device, CommandPool, Dispatch>; };
  using UniqueCommandBuffer = UniqueHandle<CommandBuffer, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<CommandPool, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueCommandPool = UniqueHandle<CommandPool, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<DescriptorPool, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueDescriptorPool = UniqueHandle<DescriptorPool, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<DescriptorSet, Dispatch> { public: using deleter = PoolFree<Device, DescriptorPool, Dispatch>; };
  using UniqueDescriptorSet = UniqueHandle<DescriptorSet, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<DescriptorSetLayout, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueDescriptorSetLayout = UniqueHandle<DescriptorSetLayout, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<DescriptorUpdateTemplate, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueDescriptorUpdateTemplate = UniqueHandle<DescriptorUpdateTemplate, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<DeviceMemory, Dispatch> { public: using deleter = ObjectFree<Device, Dispatch>; };
  using UniqueDeviceMemory = UniqueHandle<DeviceMemory, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Event, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueEvent = UniqueHandle<Event, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Fence, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueFence = UniqueHandle<Fence, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Framebuffer, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueFramebuffer = UniqueHandle<Framebuffer, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Image, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueImage = UniqueHandle<Image, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<ImageView, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueImageView = UniqueHandle<ImageView, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<IndirectCommandsLayoutNVX, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueIndirectCommandsLayoutNVX = UniqueHandle<IndirectCommandsLayoutNVX, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<ObjectTableNVX, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueObjectTableNVX = UniqueHandle<ObjectTableNVX, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Pipeline, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniquePipeline = UniqueHandle<Pipeline, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<PipelineCache, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniquePipelineCache = UniqueHandle<PipelineCache, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<PipelineLayout, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniquePipelineLayout = UniqueHandle<PipelineLayout, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<QueryPool, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueQueryPool = UniqueHandle<QueryPool, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<RenderPass, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueRenderPass = UniqueHandle<RenderPass, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Sampler, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueSampler = UniqueHandle<Sampler, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<SamplerYcbcrConversion, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueSamplerYcbcrConversion = UniqueHandle<SamplerYcbcrConversion, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<Semaphore, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueSemaphore = UniqueHandle<Semaphore, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<ShaderModule, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueShaderModule = UniqueHandle<ShaderModule, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<SwapchainKHR, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueSwapchainKHR = UniqueHandle<SwapchainKHR, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<ValidationCacheEXT, Dispatch> { public: using deleter = ObjectDestroy<Device, Dispatch>; };
  using UniqueValidationCacheEXT = UniqueHandle<ValidationCacheEXT, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/

  class Device
  {
  public:
    using CType = VkDevice;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDevice;

  public:
    VULKAN_HPP_CONSTEXPR Device() VULKAN_HPP_NOEXCEPT
      : m_device(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Device( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_device(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Device( VkDevice device ) VULKAN_HPP_NOEXCEPT
      : m_device( device )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Device & operator=(VkDevice device) VULKAN_HPP_NOEXCEPT
    {
      m_device = device;
      return *this;
    }
#endif

    Device & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_device = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Device const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_device == rhs.m_device;
    }

    bool operator!=(Device const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_device != rhs.m_device;
    }

    bool operator<(Device const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_device < rhs.m_device;
    }

#ifdef VK_USE_PLATFORM_WIN32_KHR
#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result acquireFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type acquireFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result acquireNextImage2KHR( const vk::AcquireNextImageInfoKHR* pAcquireInfo, uint32_t* pImageIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValue<uint32_t> acquireNextImage2KHR( const AcquireNextImageInfoKHR & acquireInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result acquireNextImageKHR( vk::SwapchainKHR swapchain, uint64_t timeout, vk::Semaphore semaphore, vk::Fence fence, uint32_t* pImageIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValue<uint32_t> acquireNextImageKHR( vk::SwapchainKHR swapchain, uint64_t timeout, vk::Semaphore semaphore, vk::Fence fence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result acquirePerformanceConfigurationINTEL( const vk::PerformanceConfigurationAcquireInfoINTEL* pAcquireInfo, vk::PerformanceConfigurationINTEL* pConfiguration, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::PerformanceConfigurationINTEL>::type acquirePerformanceConfigurationINTEL( const PerformanceConfigurationAcquireInfoINTEL & acquireInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result allocateCommandBuffers( const vk::CommandBufferAllocateInfo* pAllocateInfo, vk::CommandBuffer* pCommandBuffers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<CommandBuffer>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<CommandBuffer,Allocator>>::type allocateCommandBuffers( const CommandBufferAllocateInfo & allocateInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<CommandBuffer>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<CommandBuffer,Allocator>>::type allocateCommandBuffers( const CommandBufferAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Allocator = std::allocator<UniqueCommandBuffer>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<CommandBuffer,Dispatch>,Allocator>>::type allocateCommandBuffersUnique( const CommandBufferAllocateInfo & allocateInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<UniqueCommandBuffer>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<CommandBuffer,Dispatch>,Allocator>>::type allocateCommandBuffersUnique( const CommandBufferAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result allocateDescriptorSets( const vk::DescriptorSetAllocateInfo* pAllocateInfo, vk::DescriptorSet* pDescriptorSets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DescriptorSet>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DescriptorSet,Allocator>>::type allocateDescriptorSets( const DescriptorSetAllocateInfo & allocateInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DescriptorSet>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DescriptorSet,Allocator>>::type allocateDescriptorSets( const DescriptorSetAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Allocator = std::allocator<UniqueDescriptorSet>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<DescriptorSet,Dispatch>,Allocator>>::type allocateDescriptorSetsUnique( const DescriptorSetAllocateInfo & allocateInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<UniqueDescriptorSet>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<DescriptorSet,Dispatch>,Allocator>>::type allocateDescriptorSetsUnique( const DescriptorSetAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result allocateMemory( const vk::MemoryAllocateInfo* pAllocateInfo, const vk::AllocationCallbacks* pAllocator, vk::DeviceMemory* pMemory, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DeviceMemory>::type allocateMemory( const MemoryAllocateInfo & allocateInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<DeviceMemory,Dispatch>>::type allocateMemoryUnique( const MemoryAllocateInfo & allocateInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindAccelerationStructureMemoryNV( uint32_t bindInfoCount, const vk::BindAccelerationStructureMemoryInfoNV* pBindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindAccelerationStructureMemoryNV( ArrayProxy<const vk::BindAccelerationStructureMemoryInfoNV> bindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindBufferMemory( vk::Buffer buffer, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindBufferMemory( vk::Buffer buffer, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindBufferMemory2( uint32_t bindInfoCount, const vk::BindBufferMemoryInfo* pBindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindBufferMemory2( ArrayProxy<const vk::BindBufferMemoryInfo> bindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindBufferMemory2KHR( uint32_t bindInfoCount, const vk::BindBufferMemoryInfo* pBindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindBufferMemory2KHR( ArrayProxy<const vk::BindBufferMemoryInfo> bindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindImageMemory( vk::Image image, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindImageMemory( vk::Image image, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindImageMemory2( uint32_t bindInfoCount, const vk::BindImageMemoryInfo* pBindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindImageMemory2( ArrayProxy<const vk::BindImageMemoryInfo> bindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result bindImageMemory2KHR( uint32_t bindInfoCount, const vk::BindImageMemoryInfo* pBindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type bindImageMemory2KHR( ArrayProxy<const vk::BindImageMemoryInfo> bindInfos, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result compileDeferredNV( vk::Pipeline pipeline, uint32_t shader, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type compileDeferredNV( vk::Pipeline pipeline, uint32_t shader, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createAccelerationStructureNV( const vk::AccelerationStructureCreateInfoNV* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::AccelerationStructureNV* pAccelerationStructure, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::AccelerationStructureNV>::type createAccelerationStructureNV( const AccelerationStructureCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<AccelerationStructureNV,Dispatch>>::type createAccelerationStructureNVUnique( const AccelerationStructureCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createBuffer( const vk::BufferCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Buffer* pBuffer, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Buffer>::type createBuffer( const BufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Buffer,Dispatch>>::type createBufferUnique( const BufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createBufferView( const vk::BufferViewCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::BufferView* pView, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::BufferView>::type createBufferView( const BufferViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<BufferView,Dispatch>>::type createBufferViewUnique( const BufferViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createCommandPool( const vk::CommandPoolCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::CommandPool* pCommandPool, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::CommandPool>::type createCommandPool( const CommandPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<CommandPool,Dispatch>>::type createCommandPoolUnique( const CommandPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createComputePipelines( vk::PipelineCache pipelineCache, uint32_t createInfoCount, const vk::ComputePipelineCreateInfo* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::Pipeline* pPipelines, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<Pipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Pipeline,Allocator>>::type createComputePipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<Pipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Pipeline,Allocator>>::type createComputePipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<Pipeline>::type createComputePipeline( vk::PipelineCache pipelineCache, const ComputePipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Allocator = std::allocator<UniquePipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type createComputePipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<UniquePipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type createComputePipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Pipeline,Dispatch>>::type createComputePipelineUnique( vk::PipelineCache pipelineCache, const ComputePipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDescriptorPool( const vk::DescriptorPoolCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorPool* pDescriptorPool, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DescriptorPool>::type createDescriptorPool( const DescriptorPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<DescriptorPool,Dispatch>>::type createDescriptorPoolUnique( const DescriptorPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDescriptorSetLayout( const vk::DescriptorSetLayoutCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorSetLayout* pSetLayout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DescriptorSetLayout>::type createDescriptorSetLayout( const DescriptorSetLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<DescriptorSetLayout,Dispatch>>::type createDescriptorSetLayoutUnique( const DescriptorSetLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDescriptorUpdateTemplate( const vk::DescriptorUpdateTemplateCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorUpdateTemplate* pDescriptorUpdateTemplate, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DescriptorUpdateTemplate>::type createDescriptorUpdateTemplate( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<DescriptorUpdateTemplate,Dispatch>>::type createDescriptorUpdateTemplateUnique( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDescriptorUpdateTemplateKHR( const vk::DescriptorUpdateTemplateCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorUpdateTemplate* pDescriptorUpdateTemplate, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DescriptorUpdateTemplate>::type createDescriptorUpdateTemplateKHR( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<DescriptorUpdateTemplate,Dispatch>>::type createDescriptorUpdateTemplateKHRUnique( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createEvent( const vk::EventCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Event* pEvent, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Event>::type createEvent( const EventCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Event,Dispatch>>::type createEventUnique( const EventCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createFence( const vk::FenceCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Fence* pFence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Fence>::type createFence( const FenceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Fence,Dispatch>>::type createFenceUnique( const FenceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createFramebuffer( const vk::FramebufferCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Framebuffer* pFramebuffer, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Framebuffer>::type createFramebuffer( const FramebufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Framebuffer,Dispatch>>::type createFramebufferUnique( const FramebufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createGraphicsPipelines( vk::PipelineCache pipelineCache, uint32_t createInfoCount, const vk::GraphicsPipelineCreateInfo* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::Pipeline* pPipelines, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<Pipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Pipeline,Allocator>>::type createGraphicsPipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<Pipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Pipeline,Allocator>>::type createGraphicsPipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<Pipeline>::type createGraphicsPipeline( vk::PipelineCache pipelineCache, const GraphicsPipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Allocator = std::allocator<UniquePipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type createGraphicsPipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<UniquePipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type createGraphicsPipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Pipeline,Dispatch>>::type createGraphicsPipelineUnique( vk::PipelineCache pipelineCache, const GraphicsPipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createImage( const vk::ImageCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Image* pImage, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Image>::type createImage( const ImageCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Image,Dispatch>>::type createImageUnique( const ImageCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createImageView( const vk::ImageViewCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ImageView* pView, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ImageView>::type createImageView( const ImageViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<ImageView,Dispatch>>::type createImageViewUnique( const ImageViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createIndirectCommandsLayoutNVX( const vk::IndirectCommandsLayoutCreateInfoNVX* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::IndirectCommandsLayoutNVX* pIndirectCommandsLayout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::IndirectCommandsLayoutNVX>::type createIndirectCommandsLayoutNVX( const IndirectCommandsLayoutCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<IndirectCommandsLayoutNVX,Dispatch>>::type createIndirectCommandsLayoutNVXUnique( const IndirectCommandsLayoutCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createObjectTableNVX( const vk::ObjectTableCreateInfoNVX* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ObjectTableNVX* pObjectTable, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ObjectTableNVX>::type createObjectTableNVX( const ObjectTableCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<ObjectTableNVX,Dispatch>>::type createObjectTableNVXUnique( const ObjectTableCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createPipelineCache( const vk::PipelineCacheCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::PipelineCache* pPipelineCache, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::PipelineCache>::type createPipelineCache( const PipelineCacheCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<PipelineCache,Dispatch>>::type createPipelineCacheUnique( const PipelineCacheCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createPipelineLayout( const vk::PipelineLayoutCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::PipelineLayout* pPipelineLayout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::PipelineLayout>::type createPipelineLayout( const PipelineLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<PipelineLayout,Dispatch>>::type createPipelineLayoutUnique( const PipelineLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createQueryPool( const vk::QueryPoolCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::QueryPool* pQueryPool, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::QueryPool>::type createQueryPool( const QueryPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<QueryPool,Dispatch>>::type createQueryPoolUnique( const QueryPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createRayTracingPipelinesNV( vk::PipelineCache pipelineCache, uint32_t createInfoCount, const vk::RayTracingPipelineCreateInfoNV* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::Pipeline* pPipelines, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<Pipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Pipeline,Allocator>>::type createRayTracingPipelinesNV( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<Pipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Pipeline,Allocator>>::type createRayTracingPipelinesNV( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<Pipeline>::type createRayTracingPipelineNV( vk::PipelineCache pipelineCache, const RayTracingPipelineCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Allocator = std::allocator<UniquePipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type createRayTracingPipelinesNVUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<UniquePipeline>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type createRayTracingPipelinesNVUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Pipeline,Dispatch>>::type createRayTracingPipelineNVUnique( vk::PipelineCache pipelineCache, const RayTracingPipelineCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createRenderPass( const vk::RenderPassCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::RenderPass* pRenderPass, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::RenderPass>::type createRenderPass( const RenderPassCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<RenderPass,Dispatch>>::type createRenderPassUnique( const RenderPassCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createRenderPass2KHR( const vk::RenderPassCreateInfo2KHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::RenderPass* pRenderPass, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::RenderPass>::type createRenderPass2KHR( const RenderPassCreateInfo2KHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<RenderPass,Dispatch>>::type createRenderPass2KHRUnique( const RenderPassCreateInfo2KHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createSampler( const vk::SamplerCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Sampler* pSampler, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Sampler>::type createSampler( const SamplerCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Sampler,Dispatch>>::type createSamplerUnique( const SamplerCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createSamplerYcbcrConversion( const vk::SamplerYcbcrConversionCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SamplerYcbcrConversion* pYcbcrConversion, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SamplerYcbcrConversion>::type createSamplerYcbcrConversion( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SamplerYcbcrConversion,Dispatch>>::type createSamplerYcbcrConversionUnique( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createSamplerYcbcrConversionKHR( const vk::SamplerYcbcrConversionCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SamplerYcbcrConversion* pYcbcrConversion, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SamplerYcbcrConversion>::type createSamplerYcbcrConversionKHR( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SamplerYcbcrConversion,Dispatch>>::type createSamplerYcbcrConversionKHRUnique( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createSemaphore( const vk::SemaphoreCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Semaphore* pSemaphore, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Semaphore>::type createSemaphore( const SemaphoreCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Semaphore,Dispatch>>::type createSemaphoreUnique( const SemaphoreCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createShaderModule( const vk::ShaderModuleCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ShaderModule* pShaderModule, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ShaderModule>::type createShaderModule( const ShaderModuleCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<ShaderModule,Dispatch>>::type createShaderModuleUnique( const ShaderModuleCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createSharedSwapchainsKHR( uint32_t swapchainCount, const vk::SwapchainCreateInfoKHR* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::SwapchainKHR* pSwapchains, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SwapchainKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<SwapchainKHR,Allocator>>::type createSharedSwapchainsKHR( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SwapchainKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<SwapchainKHR,Allocator>>::type createSharedSwapchainsKHR( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<SwapchainKHR>::type createSharedSwapchainKHR( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Allocator = std::allocator<UniqueSwapchainKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<SwapchainKHR,Dispatch>,Allocator>>::type createSharedSwapchainsKHRUnique( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<UniqueSwapchainKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<UniqueHandle<SwapchainKHR,Dispatch>,Allocator>>::type createSharedSwapchainsKHRUnique( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SwapchainKHR,Dispatch>>::type createSharedSwapchainKHRUnique( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createSwapchainKHR( const vk::SwapchainCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SwapchainKHR* pSwapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SwapchainKHR>::type createSwapchainKHR( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SwapchainKHR,Dispatch>>::type createSwapchainKHRUnique( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createValidationCacheEXT( const vk::ValidationCacheCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ValidationCacheEXT* pValidationCache, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ValidationCacheEXT>::type createValidationCacheEXT( const ValidationCacheCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<ValidationCacheEXT,Dispatch>>::type createValidationCacheEXTUnique( const ValidationCacheCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result debugMarkerSetObjectNameEXT( const vk::DebugMarkerObjectNameInfoEXT* pNameInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type debugMarkerSetObjectNameEXT( const DebugMarkerObjectNameInfoEXT & nameInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result debugMarkerSetObjectTagEXT( const vk::DebugMarkerObjectTagInfoEXT* pTagInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type debugMarkerSetObjectTagEXT( const DebugMarkerObjectTagInfoEXT & tagInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyAccelerationStructureNV( vk::AccelerationStructureNV accelerationStructure, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyAccelerationStructureNV( vk::AccelerationStructureNV accelerationStructure, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::AccelerationStructureNV accelerationStructure, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::AccelerationStructureNV accelerationStructure, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyBuffer( vk::Buffer buffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyBuffer( vk::Buffer buffer, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Buffer buffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Buffer buffer, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyBufferView( vk::BufferView bufferView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyBufferView( vk::BufferView bufferView, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::BufferView bufferView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::BufferView bufferView, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyCommandPool( vk::CommandPool commandPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyCommandPool( vk::CommandPool commandPool, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::CommandPool commandPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::CommandPool commandPool, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorPool( vk::DescriptorPool descriptorPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorPool( vk::DescriptorPool descriptorPool, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DescriptorPool descriptorPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DescriptorPool descriptorPool, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorSetLayout( vk::DescriptorSetLayout descriptorSetLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorSetLayout( vk::DescriptorSetLayout descriptorSetLayout, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DescriptorSetLayout descriptorSetLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DescriptorSetLayout descriptorSetLayout, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorUpdateTemplate( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorUpdateTemplate( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorUpdateTemplateKHR( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDescriptorUpdateTemplateKHR( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyEvent( vk::Event event, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyEvent( vk::Event event, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Event event, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Event event, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyFence( vk::Fence fence, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyFence( vk::Fence fence, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Fence fence, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Fence fence, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyFramebuffer( vk::Framebuffer framebuffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyFramebuffer( vk::Framebuffer framebuffer, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Framebuffer framebuffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Framebuffer framebuffer, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyImage( vk::Image image, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyImage( vk::Image image, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Image image, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Image image, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyImageView( vk::ImageView imageView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyImageView( vk::ImageView imageView, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ImageView imageView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ImageView imageView, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyIndirectCommandsLayoutNVX( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyIndirectCommandsLayoutNVX( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyObjectTableNVX( vk::ObjectTableNVX objectTable, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyObjectTableNVX( vk::ObjectTableNVX objectTable, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ObjectTableNVX objectTable, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ObjectTableNVX objectTable, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyPipeline( vk::Pipeline pipeline, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyPipeline( vk::Pipeline pipeline, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Pipeline pipeline, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Pipeline pipeline, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyPipelineCache( vk::PipelineCache pipelineCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyPipelineCache( vk::PipelineCache pipelineCache, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::PipelineCache pipelineCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::PipelineCache pipelineCache, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyPipelineLayout( vk::PipelineLayout pipelineLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyPipelineLayout( vk::PipelineLayout pipelineLayout, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::PipelineLayout pipelineLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::PipelineLayout pipelineLayout, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyQueryPool( vk::QueryPool queryPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyQueryPool( vk::QueryPool queryPool, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::QueryPool queryPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::QueryPool queryPool, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyRenderPass( vk::RenderPass renderPass, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyRenderPass( vk::RenderPass renderPass, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::RenderPass renderPass, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::RenderPass renderPass, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySampler( vk::Sampler sampler, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySampler( vk::Sampler sampler, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Sampler sampler, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Sampler sampler, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySamplerYcbcrConversion( vk::SamplerYcbcrConversion ycbcrConversion, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySamplerYcbcrConversion( vk::SamplerYcbcrConversion ycbcrConversion, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::SamplerYcbcrConversion ycbcrConversion, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::SamplerYcbcrConversion ycbcrConversion, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySamplerYcbcrConversionKHR( vk::SamplerYcbcrConversion ycbcrConversion, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySamplerYcbcrConversionKHR( vk::SamplerYcbcrConversion ycbcrConversion, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySemaphore( vk::Semaphore semaphore, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySemaphore( vk::Semaphore semaphore, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Semaphore semaphore, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::Semaphore semaphore, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyShaderModule( vk::ShaderModule shaderModule, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyShaderModule( vk::ShaderModule shaderModule, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ShaderModule shaderModule, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ShaderModule shaderModule, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySwapchainKHR( vk::SwapchainKHR swapchain, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySwapchainKHR( vk::SwapchainKHR swapchain, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::SwapchainKHR swapchain, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::SwapchainKHR swapchain, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyValidationCacheEXT( vk::ValidationCacheEXT validationCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyValidationCacheEXT( vk::ValidationCacheEXT validationCache, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ValidationCacheEXT validationCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::ValidationCacheEXT validationCache, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result waitIdle(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type waitIdle(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result displayPowerControlEXT( vk::DisplayKHR display, const vk::DisplayPowerInfoEXT* pDisplayPowerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type displayPowerControlEXT( vk::DisplayKHR display, const DisplayPowerInfoEXT & displayPowerInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result flushMappedMemoryRanges( uint32_t memoryRangeCount, const vk::MappedMemoryRange* pMemoryRanges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type flushMappedMemoryRanges( ArrayProxy<const vk::MappedMemoryRange> memoryRanges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void freeCommandBuffers( vk::CommandPool commandPool, uint32_t commandBufferCount, const vk::CommandBuffer* pCommandBuffers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void freeCommandBuffers( vk::CommandPool commandPool, ArrayProxy<const vk::CommandBuffer> commandBuffers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void free( vk::CommandPool commandPool, uint32_t commandBufferCount, const vk::CommandBuffer* pCommandBuffers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void free( vk::CommandPool commandPool, ArrayProxy<const vk::CommandBuffer> commandBuffers, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result freeDescriptorSets( vk::DescriptorPool descriptorPool, uint32_t descriptorSetCount, const vk::DescriptorSet* pDescriptorSets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type freeDescriptorSets( vk::DescriptorPool descriptorPool, ArrayProxy<const vk::DescriptorSet> descriptorSets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result free( vk::DescriptorPool descriptorPool, uint32_t descriptorSetCount, const vk::DescriptorSet* pDescriptorSets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type free( vk::DescriptorPool descriptorPool, ArrayProxy<const vk::DescriptorSet> descriptorSets, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void freeMemory( vk::DeviceMemory memory, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void freeMemory( vk::DeviceMemory memory, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void free( vk::DeviceMemory memory, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void free( vk::DeviceMemory memory, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getAccelerationStructureHandleNV( vk::AccelerationStructureNV accelerationStructure, size_t dataSize, void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename T, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type getAccelerationStructureHandleNV( vk::AccelerationStructureNV accelerationStructure, ArrayProxy<T> data, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getAccelerationStructureMemoryRequirementsNV( const vk::AccelerationStructureMemoryRequirementsInfoNV* pInfo, vk::MemoryRequirements2KHR* pMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MemoryRequirements2KHR getAccelerationStructureMemoryRequirementsNV( const AccelerationStructureMemoryRequirementsInfoNV & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getAccelerationStructureMemoryRequirementsNV( const AccelerationStructureMemoryRequirementsInfoNV & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getAndroidHardwareBufferPropertiesANDROID( const struct AHardwareBuffer* buffer, vk::AndroidHardwareBufferPropertiesANDROID* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::AndroidHardwareBufferPropertiesANDROID>::type getAndroidHardwareBufferPropertiesANDROID( const struct AHardwareBuffer & buffer, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<StructureChain<X, Y, Z...>>::type getAndroidHardwareBufferPropertiesANDROID( const struct AHardwareBuffer & buffer, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    DeviceAddress getBufferAddressEXT( const vk::BufferDeviceAddressInfoEXT* pInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    DeviceAddress getBufferAddressEXT( const BufferDeviceAddressInfoEXT & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getBufferMemoryRequirements( vk::Buffer buffer, vk::MemoryRequirements* pMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MemoryRequirements getBufferMemoryRequirements( vk::Buffer buffer, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getBufferMemoryRequirements2( const vk::BufferMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MemoryRequirements2 getBufferMemoryRequirements2( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getBufferMemoryRequirements2( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getBufferMemoryRequirements2KHR( const vk::BufferMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MemoryRequirements2 getBufferMemoryRequirements2KHR( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getBufferMemoryRequirements2KHR( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getCalibratedTimestampsEXT( uint32_t timestampCount, const vk::CalibratedTimestampInfoEXT* pTimestampInfos, uint64_t* pTimestamps, uint64_t* pMaxDeviation, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<uint64_t>::type getCalibratedTimestampsEXT( ArrayProxy<const vk::CalibratedTimestampInfoEXT> timestampInfos, ArrayProxy<uint64_t> timestamps, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getDescriptorSetLayoutSupport( const vk::DescriptorSetLayoutCreateInfo* pCreateInfo, vk::DescriptorSetLayoutSupport* pSupport, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::DescriptorSetLayoutSupport getDescriptorSetLayoutSupport( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getDescriptorSetLayoutSupport( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getDescriptorSetLayoutSupportKHR( const vk::DescriptorSetLayoutCreateInfo* pCreateInfo, vk::DescriptorSetLayoutSupport* pSupport, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::DescriptorSetLayoutSupport getDescriptorSetLayoutSupportKHR( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getDescriptorSetLayoutSupportKHR( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getGroupPeerMemoryFeatures( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, vk::PeerMemoryFeatureFlags* pPeerMemoryFeatures, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PeerMemoryFeatureFlags getGroupPeerMemoryFeatures( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getGroupPeerMemoryFeaturesKHR( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, vk::PeerMemoryFeatureFlags* pPeerMemoryFeatures, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PeerMemoryFeatureFlags getGroupPeerMemoryFeaturesKHR( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getGroupPresentCapabilitiesKHR( vk::DeviceGroupPresentCapabilitiesKHR* pDeviceGroupPresentCapabilities, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DeviceGroupPresentCapabilitiesKHR>::type getGroupPresentCapabilitiesKHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getGroupSurfacePresentModes2EXT( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, vk::DeviceGroupPresentModeFlagsKHR* pModes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DeviceGroupPresentModeFlagsKHR>::type getGroupSurfacePresentModes2EXT( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getGroupSurfacePresentModesKHR( vk::SurfaceKHR surface, vk::DeviceGroupPresentModeFlagsKHR* pModes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DeviceGroupPresentModeFlagsKHR>::type getGroupSurfacePresentModesKHR( vk::SurfaceKHR surface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getMemoryCommitment( vk::DeviceMemory memory, vk::DeviceSize* pCommittedMemoryInBytes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::DeviceSize getMemoryCommitment( vk::DeviceMemory memory, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    PFN_vkVoidFunction getProcAddr( const char* pName, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    PFN_vkVoidFunction getProcAddr( const std::string & name, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getQueue( uint32_t queueFamilyIndex, uint32_t queueIndex, vk::Queue* pQueue, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::Queue getQueue( uint32_t queueFamilyIndex, uint32_t queueIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getQueue2( const vk::DeviceQueueInfo2* pQueueInfo, vk::Queue* pQueue, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::Queue getQueue2( const DeviceQueueInfo2 & queueInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getEventStatus( vk::Event event, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getFenceFdKHR( const vk::FenceGetFdInfoKHR* pGetFdInfo, int* pFd, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<int>::type getFenceFdKHR( const FenceGetFdInfoKHR & getFdInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getFenceStatus( vk::Fence fence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getFenceWin32HandleKHR( const vk::FenceGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<HANDLE>::type getFenceWin32HandleKHR( const FenceGetWin32HandleInfoKHR & getWin32HandleInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getImageDrmFormatModifierPropertiesEXT( vk::Image image, vk::ImageDrmFormatModifierPropertiesEXT* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ImageDrmFormatModifierPropertiesEXT>::type getImageDrmFormatModifierPropertiesEXT( vk::Image image, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getImageMemoryRequirements( vk::Image image, vk::MemoryRequirements* pMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MemoryRequirements getImageMemoryRequirements( vk::Image image, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getImageMemoryRequirements2( const vk::ImageMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MemoryRequirements2 getImageMemoryRequirements2( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getImageMemoryRequirements2( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getImageMemoryRequirements2KHR( const vk::ImageMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MemoryRequirements2 getImageMemoryRequirements2KHR( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getImageMemoryRequirements2KHR( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getImageSparseMemoryRequirements( vk::Image image, uint32_t* pSparseMemoryRequirementCount, vk::SparseImageMemoryRequirements* pSparseMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SparseImageMemoryRequirements>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageMemoryRequirements,Allocator> getImageSparseMemoryRequirements( vk::Image image, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SparseImageMemoryRequirements>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageMemoryRequirements,Allocator> getImageSparseMemoryRequirements( vk::Image image, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getImageSparseMemoryRequirements2( const vk::ImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, vk::SparseImageMemoryRequirements2* pSparseMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SparseImageMemoryRequirements2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageMemoryRequirements2,Allocator> getImageSparseMemoryRequirements2( const ImageSparseMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SparseImageMemoryRequirements2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageMemoryRequirements2,Allocator> getImageSparseMemoryRequirements2( const ImageSparseMemoryRequirementsInfo2 & info, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getImageSparseMemoryRequirements2KHR( const vk::ImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, vk::SparseImageMemoryRequirements2* pSparseMemoryRequirements, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SparseImageMemoryRequirements2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageMemoryRequirements2,Allocator> getImageSparseMemoryRequirements2KHR( const ImageSparseMemoryRequirementsInfo2 & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SparseImageMemoryRequirements2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageMemoryRequirements2,Allocator> getImageSparseMemoryRequirements2KHR( const ImageSparseMemoryRequirementsInfo2 & info, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getImageSubresourceLayout( vk::Image image, const vk::ImageSubresource* pSubresource, vk::SubresourceLayout* pLayout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::SubresourceLayout getImageSubresourceLayout( vk::Image image, const ImageSubresource & subresource, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    uint32_t getImageViewHandleNVX( const vk::ImageViewHandleInfoNVX* pInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    uint32_t getImageViewHandleNVX( const ImageViewHandleInfoNVX & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getMemoryAndroidHardwareBufferANDROID( const vk::MemoryGetAndroidHardwareBufferInfoANDROID* pInfo, struct AHardwareBuffer** pBuffer, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<struct AHardwareBuffer*>::type getMemoryAndroidHardwareBufferANDROID( const MemoryGetAndroidHardwareBufferInfoANDROID & info, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getMemoryFdKHR( const vk::MemoryGetFdInfoKHR* pGetFdInfo, int* pFd, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<int>::type getMemoryFdKHR( const MemoryGetFdInfoKHR & getFdInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getMemoryFdPropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, int fd, vk::MemoryFdPropertiesKHR* pMemoryFdProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::MemoryFdPropertiesKHR>::type getMemoryFdPropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, int fd, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getMemoryHostPointerPropertiesEXT( vk::ExternalMemoryHandleTypeFlagBits handleType, const void* pHostPointer, vk::MemoryHostPointerPropertiesEXT* pMemoryHostPointerProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::MemoryHostPointerPropertiesEXT>::type getMemoryHostPointerPropertiesEXT( vk::ExternalMemoryHandleTypeFlagBits handleType, const void* pHostPointer, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getMemoryWin32HandleKHR( const vk::MemoryGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<HANDLE>::type getMemoryWin32HandleKHR( const MemoryGetWin32HandleInfoKHR & getWin32HandleInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getMemoryWin32HandleNV( vk::DeviceMemory memory, vk::ExternalMemoryHandleTypeFlagsNV handleType, HANDLE* pHandle, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<HANDLE>::type getMemoryWin32HandleNV( vk::DeviceMemory memory, vk::ExternalMemoryHandleTypeFlagsNV handleType, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getMemoryWin32HandlePropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, HANDLE handle, vk::MemoryWin32HandlePropertiesKHR* pMemoryWin32HandleProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::MemoryWin32HandlePropertiesKHR>::type getMemoryWin32HandlePropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, HANDLE handle, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getPastPresentationTimingGOOGLE( vk::SwapchainKHR swapchain, uint32_t* pPresentationTimingCount, vk::PastPresentationTimingGOOGLE* pPresentationTimings, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PastPresentationTimingGOOGLE>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PastPresentationTimingGOOGLE,Allocator>>::type getPastPresentationTimingGOOGLE( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PastPresentationTimingGOOGLE>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PastPresentationTimingGOOGLE,Allocator>>::type getPastPresentationTimingGOOGLE( vk::SwapchainKHR swapchain, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getPerformanceParameterINTEL( vk::PerformanceParameterTypeINTEL parameter, vk::PerformanceValueINTEL* pValue, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::PerformanceValueINTEL>::type getPerformanceParameterINTEL( vk::PerformanceParameterTypeINTEL parameter, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getPipelineCacheData( vk::PipelineCache pipelineCache, size_t* pDataSize, void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<uint8_t>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<uint8_t,Allocator>>::type getPipelineCacheData( vk::PipelineCache pipelineCache, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<uint8_t>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<uint8_t,Allocator>>::type getPipelineCacheData( vk::PipelineCache pipelineCache, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getPipelineExecutableInternalRepresentationsKHR( const vk::PipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pInternalRepresentationCount, vk::PipelineExecutableInternalRepresentationKHR* pInternalRepresentations, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PipelineExecutableInternalRepresentationKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PipelineExecutableInternalRepresentationKHR,Allocator>>::type getPipelineExecutableInternalRepresentationsKHR( const PipelineExecutableInfoKHR & executableInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PipelineExecutableInternalRepresentationKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PipelineExecutableInternalRepresentationKHR,Allocator>>::type getPipelineExecutableInternalRepresentationsKHR( const PipelineExecutableInfoKHR & executableInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getPipelineExecutablePropertiesKHR( const vk::PipelineInfoKHR* pPipelineInfo, uint32_t* pExecutableCount, vk::PipelineExecutablePropertiesKHR* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PipelineExecutablePropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PipelineExecutablePropertiesKHR,Allocator>>::type getPipelineExecutablePropertiesKHR( const PipelineInfoKHR & pipelineInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PipelineExecutablePropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PipelineExecutablePropertiesKHR,Allocator>>::type getPipelineExecutablePropertiesKHR( const PipelineInfoKHR & pipelineInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getPipelineExecutableStatisticsKHR( const vk::PipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pStatisticCount, vk::PipelineExecutableStatisticKHR* pStatistics, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PipelineExecutableStatisticKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PipelineExecutableStatisticKHR,Allocator>>::type getPipelineExecutableStatisticsKHR( const PipelineExecutableInfoKHR & executableInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PipelineExecutableStatisticKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PipelineExecutableStatisticKHR,Allocator>>::type getPipelineExecutableStatisticsKHR( const PipelineExecutableInfoKHR & executableInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getQueryPoolResults( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, size_t dataSize, void* pData, vk::DeviceSize stride, vk::QueryResultFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename T, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getQueryPoolResults( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, ArrayProxy<T> data, vk::DeviceSize stride, vk::QueryResultFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getRayTracingShaderGroupHandlesNV( vk::Pipeline pipeline, uint32_t firstGroup, uint32_t groupCount, size_t dataSize, void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename T, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type getRayTracingShaderGroupHandlesNV( vk::Pipeline pipeline, uint32_t firstGroup, uint32_t groupCount, ArrayProxy<T> data, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getRefreshCycleDurationGOOGLE( vk::SwapchainKHR swapchain, vk::RefreshCycleDurationGOOGLE* pDisplayTimingProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::RefreshCycleDurationGOOGLE>::type getRefreshCycleDurationGOOGLE( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getRenderAreaGranularity( vk::RenderPass renderPass, vk::Extent2D* pGranularity, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::Extent2D getRenderAreaGranularity( vk::RenderPass renderPass, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSemaphoreCounterValueKHR( vk::Semaphore semaphore, uint64_t* pValue, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<uint64_t>::type getSemaphoreCounterValueKHR( vk::Semaphore semaphore, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSemaphoreFdKHR( const vk::SemaphoreGetFdInfoKHR* pGetFdInfo, int* pFd, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<int>::type getSemaphoreFdKHR( const SemaphoreGetFdInfoKHR & getFdInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSemaphoreWin32HandleKHR( const vk::SemaphoreGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<HANDLE>::type getSemaphoreWin32HandleKHR( const SemaphoreGetWin32HandleInfoKHR & getWin32HandleInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getShaderInfoAMD( vk::Pipeline pipeline, vk::ShaderStageFlagBits shaderStage, vk::ShaderInfoTypeAMD infoType, size_t* pInfoSize, void* pInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<uint8_t>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<uint8_t,Allocator>>::type getShaderInfoAMD( vk::Pipeline pipeline, vk::ShaderStageFlagBits shaderStage, vk::ShaderInfoTypeAMD infoType, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<uint8_t>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<uint8_t,Allocator>>::type getShaderInfoAMD( vk::Pipeline pipeline, vk::ShaderStageFlagBits shaderStage, vk::ShaderInfoTypeAMD infoType, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSwapchainCounterEXT( vk::SwapchainKHR swapchain, vk::SurfaceCounterFlagBitsEXT counter, uint64_t* pCounterValue, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<uint64_t>::type getSwapchainCounterEXT( vk::SwapchainKHR swapchain, vk::SurfaceCounterFlagBitsEXT counter, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSwapchainImagesKHR( vk::SwapchainKHR swapchain, uint32_t* pSwapchainImageCount, vk::Image* pSwapchainImages, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<Image>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Image,Allocator>>::type getSwapchainImagesKHR( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<Image>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Image,Allocator>>::type getSwapchainImagesKHR( vk::SwapchainKHR swapchain, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSwapchainStatusKHR( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getValidationCacheDataEXT( vk::ValidationCacheEXT validationCache, size_t* pDataSize, void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<uint8_t>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<uint8_t,Allocator>>::type getValidationCacheDataEXT( vk::ValidationCacheEXT validationCache, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<uint8_t>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<uint8_t,Allocator>>::type getValidationCacheDataEXT( vk::ValidationCacheEXT validationCache, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result importFenceFdKHR( const vk::ImportFenceFdInfoKHR* pImportFenceFdInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type importFenceFdKHR( const ImportFenceFdInfoKHR & importFenceFdInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result importFenceWin32HandleKHR( const vk::ImportFenceWin32HandleInfoKHR* pImportFenceWin32HandleInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type importFenceWin32HandleKHR( const ImportFenceWin32HandleInfoKHR & importFenceWin32HandleInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result importSemaphoreFdKHR( const vk::ImportSemaphoreFdInfoKHR* pImportSemaphoreFdInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type importSemaphoreFdKHR( const ImportSemaphoreFdInfoKHR & importSemaphoreFdInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result importSemaphoreWin32HandleKHR( const vk::ImportSemaphoreWin32HandleInfoKHR* pImportSemaphoreWin32HandleInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type importSemaphoreWin32HandleKHR( const ImportSemaphoreWin32HandleInfoKHR & importSemaphoreWin32HandleInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result initializePerformanceApiINTEL( const vk::InitializePerformanceApiInfoINTEL* pInitializeInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type initializePerformanceApiINTEL( const InitializePerformanceApiInfoINTEL & initializeInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result invalidateMappedMemoryRanges( uint32_t memoryRangeCount, const vk::MappedMemoryRange* pMemoryRanges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type invalidateMappedMemoryRanges( ArrayProxy<const vk::MappedMemoryRange> memoryRanges, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result mapMemory( vk::DeviceMemory memory, vk::DeviceSize offset, vk::DeviceSize size, vk::MemoryMapFlags flags, void** ppData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void*>::type mapMemory( vk::DeviceMemory memory, vk::DeviceSize offset, vk::DeviceSize size, vk::MemoryMapFlags flags = MemoryMapFlags(), Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result mergePipelineCaches( vk::PipelineCache dstCache, uint32_t srcCacheCount, const vk::PipelineCache* pSrcCaches, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type mergePipelineCaches( vk::PipelineCache dstCache, ArrayProxy<const vk::PipelineCache> srcCaches, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result mergeValidationCachesEXT( vk::ValidationCacheEXT dstCache, uint32_t srcCacheCount, const vk::ValidationCacheEXT* pSrcCaches, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type mergeValidationCachesEXT( vk::ValidationCacheEXT dstCache, ArrayProxy<const vk::ValidationCacheEXT> srcCaches, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result registerEventEXT( const vk::DeviceEventInfoEXT* pDeviceEventInfo, const vk::AllocationCallbacks* pAllocator, vk::Fence* pFence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Fence>::type registerEventEXT( const DeviceEventInfoEXT & deviceEventInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result registerDisplayEventEXT( vk::DisplayKHR display, const vk::DisplayEventInfoEXT* pDisplayEventInfo, const vk::AllocationCallbacks* pAllocator, vk::Fence* pFence, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Fence>::type registerDisplayEventEXT( vk::DisplayKHR display, const DisplayEventInfoEXT & displayEventInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result registerObjectsNVX( vk::ObjectTableNVX objectTable, uint32_t objectCount, const vk::ObjectTableEntryNVX* const* ppObjectTableEntries, const uint32_t* pObjectIndices, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type registerObjectsNVX( vk::ObjectTableNVX objectTable, ArrayProxy<const vk::ObjectTableEntryNVX* const> pObjectTableEntries, ArrayProxy<const uint32_t> objectIndices, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result releaseFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type releaseFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result releasePerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type releasePerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result resetCommandPool( vk::CommandPool commandPool, vk::CommandPoolResetFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type resetCommandPool( vk::CommandPool commandPool, vk::CommandPoolResetFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result resetDescriptorPool( vk::DescriptorPool descriptorPool, vk::DescriptorPoolResetFlags flags = DescriptorPoolResetFlags(), Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type resetDescriptorPool( vk::DescriptorPool descriptorPool, vk::DescriptorPoolResetFlags flags = DescriptorPoolResetFlags(), Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result resetEvent( vk::Event event, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type resetEvent( vk::Event event, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result resetFences( uint32_t fenceCount, const vk::Fence* pFences, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type resetFences( ArrayProxy<const vk::Fence> fences, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void resetQueryPoolEXT( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result setDebugUtilsObjectNameEXT( const vk::DebugUtilsObjectNameInfoEXT* pNameInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type setDebugUtilsObjectNameEXT( const DebugUtilsObjectNameInfoEXT & nameInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result setDebugUtilsObjectTagEXT( const vk::DebugUtilsObjectTagInfoEXT* pTagInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type setDebugUtilsObjectTagEXT( const DebugUtilsObjectTagInfoEXT & tagInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result setEvent( vk::Event event, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type setEvent( vk::Event event, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setHdrMetadataEXT( uint32_t swapchainCount, const vk::SwapchainKHR* pSwapchains, const vk::HdrMetadataEXT* pMetadata, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setHdrMetadataEXT( ArrayProxy<const vk::SwapchainKHR> swapchains, ArrayProxy<const vk::HdrMetadataEXT> metadata, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void setLocalDimmingAMD( vk::SwapchainKHR swapChain, vk::Bool32 localDimmingEnable, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result signalSemaphoreKHR( const vk::SemaphoreSignalInfoKHR* pSignalInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type signalSemaphoreKHR( const SemaphoreSignalInfoKHR & signalInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void trimCommandPool( vk::CommandPool commandPool, vk::CommandPoolTrimFlags flags = CommandPoolTrimFlags(), Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void trimCommandPoolKHR( vk::CommandPool commandPool, vk::CommandPoolTrimFlags flags = CommandPoolTrimFlags(), Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void uninitializePerformanceApiINTEL(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void unmapMemory( vk::DeviceMemory memory, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result unregisterObjectsNVX( vk::ObjectTableNVX objectTable, uint32_t objectCount, const vk::ObjectEntryTypeNVX* pObjectEntryTypes, const uint32_t* pObjectIndices, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type unregisterObjectsNVX( vk::ObjectTableNVX objectTable, ArrayProxy<const vk::ObjectEntryTypeNVX> objectEntryTypes, ArrayProxy<const uint32_t> objectIndices, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void updateDescriptorSetWithTemplate( vk::DescriptorSet descriptorSet, vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void updateDescriptorSetWithTemplateKHR( vk::DescriptorSet descriptorSet, vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void updateDescriptorSets( uint32_t descriptorWriteCount, const vk::WriteDescriptorSet* pDescriptorWrites, uint32_t descriptorCopyCount, const vk::CopyDescriptorSet* pDescriptorCopies, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void updateDescriptorSets( ArrayProxy<const vk::WriteDescriptorSet> descriptorWrites, ArrayProxy<const vk::CopyDescriptorSet> descriptorCopies, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result waitForFences( uint32_t fenceCount, const vk::Fence* pFences, vk::Bool32 waitAll, uint64_t timeout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result waitForFences( ArrayProxy<const vk::Fence> fences, vk::Bool32 waitAll, uint64_t timeout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result waitSemaphoresKHR( const vk::SemaphoreWaitInfoKHR* pWaitInfo, uint64_t timeout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result waitSemaphoresKHR( const SemaphoreWaitInfoKHR & waitInfo, uint64_t timeout, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDevice() const VULKAN_HPP_NOEXCEPT
    {
      return m_device;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_device != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_device == VK_NULL_HANDLE;
    }

  private:
    VkDevice m_device;
  };
  static_assert( sizeof( Device ) == sizeof( VkDevice ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDevice>
  {
    using type = Device;
  };

  class DisplayModeKHR
  {
  public:
    using CType = VkDisplayModeKHR;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eDisplayModeKHR;

  public:
    VULKAN_HPP_CONSTEXPR DisplayModeKHR() VULKAN_HPP_NOEXCEPT
      : m_displayModeKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR DisplayModeKHR( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_displayModeKHR(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT DisplayModeKHR( VkDisplayModeKHR displayModeKHR ) VULKAN_HPP_NOEXCEPT
      : m_displayModeKHR( displayModeKHR )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    DisplayModeKHR & operator=(VkDisplayModeKHR displayModeKHR) VULKAN_HPP_NOEXCEPT
    {
      m_displayModeKHR = displayModeKHR;
      return *this;
    }
#endif

    DisplayModeKHR & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_displayModeKHR = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( DisplayModeKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_displayModeKHR == rhs.m_displayModeKHR;
    }

    bool operator!=(DisplayModeKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_displayModeKHR != rhs.m_displayModeKHR;
    }

    bool operator<(DisplayModeKHR const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_displayModeKHR < rhs.m_displayModeKHR;
    }

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkDisplayModeKHR() const VULKAN_HPP_NOEXCEPT
    {
      return m_displayModeKHR;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_displayModeKHR != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_displayModeKHR == VK_NULL_HANDLE;
    }

  private:
    VkDisplayModeKHR m_displayModeKHR;
  };
  static_assert( sizeof( DisplayModeKHR ) == sizeof( VkDisplayModeKHR ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eDisplayModeKHR>
  {
    using type = DisplayModeKHR;
  };

#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template <typename Dispatch> class UniqueHandleTraits<Device, Dispatch> { public: using deleter = ObjectDestroy<NoParent, Dispatch>; };
  using UniqueDevice = UniqueHandle<Device, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/

  class PhysicalDevice
  {
  public:
    using CType = VkPhysicalDevice;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::ePhysicalDevice;

  public:
    VULKAN_HPP_CONSTEXPR PhysicalDevice() VULKAN_HPP_NOEXCEPT
      : m_physicalDevice(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR PhysicalDevice( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_physicalDevice(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT PhysicalDevice( VkPhysicalDevice physicalDevice ) VULKAN_HPP_NOEXCEPT
      : m_physicalDevice( physicalDevice )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    PhysicalDevice & operator=(VkPhysicalDevice physicalDevice) VULKAN_HPP_NOEXCEPT
    {
      m_physicalDevice = physicalDevice;
      return *this;
    }
#endif

    PhysicalDevice & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_physicalDevice = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( PhysicalDevice const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_physicalDevice == rhs.m_physicalDevice;
    }

    bool operator!=(PhysicalDevice const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_physicalDevice != rhs.m_physicalDevice;
    }

    bool operator<(PhysicalDevice const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_physicalDevice < rhs.m_physicalDevice;
    }

#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result acquireXlibDisplayEXT( Display* dpy, vk::DisplayKHR display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<Display>::type acquireXlibDisplayEXT( vk::DisplayKHR display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDevice( const vk::DeviceCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Device* pDevice, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Device>::type createDevice( const DeviceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<Device,Dispatch>>::type createDeviceUnique( const DeviceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDisplayModeKHR( vk::DisplayKHR display, const vk::DisplayModeCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DisplayModeKHR* pMode, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DisplayModeKHR>::type createDisplayModeKHR( vk::DisplayKHR display, const DisplayModeCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result enumerateDeviceExtensionProperties( const char* pLayerName, uint32_t* pPropertyCount, vk::ExtensionProperties* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<ExtensionProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type enumerateDeviceExtensionProperties( Optional<const std::string> layerName = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<ExtensionProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type enumerateDeviceExtensionProperties( Optional<const std::string> layerName, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result enumerateDeviceLayerProperties( uint32_t* pPropertyCount, vk::LayerProperties* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<LayerProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<LayerProperties,Allocator>>::type enumerateDeviceLayerProperties(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<LayerProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<LayerProperties,Allocator>>::type enumerateDeviceLayerProperties(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayModeProperties2KHR( vk::DisplayKHR display, uint32_t* pPropertyCount, vk::DisplayModeProperties2KHR* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DisplayModeProperties2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayModeProperties2KHR,Allocator>>::type getDisplayModeProperties2KHR( vk::DisplayKHR display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DisplayModeProperties2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayModeProperties2KHR,Allocator>>::type getDisplayModeProperties2KHR( vk::DisplayKHR display, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayModePropertiesKHR( vk::DisplayKHR display, uint32_t* pPropertyCount, vk::DisplayModePropertiesKHR* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DisplayModePropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayModePropertiesKHR,Allocator>>::type getDisplayModePropertiesKHR( vk::DisplayKHR display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DisplayModePropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayModePropertiesKHR,Allocator>>::type getDisplayModePropertiesKHR( vk::DisplayKHR display, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayPlaneCapabilities2KHR( const vk::DisplayPlaneInfo2KHR* pDisplayPlaneInfo, vk::DisplayPlaneCapabilities2KHR* pCapabilities, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DisplayPlaneCapabilities2KHR>::type getDisplayPlaneCapabilities2KHR( const DisplayPlaneInfo2KHR & displayPlaneInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayPlaneCapabilitiesKHR( vk::DisplayModeKHR mode, uint32_t planeIndex, vk::DisplayPlaneCapabilitiesKHR* pCapabilities, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DisplayPlaneCapabilitiesKHR>::type getDisplayPlaneCapabilitiesKHR( vk::DisplayModeKHR mode, uint32_t planeIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayPlaneSupportedDisplaysKHR( uint32_t planeIndex, uint32_t* pDisplayCount, vk::DisplayKHR* pDisplays, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DisplayKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayKHR,Allocator>>::type getDisplayPlaneSupportedDisplaysKHR( uint32_t planeIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DisplayKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayKHR,Allocator>>::type getDisplayPlaneSupportedDisplaysKHR( uint32_t planeIndex, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getCalibrateableTimeDomainsEXT( uint32_t* pTimeDomainCount, vk::TimeDomainEXT* pTimeDomains, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<TimeDomainEXT>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<TimeDomainEXT,Allocator>>::type getCalibrateableTimeDomainsEXT(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<TimeDomainEXT>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<TimeDomainEXT,Allocator>>::type getCalibrateableTimeDomainsEXT(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getCooperativeMatrixPropertiesNV( uint32_t* pPropertyCount, vk::CooperativeMatrixPropertiesNV* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<CooperativeMatrixPropertiesNV>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<CooperativeMatrixPropertiesNV,Allocator>>::type getCooperativeMatrixPropertiesNV(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<CooperativeMatrixPropertiesNV>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<CooperativeMatrixPropertiesNV,Allocator>>::type getCooperativeMatrixPropertiesNV(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayPlaneProperties2KHR( uint32_t* pPropertyCount, vk::DisplayPlaneProperties2KHR* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DisplayPlaneProperties2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayPlaneProperties2KHR,Allocator>>::type getDisplayPlaneProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DisplayPlaneProperties2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayPlaneProperties2KHR,Allocator>>::type getDisplayPlaneProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayPlanePropertiesKHR( uint32_t* pPropertyCount, vk::DisplayPlanePropertiesKHR* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DisplayPlanePropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayPlanePropertiesKHR,Allocator>>::type getDisplayPlanePropertiesKHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DisplayPlanePropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayPlanePropertiesKHR,Allocator>>::type getDisplayPlanePropertiesKHR(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayProperties2KHR( uint32_t* pPropertyCount, vk::DisplayProperties2KHR* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DisplayProperties2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayProperties2KHR,Allocator>>::type getDisplayProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DisplayProperties2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayProperties2KHR,Allocator>>::type getDisplayProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getDisplayPropertiesKHR( uint32_t* pPropertyCount, vk::DisplayPropertiesKHR* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<DisplayPropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayPropertiesKHR,Allocator>>::type getDisplayPropertiesKHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<DisplayPropertiesKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<DisplayPropertiesKHR,Allocator>>::type getDisplayPropertiesKHR(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getExternalBufferProperties( const vk::PhysicalDeviceExternalBufferInfo* pExternalBufferInfo, vk::ExternalBufferProperties* pExternalBufferProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::ExternalBufferProperties getExternalBufferProperties( const PhysicalDeviceExternalBufferInfo & externalBufferInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getExternalBufferPropertiesKHR( const vk::PhysicalDeviceExternalBufferInfo* pExternalBufferInfo, vk::ExternalBufferProperties* pExternalBufferProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::ExternalBufferProperties getExternalBufferPropertiesKHR( const PhysicalDeviceExternalBufferInfo & externalBufferInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getExternalFenceProperties( const vk::PhysicalDeviceExternalFenceInfo* pExternalFenceInfo, vk::ExternalFenceProperties* pExternalFenceProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::ExternalFenceProperties getExternalFenceProperties( const PhysicalDeviceExternalFenceInfo & externalFenceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getExternalFencePropertiesKHR( const vk::PhysicalDeviceExternalFenceInfo* pExternalFenceInfo, vk::ExternalFenceProperties* pExternalFenceProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::ExternalFenceProperties getExternalFencePropertiesKHR( const PhysicalDeviceExternalFenceInfo & externalFenceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getExternalImageFormatPropertiesNV( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, vk::ExternalMemoryHandleTypeFlagsNV externalHandleType, vk::ExternalImageFormatPropertiesNV* pExternalImageFormatProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ExternalImageFormatPropertiesNV>::type getExternalImageFormatPropertiesNV( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, vk::ExternalMemoryHandleTypeFlagsNV externalHandleType, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getExternalSemaphoreProperties( const vk::PhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, vk::ExternalSemaphoreProperties* pExternalSemaphoreProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::ExternalSemaphoreProperties getExternalSemaphoreProperties( const PhysicalDeviceExternalSemaphoreInfo & externalSemaphoreInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getExternalSemaphorePropertiesKHR( const vk::PhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, vk::ExternalSemaphoreProperties* pExternalSemaphoreProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::ExternalSemaphoreProperties getExternalSemaphorePropertiesKHR( const PhysicalDeviceExternalSemaphoreInfo & externalSemaphoreInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getFeatures( vk::PhysicalDeviceFeatures* pFeatures, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceFeatures getFeatures(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getFeatures2( vk::PhysicalDeviceFeatures2* pFeatures, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceFeatures2 getFeatures2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getFeatures2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getFeatures2KHR( vk::PhysicalDeviceFeatures2* pFeatures, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceFeatures2 getFeatures2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getFeatures2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getFormatProperties( vk::Format format, vk::FormatProperties* pFormatProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::FormatProperties getFormatProperties( vk::Format format, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getFormatProperties2( vk::Format format, vk::FormatProperties2* pFormatProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::FormatProperties2 getFormatProperties2( vk::Format format, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getFormatProperties2( vk::Format format, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getFormatProperties2KHR( vk::Format format, vk::FormatProperties2* pFormatProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::FormatProperties2 getFormatProperties2KHR( vk::Format format, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getFormatProperties2KHR( vk::Format format, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getGeneratedCommandsPropertiesNVX( vk::DeviceGeneratedCommandsFeaturesNVX* pFeatures, vk::DeviceGeneratedCommandsLimitsNVX* pLimits, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::DeviceGeneratedCommandsLimitsNVX getGeneratedCommandsPropertiesNVX( DeviceGeneratedCommandsFeaturesNVX & features, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getImageFormatProperties( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, vk::ImageFormatProperties* pImageFormatProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ImageFormatProperties>::type getImageFormatProperties( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getImageFormatProperties2( const vk::PhysicalDeviceImageFormatInfo2* pImageFormatInfo, vk::ImageFormatProperties2* pImageFormatProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ImageFormatProperties2>::type getImageFormatProperties2( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<StructureChain<X, Y, Z...>>::type getImageFormatProperties2( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getImageFormatProperties2KHR( const vk::PhysicalDeviceImageFormatInfo2* pImageFormatInfo, vk::ImageFormatProperties2* pImageFormatProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::ImageFormatProperties2>::type getImageFormatProperties2KHR( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<StructureChain<X, Y, Z...>>::type getImageFormatProperties2KHR( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getMemoryProperties( vk::PhysicalDeviceMemoryProperties* pMemoryProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceMemoryProperties getMemoryProperties(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getMemoryProperties2( vk::PhysicalDeviceMemoryProperties2* pMemoryProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceMemoryProperties2 getMemoryProperties2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getMemoryProperties2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getMemoryProperties2KHR( vk::PhysicalDeviceMemoryProperties2* pMemoryProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceMemoryProperties2 getMemoryProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getMemoryProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getMultisamplePropertiesEXT( vk::SampleCountFlagBits samples, vk::MultisamplePropertiesEXT* pMultisampleProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::MultisamplePropertiesEXT getMultisamplePropertiesEXT( vk::SampleCountFlagBits samples, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getPresentRectanglesKHR( vk::SurfaceKHR surface, uint32_t* pRectCount, vk::Rect2D* pRects, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<Rect2D>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Rect2D,Allocator>>::type getPresentRectanglesKHR( vk::SurfaceKHR surface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<Rect2D>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<Rect2D,Allocator>>::type getPresentRectanglesKHR( vk::SurfaceKHR surface, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getProperties( vk::PhysicalDeviceProperties* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceProperties getProperties(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getProperties2( vk::PhysicalDeviceProperties2* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceProperties2 getProperties2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getProperties2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getProperties2KHR( vk::PhysicalDeviceProperties2* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    vk::PhysicalDeviceProperties2 getProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    StructureChain<X, Y, Z...> getProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getQueueFamilyProperties( uint32_t* pQueueFamilyPropertyCount, vk::QueueFamilyProperties* pQueueFamilyProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<QueueFamilyProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<QueueFamilyProperties,Allocator> getQueueFamilyProperties(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<QueueFamilyProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<QueueFamilyProperties,Allocator> getQueueFamilyProperties(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getQueueFamilyProperties2( uint32_t* pQueueFamilyPropertyCount, vk::QueueFamilyProperties2* pQueueFamilyProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<QueueFamilyProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<QueueFamilyProperties2,Allocator> getQueueFamilyProperties2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<QueueFamilyProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<QueueFamilyProperties2,Allocator> getQueueFamilyProperties2(Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename StructureChain, typename Allocator = std::allocator<StructureChain>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<StructureChain,Allocator> getQueueFamilyProperties2(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename StructureChain, typename Allocator = std::allocator<StructureChain>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<StructureChain,Allocator> getQueueFamilyProperties2(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getQueueFamilyProperties2KHR( uint32_t* pQueueFamilyPropertyCount, vk::QueueFamilyProperties2* pQueueFamilyProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<QueueFamilyProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<QueueFamilyProperties2,Allocator> getQueueFamilyProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<QueueFamilyProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<QueueFamilyProperties2,Allocator> getQueueFamilyProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const;
    template<typename StructureChain, typename Allocator = std::allocator<StructureChain>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<StructureChain,Allocator> getQueueFamilyProperties2KHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename StructureChain, typename Allocator = std::allocator<StructureChain>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<StructureChain,Allocator> getQueueFamilyProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getSparseImageFormatProperties( vk::Format format, vk::ImageType type, vk::SampleCountFlagBits samples, vk::ImageUsageFlags usage, vk::ImageTiling tiling, uint32_t* pPropertyCount, vk::SparseImageFormatProperties* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SparseImageFormatProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageFormatProperties,Allocator> getSparseImageFormatProperties( vk::Format format, vk::ImageType type, vk::SampleCountFlagBits samples, vk::ImageUsageFlags usage, vk::ImageTiling tiling, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SparseImageFormatProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageFormatProperties,Allocator> getSparseImageFormatProperties( vk::Format format, vk::ImageType type, vk::SampleCountFlagBits samples, vk::ImageUsageFlags usage, vk::ImageTiling tiling, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getSparseImageFormatProperties2( const vk::PhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, vk::SparseImageFormatProperties2* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SparseImageFormatProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageFormatProperties2,Allocator> getSparseImageFormatProperties2( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SparseImageFormatProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageFormatProperties2,Allocator> getSparseImageFormatProperties2( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void getSparseImageFormatProperties2KHR( const vk::PhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, vk::SparseImageFormatProperties2* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SparseImageFormatProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageFormatProperties2,Allocator> getSparseImageFormatProperties2KHR( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SparseImageFormatProperties2>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    std::vector<SparseImageFormatProperties2,Allocator> getSparseImageFormatProperties2KHR( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSupportedFramebufferMixedSamplesCombinationsNV( uint32_t* pCombinationCount, vk::FramebufferMixedSamplesCombinationNV* pCombinations, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<FramebufferMixedSamplesCombinationNV>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<FramebufferMixedSamplesCombinationNV,Allocator>>::type getSupportedFramebufferMixedSamplesCombinationsNV(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<FramebufferMixedSamplesCombinationNV>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<FramebufferMixedSamplesCombinationNV,Allocator>>::type getSupportedFramebufferMixedSamplesCombinationsNV(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfaceCapabilities2EXT( vk::SurfaceKHR surface, vk::SurfaceCapabilities2EXT* pSurfaceCapabilities, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceCapabilities2EXT>::type getSurfaceCapabilities2EXT( vk::SurfaceKHR surface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfaceCapabilities2KHR( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, vk::SurfaceCapabilities2KHR* pSurfaceCapabilities, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceCapabilities2KHR>::type getSurfaceCapabilities2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename X, typename Y, typename ...Z, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<StructureChain<X, Y, Z...>>::type getSurfaceCapabilities2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfaceCapabilitiesKHR( vk::SurfaceKHR surface, vk::SurfaceCapabilitiesKHR* pSurfaceCapabilities, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceCapabilitiesKHR>::type getSurfaceCapabilitiesKHR( vk::SurfaceKHR surface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfaceFormats2KHR( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, uint32_t* pSurfaceFormatCount, vk::SurfaceFormat2KHR* pSurfaceFormats, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SurfaceFormat2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<SurfaceFormat2KHR,Allocator>>::type getSurfaceFormats2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SurfaceFormat2KHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<SurfaceFormat2KHR,Allocator>>::type getSurfaceFormats2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfaceFormatsKHR( vk::SurfaceKHR surface, uint32_t* pSurfaceFormatCount, vk::SurfaceFormatKHR* pSurfaceFormats, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<SurfaceFormatKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<SurfaceFormatKHR,Allocator>>::type getSurfaceFormatsKHR( vk::SurfaceKHR surface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<SurfaceFormatKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<SurfaceFormatKHR,Allocator>>::type getSurfaceFormatsKHR( vk::SurfaceKHR surface, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfacePresentModes2EXT( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, uint32_t* pPresentModeCount, vk::PresentModeKHR* pPresentModes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PresentModeKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type getSurfacePresentModes2EXT( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PresentModeKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type getSurfacePresentModes2EXT( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfacePresentModesKHR( vk::SurfaceKHR surface, uint32_t* pPresentModeCount, vk::PresentModeKHR* pPresentModes, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PresentModeKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type getSurfacePresentModesKHR( vk::SurfaceKHR surface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PresentModeKHR>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type getSurfacePresentModesKHR( vk::SurfaceKHR surface, Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getSurfaceSupportKHR( uint32_t queueFamilyIndex, vk::SurfaceKHR surface, vk::Bool32* pSupported, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::Bool32>::type getSurfaceSupportKHR( uint32_t queueFamilyIndex, vk::SurfaceKHR surface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WAYLAND_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Bool32 getWaylandPresentationSupportKHR( uint32_t queueFamilyIndex, struct wl_display* display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Bool32 getWaylandPresentationSupportKHR( uint32_t queueFamilyIndex, struct wl_display & display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Bool32 getWin32PresentationSupportKHR( uint32_t queueFamilyIndex, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_XCB_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Bool32 getXcbPresentationSupportKHR( uint32_t queueFamilyIndex, xcb_connection_t* connection, xcb_visualid_t visual_id, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Bool32 getXcbPresentationSupportKHR( uint32_t queueFamilyIndex, xcb_connection_t & connection, xcb_visualid_t visual_id, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Bool32 getXlibPresentationSupportKHR( uint32_t queueFamilyIndex, Display* dpy, VisualID visualID, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Bool32 getXlibPresentationSupportKHR( uint32_t queueFamilyIndex, Display & dpy, VisualID visualID, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result getRandROutputDisplayEXT( Display* dpy, RROutput rrOutput, vk::DisplayKHR* pDisplay, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DisplayKHR>::type getRandROutputDisplayEXT( Display & dpy, RROutput rrOutput, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result releaseDisplayEXT( vk::DisplayKHR display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#else
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<void>::type releaseDisplayEXT( vk::DisplayKHR display, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkPhysicalDevice() const VULKAN_HPP_NOEXCEPT
    {
      return m_physicalDevice;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_physicalDevice != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_physicalDevice == VK_NULL_HANDLE;
    }

  private:
    VkPhysicalDevice m_physicalDevice;
  };
  static_assert( sizeof( PhysicalDevice ) == sizeof( VkPhysicalDevice ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::ePhysicalDevice>
  {
    using type = PhysicalDevice;
  };

#ifndef VULKAN_HPP_NO_SMART_HANDLE
  class Instance;
  template <typename Dispatch> class UniqueHandleTraits<DebugReportCallbackEXT, Dispatch> { public: using deleter = ObjectDestroy<Instance, Dispatch>; };
  using UniqueDebugReportCallbackEXT = UniqueHandle<DebugReportCallbackEXT, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<DebugUtilsMessengerEXT, Dispatch> { public: using deleter = ObjectDestroy<Instance, Dispatch>; };
  using UniqueDebugUtilsMessengerEXT = UniqueHandle<DebugUtilsMessengerEXT, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
  template <typename Dispatch> class UniqueHandleTraits<SurfaceKHR, Dispatch> { public: using deleter = ObjectDestroy<Instance, Dispatch>; };
  using UniqueSurfaceKHR = UniqueHandle<SurfaceKHR, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/

  class Instance
  {
  public:
    using CType = VkInstance;

    static VULKAN_HPP_CONST_OR_CONSTEXPR ObjectType objectType = ObjectType::eInstance;

  public:
    VULKAN_HPP_CONSTEXPR Instance() VULKAN_HPP_NOEXCEPT
      : m_instance(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_CONSTEXPR Instance( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
      : m_instance(VK_NULL_HANDLE)
    {}

    VULKAN_HPP_TYPESAFE_EXPLICIT Instance( VkInstance instance ) VULKAN_HPP_NOEXCEPT
      : m_instance( instance )
    {}

#if defined(VULKAN_HPP_TYPESAFE_CONVERSION)
    Instance & operator=(VkInstance instance) VULKAN_HPP_NOEXCEPT
    {
      m_instance = instance;
      return *this;
    }
#endif

    Instance & operator=( std::nullptr_t ) VULKAN_HPP_NOEXCEPT
    {
      m_instance = VK_NULL_HANDLE;
      return *this;
    }

    bool operator==( Instance const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_instance == rhs.m_instance;
    }

    bool operator!=(Instance const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_instance != rhs.m_instance;
    }

    bool operator<(Instance const & rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return m_instance < rhs.m_instance;
    }

#ifdef VK_USE_PLATFORM_ANDROID_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createAndroidSurfaceKHR( const vk::AndroidSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createAndroidSurfaceKHR( const AndroidSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createAndroidSurfaceKHRUnique( const AndroidSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDebugReportCallbackEXT( const vk::DebugReportCallbackCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DebugReportCallbackEXT* pCallback, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DebugReportCallbackEXT>::type createDebugReportCallbackEXT( const DebugReportCallbackCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<DebugReportCallbackEXT,Dispatch>>::type createDebugReportCallbackEXTUnique( const DebugReportCallbackCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDebugUtilsMessengerEXT( const vk::DebugUtilsMessengerCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DebugUtilsMessengerEXT* pMessenger, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::DebugUtilsMessengerEXT>::type createDebugUtilsMessengerEXT( const DebugUtilsMessengerCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<DebugUtilsMessengerEXT,Dispatch>>::type createDebugUtilsMessengerEXTUnique( const DebugUtilsMessengerCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createDisplayPlaneSurfaceKHR( const vk::DisplaySurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createDisplayPlaneSurfaceKHR( const DisplaySurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createDisplayPlaneSurfaceKHRUnique( const DisplaySurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createHeadlessSurfaceEXT( const vk::HeadlessSurfaceCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createHeadlessSurfaceEXT( const HeadlessSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createHeadlessSurfaceEXTUnique( const HeadlessSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_IOS_MVK
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createIOSSurfaceMVK( const vk::IOSSurfaceCreateInfoMVK* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createIOSSurfaceMVK( const IOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createIOSSurfaceMVKUnique( const IOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_IOS_MVK*/

#ifdef VK_USE_PLATFORM_FUCHSIA
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createImagePipeSurfaceFUCHSIA( const vk::ImagePipeSurfaceCreateInfoFUCHSIA* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createImagePipeSurfaceFUCHSIA( const ImagePipeSurfaceCreateInfoFUCHSIA & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createImagePipeSurfaceFUCHSIAUnique( const ImagePipeSurfaceCreateInfoFUCHSIA & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_FUCHSIA*/

#ifdef VK_USE_PLATFORM_MACOS_MVK
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createMacOSSurfaceMVK( const vk::MacOSSurfaceCreateInfoMVK* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createMacOSSurfaceMVK( const MacOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createMacOSSurfaceMVKUnique( const MacOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_MACOS_MVK*/

#ifdef VK_USE_PLATFORM_METAL_EXT
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createMetalSurfaceEXT( const vk::MetalSurfaceCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createMetalSurfaceEXT( const MetalSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createMetalSurfaceEXTUnique( const MetalSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_METAL_EXT*/

#ifdef VK_USE_PLATFORM_GGP
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createStreamDescriptorSurfaceGGP( const vk::StreamDescriptorSurfaceCreateInfoGGP* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createStreamDescriptorSurfaceGGP( const StreamDescriptorSurfaceCreateInfoGGP & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createStreamDescriptorSurfaceGGPUnique( const StreamDescriptorSurfaceCreateInfoGGP & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_GGP*/

#ifdef VK_USE_PLATFORM_VI_NN
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createViSurfaceNN( const vk::ViSurfaceCreateInfoNN* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createViSurfaceNN( const ViSurfaceCreateInfoNN & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createViSurfaceNNUnique( const ViSurfaceCreateInfoNN & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_VI_NN*/

#ifdef VK_USE_PLATFORM_WAYLAND_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createWaylandSurfaceKHR( const vk::WaylandSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createWaylandSurfaceKHR( const WaylandSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createWaylandSurfaceKHRUnique( const WaylandSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createWin32SurfaceKHR( const vk::Win32SurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createWin32SurfaceKHR( const Win32SurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createWin32SurfaceKHRUnique( const Win32SurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_XCB_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createXcbSurfaceKHR( const vk::XcbSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createXcbSurfaceKHR( const XcbSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createXcbSurfaceKHRUnique( const XcbSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result createXlibSurfaceKHR( const vk::XlibSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    ResultValueType<vk::SurfaceKHR>::type createXlibSurfaceKHR( const XlibSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_NO_SMART_HANDLE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type createXlibSurfaceKHRUnique( const XlibSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void debugReportMessageEXT( vk::DebugReportFlagsEXT flags, vk::DebugReportObjectTypeEXT objectType, uint64_t object, size_t location, int32_t messageCode, const char* pLayerPrefix, const char* pMessage, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void debugReportMessageEXT( vk::DebugReportFlagsEXT flags, vk::DebugReportObjectTypeEXT objectType, uint64_t object, size_t location, int32_t messageCode, const std::string & layerPrefix, const std::string & message, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDebugReportCallbackEXT( vk::DebugReportCallbackEXT callback, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDebugReportCallbackEXT( vk::DebugReportCallbackEXT callback, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DebugReportCallbackEXT callback, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DebugReportCallbackEXT callback, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDebugUtilsMessengerEXT( vk::DebugUtilsMessengerEXT messenger, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroyDebugUtilsMessengerEXT( vk::DebugUtilsMessengerEXT messenger, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DebugUtilsMessengerEXT messenger, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::DebugUtilsMessengerEXT messenger, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySurfaceKHR( vk::SurfaceKHR surface, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroySurfaceKHR( vk::SurfaceKHR surface, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::SurfaceKHR surface, const vk::AllocationCallbacks* pAllocator, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void destroy( vk::SurfaceKHR surface, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result enumeratePhysicalDeviceGroups( uint32_t* pPhysicalDeviceGroupCount, vk::PhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PhysicalDeviceGroupProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type enumeratePhysicalDeviceGroups(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PhysicalDeviceGroupProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type enumeratePhysicalDeviceGroups(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result enumeratePhysicalDeviceGroupsKHR( uint32_t* pPhysicalDeviceGroupCount, vk::PhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PhysicalDeviceGroupProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type enumeratePhysicalDeviceGroupsKHR(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PhysicalDeviceGroupProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type enumeratePhysicalDeviceGroupsKHR(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    Result enumeratePhysicalDevices( uint32_t* pPhysicalDeviceCount, vk::PhysicalDevice* pPhysicalDevices, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Allocator = std::allocator<PhysicalDevice>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PhysicalDevice,Allocator>>::type enumeratePhysicalDevices(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const;
    template<typename Allocator = std::allocator<PhysicalDevice>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    typename ResultValueType<std::vector<PhysicalDevice,Allocator>>::type enumeratePhysicalDevices(Allocator const& vectorAllocator, Dispatch const &d ) const;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    PFN_vkVoidFunction getProcAddr( const char* pName, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    PFN_vkVoidFunction getProcAddr( const std::string & name, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void submitDebugUtilsMessageEXT( vk::DebugUtilsMessageSeverityFlagBitsEXT messageSeverity, vk::DebugUtilsMessageTypeFlagsEXT messageTypes, const vk::DebugUtilsMessengerCallbackDataEXT* pCallbackData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
    template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
    void submitDebugUtilsMessageEXT( vk::DebugUtilsMessageSeverityFlagBitsEXT messageSeverity, vk::DebugUtilsMessageTypeFlagsEXT messageTypes, const DebugUtilsMessengerCallbackDataEXT & callbackData, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER ) const VULKAN_HPP_NOEXCEPT;
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

    VULKAN_HPP_TYPESAFE_EXPLICIT operator VkInstance() const VULKAN_HPP_NOEXCEPT
    {
      return m_instance;
    }

    explicit operator bool() const VULKAN_HPP_NOEXCEPT
    {
      return m_instance != VK_NULL_HANDLE;
    }

    bool operator!() const VULKAN_HPP_NOEXCEPT
    {
      return m_instance == VK_NULL_HANDLE;
    }

  private:
    VkInstance m_instance;
  };
  static_assert( sizeof( Instance ) == sizeof( VkInstance ), "handle and wrapper have different size!" );

  template <>
  struct cpp_type<ObjectType::eInstance>
  {
    using type = Instance;
  };

#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template <typename Dispatch> class UniqueHandleTraits<Instance, Dispatch> { public: using deleter = ObjectDestroy<NoParent, Dispatch>; };
  using UniqueInstance = UniqueHandle<Instance, VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>;
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/

  template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  Result createInstance( const vk::InstanceCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Instance* pInstance, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  ResultValueType<vk::Instance>::type createInstance( const InstanceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  typename ResultValueType<UniqueHandle<Instance,Dispatch>>::type createInstanceUnique( const InstanceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  Result enumerateInstanceExtensionProperties( const char* pLayerName, uint32_t* pPropertyCount, vk::ExtensionProperties* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator = std::allocator<ExtensionProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type enumerateInstanceExtensionProperties( Optional<const std::string> layerName = nullptr, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
  template<typename Allocator = std::allocator<ExtensionProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type enumerateInstanceExtensionProperties( Optional<const std::string> layerName, Allocator const& vectorAllocator, Dispatch const &d );
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  Result enumerateInstanceLayerProperties( uint32_t* pPropertyCount, vk::LayerProperties* pProperties, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator = std::allocator<LayerProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  typename ResultValueType<std::vector<LayerProperties,Allocator>>::type enumerateInstanceLayerProperties(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
  template<typename Allocator = std::allocator<LayerProperties>, typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  typename ResultValueType<std::vector<LayerProperties,Allocator>>::type enumerateInstanceLayerProperties(Allocator const& vectorAllocator, Dispatch const &d );
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  Result enumerateInstanceVersion( uint32_t* pApiVersion, Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch = VULKAN_HPP_DEFAULT_DISPATCHER_TYPE>
  ResultValueType<uint32_t>::type enumerateInstanceVersion(Dispatch const &d = VULKAN_HPP_DEFAULT_DISPATCHER );
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  namespace layout
  {
    struct GeometryTrianglesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR GeometryTrianglesNV( vk::Buffer vertexData_ = vk::Buffer(),
                                                vk::DeviceSize vertexOffset_ = 0,
                                                uint32_t vertexCount_ = 0,
                                                vk::DeviceSize vertexStride_ = 0,
                                                vk::Format vertexFormat_ = vk::Format::eUndefined,
                                                vk::Buffer indexData_ = vk::Buffer(),
                                                vk::DeviceSize indexOffset_ = 0,
                                                uint32_t indexCount_ = 0,
                                                vk::IndexType indexType_ = vk::IndexType::eUint16,
                                                vk::Buffer transformData_ = vk::Buffer(),
                                                vk::DeviceSize transformOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
        : vertexData( vertexData_ )
        , vertexOffset( vertexOffset_ )
        , vertexCount( vertexCount_ )
        , vertexStride( vertexStride_ )
        , vertexFormat( vertexFormat_ )
        , indexData( indexData_ )
        , indexOffset( indexOffset_ )
        , indexCount( indexCount_ )
        , indexType( indexType_ )
        , transformData( transformData_ )
        , transformOffset( transformOffset_ )
      {}

      GeometryTrianglesNV( VkGeometryTrianglesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGeometryTrianglesNV*>(this) = rhs;
      }

      GeometryTrianglesNV& operator=( VkGeometryTrianglesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGeometryTrianglesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eGeometryTrianglesNV;
      const void* pNext = nullptr;
      vk::Buffer vertexData;
      vk::DeviceSize vertexOffset;
      uint32_t vertexCount;
      vk::DeviceSize vertexStride;
      vk::Format vertexFormat;
      vk::Buffer indexData;
      vk::DeviceSize indexOffset;
      uint32_t indexCount;
      vk::IndexType indexType;
      vk::Buffer transformData;
      vk::DeviceSize transformOffset;
    };
    static_assert( sizeof( GeometryTrianglesNV ) == sizeof( VkGeometryTrianglesNV ), "layout struct and wrapper have different size!" );
  }

  struct GeometryTrianglesNV : public layout::GeometryTrianglesNV
  {
    VULKAN_HPP_CONSTEXPR GeometryTrianglesNV( vk::Buffer vertexData_ = vk::Buffer(),
                                              vk::DeviceSize vertexOffset_ = 0,
                                              uint32_t vertexCount_ = 0,
                                              vk::DeviceSize vertexStride_ = 0,
                                              vk::Format vertexFormat_ = vk::Format::eUndefined,
                                              vk::Buffer indexData_ = vk::Buffer(),
                                              vk::DeviceSize indexOffset_ = 0,
                                              uint32_t indexCount_ = 0,
                                              vk::IndexType indexType_ = vk::IndexType::eUint16,
                                              vk::Buffer transformData_ = vk::Buffer(),
                                              vk::DeviceSize transformOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::GeometryTrianglesNV( vertexData_, vertexOffset_, vertexCount_, vertexStride_, vertexFormat_, indexData_, indexOffset_, indexCount_, indexType_, transformData_, transformOffset_ )
    {}

    GeometryTrianglesNV( VkGeometryTrianglesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::GeometryTrianglesNV( rhs )
    {}

    GeometryTrianglesNV& operator=( VkGeometryTrianglesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::GeometryTrianglesNV::operator=(rhs);
      return *this;
    }

    GeometryTrianglesNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    GeometryTrianglesNV & setVertexData( vk::Buffer vertexData_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexData = vertexData_;
      return *this;
    }

    GeometryTrianglesNV & setVertexOffset( vk::DeviceSize vertexOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexOffset = vertexOffset_;
      return *this;
    }

    GeometryTrianglesNV & setVertexCount( uint32_t vertexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexCount = vertexCount_;
      return *this;
    }

    GeometryTrianglesNV & setVertexStride( vk::DeviceSize vertexStride_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexStride = vertexStride_;
      return *this;
    }

    GeometryTrianglesNV & setVertexFormat( vk::Format vertexFormat_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexFormat = vertexFormat_;
      return *this;
    }

    GeometryTrianglesNV & setIndexData( vk::Buffer indexData_ ) VULKAN_HPP_NOEXCEPT
    {
      indexData = indexData_;
      return *this;
    }

    GeometryTrianglesNV & setIndexOffset( vk::DeviceSize indexOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      indexOffset = indexOffset_;
      return *this;
    }

    GeometryTrianglesNV & setIndexCount( uint32_t indexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      indexCount = indexCount_;
      return *this;
    }

    GeometryTrianglesNV & setIndexType( vk::IndexType indexType_ ) VULKAN_HPP_NOEXCEPT
    {
      indexType = indexType_;
      return *this;
    }

    GeometryTrianglesNV & setTransformData( vk::Buffer transformData_ ) VULKAN_HPP_NOEXCEPT
    {
      transformData = transformData_;
      return *this;
    }

    GeometryTrianglesNV & setTransformOffset( vk::DeviceSize transformOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      transformOffset = transformOffset_;
      return *this;
    }

    operator VkGeometryTrianglesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkGeometryTrianglesNV*>( this );
    }

    operator VkGeometryTrianglesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkGeometryTrianglesNV*>( this );
    }

    bool operator==( GeometryTrianglesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( vertexData == rhs.vertexData )
          && ( vertexOffset == rhs.vertexOffset )
          && ( vertexCount == rhs.vertexCount )
          && ( vertexStride == rhs.vertexStride )
          && ( vertexFormat == rhs.vertexFormat )
          && ( indexData == rhs.indexData )
          && ( indexOffset == rhs.indexOffset )
          && ( indexCount == rhs.indexCount )
          && ( indexType == rhs.indexType )
          && ( transformData == rhs.transformData )
          && ( transformOffset == rhs.transformOffset );
    }

    bool operator!=( GeometryTrianglesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::GeometryTrianglesNV::sType;
  };
  static_assert( sizeof( GeometryTrianglesNV ) == sizeof( VkGeometryTrianglesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<GeometryTrianglesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct GeometryAABBNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR GeometryAABBNV( vk::Buffer aabbData_ = vk::Buffer(),
                                           uint32_t numAABBs_ = 0,
                                           uint32_t stride_ = 0,
                                           vk::DeviceSize offset_ = 0 ) VULKAN_HPP_NOEXCEPT
        : aabbData( aabbData_ )
        , numAABBs( numAABBs_ )
        , stride( stride_ )
        , offset( offset_ )
      {}

      GeometryAABBNV( VkGeometryAABBNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGeometryAABBNV*>(this) = rhs;
      }

      GeometryAABBNV& operator=( VkGeometryAABBNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGeometryAABBNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eGeometryAabbNV;
      const void* pNext = nullptr;
      vk::Buffer aabbData;
      uint32_t numAABBs;
      uint32_t stride;
      vk::DeviceSize offset;
    };
    static_assert( sizeof( GeometryAABBNV ) == sizeof( VkGeometryAABBNV ), "layout struct and wrapper have different size!" );
  }

  struct GeometryAABBNV : public layout::GeometryAABBNV
  {
    VULKAN_HPP_CONSTEXPR GeometryAABBNV( vk::Buffer aabbData_ = vk::Buffer(),
                                         uint32_t numAABBs_ = 0,
                                         uint32_t stride_ = 0,
                                         vk::DeviceSize offset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::GeometryAABBNV( aabbData_, numAABBs_, stride_, offset_ )
    {}

    GeometryAABBNV( VkGeometryAABBNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::GeometryAABBNV( rhs )
    {}

    GeometryAABBNV& operator=( VkGeometryAABBNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::GeometryAABBNV::operator=(rhs);
      return *this;
    }

    GeometryAABBNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    GeometryAABBNV & setAabbData( vk::Buffer aabbData_ ) VULKAN_HPP_NOEXCEPT
    {
      aabbData = aabbData_;
      return *this;
    }

    GeometryAABBNV & setNumAABBs( uint32_t numAABBs_ ) VULKAN_HPP_NOEXCEPT
    {
      numAABBs = numAABBs_;
      return *this;
    }

    GeometryAABBNV & setStride( uint32_t stride_ ) VULKAN_HPP_NOEXCEPT
    {
      stride = stride_;
      return *this;
    }

    GeometryAABBNV & setOffset( vk::DeviceSize offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    operator VkGeometryAABBNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkGeometryAABBNV*>( this );
    }

    operator VkGeometryAABBNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkGeometryAABBNV*>( this );
    }

    bool operator==( GeometryAABBNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( aabbData == rhs.aabbData )
          && ( numAABBs == rhs.numAABBs )
          && ( stride == rhs.stride )
          && ( offset == rhs.offset );
    }

    bool operator!=( GeometryAABBNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::GeometryAABBNV::sType;
  };
  static_assert( sizeof( GeometryAABBNV ) == sizeof( VkGeometryAABBNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<GeometryAABBNV>::value, "struct wrapper is not a standard layout!" );

  struct GeometryDataNV
  {
    VULKAN_HPP_CONSTEXPR GeometryDataNV( vk::GeometryTrianglesNV triangles_ = vk::GeometryTrianglesNV(),
                                         vk::GeometryAABBNV aabbs_ = vk::GeometryAABBNV() ) VULKAN_HPP_NOEXCEPT
      : triangles( triangles_ )
      , aabbs( aabbs_ )
    {}

    GeometryDataNV( VkGeometryDataNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkGeometryDataNV*>(this) = rhs;
    }

    GeometryDataNV& operator=( VkGeometryDataNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkGeometryDataNV*>(this) = rhs;
      return *this;
    }

    GeometryDataNV & setTriangles( vk::GeometryTrianglesNV triangles_ ) VULKAN_HPP_NOEXCEPT
    {
      triangles = triangles_;
      return *this;
    }

    GeometryDataNV & setAabbs( vk::GeometryAABBNV aabbs_ ) VULKAN_HPP_NOEXCEPT
    {
      aabbs = aabbs_;
      return *this;
    }

    operator VkGeometryDataNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkGeometryDataNV*>( this );
    }

    operator VkGeometryDataNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkGeometryDataNV*>( this );
    }

    bool operator==( GeometryDataNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( triangles == rhs.triangles )
          && ( aabbs == rhs.aabbs );
    }

    bool operator!=( GeometryDataNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::GeometryTrianglesNV triangles;
    vk::GeometryAABBNV aabbs;
  };
  static_assert( sizeof( GeometryDataNV ) == sizeof( VkGeometryDataNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<GeometryDataNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct GeometryNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR GeometryNV( vk::GeometryTypeNV geometryType_ = vk::GeometryTypeNV::eTriangles,
                                       vk::GeometryDataNV geometry_ = vk::GeometryDataNV(),
                                       vk::GeometryFlagsNV flags_ = vk::GeometryFlagsNV() ) VULKAN_HPP_NOEXCEPT
        : geometryType( geometryType_ )
        , geometry( geometry_ )
        , flags( flags_ )
      {}

      GeometryNV( VkGeometryNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGeometryNV*>(this) = rhs;
      }

      GeometryNV& operator=( VkGeometryNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGeometryNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eGeometryNV;
      const void* pNext = nullptr;
      vk::GeometryTypeNV geometryType;
      vk::GeometryDataNV geometry;
      vk::GeometryFlagsNV flags;
    };
    static_assert( sizeof( GeometryNV ) == sizeof( VkGeometryNV ), "layout struct and wrapper have different size!" );
  }

  struct GeometryNV : public layout::GeometryNV
  {
    VULKAN_HPP_CONSTEXPR GeometryNV( vk::GeometryTypeNV geometryType_ = vk::GeometryTypeNV::eTriangles,
                                     vk::GeometryDataNV geometry_ = vk::GeometryDataNV(),
                                     vk::GeometryFlagsNV flags_ = vk::GeometryFlagsNV() ) VULKAN_HPP_NOEXCEPT
      : layout::GeometryNV( geometryType_, geometry_, flags_ )
    {}

    GeometryNV( VkGeometryNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::GeometryNV( rhs )
    {}

    GeometryNV& operator=( VkGeometryNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::GeometryNV::operator=(rhs);
      return *this;
    }

    GeometryNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    GeometryNV & setGeometryType( vk::GeometryTypeNV geometryType_ ) VULKAN_HPP_NOEXCEPT
    {
      geometryType = geometryType_;
      return *this;
    }

    GeometryNV & setGeometry( vk::GeometryDataNV geometry_ ) VULKAN_HPP_NOEXCEPT
    {
      geometry = geometry_;
      return *this;
    }

    GeometryNV & setFlags( vk::GeometryFlagsNV flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkGeometryNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkGeometryNV*>( this );
    }

    operator VkGeometryNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkGeometryNV*>( this );
    }

    bool operator==( GeometryNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( geometryType == rhs.geometryType )
          && ( geometry == rhs.geometry )
          && ( flags == rhs.flags );
    }

    bool operator!=( GeometryNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::GeometryNV::sType;
  };
  static_assert( sizeof( GeometryNV ) == sizeof( VkGeometryNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<GeometryNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct AccelerationStructureInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR AccelerationStructureInfoNV( vk::AccelerationStructureTypeNV type_ = vk::AccelerationStructureTypeNV::eTopLevel,
                                                        vk::BuildAccelerationStructureFlagsNV flags_ = vk::BuildAccelerationStructureFlagsNV(),
                                                        uint32_t instanceCount_ = 0,
                                                        uint32_t geometryCount_ = 0,
                                                        const vk::GeometryNV* pGeometries_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : type( type_ )
        , flags( flags_ )
        , instanceCount( instanceCount_ )
        , geometryCount( geometryCount_ )
        , pGeometries( pGeometries_ )
      {}

      AccelerationStructureInfoNV( VkAccelerationStructureInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAccelerationStructureInfoNV*>(this) = rhs;
      }

      AccelerationStructureInfoNV& operator=( VkAccelerationStructureInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAccelerationStructureInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAccelerationStructureInfoNV;
      const void* pNext = nullptr;
      vk::AccelerationStructureTypeNV type;
      vk::BuildAccelerationStructureFlagsNV flags;
      uint32_t instanceCount;
      uint32_t geometryCount;
      const vk::GeometryNV* pGeometries;
    };
    static_assert( sizeof( AccelerationStructureInfoNV ) == sizeof( VkAccelerationStructureInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct AccelerationStructureInfoNV : public layout::AccelerationStructureInfoNV
  {
    VULKAN_HPP_CONSTEXPR AccelerationStructureInfoNV( vk::AccelerationStructureTypeNV type_ = vk::AccelerationStructureTypeNV::eTopLevel,
                                                      vk::BuildAccelerationStructureFlagsNV flags_ = vk::BuildAccelerationStructureFlagsNV(),
                                                      uint32_t instanceCount_ = 0,
                                                      uint32_t geometryCount_ = 0,
                                                      const vk::GeometryNV* pGeometries_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::AccelerationStructureInfoNV( type_, flags_, instanceCount_, geometryCount_, pGeometries_ )
    {}

    AccelerationStructureInfoNV( VkAccelerationStructureInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AccelerationStructureInfoNV( rhs )
    {}

    AccelerationStructureInfoNV& operator=( VkAccelerationStructureInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AccelerationStructureInfoNV::operator=(rhs);
      return *this;
    }

    AccelerationStructureInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    AccelerationStructureInfoNV & setType( vk::AccelerationStructureTypeNV type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    AccelerationStructureInfoNV & setFlags( vk::BuildAccelerationStructureFlagsNV flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    AccelerationStructureInfoNV & setInstanceCount( uint32_t instanceCount_ ) VULKAN_HPP_NOEXCEPT
    {
      instanceCount = instanceCount_;
      return *this;
    }

    AccelerationStructureInfoNV & setGeometryCount( uint32_t geometryCount_ ) VULKAN_HPP_NOEXCEPT
    {
      geometryCount = geometryCount_;
      return *this;
    }

    AccelerationStructureInfoNV & setPGeometries( const vk::GeometryNV* pGeometries_ ) VULKAN_HPP_NOEXCEPT
    {
      pGeometries = pGeometries_;
      return *this;
    }

    operator VkAccelerationStructureInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAccelerationStructureInfoNV*>( this );
    }

    operator VkAccelerationStructureInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAccelerationStructureInfoNV*>( this );
    }

    bool operator==( AccelerationStructureInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( type == rhs.type )
          && ( flags == rhs.flags )
          && ( instanceCount == rhs.instanceCount )
          && ( geometryCount == rhs.geometryCount )
          && ( pGeometries == rhs.pGeometries );
    }

    bool operator!=( AccelerationStructureInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AccelerationStructureInfoNV::sType;
  };
  static_assert( sizeof( AccelerationStructureInfoNV ) == sizeof( VkAccelerationStructureInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AccelerationStructureInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct AccelerationStructureCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR AccelerationStructureCreateInfoNV( vk::DeviceSize compactedSize_ = 0,
                                                              vk::AccelerationStructureInfoNV info_ = vk::AccelerationStructureInfoNV() ) VULKAN_HPP_NOEXCEPT
        : compactedSize( compactedSize_ )
        , info( info_ )
      {}

      AccelerationStructureCreateInfoNV( VkAccelerationStructureCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAccelerationStructureCreateInfoNV*>(this) = rhs;
      }

      AccelerationStructureCreateInfoNV& operator=( VkAccelerationStructureCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAccelerationStructureCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAccelerationStructureCreateInfoNV;
      const void* pNext = nullptr;
      vk::DeviceSize compactedSize;
      vk::AccelerationStructureInfoNV info;
    };
    static_assert( sizeof( AccelerationStructureCreateInfoNV ) == sizeof( VkAccelerationStructureCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct AccelerationStructureCreateInfoNV : public layout::AccelerationStructureCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR AccelerationStructureCreateInfoNV( vk::DeviceSize compactedSize_ = 0,
                                                            vk::AccelerationStructureInfoNV info_ = vk::AccelerationStructureInfoNV() ) VULKAN_HPP_NOEXCEPT
      : layout::AccelerationStructureCreateInfoNV( compactedSize_, info_ )
    {}

    AccelerationStructureCreateInfoNV( VkAccelerationStructureCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AccelerationStructureCreateInfoNV( rhs )
    {}

    AccelerationStructureCreateInfoNV& operator=( VkAccelerationStructureCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AccelerationStructureCreateInfoNV::operator=(rhs);
      return *this;
    }

    AccelerationStructureCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    AccelerationStructureCreateInfoNV & setCompactedSize( vk::DeviceSize compactedSize_ ) VULKAN_HPP_NOEXCEPT
    {
      compactedSize = compactedSize_;
      return *this;
    }

    AccelerationStructureCreateInfoNV & setInfo( vk::AccelerationStructureInfoNV info_ ) VULKAN_HPP_NOEXCEPT
    {
      info = info_;
      return *this;
    }

    operator VkAccelerationStructureCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAccelerationStructureCreateInfoNV*>( this );
    }

    operator VkAccelerationStructureCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAccelerationStructureCreateInfoNV*>( this );
    }

    bool operator==( AccelerationStructureCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( compactedSize == rhs.compactedSize )
          && ( info == rhs.info );
    }

    bool operator!=( AccelerationStructureCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AccelerationStructureCreateInfoNV::sType;
  };
  static_assert( sizeof( AccelerationStructureCreateInfoNV ) == sizeof( VkAccelerationStructureCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AccelerationStructureCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct AccelerationStructureMemoryRequirementsInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR AccelerationStructureMemoryRequirementsInfoNV( vk::AccelerationStructureMemoryRequirementsTypeNV type_ = vk::AccelerationStructureMemoryRequirementsTypeNV::eObject,
                                                                          vk::AccelerationStructureNV accelerationStructure_ = vk::AccelerationStructureNV() ) VULKAN_HPP_NOEXCEPT
        : type( type_ )
        , accelerationStructure( accelerationStructure_ )
      {}

      AccelerationStructureMemoryRequirementsInfoNV( VkAccelerationStructureMemoryRequirementsInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAccelerationStructureMemoryRequirementsInfoNV*>(this) = rhs;
      }

      AccelerationStructureMemoryRequirementsInfoNV& operator=( VkAccelerationStructureMemoryRequirementsInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAccelerationStructureMemoryRequirementsInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAccelerationStructureMemoryRequirementsInfoNV;
      const void* pNext = nullptr;
      vk::AccelerationStructureMemoryRequirementsTypeNV type;
      vk::AccelerationStructureNV accelerationStructure;
    };
    static_assert( sizeof( AccelerationStructureMemoryRequirementsInfoNV ) == sizeof( VkAccelerationStructureMemoryRequirementsInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct AccelerationStructureMemoryRequirementsInfoNV : public layout::AccelerationStructureMemoryRequirementsInfoNV
  {
    VULKAN_HPP_CONSTEXPR AccelerationStructureMemoryRequirementsInfoNV( vk::AccelerationStructureMemoryRequirementsTypeNV type_ = vk::AccelerationStructureMemoryRequirementsTypeNV::eObject,
                                                                        vk::AccelerationStructureNV accelerationStructure_ = vk::AccelerationStructureNV() ) VULKAN_HPP_NOEXCEPT
      : layout::AccelerationStructureMemoryRequirementsInfoNV( type_, accelerationStructure_ )
    {}

    AccelerationStructureMemoryRequirementsInfoNV( VkAccelerationStructureMemoryRequirementsInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AccelerationStructureMemoryRequirementsInfoNV( rhs )
    {}

    AccelerationStructureMemoryRequirementsInfoNV& operator=( VkAccelerationStructureMemoryRequirementsInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AccelerationStructureMemoryRequirementsInfoNV::operator=(rhs);
      return *this;
    }

    AccelerationStructureMemoryRequirementsInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    AccelerationStructureMemoryRequirementsInfoNV & setType( vk::AccelerationStructureMemoryRequirementsTypeNV type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    AccelerationStructureMemoryRequirementsInfoNV & setAccelerationStructure( vk::AccelerationStructureNV accelerationStructure_ ) VULKAN_HPP_NOEXCEPT
    {
      accelerationStructure = accelerationStructure_;
      return *this;
    }

    operator VkAccelerationStructureMemoryRequirementsInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAccelerationStructureMemoryRequirementsInfoNV*>( this );
    }

    operator VkAccelerationStructureMemoryRequirementsInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAccelerationStructureMemoryRequirementsInfoNV*>( this );
    }

    bool operator==( AccelerationStructureMemoryRequirementsInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( type == rhs.type )
          && ( accelerationStructure == rhs.accelerationStructure );
    }

    bool operator!=( AccelerationStructureMemoryRequirementsInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AccelerationStructureMemoryRequirementsInfoNV::sType;
  };
  static_assert( sizeof( AccelerationStructureMemoryRequirementsInfoNV ) == sizeof( VkAccelerationStructureMemoryRequirementsInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AccelerationStructureMemoryRequirementsInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct AcquireNextImageInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR AcquireNextImageInfoKHR( vk::SwapchainKHR swapchain_ = vk::SwapchainKHR(),
                                                    uint64_t timeout_ = 0,
                                                    vk::Semaphore semaphore_ = vk::Semaphore(),
                                                    vk::Fence fence_ = vk::Fence(),
                                                    uint32_t deviceMask_ = 0 ) VULKAN_HPP_NOEXCEPT
        : swapchain( swapchain_ )
        , timeout( timeout_ )
        , semaphore( semaphore_ )
        , fence( fence_ )
        , deviceMask( deviceMask_ )
      {}

      AcquireNextImageInfoKHR( VkAcquireNextImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAcquireNextImageInfoKHR*>(this) = rhs;
      }

      AcquireNextImageInfoKHR& operator=( VkAcquireNextImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAcquireNextImageInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAcquireNextImageInfoKHR;
      const void* pNext = nullptr;
      vk::SwapchainKHR swapchain;
      uint64_t timeout;
      vk::Semaphore semaphore;
      vk::Fence fence;
      uint32_t deviceMask;
    };
    static_assert( sizeof( AcquireNextImageInfoKHR ) == sizeof( VkAcquireNextImageInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct AcquireNextImageInfoKHR : public layout::AcquireNextImageInfoKHR
  {
    VULKAN_HPP_CONSTEXPR AcquireNextImageInfoKHR( vk::SwapchainKHR swapchain_ = vk::SwapchainKHR(),
                                                  uint64_t timeout_ = 0,
                                                  vk::Semaphore semaphore_ = vk::Semaphore(),
                                                  vk::Fence fence_ = vk::Fence(),
                                                  uint32_t deviceMask_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::AcquireNextImageInfoKHR( swapchain_, timeout_, semaphore_, fence_, deviceMask_ )
    {}

    AcquireNextImageInfoKHR( VkAcquireNextImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AcquireNextImageInfoKHR( rhs )
    {}

    AcquireNextImageInfoKHR& operator=( VkAcquireNextImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AcquireNextImageInfoKHR::operator=(rhs);
      return *this;
    }

    AcquireNextImageInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    AcquireNextImageInfoKHR & setSwapchain( vk::SwapchainKHR swapchain_ ) VULKAN_HPP_NOEXCEPT
    {
      swapchain = swapchain_;
      return *this;
    }

    AcquireNextImageInfoKHR & setTimeout( uint64_t timeout_ ) VULKAN_HPP_NOEXCEPT
    {
      timeout = timeout_;
      return *this;
    }

    AcquireNextImageInfoKHR & setSemaphore( vk::Semaphore semaphore_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphore = semaphore_;
      return *this;
    }

    AcquireNextImageInfoKHR & setFence( vk::Fence fence_ ) VULKAN_HPP_NOEXCEPT
    {
      fence = fence_;
      return *this;
    }

    AcquireNextImageInfoKHR & setDeviceMask( uint32_t deviceMask_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceMask = deviceMask_;
      return *this;
    }

    operator VkAcquireNextImageInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAcquireNextImageInfoKHR*>( this );
    }

    operator VkAcquireNextImageInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAcquireNextImageInfoKHR*>( this );
    }

    bool operator==( AcquireNextImageInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( swapchain == rhs.swapchain )
          && ( timeout == rhs.timeout )
          && ( semaphore == rhs.semaphore )
          && ( fence == rhs.fence )
          && ( deviceMask == rhs.deviceMask );
    }

    bool operator!=( AcquireNextImageInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AcquireNextImageInfoKHR::sType;
  };
  static_assert( sizeof( AcquireNextImageInfoKHR ) == sizeof( VkAcquireNextImageInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AcquireNextImageInfoKHR>::value, "struct wrapper is not a standard layout!" );

  struct AllocationCallbacks
  {
    VULKAN_HPP_CONSTEXPR AllocationCallbacks( void* pUserData_ = nullptr,
                                              PFN_vkAllocationFunction pfnAllocation_ = nullptr,
                                              PFN_vkReallocationFunction pfnReallocation_ = nullptr,
                                              PFN_vkFreeFunction pfnFree_ = nullptr,
                                              PFN_vkInternalAllocationNotification pfnInternalAllocation_ = nullptr,
                                              PFN_vkInternalFreeNotification pfnInternalFree_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : pUserData( pUserData_ )
      , pfnAllocation( pfnAllocation_ )
      , pfnReallocation( pfnReallocation_ )
      , pfnFree( pfnFree_ )
      , pfnInternalAllocation( pfnInternalAllocation_ )
      , pfnInternalFree( pfnInternalFree_ )
    {}

    AllocationCallbacks( VkAllocationCallbacks const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAllocationCallbacks*>(this) = rhs;
    }

    AllocationCallbacks& operator=( VkAllocationCallbacks const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAllocationCallbacks*>(this) = rhs;
      return *this;
    }

    AllocationCallbacks & setPUserData( void* pUserData_ ) VULKAN_HPP_NOEXCEPT
    {
      pUserData = pUserData_;
      return *this;
    }

    AllocationCallbacks & setPfnAllocation( PFN_vkAllocationFunction pfnAllocation_ ) VULKAN_HPP_NOEXCEPT
    {
      pfnAllocation = pfnAllocation_;
      return *this;
    }

    AllocationCallbacks & setPfnReallocation( PFN_vkReallocationFunction pfnReallocation_ ) VULKAN_HPP_NOEXCEPT
    {
      pfnReallocation = pfnReallocation_;
      return *this;
    }

    AllocationCallbacks & setPfnFree( PFN_vkFreeFunction pfnFree_ ) VULKAN_HPP_NOEXCEPT
    {
      pfnFree = pfnFree_;
      return *this;
    }

    AllocationCallbacks & setPfnInternalAllocation( PFN_vkInternalAllocationNotification pfnInternalAllocation_ ) VULKAN_HPP_NOEXCEPT
    {
      pfnInternalAllocation = pfnInternalAllocation_;
      return *this;
    }

    AllocationCallbacks & setPfnInternalFree( PFN_vkInternalFreeNotification pfnInternalFree_ ) VULKAN_HPP_NOEXCEPT
    {
      pfnInternalFree = pfnInternalFree_;
      return *this;
    }

    operator VkAllocationCallbacks const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAllocationCallbacks*>( this );
    }

    operator VkAllocationCallbacks &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAllocationCallbacks*>( this );
    }

    bool operator==( AllocationCallbacks const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( pUserData == rhs.pUserData )
          && ( pfnAllocation == rhs.pfnAllocation )
          && ( pfnReallocation == rhs.pfnReallocation )
          && ( pfnFree == rhs.pfnFree )
          && ( pfnInternalAllocation == rhs.pfnInternalAllocation )
          && ( pfnInternalFree == rhs.pfnInternalFree );
    }

    bool operator!=( AllocationCallbacks const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    void* pUserData;
    PFN_vkAllocationFunction pfnAllocation;
    PFN_vkReallocationFunction pfnReallocation;
    PFN_vkFreeFunction pfnFree;
    PFN_vkInternalAllocationNotification pfnInternalAllocation;
    PFN_vkInternalFreeNotification pfnInternalFree;
  };
  static_assert( sizeof( AllocationCallbacks ) == sizeof( VkAllocationCallbacks ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AllocationCallbacks>::value, "struct wrapper is not a standard layout!" );

  struct ComponentMapping
  {
    VULKAN_HPP_CONSTEXPR ComponentMapping( vk::ComponentSwizzle r_ = vk::ComponentSwizzle::eIdentity,
                                           vk::ComponentSwizzle g_ = vk::ComponentSwizzle::eIdentity,
                                           vk::ComponentSwizzle b_ = vk::ComponentSwizzle::eIdentity,
                                           vk::ComponentSwizzle a_ = vk::ComponentSwizzle::eIdentity ) VULKAN_HPP_NOEXCEPT
      : r( r_ )
      , g( g_ )
      , b( b_ )
      , a( a_ )
    {}

    ComponentMapping( VkComponentMapping const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkComponentMapping*>(this) = rhs;
    }

    ComponentMapping& operator=( VkComponentMapping const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkComponentMapping*>(this) = rhs;
      return *this;
    }

    ComponentMapping & setR( vk::ComponentSwizzle r_ ) VULKAN_HPP_NOEXCEPT
    {
      r = r_;
      return *this;
    }

    ComponentMapping & setG( vk::ComponentSwizzle g_ ) VULKAN_HPP_NOEXCEPT
    {
      g = g_;
      return *this;
    }

    ComponentMapping & setB( vk::ComponentSwizzle b_ ) VULKAN_HPP_NOEXCEPT
    {
      b = b_;
      return *this;
    }

    ComponentMapping & setA( vk::ComponentSwizzle a_ ) VULKAN_HPP_NOEXCEPT
    {
      a = a_;
      return *this;
    }

    operator VkComponentMapping const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkComponentMapping*>( this );
    }

    operator VkComponentMapping &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkComponentMapping*>( this );
    }

    bool operator==( ComponentMapping const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( r == rhs.r )
          && ( g == rhs.g )
          && ( b == rhs.b )
          && ( a == rhs.a );
    }

    bool operator!=( ComponentMapping const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ComponentSwizzle r;
    vk::ComponentSwizzle g;
    vk::ComponentSwizzle b;
    vk::ComponentSwizzle a;
  };
  static_assert( sizeof( ComponentMapping ) == sizeof( VkComponentMapping ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ComponentMapping>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_ANDROID_KHR

  namespace layout
  {
    struct AndroidHardwareBufferFormatPropertiesANDROID
    {
    protected:
      AndroidHardwareBufferFormatPropertiesANDROID() VULKAN_HPP_NOEXCEPT
      {}

      AndroidHardwareBufferFormatPropertiesANDROID( VkAndroidHardwareBufferFormatPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidHardwareBufferFormatPropertiesANDROID*>(this) = rhs;
      }

      AndroidHardwareBufferFormatPropertiesANDROID& operator=( VkAndroidHardwareBufferFormatPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidHardwareBufferFormatPropertiesANDROID*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAndroidHardwareBufferFormatPropertiesANDROID;
      void* pNext = nullptr;
      vk::Format format;
      uint64_t externalFormat;
      vk::FormatFeatureFlags formatFeatures;
      vk::ComponentMapping samplerYcbcrConversionComponents;
      vk::SamplerYcbcrModelConversion suggestedYcbcrModel;
      vk::SamplerYcbcrRange suggestedYcbcrRange;
      vk::ChromaLocation suggestedXChromaOffset;
      vk::ChromaLocation suggestedYChromaOffset;
    };
    static_assert( sizeof( AndroidHardwareBufferFormatPropertiesANDROID ) == sizeof( VkAndroidHardwareBufferFormatPropertiesANDROID ), "layout struct and wrapper have different size!" );
  }

  struct AndroidHardwareBufferFormatPropertiesANDROID : public layout::AndroidHardwareBufferFormatPropertiesANDROID
  {
    AndroidHardwareBufferFormatPropertiesANDROID() VULKAN_HPP_NOEXCEPT
      : layout::AndroidHardwareBufferFormatPropertiesANDROID()
    {}

    AndroidHardwareBufferFormatPropertiesANDROID( VkAndroidHardwareBufferFormatPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AndroidHardwareBufferFormatPropertiesANDROID( rhs )
    {}

    AndroidHardwareBufferFormatPropertiesANDROID& operator=( VkAndroidHardwareBufferFormatPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AndroidHardwareBufferFormatPropertiesANDROID::operator=(rhs);
      return *this;
    }

    operator VkAndroidHardwareBufferFormatPropertiesANDROID const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAndroidHardwareBufferFormatPropertiesANDROID*>( this );
    }

    operator VkAndroidHardwareBufferFormatPropertiesANDROID &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAndroidHardwareBufferFormatPropertiesANDROID*>( this );
    }

    bool operator==( AndroidHardwareBufferFormatPropertiesANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( format == rhs.format )
          && ( externalFormat == rhs.externalFormat )
          && ( formatFeatures == rhs.formatFeatures )
          && ( samplerYcbcrConversionComponents == rhs.samplerYcbcrConversionComponents )
          && ( suggestedYcbcrModel == rhs.suggestedYcbcrModel )
          && ( suggestedYcbcrRange == rhs.suggestedYcbcrRange )
          && ( suggestedXChromaOffset == rhs.suggestedXChromaOffset )
          && ( suggestedYChromaOffset == rhs.suggestedYChromaOffset );
    }

    bool operator!=( AndroidHardwareBufferFormatPropertiesANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AndroidHardwareBufferFormatPropertiesANDROID::sType;
  };
  static_assert( sizeof( AndroidHardwareBufferFormatPropertiesANDROID ) == sizeof( VkAndroidHardwareBufferFormatPropertiesANDROID ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AndroidHardwareBufferFormatPropertiesANDROID>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR

  namespace layout
  {
    struct AndroidHardwareBufferPropertiesANDROID
    {
    protected:
      AndroidHardwareBufferPropertiesANDROID() VULKAN_HPP_NOEXCEPT
      {}

      AndroidHardwareBufferPropertiesANDROID( VkAndroidHardwareBufferPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidHardwareBufferPropertiesANDROID*>(this) = rhs;
      }

      AndroidHardwareBufferPropertiesANDROID& operator=( VkAndroidHardwareBufferPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidHardwareBufferPropertiesANDROID*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAndroidHardwareBufferPropertiesANDROID;
      void* pNext = nullptr;
      vk::DeviceSize allocationSize;
      uint32_t memoryTypeBits;
    };
    static_assert( sizeof( AndroidHardwareBufferPropertiesANDROID ) == sizeof( VkAndroidHardwareBufferPropertiesANDROID ), "layout struct and wrapper have different size!" );
  }

  struct AndroidHardwareBufferPropertiesANDROID : public layout::AndroidHardwareBufferPropertiesANDROID
  {
    AndroidHardwareBufferPropertiesANDROID() VULKAN_HPP_NOEXCEPT
      : layout::AndroidHardwareBufferPropertiesANDROID()
    {}

    AndroidHardwareBufferPropertiesANDROID( VkAndroidHardwareBufferPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AndroidHardwareBufferPropertiesANDROID( rhs )
    {}

    AndroidHardwareBufferPropertiesANDROID& operator=( VkAndroidHardwareBufferPropertiesANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AndroidHardwareBufferPropertiesANDROID::operator=(rhs);
      return *this;
    }

    operator VkAndroidHardwareBufferPropertiesANDROID const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAndroidHardwareBufferPropertiesANDROID*>( this );
    }

    operator VkAndroidHardwareBufferPropertiesANDROID &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAndroidHardwareBufferPropertiesANDROID*>( this );
    }

    bool operator==( AndroidHardwareBufferPropertiesANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( allocationSize == rhs.allocationSize )
          && ( memoryTypeBits == rhs.memoryTypeBits );
    }

    bool operator!=( AndroidHardwareBufferPropertiesANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AndroidHardwareBufferPropertiesANDROID::sType;
  };
  static_assert( sizeof( AndroidHardwareBufferPropertiesANDROID ) == sizeof( VkAndroidHardwareBufferPropertiesANDROID ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AndroidHardwareBufferPropertiesANDROID>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR

  namespace layout
  {
    struct AndroidHardwareBufferUsageANDROID
    {
    protected:
      AndroidHardwareBufferUsageANDROID() VULKAN_HPP_NOEXCEPT
      {}

      AndroidHardwareBufferUsageANDROID( VkAndroidHardwareBufferUsageANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidHardwareBufferUsageANDROID*>(this) = rhs;
      }

      AndroidHardwareBufferUsageANDROID& operator=( VkAndroidHardwareBufferUsageANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidHardwareBufferUsageANDROID*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAndroidHardwareBufferUsageANDROID;
      void* pNext = nullptr;
      uint64_t androidHardwareBufferUsage;
    };
    static_assert( sizeof( AndroidHardwareBufferUsageANDROID ) == sizeof( VkAndroidHardwareBufferUsageANDROID ), "layout struct and wrapper have different size!" );
  }

  struct AndroidHardwareBufferUsageANDROID : public layout::AndroidHardwareBufferUsageANDROID
  {
    AndroidHardwareBufferUsageANDROID() VULKAN_HPP_NOEXCEPT
      : layout::AndroidHardwareBufferUsageANDROID()
    {}

    AndroidHardwareBufferUsageANDROID( VkAndroidHardwareBufferUsageANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AndroidHardwareBufferUsageANDROID( rhs )
    {}

    AndroidHardwareBufferUsageANDROID& operator=( VkAndroidHardwareBufferUsageANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AndroidHardwareBufferUsageANDROID::operator=(rhs);
      return *this;
    }

    operator VkAndroidHardwareBufferUsageANDROID const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAndroidHardwareBufferUsageANDROID*>( this );
    }

    operator VkAndroidHardwareBufferUsageANDROID &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAndroidHardwareBufferUsageANDROID*>( this );
    }

    bool operator==( AndroidHardwareBufferUsageANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( androidHardwareBufferUsage == rhs.androidHardwareBufferUsage );
    }

    bool operator!=( AndroidHardwareBufferUsageANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AndroidHardwareBufferUsageANDROID::sType;
  };
  static_assert( sizeof( AndroidHardwareBufferUsageANDROID ) == sizeof( VkAndroidHardwareBufferUsageANDROID ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AndroidHardwareBufferUsageANDROID>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR

  namespace layout
  {
    struct AndroidSurfaceCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR AndroidSurfaceCreateInfoKHR( vk::AndroidSurfaceCreateFlagsKHR flags_ = vk::AndroidSurfaceCreateFlagsKHR(),
                                                        struct ANativeWindow* window_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , window( window_ )
      {}

      AndroidSurfaceCreateInfoKHR( VkAndroidSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidSurfaceCreateInfoKHR*>(this) = rhs;
      }

      AndroidSurfaceCreateInfoKHR& operator=( VkAndroidSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAndroidSurfaceCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAndroidSurfaceCreateInfoKHR;
      const void* pNext = nullptr;
      vk::AndroidSurfaceCreateFlagsKHR flags;
      struct ANativeWindow* window;
    };
    static_assert( sizeof( AndroidSurfaceCreateInfoKHR ) == sizeof( VkAndroidSurfaceCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct AndroidSurfaceCreateInfoKHR : public layout::AndroidSurfaceCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR AndroidSurfaceCreateInfoKHR( vk::AndroidSurfaceCreateFlagsKHR flags_ = vk::AndroidSurfaceCreateFlagsKHR(),
                                                      struct ANativeWindow* window_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::AndroidSurfaceCreateInfoKHR( flags_, window_ )
    {}

    AndroidSurfaceCreateInfoKHR( VkAndroidSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AndroidSurfaceCreateInfoKHR( rhs )
    {}

    AndroidSurfaceCreateInfoKHR& operator=( VkAndroidSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AndroidSurfaceCreateInfoKHR::operator=(rhs);
      return *this;
    }

    AndroidSurfaceCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    AndroidSurfaceCreateInfoKHR & setFlags( vk::AndroidSurfaceCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    AndroidSurfaceCreateInfoKHR & setWindow( struct ANativeWindow* window_ ) VULKAN_HPP_NOEXCEPT
    {
      window = window_;
      return *this;
    }

    operator VkAndroidSurfaceCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAndroidSurfaceCreateInfoKHR*>( this );
    }

    operator VkAndroidSurfaceCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAndroidSurfaceCreateInfoKHR*>( this );
    }

    bool operator==( AndroidSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( window == rhs.window );
    }

    bool operator!=( AndroidSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AndroidSurfaceCreateInfoKHR::sType;
  };
  static_assert( sizeof( AndroidSurfaceCreateInfoKHR ) == sizeof( VkAndroidSurfaceCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AndroidSurfaceCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  namespace layout
  {
    struct ApplicationInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ApplicationInfo( const char* pApplicationName_ = nullptr,
                                            uint32_t applicationVersion_ = 0,
                                            const char* pEngineName_ = nullptr,
                                            uint32_t engineVersion_ = 0,
                                            uint32_t apiVersion_ = 0 ) VULKAN_HPP_NOEXCEPT
        : pApplicationName( pApplicationName_ )
        , applicationVersion( applicationVersion_ )
        , pEngineName( pEngineName_ )
        , engineVersion( engineVersion_ )
        , apiVersion( apiVersion_ )
      {}

      ApplicationInfo( VkApplicationInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkApplicationInfo*>(this) = rhs;
      }

      ApplicationInfo& operator=( VkApplicationInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkApplicationInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eApplicationInfo;
      const void* pNext = nullptr;
      const char* pApplicationName;
      uint32_t applicationVersion;
      const char* pEngineName;
      uint32_t engineVersion;
      uint32_t apiVersion;
    };
    static_assert( sizeof( ApplicationInfo ) == sizeof( VkApplicationInfo ), "layout struct and wrapper have different size!" );
  }

  struct ApplicationInfo : public layout::ApplicationInfo
  {
    VULKAN_HPP_CONSTEXPR ApplicationInfo( const char* pApplicationName_ = nullptr,
                                          uint32_t applicationVersion_ = 0,
                                          const char* pEngineName_ = nullptr,
                                          uint32_t engineVersion_ = 0,
                                          uint32_t apiVersion_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ApplicationInfo( pApplicationName_, applicationVersion_, pEngineName_, engineVersion_, apiVersion_ )
    {}

    ApplicationInfo( VkApplicationInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ApplicationInfo( rhs )
    {}

    ApplicationInfo& operator=( VkApplicationInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ApplicationInfo::operator=(rhs);
      return *this;
    }

    ApplicationInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ApplicationInfo & setPApplicationName( const char* pApplicationName_ ) VULKAN_HPP_NOEXCEPT
    {
      pApplicationName = pApplicationName_;
      return *this;
    }

    ApplicationInfo & setApplicationVersion( uint32_t applicationVersion_ ) VULKAN_HPP_NOEXCEPT
    {
      applicationVersion = applicationVersion_;
      return *this;
    }

    ApplicationInfo & setPEngineName( const char* pEngineName_ ) VULKAN_HPP_NOEXCEPT
    {
      pEngineName = pEngineName_;
      return *this;
    }

    ApplicationInfo & setEngineVersion( uint32_t engineVersion_ ) VULKAN_HPP_NOEXCEPT
    {
      engineVersion = engineVersion_;
      return *this;
    }

    ApplicationInfo & setApiVersion( uint32_t apiVersion_ ) VULKAN_HPP_NOEXCEPT
    {
      apiVersion = apiVersion_;
      return *this;
    }

    operator VkApplicationInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkApplicationInfo*>( this );
    }

    operator VkApplicationInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkApplicationInfo*>( this );
    }

    bool operator==( ApplicationInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pApplicationName == rhs.pApplicationName )
          && ( applicationVersion == rhs.applicationVersion )
          && ( pEngineName == rhs.pEngineName )
          && ( engineVersion == rhs.engineVersion )
          && ( apiVersion == rhs.apiVersion );
    }

    bool operator!=( ApplicationInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ApplicationInfo::sType;
  };
  static_assert( sizeof( ApplicationInfo ) == sizeof( VkApplicationInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ApplicationInfo>::value, "struct wrapper is not a standard layout!" );

  struct AttachmentDescription
  {
    VULKAN_HPP_CONSTEXPR AttachmentDescription( vk::AttachmentDescriptionFlags flags_ = vk::AttachmentDescriptionFlags(),
                                                vk::Format format_ = vk::Format::eUndefined,
                                                vk::SampleCountFlagBits samples_ = vk::SampleCountFlagBits::e1,
                                                vk::AttachmentLoadOp loadOp_ = vk::AttachmentLoadOp::eLoad,
                                                vk::AttachmentStoreOp storeOp_ = vk::AttachmentStoreOp::eStore,
                                                vk::AttachmentLoadOp stencilLoadOp_ = vk::AttachmentLoadOp::eLoad,
                                                vk::AttachmentStoreOp stencilStoreOp_ = vk::AttachmentStoreOp::eStore,
                                                vk::ImageLayout initialLayout_ = vk::ImageLayout::eUndefined,
                                                vk::ImageLayout finalLayout_ = vk::ImageLayout::eUndefined ) VULKAN_HPP_NOEXCEPT
      : flags( flags_ )
      , format( format_ )
      , samples( samples_ )
      , loadOp( loadOp_ )
      , storeOp( storeOp_ )
      , stencilLoadOp( stencilLoadOp_ )
      , stencilStoreOp( stencilStoreOp_ )
      , initialLayout( initialLayout_ )
      , finalLayout( finalLayout_ )
    {}

    AttachmentDescription( VkAttachmentDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAttachmentDescription*>(this) = rhs;
    }

    AttachmentDescription& operator=( VkAttachmentDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAttachmentDescription*>(this) = rhs;
      return *this;
    }

    AttachmentDescription & setFlags( vk::AttachmentDescriptionFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    AttachmentDescription & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    AttachmentDescription & setSamples( vk::SampleCountFlagBits samples_ ) VULKAN_HPP_NOEXCEPT
    {
      samples = samples_;
      return *this;
    }

    AttachmentDescription & setLoadOp( vk::AttachmentLoadOp loadOp_ ) VULKAN_HPP_NOEXCEPT
    {
      loadOp = loadOp_;
      return *this;
    }

    AttachmentDescription & setStoreOp( vk::AttachmentStoreOp storeOp_ ) VULKAN_HPP_NOEXCEPT
    {
      storeOp = storeOp_;
      return *this;
    }

    AttachmentDescription & setStencilLoadOp( vk::AttachmentLoadOp stencilLoadOp_ ) VULKAN_HPP_NOEXCEPT
    {
      stencilLoadOp = stencilLoadOp_;
      return *this;
    }

    AttachmentDescription & setStencilStoreOp( vk::AttachmentStoreOp stencilStoreOp_ ) VULKAN_HPP_NOEXCEPT
    {
      stencilStoreOp = stencilStoreOp_;
      return *this;
    }

    AttachmentDescription & setInitialLayout( vk::ImageLayout initialLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      initialLayout = initialLayout_;
      return *this;
    }

    AttachmentDescription & setFinalLayout( vk::ImageLayout finalLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      finalLayout = finalLayout_;
      return *this;
    }

    operator VkAttachmentDescription const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAttachmentDescription*>( this );
    }

    operator VkAttachmentDescription &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAttachmentDescription*>( this );
    }

    bool operator==( AttachmentDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( flags == rhs.flags )
          && ( format == rhs.format )
          && vk::operator==( samples, rhs.samples )
          && ( loadOp == rhs.loadOp )
          && ( storeOp == rhs.storeOp )
          && ( stencilLoadOp == rhs.stencilLoadOp )
          && ( stencilStoreOp == rhs.stencilStoreOp )
          && ( initialLayout == rhs.initialLayout )
          && ( finalLayout == rhs.finalLayout );
    }

    bool operator!=( AttachmentDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::AttachmentDescriptionFlags flags;
    vk::Format format;
    vk::SampleCountFlagBits samples;
    vk::AttachmentLoadOp loadOp;
    vk::AttachmentStoreOp storeOp;
    vk::AttachmentLoadOp stencilLoadOp;
    vk::AttachmentStoreOp stencilStoreOp;
    vk::ImageLayout initialLayout;
    vk::ImageLayout finalLayout;
  };
  static_assert( sizeof( AttachmentDescription ) == sizeof( VkAttachmentDescription ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AttachmentDescription>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct AttachmentDescription2KHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR AttachmentDescription2KHR( vk::AttachmentDescriptionFlags flags_ = vk::AttachmentDescriptionFlags(),
                                                      vk::Format format_ = vk::Format::eUndefined,
                                                      vk::SampleCountFlagBits samples_ = vk::SampleCountFlagBits::e1,
                                                      vk::AttachmentLoadOp loadOp_ = vk::AttachmentLoadOp::eLoad,
                                                      vk::AttachmentStoreOp storeOp_ = vk::AttachmentStoreOp::eStore,
                                                      vk::AttachmentLoadOp stencilLoadOp_ = vk::AttachmentLoadOp::eLoad,
                                                      vk::AttachmentStoreOp stencilStoreOp_ = vk::AttachmentStoreOp::eStore,
                                                      vk::ImageLayout initialLayout_ = vk::ImageLayout::eUndefined,
                                                      vk::ImageLayout finalLayout_ = vk::ImageLayout::eUndefined ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , format( format_ )
        , samples( samples_ )
        , loadOp( loadOp_ )
        , storeOp( storeOp_ )
        , stencilLoadOp( stencilLoadOp_ )
        , stencilStoreOp( stencilStoreOp_ )
        , initialLayout( initialLayout_ )
        , finalLayout( finalLayout_ )
      {}

      AttachmentDescription2KHR( VkAttachmentDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAttachmentDescription2KHR*>(this) = rhs;
      }

      AttachmentDescription2KHR& operator=( VkAttachmentDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAttachmentDescription2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAttachmentDescription2KHR;
      const void* pNext = nullptr;
      vk::AttachmentDescriptionFlags flags;
      vk::Format format;
      vk::SampleCountFlagBits samples;
      vk::AttachmentLoadOp loadOp;
      vk::AttachmentStoreOp storeOp;
      vk::AttachmentLoadOp stencilLoadOp;
      vk::AttachmentStoreOp stencilStoreOp;
      vk::ImageLayout initialLayout;
      vk::ImageLayout finalLayout;
    };
    static_assert( sizeof( AttachmentDescription2KHR ) == sizeof( VkAttachmentDescription2KHR ), "layout struct and wrapper have different size!" );
  }

  struct AttachmentDescription2KHR : public layout::AttachmentDescription2KHR
  {
    VULKAN_HPP_CONSTEXPR AttachmentDescription2KHR( vk::AttachmentDescriptionFlags flags_ = vk::AttachmentDescriptionFlags(),
                                                    vk::Format format_ = vk::Format::eUndefined,
                                                    vk::SampleCountFlagBits samples_ = vk::SampleCountFlagBits::e1,
                                                    vk::AttachmentLoadOp loadOp_ = vk::AttachmentLoadOp::eLoad,
                                                    vk::AttachmentStoreOp storeOp_ = vk::AttachmentStoreOp::eStore,
                                                    vk::AttachmentLoadOp stencilLoadOp_ = vk::AttachmentLoadOp::eLoad,
                                                    vk::AttachmentStoreOp stencilStoreOp_ = vk::AttachmentStoreOp::eStore,
                                                    vk::ImageLayout initialLayout_ = vk::ImageLayout::eUndefined,
                                                    vk::ImageLayout finalLayout_ = vk::ImageLayout::eUndefined ) VULKAN_HPP_NOEXCEPT
      : layout::AttachmentDescription2KHR( flags_, format_, samples_, loadOp_, storeOp_, stencilLoadOp_, stencilStoreOp_, initialLayout_, finalLayout_ )
    {}

    AttachmentDescription2KHR( VkAttachmentDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AttachmentDescription2KHR( rhs )
    {}

    AttachmentDescription2KHR& operator=( VkAttachmentDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AttachmentDescription2KHR::operator=(rhs);
      return *this;
    }

    AttachmentDescription2KHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    AttachmentDescription2KHR & setFlags( vk::AttachmentDescriptionFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    AttachmentDescription2KHR & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    AttachmentDescription2KHR & setSamples( vk::SampleCountFlagBits samples_ ) VULKAN_HPP_NOEXCEPT
    {
      samples = samples_;
      return *this;
    }

    AttachmentDescription2KHR & setLoadOp( vk::AttachmentLoadOp loadOp_ ) VULKAN_HPP_NOEXCEPT
    {
      loadOp = loadOp_;
      return *this;
    }

    AttachmentDescription2KHR & setStoreOp( vk::AttachmentStoreOp storeOp_ ) VULKAN_HPP_NOEXCEPT
    {
      storeOp = storeOp_;
      return *this;
    }

    AttachmentDescription2KHR & setStencilLoadOp( vk::AttachmentLoadOp stencilLoadOp_ ) VULKAN_HPP_NOEXCEPT
    {
      stencilLoadOp = stencilLoadOp_;
      return *this;
    }

    AttachmentDescription2KHR & setStencilStoreOp( vk::AttachmentStoreOp stencilStoreOp_ ) VULKAN_HPP_NOEXCEPT
    {
      stencilStoreOp = stencilStoreOp_;
      return *this;
    }

    AttachmentDescription2KHR & setInitialLayout( vk::ImageLayout initialLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      initialLayout = initialLayout_;
      return *this;
    }

    AttachmentDescription2KHR & setFinalLayout( vk::ImageLayout finalLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      finalLayout = finalLayout_;
      return *this;
    }

    operator VkAttachmentDescription2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAttachmentDescription2KHR*>( this );
    }

    operator VkAttachmentDescription2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAttachmentDescription2KHR*>( this );
    }

    bool operator==( AttachmentDescription2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( format == rhs.format )
          && vk::operator==( samples, rhs.samples )
          && ( loadOp == rhs.loadOp )
          && ( storeOp == rhs.storeOp )
          && ( stencilLoadOp == rhs.stencilLoadOp )
          && ( stencilStoreOp == rhs.stencilStoreOp )
          && ( initialLayout == rhs.initialLayout )
          && ( finalLayout == rhs.finalLayout );
    }

    bool operator!=( AttachmentDescription2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AttachmentDescription2KHR::sType;
  };
  static_assert( sizeof( AttachmentDescription2KHR ) == sizeof( VkAttachmentDescription2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AttachmentDescription2KHR>::value, "struct wrapper is not a standard layout!" );

  struct AttachmentReference
  {
    VULKAN_HPP_CONSTEXPR AttachmentReference( uint32_t attachment_ = 0,
                                              vk::ImageLayout layout_ = vk::ImageLayout::eUndefined ) VULKAN_HPP_NOEXCEPT
      : attachment( attachment_ )
      , layout( layout_ )
    {}

    AttachmentReference( VkAttachmentReference const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAttachmentReference*>(this) = rhs;
    }

    AttachmentReference& operator=( VkAttachmentReference const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAttachmentReference*>(this) = rhs;
      return *this;
    }

    AttachmentReference & setAttachment( uint32_t attachment_ ) VULKAN_HPP_NOEXCEPT
    {
      attachment = attachment_;
      return *this;
    }

    AttachmentReference & setLayout( vk::ImageLayout layout_ ) VULKAN_HPP_NOEXCEPT
    {
      layout = layout_;
      return *this;
    }

    operator VkAttachmentReference const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAttachmentReference*>( this );
    }

    operator VkAttachmentReference &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAttachmentReference*>( this );
    }

    bool operator==( AttachmentReference const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( attachment == rhs.attachment )
          && ( layout == rhs.layout );
    }

    bool operator!=( AttachmentReference const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t attachment;
    vk::ImageLayout layout;
  };
  static_assert( sizeof( AttachmentReference ) == sizeof( VkAttachmentReference ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AttachmentReference>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct AttachmentReference2KHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR AttachmentReference2KHR( uint32_t attachment_ = 0,
                                                    vk::ImageLayout layout_ = vk::ImageLayout::eUndefined,
                                                    vk::ImageAspectFlags aspectMask_ = vk::ImageAspectFlags() ) VULKAN_HPP_NOEXCEPT
        : attachment( attachment_ )
        , layout( layout_ )
        , aspectMask( aspectMask_ )
      {}

      AttachmentReference2KHR( VkAttachmentReference2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAttachmentReference2KHR*>(this) = rhs;
      }

      AttachmentReference2KHR& operator=( VkAttachmentReference2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkAttachmentReference2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eAttachmentReference2KHR;
      const void* pNext = nullptr;
      uint32_t attachment;
      vk::ImageLayout layout;
      vk::ImageAspectFlags aspectMask;
    };
    static_assert( sizeof( AttachmentReference2KHR ) == sizeof( VkAttachmentReference2KHR ), "layout struct and wrapper have different size!" );
  }

  struct AttachmentReference2KHR : public layout::AttachmentReference2KHR
  {
    VULKAN_HPP_CONSTEXPR AttachmentReference2KHR( uint32_t attachment_ = 0,
                                                  vk::ImageLayout layout_ = vk::ImageLayout::eUndefined,
                                                  vk::ImageAspectFlags aspectMask_ = vk::ImageAspectFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::AttachmentReference2KHR( attachment_, layout_, aspectMask_ )
    {}

    AttachmentReference2KHR( VkAttachmentReference2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::AttachmentReference2KHR( rhs )
    {}

    AttachmentReference2KHR& operator=( VkAttachmentReference2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::AttachmentReference2KHR::operator=(rhs);
      return *this;
    }

    AttachmentReference2KHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    AttachmentReference2KHR & setAttachment( uint32_t attachment_ ) VULKAN_HPP_NOEXCEPT
    {
      attachment = attachment_;
      return *this;
    }

    AttachmentReference2KHR & setLayout( vk::ImageLayout layout_ ) VULKAN_HPP_NOEXCEPT
    {
      layout = layout_;
      return *this;
    }

    AttachmentReference2KHR & setAspectMask( vk::ImageAspectFlags aspectMask_ ) VULKAN_HPP_NOEXCEPT
    {
      aspectMask = aspectMask_;
      return *this;
    }

    operator VkAttachmentReference2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAttachmentReference2KHR*>( this );
    }

    operator VkAttachmentReference2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAttachmentReference2KHR*>( this );
    }

    bool operator==( AttachmentReference2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( attachment == rhs.attachment )
          && ( layout == rhs.layout )
          && ( aspectMask == rhs.aspectMask );
    }

    bool operator!=( AttachmentReference2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::AttachmentReference2KHR::sType;
  };
  static_assert( sizeof( AttachmentReference2KHR ) == sizeof( VkAttachmentReference2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AttachmentReference2KHR>::value, "struct wrapper is not a standard layout!" );

  struct Extent2D
  {
    VULKAN_HPP_CONSTEXPR Extent2D( uint32_t width_ = 0,
                                   uint32_t height_ = 0 ) VULKAN_HPP_NOEXCEPT
      : width( width_ )
      , height( height_ )
    {}

    Extent2D( VkExtent2D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExtent2D*>(this) = rhs;
    }

    Extent2D& operator=( VkExtent2D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExtent2D*>(this) = rhs;
      return *this;
    }

    Extent2D & setWidth( uint32_t width_ ) VULKAN_HPP_NOEXCEPT
    {
      width = width_;
      return *this;
    }

    Extent2D & setHeight( uint32_t height_ ) VULKAN_HPP_NOEXCEPT
    {
      height = height_;
      return *this;
    }

    operator VkExtent2D const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExtent2D*>( this );
    }

    operator VkExtent2D &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExtent2D*>( this );
    }

    bool operator==( Extent2D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( width == rhs.width )
          && ( height == rhs.height );
    }

    bool operator!=( Extent2D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t width;
    uint32_t height;
  };
  static_assert( sizeof( Extent2D ) == sizeof( VkExtent2D ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Extent2D>::value, "struct wrapper is not a standard layout!" );

  struct SampleLocationEXT
  {
    VULKAN_HPP_CONSTEXPR SampleLocationEXT( float x_ = 0,
                                            float y_ = 0 ) VULKAN_HPP_NOEXCEPT
      : x( x_ )
      , y( y_ )
    {}

    SampleLocationEXT( VkSampleLocationEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSampleLocationEXT*>(this) = rhs;
    }

    SampleLocationEXT& operator=( VkSampleLocationEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSampleLocationEXT*>(this) = rhs;
      return *this;
    }

    SampleLocationEXT & setX( float x_ ) VULKAN_HPP_NOEXCEPT
    {
      x = x_;
      return *this;
    }

    SampleLocationEXT & setY( float y_ ) VULKAN_HPP_NOEXCEPT
    {
      y = y_;
      return *this;
    }

    operator VkSampleLocationEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSampleLocationEXT*>( this );
    }

    operator VkSampleLocationEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSampleLocationEXT*>( this );
    }

    bool operator==( SampleLocationEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( x == rhs.x )
          && ( y == rhs.y );
    }

    bool operator!=( SampleLocationEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    float x;
    float y;
  };
  static_assert( sizeof( SampleLocationEXT ) == sizeof( VkSampleLocationEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SampleLocationEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SampleLocationsInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR SampleLocationsInfoEXT( vk::SampleCountFlagBits sampleLocationsPerPixel_ = vk::SampleCountFlagBits::e1,
                                                   vk::Extent2D sampleLocationGridSize_ = vk::Extent2D(),
                                                   uint32_t sampleLocationsCount_ = 0,
                                                   const vk::SampleLocationEXT* pSampleLocations_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : sampleLocationsPerPixel( sampleLocationsPerPixel_ )
        , sampleLocationGridSize( sampleLocationGridSize_ )
        , sampleLocationsCount( sampleLocationsCount_ )
        , pSampleLocations( pSampleLocations_ )
      {}

      SampleLocationsInfoEXT( VkSampleLocationsInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSampleLocationsInfoEXT*>(this) = rhs;
      }

      SampleLocationsInfoEXT& operator=( VkSampleLocationsInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSampleLocationsInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSampleLocationsInfoEXT;
      const void* pNext = nullptr;
      vk::SampleCountFlagBits sampleLocationsPerPixel;
      vk::Extent2D sampleLocationGridSize;
      uint32_t sampleLocationsCount;
      const vk::SampleLocationEXT* pSampleLocations;
    };
    static_assert( sizeof( SampleLocationsInfoEXT ) == sizeof( VkSampleLocationsInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct SampleLocationsInfoEXT : public layout::SampleLocationsInfoEXT
  {
    VULKAN_HPP_CONSTEXPR SampleLocationsInfoEXT( vk::SampleCountFlagBits sampleLocationsPerPixel_ = vk::SampleCountFlagBits::e1,
                                                 vk::Extent2D sampleLocationGridSize_ = vk::Extent2D(),
                                                 uint32_t sampleLocationsCount_ = 0,
                                                 const vk::SampleLocationEXT* pSampleLocations_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::SampleLocationsInfoEXT( sampleLocationsPerPixel_, sampleLocationGridSize_, sampleLocationsCount_, pSampleLocations_ )
    {}

    SampleLocationsInfoEXT( VkSampleLocationsInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SampleLocationsInfoEXT( rhs )
    {}

    SampleLocationsInfoEXT& operator=( VkSampleLocationsInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SampleLocationsInfoEXT::operator=(rhs);
      return *this;
    }

    SampleLocationsInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SampleLocationsInfoEXT & setSampleLocationsPerPixel( vk::SampleCountFlagBits sampleLocationsPerPixel_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationsPerPixel = sampleLocationsPerPixel_;
      return *this;
    }

    SampleLocationsInfoEXT & setSampleLocationGridSize( vk::Extent2D sampleLocationGridSize_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationGridSize = sampleLocationGridSize_;
      return *this;
    }

    SampleLocationsInfoEXT & setSampleLocationsCount( uint32_t sampleLocationsCount_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationsCount = sampleLocationsCount_;
      return *this;
    }

    SampleLocationsInfoEXT & setPSampleLocations( const vk::SampleLocationEXT* pSampleLocations_ ) VULKAN_HPP_NOEXCEPT
    {
      pSampleLocations = pSampleLocations_;
      return *this;
    }

    operator VkSampleLocationsInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSampleLocationsInfoEXT*>( this );
    }

    operator VkSampleLocationsInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSampleLocationsInfoEXT*>( this );
    }

    bool operator==( SampleLocationsInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( sampleLocationsPerPixel, rhs.sampleLocationsPerPixel )
          && ( sampleLocationGridSize == rhs.sampleLocationGridSize )
          && ( sampleLocationsCount == rhs.sampleLocationsCount )
          && ( pSampleLocations == rhs.pSampleLocations );
    }

    bool operator!=( SampleLocationsInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SampleLocationsInfoEXT::sType;
  };
  static_assert( sizeof( SampleLocationsInfoEXT ) == sizeof( VkSampleLocationsInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SampleLocationsInfoEXT>::value, "struct wrapper is not a standard layout!" );

  struct AttachmentSampleLocationsEXT
  {
    VULKAN_HPP_CONSTEXPR AttachmentSampleLocationsEXT( uint32_t attachmentIndex_ = 0,
                                                       vk::SampleLocationsInfoEXT sampleLocationsInfo_ = vk::SampleLocationsInfoEXT() ) VULKAN_HPP_NOEXCEPT
      : attachmentIndex( attachmentIndex_ )
      , sampleLocationsInfo( sampleLocationsInfo_ )
    {}

    AttachmentSampleLocationsEXT( VkAttachmentSampleLocationsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAttachmentSampleLocationsEXT*>(this) = rhs;
    }

    AttachmentSampleLocationsEXT& operator=( VkAttachmentSampleLocationsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkAttachmentSampleLocationsEXT*>(this) = rhs;
      return *this;
    }

    AttachmentSampleLocationsEXT & setAttachmentIndex( uint32_t attachmentIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentIndex = attachmentIndex_;
      return *this;
    }

    AttachmentSampleLocationsEXT & setSampleLocationsInfo( vk::SampleLocationsInfoEXT sampleLocationsInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationsInfo = sampleLocationsInfo_;
      return *this;
    }

    operator VkAttachmentSampleLocationsEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkAttachmentSampleLocationsEXT*>( this );
    }

    operator VkAttachmentSampleLocationsEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkAttachmentSampleLocationsEXT*>( this );
    }

    bool operator==( AttachmentSampleLocationsEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( attachmentIndex == rhs.attachmentIndex )
          && ( sampleLocationsInfo == rhs.sampleLocationsInfo );
    }

    bool operator!=( AttachmentSampleLocationsEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t attachmentIndex;
    vk::SampleLocationsInfoEXT sampleLocationsInfo;
  };
  static_assert( sizeof( AttachmentSampleLocationsEXT ) == sizeof( VkAttachmentSampleLocationsEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<AttachmentSampleLocationsEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BaseInStructure
    {
    protected:
      BaseInStructure() VULKAN_HPP_NOEXCEPT
      {}

      BaseInStructure( VkBaseInStructure const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBaseInStructure*>(this) = rhs;
      }

      BaseInStructure& operator=( VkBaseInStructure const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBaseInStructure*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType;
      const struct vk::BaseInStructure* pNext = nullptr;
    };
    static_assert( sizeof( BaseInStructure ) == sizeof( VkBaseInStructure ), "layout struct and wrapper have different size!" );
  }

  struct BaseInStructure : public layout::BaseInStructure
  {
    BaseInStructure() VULKAN_HPP_NOEXCEPT
      : layout::BaseInStructure()
    {}

    BaseInStructure( VkBaseInStructure const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BaseInStructure( rhs )
    {}

    BaseInStructure& operator=( VkBaseInStructure const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BaseInStructure::operator=(rhs);
      return *this;
    }

    BaseInStructure & setPNext( const struct vk::BaseInStructure* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    operator VkBaseInStructure const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBaseInStructure*>( this );
    }

    operator VkBaseInStructure &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBaseInStructure*>( this );
    }

    bool operator==( BaseInStructure const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext );
    }

    bool operator!=( BaseInStructure const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BaseInStructure::sType;
  };
  static_assert( sizeof( BaseInStructure ) == sizeof( VkBaseInStructure ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BaseInStructure>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BaseOutStructure
    {
    protected:
      BaseOutStructure() VULKAN_HPP_NOEXCEPT
      {}

      BaseOutStructure( VkBaseOutStructure const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBaseOutStructure*>(this) = rhs;
      }

      BaseOutStructure& operator=( VkBaseOutStructure const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBaseOutStructure*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType;
      struct vk::BaseOutStructure* pNext = nullptr;
    };
    static_assert( sizeof( BaseOutStructure ) == sizeof( VkBaseOutStructure ), "layout struct and wrapper have different size!" );
  }

  struct BaseOutStructure : public layout::BaseOutStructure
  {
    BaseOutStructure() VULKAN_HPP_NOEXCEPT
      : layout::BaseOutStructure()
    {}

    BaseOutStructure( VkBaseOutStructure const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BaseOutStructure( rhs )
    {}

    BaseOutStructure& operator=( VkBaseOutStructure const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BaseOutStructure::operator=(rhs);
      return *this;
    }

    BaseOutStructure & setPNext( struct vk::BaseOutStructure* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    operator VkBaseOutStructure const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBaseOutStructure*>( this );
    }

    operator VkBaseOutStructure &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBaseOutStructure*>( this );
    }

    bool operator==( BaseOutStructure const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext );
    }

    bool operator!=( BaseOutStructure const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BaseOutStructure::sType;
  };
  static_assert( sizeof( BaseOutStructure ) == sizeof( VkBaseOutStructure ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BaseOutStructure>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindAccelerationStructureMemoryInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindAccelerationStructureMemoryInfoNV( vk::AccelerationStructureNV accelerationStructure_ = vk::AccelerationStructureNV(),
                                                                  vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                                                  vk::DeviceSize memoryOffset_ = 0,
                                                                  uint32_t deviceIndexCount_ = 0,
                                                                  const uint32_t* pDeviceIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : accelerationStructure( accelerationStructure_ )
        , memory( memory_ )
        , memoryOffset( memoryOffset_ )
        , deviceIndexCount( deviceIndexCount_ )
        , pDeviceIndices( pDeviceIndices_ )
      {}

      BindAccelerationStructureMemoryInfoNV( VkBindAccelerationStructureMemoryInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindAccelerationStructureMemoryInfoNV*>(this) = rhs;
      }

      BindAccelerationStructureMemoryInfoNV& operator=( VkBindAccelerationStructureMemoryInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindAccelerationStructureMemoryInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindAccelerationStructureMemoryInfoNV;
      const void* pNext = nullptr;
      vk::AccelerationStructureNV accelerationStructure;
      vk::DeviceMemory memory;
      vk::DeviceSize memoryOffset;
      uint32_t deviceIndexCount;
      const uint32_t* pDeviceIndices;
    };
    static_assert( sizeof( BindAccelerationStructureMemoryInfoNV ) == sizeof( VkBindAccelerationStructureMemoryInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct BindAccelerationStructureMemoryInfoNV : public layout::BindAccelerationStructureMemoryInfoNV
  {
    VULKAN_HPP_CONSTEXPR BindAccelerationStructureMemoryInfoNV( vk::AccelerationStructureNV accelerationStructure_ = vk::AccelerationStructureNV(),
                                                                vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                                                vk::DeviceSize memoryOffset_ = 0,
                                                                uint32_t deviceIndexCount_ = 0,
                                                                const uint32_t* pDeviceIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::BindAccelerationStructureMemoryInfoNV( accelerationStructure_, memory_, memoryOffset_, deviceIndexCount_, pDeviceIndices_ )
    {}

    BindAccelerationStructureMemoryInfoNV( VkBindAccelerationStructureMemoryInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindAccelerationStructureMemoryInfoNV( rhs )
    {}

    BindAccelerationStructureMemoryInfoNV& operator=( VkBindAccelerationStructureMemoryInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindAccelerationStructureMemoryInfoNV::operator=(rhs);
      return *this;
    }

    BindAccelerationStructureMemoryInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindAccelerationStructureMemoryInfoNV & setAccelerationStructure( vk::AccelerationStructureNV accelerationStructure_ ) VULKAN_HPP_NOEXCEPT
    {
      accelerationStructure = accelerationStructure_;
      return *this;
    }

    BindAccelerationStructureMemoryInfoNV & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    BindAccelerationStructureMemoryInfoNV & setMemoryOffset( vk::DeviceSize memoryOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryOffset = memoryOffset_;
      return *this;
    }

    BindAccelerationStructureMemoryInfoNV & setDeviceIndexCount( uint32_t deviceIndexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceIndexCount = deviceIndexCount_;
      return *this;
    }

    BindAccelerationStructureMemoryInfoNV & setPDeviceIndices( const uint32_t* pDeviceIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pDeviceIndices = pDeviceIndices_;
      return *this;
    }

    operator VkBindAccelerationStructureMemoryInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindAccelerationStructureMemoryInfoNV*>( this );
    }

    operator VkBindAccelerationStructureMemoryInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindAccelerationStructureMemoryInfoNV*>( this );
    }

    bool operator==( BindAccelerationStructureMemoryInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( accelerationStructure == rhs.accelerationStructure )
          && ( memory == rhs.memory )
          && ( memoryOffset == rhs.memoryOffset )
          && ( deviceIndexCount == rhs.deviceIndexCount )
          && ( pDeviceIndices == rhs.pDeviceIndices );
    }

    bool operator!=( BindAccelerationStructureMemoryInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindAccelerationStructureMemoryInfoNV::sType;
  };
  static_assert( sizeof( BindAccelerationStructureMemoryInfoNV ) == sizeof( VkBindAccelerationStructureMemoryInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindAccelerationStructureMemoryInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindBufferMemoryDeviceGroupInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindBufferMemoryDeviceGroupInfo( uint32_t deviceIndexCount_ = 0,
                                                            const uint32_t* pDeviceIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : deviceIndexCount( deviceIndexCount_ )
        , pDeviceIndices( pDeviceIndices_ )
      {}

      BindBufferMemoryDeviceGroupInfo( VkBindBufferMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindBufferMemoryDeviceGroupInfo*>(this) = rhs;
      }

      BindBufferMemoryDeviceGroupInfo& operator=( VkBindBufferMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindBufferMemoryDeviceGroupInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindBufferMemoryDeviceGroupInfo;
      const void* pNext = nullptr;
      uint32_t deviceIndexCount;
      const uint32_t* pDeviceIndices;
    };
    static_assert( sizeof( BindBufferMemoryDeviceGroupInfo ) == sizeof( VkBindBufferMemoryDeviceGroupInfo ), "layout struct and wrapper have different size!" );
  }

  struct BindBufferMemoryDeviceGroupInfo : public layout::BindBufferMemoryDeviceGroupInfo
  {
    VULKAN_HPP_CONSTEXPR BindBufferMemoryDeviceGroupInfo( uint32_t deviceIndexCount_ = 0,
                                                          const uint32_t* pDeviceIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::BindBufferMemoryDeviceGroupInfo( deviceIndexCount_, pDeviceIndices_ )
    {}

    BindBufferMemoryDeviceGroupInfo( VkBindBufferMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindBufferMemoryDeviceGroupInfo( rhs )
    {}

    BindBufferMemoryDeviceGroupInfo& operator=( VkBindBufferMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindBufferMemoryDeviceGroupInfo::operator=(rhs);
      return *this;
    }

    BindBufferMemoryDeviceGroupInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindBufferMemoryDeviceGroupInfo & setDeviceIndexCount( uint32_t deviceIndexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceIndexCount = deviceIndexCount_;
      return *this;
    }

    BindBufferMemoryDeviceGroupInfo & setPDeviceIndices( const uint32_t* pDeviceIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pDeviceIndices = pDeviceIndices_;
      return *this;
    }

    operator VkBindBufferMemoryDeviceGroupInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindBufferMemoryDeviceGroupInfo*>( this );
    }

    operator VkBindBufferMemoryDeviceGroupInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindBufferMemoryDeviceGroupInfo*>( this );
    }

    bool operator==( BindBufferMemoryDeviceGroupInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( deviceIndexCount == rhs.deviceIndexCount )
          && ( pDeviceIndices == rhs.pDeviceIndices );
    }

    bool operator!=( BindBufferMemoryDeviceGroupInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindBufferMemoryDeviceGroupInfo::sType;
  };
  static_assert( sizeof( BindBufferMemoryDeviceGroupInfo ) == sizeof( VkBindBufferMemoryDeviceGroupInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindBufferMemoryDeviceGroupInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindBufferMemoryInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindBufferMemoryInfo( vk::Buffer buffer_ = vk::Buffer(),
                                                 vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                                 vk::DeviceSize memoryOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
        : buffer( buffer_ )
        , memory( memory_ )
        , memoryOffset( memoryOffset_ )
      {}

      BindBufferMemoryInfo( VkBindBufferMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindBufferMemoryInfo*>(this) = rhs;
      }

      BindBufferMemoryInfo& operator=( VkBindBufferMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindBufferMemoryInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindBufferMemoryInfo;
      const void* pNext = nullptr;
      vk::Buffer buffer;
      vk::DeviceMemory memory;
      vk::DeviceSize memoryOffset;
    };
    static_assert( sizeof( BindBufferMemoryInfo ) == sizeof( VkBindBufferMemoryInfo ), "layout struct and wrapper have different size!" );
  }

  struct BindBufferMemoryInfo : public layout::BindBufferMemoryInfo
  {
    VULKAN_HPP_CONSTEXPR BindBufferMemoryInfo( vk::Buffer buffer_ = vk::Buffer(),
                                               vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                               vk::DeviceSize memoryOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::BindBufferMemoryInfo( buffer_, memory_, memoryOffset_ )
    {}

    BindBufferMemoryInfo( VkBindBufferMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindBufferMemoryInfo( rhs )
    {}

    BindBufferMemoryInfo& operator=( VkBindBufferMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindBufferMemoryInfo::operator=(rhs);
      return *this;
    }

    BindBufferMemoryInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindBufferMemoryInfo & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    BindBufferMemoryInfo & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    BindBufferMemoryInfo & setMemoryOffset( vk::DeviceSize memoryOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryOffset = memoryOffset_;
      return *this;
    }

    operator VkBindBufferMemoryInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindBufferMemoryInfo*>( this );
    }

    operator VkBindBufferMemoryInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindBufferMemoryInfo*>( this );
    }

    bool operator==( BindBufferMemoryInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( buffer == rhs.buffer )
          && ( memory == rhs.memory )
          && ( memoryOffset == rhs.memoryOffset );
    }

    bool operator!=( BindBufferMemoryInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindBufferMemoryInfo::sType;
  };
  static_assert( sizeof( BindBufferMemoryInfo ) == sizeof( VkBindBufferMemoryInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindBufferMemoryInfo>::value, "struct wrapper is not a standard layout!" );

  struct Offset2D
  {
    VULKAN_HPP_CONSTEXPR Offset2D( int32_t x_ = 0,
                                   int32_t y_ = 0 ) VULKAN_HPP_NOEXCEPT
      : x( x_ )
      , y( y_ )
    {}

    Offset2D( VkOffset2D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkOffset2D*>(this) = rhs;
    }

    Offset2D& operator=( VkOffset2D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkOffset2D*>(this) = rhs;
      return *this;
    }

    Offset2D & setX( int32_t x_ ) VULKAN_HPP_NOEXCEPT
    {
      x = x_;
      return *this;
    }

    Offset2D & setY( int32_t y_ ) VULKAN_HPP_NOEXCEPT
    {
      y = y_;
      return *this;
    }

    operator VkOffset2D const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkOffset2D*>( this );
    }

    operator VkOffset2D &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkOffset2D*>( this );
    }

    bool operator==( Offset2D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( x == rhs.x )
          && ( y == rhs.y );
    }

    bool operator!=( Offset2D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    int32_t x;
    int32_t y;
  };
  static_assert( sizeof( Offset2D ) == sizeof( VkOffset2D ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Offset2D>::value, "struct wrapper is not a standard layout!" );

  struct Rect2D
  {
    VULKAN_HPP_CONSTEXPR Rect2D( vk::Offset2D offset_ = vk::Offset2D(),
                                 vk::Extent2D extent_ = vk::Extent2D() ) VULKAN_HPP_NOEXCEPT
      : offset( offset_ )
      , extent( extent_ )
    {}

    Rect2D( VkRect2D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkRect2D*>(this) = rhs;
    }

    Rect2D& operator=( VkRect2D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkRect2D*>(this) = rhs;
      return *this;
    }

    Rect2D & setOffset( vk::Offset2D offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    Rect2D & setExtent( vk::Extent2D extent_ ) VULKAN_HPP_NOEXCEPT
    {
      extent = extent_;
      return *this;
    }

    operator VkRect2D const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRect2D*>( this );
    }

    operator VkRect2D &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRect2D*>( this );
    }

    bool operator==( Rect2D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( offset == rhs.offset )
          && ( extent == rhs.extent );
    }

    bool operator!=( Rect2D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Offset2D offset;
    vk::Extent2D extent;
  };
  static_assert( sizeof( Rect2D ) == sizeof( VkRect2D ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Rect2D>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindImageMemoryDeviceGroupInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindImageMemoryDeviceGroupInfo( uint32_t deviceIndexCount_ = 0,
                                                           const uint32_t* pDeviceIndices_ = nullptr,
                                                           uint32_t splitInstanceBindRegionCount_ = 0,
                                                           const vk::Rect2D* pSplitInstanceBindRegions_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : deviceIndexCount( deviceIndexCount_ )
        , pDeviceIndices( pDeviceIndices_ )
        , splitInstanceBindRegionCount( splitInstanceBindRegionCount_ )
        , pSplitInstanceBindRegions( pSplitInstanceBindRegions_ )
      {}

      BindImageMemoryDeviceGroupInfo( VkBindImageMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImageMemoryDeviceGroupInfo*>(this) = rhs;
      }

      BindImageMemoryDeviceGroupInfo& operator=( VkBindImageMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImageMemoryDeviceGroupInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindImageMemoryDeviceGroupInfo;
      const void* pNext = nullptr;
      uint32_t deviceIndexCount;
      const uint32_t* pDeviceIndices;
      uint32_t splitInstanceBindRegionCount;
      const vk::Rect2D* pSplitInstanceBindRegions;
    };
    static_assert( sizeof( BindImageMemoryDeviceGroupInfo ) == sizeof( VkBindImageMemoryDeviceGroupInfo ), "layout struct and wrapper have different size!" );
  }

  struct BindImageMemoryDeviceGroupInfo : public layout::BindImageMemoryDeviceGroupInfo
  {
    VULKAN_HPP_CONSTEXPR BindImageMemoryDeviceGroupInfo( uint32_t deviceIndexCount_ = 0,
                                                         const uint32_t* pDeviceIndices_ = nullptr,
                                                         uint32_t splitInstanceBindRegionCount_ = 0,
                                                         const vk::Rect2D* pSplitInstanceBindRegions_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::BindImageMemoryDeviceGroupInfo( deviceIndexCount_, pDeviceIndices_, splitInstanceBindRegionCount_, pSplitInstanceBindRegions_ )
    {}

    BindImageMemoryDeviceGroupInfo( VkBindImageMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindImageMemoryDeviceGroupInfo( rhs )
    {}

    BindImageMemoryDeviceGroupInfo& operator=( VkBindImageMemoryDeviceGroupInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindImageMemoryDeviceGroupInfo::operator=(rhs);
      return *this;
    }

    BindImageMemoryDeviceGroupInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindImageMemoryDeviceGroupInfo & setDeviceIndexCount( uint32_t deviceIndexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceIndexCount = deviceIndexCount_;
      return *this;
    }

    BindImageMemoryDeviceGroupInfo & setPDeviceIndices( const uint32_t* pDeviceIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pDeviceIndices = pDeviceIndices_;
      return *this;
    }

    BindImageMemoryDeviceGroupInfo & setSplitInstanceBindRegionCount( uint32_t splitInstanceBindRegionCount_ ) VULKAN_HPP_NOEXCEPT
    {
      splitInstanceBindRegionCount = splitInstanceBindRegionCount_;
      return *this;
    }

    BindImageMemoryDeviceGroupInfo & setPSplitInstanceBindRegions( const vk::Rect2D* pSplitInstanceBindRegions_ ) VULKAN_HPP_NOEXCEPT
    {
      pSplitInstanceBindRegions = pSplitInstanceBindRegions_;
      return *this;
    }

    operator VkBindImageMemoryDeviceGroupInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindImageMemoryDeviceGroupInfo*>( this );
    }

    operator VkBindImageMemoryDeviceGroupInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindImageMemoryDeviceGroupInfo*>( this );
    }

    bool operator==( BindImageMemoryDeviceGroupInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( deviceIndexCount == rhs.deviceIndexCount )
          && ( pDeviceIndices == rhs.pDeviceIndices )
          && ( splitInstanceBindRegionCount == rhs.splitInstanceBindRegionCount )
          && ( pSplitInstanceBindRegions == rhs.pSplitInstanceBindRegions );
    }

    bool operator!=( BindImageMemoryDeviceGroupInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindImageMemoryDeviceGroupInfo::sType;
  };
  static_assert( sizeof( BindImageMemoryDeviceGroupInfo ) == sizeof( VkBindImageMemoryDeviceGroupInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindImageMemoryDeviceGroupInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindImageMemoryInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindImageMemoryInfo( vk::Image image_ = vk::Image(),
                                                vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                                vk::DeviceSize memoryOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
        : image( image_ )
        , memory( memory_ )
        , memoryOffset( memoryOffset_ )
      {}

      BindImageMemoryInfo( VkBindImageMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImageMemoryInfo*>(this) = rhs;
      }

      BindImageMemoryInfo& operator=( VkBindImageMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImageMemoryInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindImageMemoryInfo;
      const void* pNext = nullptr;
      vk::Image image;
      vk::DeviceMemory memory;
      vk::DeviceSize memoryOffset;
    };
    static_assert( sizeof( BindImageMemoryInfo ) == sizeof( VkBindImageMemoryInfo ), "layout struct and wrapper have different size!" );
  }

  struct BindImageMemoryInfo : public layout::BindImageMemoryInfo
  {
    VULKAN_HPP_CONSTEXPR BindImageMemoryInfo( vk::Image image_ = vk::Image(),
                                              vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                              vk::DeviceSize memoryOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::BindImageMemoryInfo( image_, memory_, memoryOffset_ )
    {}

    BindImageMemoryInfo( VkBindImageMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindImageMemoryInfo( rhs )
    {}

    BindImageMemoryInfo& operator=( VkBindImageMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindImageMemoryInfo::operator=(rhs);
      return *this;
    }

    BindImageMemoryInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindImageMemoryInfo & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    BindImageMemoryInfo & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    BindImageMemoryInfo & setMemoryOffset( vk::DeviceSize memoryOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryOffset = memoryOffset_;
      return *this;
    }

    operator VkBindImageMemoryInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindImageMemoryInfo*>( this );
    }

    operator VkBindImageMemoryInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindImageMemoryInfo*>( this );
    }

    bool operator==( BindImageMemoryInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( image == rhs.image )
          && ( memory == rhs.memory )
          && ( memoryOffset == rhs.memoryOffset );
    }

    bool operator!=( BindImageMemoryInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindImageMemoryInfo::sType;
  };
  static_assert( sizeof( BindImageMemoryInfo ) == sizeof( VkBindImageMemoryInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindImageMemoryInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindImageMemorySwapchainInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindImageMemorySwapchainInfoKHR( vk::SwapchainKHR swapchain_ = vk::SwapchainKHR(),
                                                            uint32_t imageIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : swapchain( swapchain_ )
        , imageIndex( imageIndex_ )
      {}

      BindImageMemorySwapchainInfoKHR( VkBindImageMemorySwapchainInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImageMemorySwapchainInfoKHR*>(this) = rhs;
      }

      BindImageMemorySwapchainInfoKHR& operator=( VkBindImageMemorySwapchainInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImageMemorySwapchainInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindImageMemorySwapchainInfoKHR;
      const void* pNext = nullptr;
      vk::SwapchainKHR swapchain;
      uint32_t imageIndex;
    };
    static_assert( sizeof( BindImageMemorySwapchainInfoKHR ) == sizeof( VkBindImageMemorySwapchainInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct BindImageMemorySwapchainInfoKHR : public layout::BindImageMemorySwapchainInfoKHR
  {
    VULKAN_HPP_CONSTEXPR BindImageMemorySwapchainInfoKHR( vk::SwapchainKHR swapchain_ = vk::SwapchainKHR(),
                                                          uint32_t imageIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::BindImageMemorySwapchainInfoKHR( swapchain_, imageIndex_ )
    {}

    BindImageMemorySwapchainInfoKHR( VkBindImageMemorySwapchainInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindImageMemorySwapchainInfoKHR( rhs )
    {}

    BindImageMemorySwapchainInfoKHR& operator=( VkBindImageMemorySwapchainInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindImageMemorySwapchainInfoKHR::operator=(rhs);
      return *this;
    }

    BindImageMemorySwapchainInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindImageMemorySwapchainInfoKHR & setSwapchain( vk::SwapchainKHR swapchain_ ) VULKAN_HPP_NOEXCEPT
    {
      swapchain = swapchain_;
      return *this;
    }

    BindImageMemorySwapchainInfoKHR & setImageIndex( uint32_t imageIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      imageIndex = imageIndex_;
      return *this;
    }

    operator VkBindImageMemorySwapchainInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindImageMemorySwapchainInfoKHR*>( this );
    }

    operator VkBindImageMemorySwapchainInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindImageMemorySwapchainInfoKHR*>( this );
    }

    bool operator==( BindImageMemorySwapchainInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( swapchain == rhs.swapchain )
          && ( imageIndex == rhs.imageIndex );
    }

    bool operator!=( BindImageMemorySwapchainInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindImageMemorySwapchainInfoKHR::sType;
  };
  static_assert( sizeof( BindImageMemorySwapchainInfoKHR ) == sizeof( VkBindImageMemorySwapchainInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindImageMemorySwapchainInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindImagePlaneMemoryInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindImagePlaneMemoryInfo( vk::ImageAspectFlagBits planeAspect_ = vk::ImageAspectFlagBits::eColor ) VULKAN_HPP_NOEXCEPT
        : planeAspect( planeAspect_ )
      {}

      BindImagePlaneMemoryInfo( VkBindImagePlaneMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImagePlaneMemoryInfo*>(this) = rhs;
      }

      BindImagePlaneMemoryInfo& operator=( VkBindImagePlaneMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindImagePlaneMemoryInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindImagePlaneMemoryInfo;
      const void* pNext = nullptr;
      vk::ImageAspectFlagBits planeAspect;
    };
    static_assert( sizeof( BindImagePlaneMemoryInfo ) == sizeof( VkBindImagePlaneMemoryInfo ), "layout struct and wrapper have different size!" );
  }

  struct BindImagePlaneMemoryInfo : public layout::BindImagePlaneMemoryInfo
  {
    VULKAN_HPP_CONSTEXPR BindImagePlaneMemoryInfo( vk::ImageAspectFlagBits planeAspect_ = vk::ImageAspectFlagBits::eColor ) VULKAN_HPP_NOEXCEPT
      : layout::BindImagePlaneMemoryInfo( planeAspect_ )
    {}

    BindImagePlaneMemoryInfo( VkBindImagePlaneMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindImagePlaneMemoryInfo( rhs )
    {}

    BindImagePlaneMemoryInfo& operator=( VkBindImagePlaneMemoryInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindImagePlaneMemoryInfo::operator=(rhs);
      return *this;
    }

    BindImagePlaneMemoryInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindImagePlaneMemoryInfo & setPlaneAspect( vk::ImageAspectFlagBits planeAspect_ ) VULKAN_HPP_NOEXCEPT
    {
      planeAspect = planeAspect_;
      return *this;
    }

    operator VkBindImagePlaneMemoryInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindImagePlaneMemoryInfo*>( this );
    }

    operator VkBindImagePlaneMemoryInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindImagePlaneMemoryInfo*>( this );
    }

    bool operator==( BindImagePlaneMemoryInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( planeAspect, rhs.planeAspect );
    }

    bool operator!=( BindImagePlaneMemoryInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindImagePlaneMemoryInfo::sType;
  };
  static_assert( sizeof( BindImagePlaneMemoryInfo ) == sizeof( VkBindImagePlaneMemoryInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindImagePlaneMemoryInfo>::value, "struct wrapper is not a standard layout!" );

  struct SparseMemoryBind
  {
    VULKAN_HPP_CONSTEXPR SparseMemoryBind( vk::DeviceSize resourceOffset_ = 0,
                                           vk::DeviceSize size_ = 0,
                                           vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                           vk::DeviceSize memoryOffset_ = 0,
                                           vk::SparseMemoryBindFlags flags_ = vk::SparseMemoryBindFlags() ) VULKAN_HPP_NOEXCEPT
      : resourceOffset( resourceOffset_ )
      , size( size_ )
      , memory( memory_ )
      , memoryOffset( memoryOffset_ )
      , flags( flags_ )
    {}

    SparseMemoryBind( VkSparseMemoryBind const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseMemoryBind*>(this) = rhs;
    }

    SparseMemoryBind& operator=( VkSparseMemoryBind const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseMemoryBind*>(this) = rhs;
      return *this;
    }

    SparseMemoryBind & setResourceOffset( vk::DeviceSize resourceOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      resourceOffset = resourceOffset_;
      return *this;
    }

    SparseMemoryBind & setSize( vk::DeviceSize size_ ) VULKAN_HPP_NOEXCEPT
    {
      size = size_;
      return *this;
    }

    SparseMemoryBind & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    SparseMemoryBind & setMemoryOffset( vk::DeviceSize memoryOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryOffset = memoryOffset_;
      return *this;
    }

    SparseMemoryBind & setFlags( vk::SparseMemoryBindFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkSparseMemoryBind const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseMemoryBind*>( this );
    }

    operator VkSparseMemoryBind &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseMemoryBind*>( this );
    }

    bool operator==( SparseMemoryBind const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( resourceOffset == rhs.resourceOffset )
          && ( size == rhs.size )
          && ( memory == rhs.memory )
          && ( memoryOffset == rhs.memoryOffset )
          && ( flags == rhs.flags );
    }

    bool operator!=( SparseMemoryBind const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DeviceSize resourceOffset;
    vk::DeviceSize size;
    vk::DeviceMemory memory;
    vk::DeviceSize memoryOffset;
    vk::SparseMemoryBindFlags flags;
  };
  static_assert( sizeof( SparseMemoryBind ) == sizeof( VkSparseMemoryBind ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseMemoryBind>::value, "struct wrapper is not a standard layout!" );

  struct SparseBufferMemoryBindInfo
  {
    VULKAN_HPP_CONSTEXPR SparseBufferMemoryBindInfo( vk::Buffer buffer_ = vk::Buffer(),
                                                     uint32_t bindCount_ = 0,
                                                     const vk::SparseMemoryBind* pBinds_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : buffer( buffer_ )
      , bindCount( bindCount_ )
      , pBinds( pBinds_ )
    {}

    SparseBufferMemoryBindInfo( VkSparseBufferMemoryBindInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseBufferMemoryBindInfo*>(this) = rhs;
    }

    SparseBufferMemoryBindInfo& operator=( VkSparseBufferMemoryBindInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseBufferMemoryBindInfo*>(this) = rhs;
      return *this;
    }

    SparseBufferMemoryBindInfo & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    SparseBufferMemoryBindInfo & setBindCount( uint32_t bindCount_ ) VULKAN_HPP_NOEXCEPT
    {
      bindCount = bindCount_;
      return *this;
    }

    SparseBufferMemoryBindInfo & setPBinds( const vk::SparseMemoryBind* pBinds_ ) VULKAN_HPP_NOEXCEPT
    {
      pBinds = pBinds_;
      return *this;
    }

    operator VkSparseBufferMemoryBindInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseBufferMemoryBindInfo*>( this );
    }

    operator VkSparseBufferMemoryBindInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseBufferMemoryBindInfo*>( this );
    }

    bool operator==( SparseBufferMemoryBindInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( buffer == rhs.buffer )
          && ( bindCount == rhs.bindCount )
          && ( pBinds == rhs.pBinds );
    }

    bool operator!=( SparseBufferMemoryBindInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Buffer buffer;
    uint32_t bindCount;
    const vk::SparseMemoryBind* pBinds;
  };
  static_assert( sizeof( SparseBufferMemoryBindInfo ) == sizeof( VkSparseBufferMemoryBindInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseBufferMemoryBindInfo>::value, "struct wrapper is not a standard layout!" );

  struct SparseImageOpaqueMemoryBindInfo
  {
    VULKAN_HPP_CONSTEXPR SparseImageOpaqueMemoryBindInfo( vk::Image image_ = vk::Image(),
                                                          uint32_t bindCount_ = 0,
                                                          const vk::SparseMemoryBind* pBinds_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : image( image_ )
      , bindCount( bindCount_ )
      , pBinds( pBinds_ )
    {}

    SparseImageOpaqueMemoryBindInfo( VkSparseImageOpaqueMemoryBindInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageOpaqueMemoryBindInfo*>(this) = rhs;
    }

    SparseImageOpaqueMemoryBindInfo& operator=( VkSparseImageOpaqueMemoryBindInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageOpaqueMemoryBindInfo*>(this) = rhs;
      return *this;
    }

    SparseImageOpaqueMemoryBindInfo & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    SparseImageOpaqueMemoryBindInfo & setBindCount( uint32_t bindCount_ ) VULKAN_HPP_NOEXCEPT
    {
      bindCount = bindCount_;
      return *this;
    }

    SparseImageOpaqueMemoryBindInfo & setPBinds( const vk::SparseMemoryBind* pBinds_ ) VULKAN_HPP_NOEXCEPT
    {
      pBinds = pBinds_;
      return *this;
    }

    operator VkSparseImageOpaqueMemoryBindInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseImageOpaqueMemoryBindInfo*>( this );
    }

    operator VkSparseImageOpaqueMemoryBindInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseImageOpaqueMemoryBindInfo*>( this );
    }

    bool operator==( SparseImageOpaqueMemoryBindInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( image == rhs.image )
          && ( bindCount == rhs.bindCount )
          && ( pBinds == rhs.pBinds );
    }

    bool operator!=( SparseImageOpaqueMemoryBindInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Image image;
    uint32_t bindCount;
    const vk::SparseMemoryBind* pBinds;
  };
  static_assert( sizeof( SparseImageOpaqueMemoryBindInfo ) == sizeof( VkSparseImageOpaqueMemoryBindInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseImageOpaqueMemoryBindInfo>::value, "struct wrapper is not a standard layout!" );

  struct ImageSubresource
  {
    VULKAN_HPP_CONSTEXPR ImageSubresource( vk::ImageAspectFlags aspectMask_ = vk::ImageAspectFlags(),
                                           uint32_t mipLevel_ = 0,
                                           uint32_t arrayLayer_ = 0 ) VULKAN_HPP_NOEXCEPT
      : aspectMask( aspectMask_ )
      , mipLevel( mipLevel_ )
      , arrayLayer( arrayLayer_ )
    {}

    ImageSubresource( VkImageSubresource const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageSubresource*>(this) = rhs;
    }

    ImageSubresource& operator=( VkImageSubresource const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageSubresource*>(this) = rhs;
      return *this;
    }

    ImageSubresource & setAspectMask( vk::ImageAspectFlags aspectMask_ ) VULKAN_HPP_NOEXCEPT
    {
      aspectMask = aspectMask_;
      return *this;
    }

    ImageSubresource & setMipLevel( uint32_t mipLevel_ ) VULKAN_HPP_NOEXCEPT
    {
      mipLevel = mipLevel_;
      return *this;
    }

    ImageSubresource & setArrayLayer( uint32_t arrayLayer_ ) VULKAN_HPP_NOEXCEPT
    {
      arrayLayer = arrayLayer_;
      return *this;
    }

    operator VkImageSubresource const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageSubresource*>( this );
    }

    operator VkImageSubresource &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageSubresource*>( this );
    }

    bool operator==( ImageSubresource const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( aspectMask == rhs.aspectMask )
          && ( mipLevel == rhs.mipLevel )
          && ( arrayLayer == rhs.arrayLayer );
    }

    bool operator!=( ImageSubresource const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageAspectFlags aspectMask;
    uint32_t mipLevel;
    uint32_t arrayLayer;
  };
  static_assert( sizeof( ImageSubresource ) == sizeof( VkImageSubresource ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageSubresource>::value, "struct wrapper is not a standard layout!" );

  struct Offset3D
  {
    VULKAN_HPP_CONSTEXPR Offset3D( int32_t x_ = 0,
                                   int32_t y_ = 0,
                                   int32_t z_ = 0 ) VULKAN_HPP_NOEXCEPT
      : x( x_ )
      , y( y_ )
      , z( z_ )
    {}

    explicit Offset3D( Offset2D const& offset2D,
                       int32_t z_ = 0 )
      : x( offset2D.x )
      , y( offset2D.y )
      , z( z_ )
    {}

    Offset3D( VkOffset3D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkOffset3D*>(this) = rhs;
    }

    Offset3D& operator=( VkOffset3D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkOffset3D*>(this) = rhs;
      return *this;
    }

    Offset3D & setX( int32_t x_ ) VULKAN_HPP_NOEXCEPT
    {
      x = x_;
      return *this;
    }

    Offset3D & setY( int32_t y_ ) VULKAN_HPP_NOEXCEPT
    {
      y = y_;
      return *this;
    }

    Offset3D & setZ( int32_t z_ ) VULKAN_HPP_NOEXCEPT
    {
      z = z_;
      return *this;
    }

    operator VkOffset3D const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkOffset3D*>( this );
    }

    operator VkOffset3D &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkOffset3D*>( this );
    }

    bool operator==( Offset3D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( x == rhs.x )
          && ( y == rhs.y )
          && ( z == rhs.z );
    }

    bool operator!=( Offset3D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    int32_t x;
    int32_t y;
    int32_t z;
  };
  static_assert( sizeof( Offset3D ) == sizeof( VkOffset3D ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Offset3D>::value, "struct wrapper is not a standard layout!" );

  struct Extent3D
  {
    VULKAN_HPP_CONSTEXPR Extent3D( uint32_t width_ = 0,
                                   uint32_t height_ = 0,
                                   uint32_t depth_ = 0 ) VULKAN_HPP_NOEXCEPT
      : width( width_ )
      , height( height_ )
      , depth( depth_ )
    {}

    explicit Extent3D( Extent2D const& extent2D,
                       uint32_t depth_ = 0 )
      : width( extent2D.width )
      , height( extent2D.height )
      , depth( depth_ )
    {}

    Extent3D( VkExtent3D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExtent3D*>(this) = rhs;
    }

    Extent3D& operator=( VkExtent3D const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExtent3D*>(this) = rhs;
      return *this;
    }

    Extent3D & setWidth( uint32_t width_ ) VULKAN_HPP_NOEXCEPT
    {
      width = width_;
      return *this;
    }

    Extent3D & setHeight( uint32_t height_ ) VULKAN_HPP_NOEXCEPT
    {
      height = height_;
      return *this;
    }

    Extent3D & setDepth( uint32_t depth_ ) VULKAN_HPP_NOEXCEPT
    {
      depth = depth_;
      return *this;
    }

    operator VkExtent3D const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExtent3D*>( this );
    }

    operator VkExtent3D &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExtent3D*>( this );
    }

    bool operator==( Extent3D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( width == rhs.width )
          && ( height == rhs.height )
          && ( depth == rhs.depth );
    }

    bool operator!=( Extent3D const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t width;
    uint32_t height;
    uint32_t depth;
  };
  static_assert( sizeof( Extent3D ) == sizeof( VkExtent3D ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Extent3D>::value, "struct wrapper is not a standard layout!" );

  struct SparseImageMemoryBind
  {
    VULKAN_HPP_CONSTEXPR SparseImageMemoryBind( vk::ImageSubresource subresource_ = vk::ImageSubresource(),
                                                vk::Offset3D offset_ = vk::Offset3D(),
                                                vk::Extent3D extent_ = vk::Extent3D(),
                                                vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                                vk::DeviceSize memoryOffset_ = 0,
                                                vk::SparseMemoryBindFlags flags_ = vk::SparseMemoryBindFlags() ) VULKAN_HPP_NOEXCEPT
      : subresource( subresource_ )
      , offset( offset_ )
      , extent( extent_ )
      , memory( memory_ )
      , memoryOffset( memoryOffset_ )
      , flags( flags_ )
    {}

    SparseImageMemoryBind( VkSparseImageMemoryBind const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageMemoryBind*>(this) = rhs;
    }

    SparseImageMemoryBind& operator=( VkSparseImageMemoryBind const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageMemoryBind*>(this) = rhs;
      return *this;
    }

    SparseImageMemoryBind & setSubresource( vk::ImageSubresource subresource_ ) VULKAN_HPP_NOEXCEPT
    {
      subresource = subresource_;
      return *this;
    }

    SparseImageMemoryBind & setOffset( vk::Offset3D offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    SparseImageMemoryBind & setExtent( vk::Extent3D extent_ ) VULKAN_HPP_NOEXCEPT
    {
      extent = extent_;
      return *this;
    }

    SparseImageMemoryBind & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    SparseImageMemoryBind & setMemoryOffset( vk::DeviceSize memoryOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryOffset = memoryOffset_;
      return *this;
    }

    SparseImageMemoryBind & setFlags( vk::SparseMemoryBindFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkSparseImageMemoryBind const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseImageMemoryBind*>( this );
    }

    operator VkSparseImageMemoryBind &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseImageMemoryBind*>( this );
    }

    bool operator==( SparseImageMemoryBind const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( subresource == rhs.subresource )
          && ( offset == rhs.offset )
          && ( extent == rhs.extent )
          && ( memory == rhs.memory )
          && ( memoryOffset == rhs.memoryOffset )
          && ( flags == rhs.flags );
    }

    bool operator!=( SparseImageMemoryBind const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageSubresource subresource;
    vk::Offset3D offset;
    vk::Extent3D extent;
    vk::DeviceMemory memory;
    vk::DeviceSize memoryOffset;
    vk::SparseMemoryBindFlags flags;
  };
  static_assert( sizeof( SparseImageMemoryBind ) == sizeof( VkSparseImageMemoryBind ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseImageMemoryBind>::value, "struct wrapper is not a standard layout!" );

  struct SparseImageMemoryBindInfo
  {
    VULKAN_HPP_CONSTEXPR SparseImageMemoryBindInfo( vk::Image image_ = vk::Image(),
                                                    uint32_t bindCount_ = 0,
                                                    const vk::SparseImageMemoryBind* pBinds_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : image( image_ )
      , bindCount( bindCount_ )
      , pBinds( pBinds_ )
    {}

    SparseImageMemoryBindInfo( VkSparseImageMemoryBindInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageMemoryBindInfo*>(this) = rhs;
    }

    SparseImageMemoryBindInfo& operator=( VkSparseImageMemoryBindInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageMemoryBindInfo*>(this) = rhs;
      return *this;
    }

    SparseImageMemoryBindInfo & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    SparseImageMemoryBindInfo & setBindCount( uint32_t bindCount_ ) VULKAN_HPP_NOEXCEPT
    {
      bindCount = bindCount_;
      return *this;
    }

    SparseImageMemoryBindInfo & setPBinds( const vk::SparseImageMemoryBind* pBinds_ ) VULKAN_HPP_NOEXCEPT
    {
      pBinds = pBinds_;
      return *this;
    }

    operator VkSparseImageMemoryBindInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseImageMemoryBindInfo*>( this );
    }

    operator VkSparseImageMemoryBindInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseImageMemoryBindInfo*>( this );
    }

    bool operator==( SparseImageMemoryBindInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( image == rhs.image )
          && ( bindCount == rhs.bindCount )
          && ( pBinds == rhs.pBinds );
    }

    bool operator!=( SparseImageMemoryBindInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Image image;
    uint32_t bindCount;
    const vk::SparseImageMemoryBind* pBinds;
  };
  static_assert( sizeof( SparseImageMemoryBindInfo ) == sizeof( VkSparseImageMemoryBindInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseImageMemoryBindInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BindSparseInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BindSparseInfo( uint32_t waitSemaphoreCount_ = 0,
                                           const vk::Semaphore* pWaitSemaphores_ = nullptr,
                                           uint32_t bufferBindCount_ = 0,
                                           const vk::SparseBufferMemoryBindInfo* pBufferBinds_ = nullptr,
                                           uint32_t imageOpaqueBindCount_ = 0,
                                           const vk::SparseImageOpaqueMemoryBindInfo* pImageOpaqueBinds_ = nullptr,
                                           uint32_t imageBindCount_ = 0,
                                           const vk::SparseImageMemoryBindInfo* pImageBinds_ = nullptr,
                                           uint32_t signalSemaphoreCount_ = 0,
                                           const vk::Semaphore* pSignalSemaphores_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : waitSemaphoreCount( waitSemaphoreCount_ )
        , pWaitSemaphores( pWaitSemaphores_ )
        , bufferBindCount( bufferBindCount_ )
        , pBufferBinds( pBufferBinds_ )
        , imageOpaqueBindCount( imageOpaqueBindCount_ )
        , pImageOpaqueBinds( pImageOpaqueBinds_ )
        , imageBindCount( imageBindCount_ )
        , pImageBinds( pImageBinds_ )
        , signalSemaphoreCount( signalSemaphoreCount_ )
        , pSignalSemaphores( pSignalSemaphores_ )
      {}

      BindSparseInfo( VkBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindSparseInfo*>(this) = rhs;
      }

      BindSparseInfo& operator=( VkBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBindSparseInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBindSparseInfo;
      const void* pNext = nullptr;
      uint32_t waitSemaphoreCount;
      const vk::Semaphore* pWaitSemaphores;
      uint32_t bufferBindCount;
      const vk::SparseBufferMemoryBindInfo* pBufferBinds;
      uint32_t imageOpaqueBindCount;
      const vk::SparseImageOpaqueMemoryBindInfo* pImageOpaqueBinds;
      uint32_t imageBindCount;
      const vk::SparseImageMemoryBindInfo* pImageBinds;
      uint32_t signalSemaphoreCount;
      const vk::Semaphore* pSignalSemaphores;
    };
    static_assert( sizeof( BindSparseInfo ) == sizeof( VkBindSparseInfo ), "layout struct and wrapper have different size!" );
  }

  struct BindSparseInfo : public layout::BindSparseInfo
  {
    VULKAN_HPP_CONSTEXPR BindSparseInfo( uint32_t waitSemaphoreCount_ = 0,
                                         const vk::Semaphore* pWaitSemaphores_ = nullptr,
                                         uint32_t bufferBindCount_ = 0,
                                         const vk::SparseBufferMemoryBindInfo* pBufferBinds_ = nullptr,
                                         uint32_t imageOpaqueBindCount_ = 0,
                                         const vk::SparseImageOpaqueMemoryBindInfo* pImageOpaqueBinds_ = nullptr,
                                         uint32_t imageBindCount_ = 0,
                                         const vk::SparseImageMemoryBindInfo* pImageBinds_ = nullptr,
                                         uint32_t signalSemaphoreCount_ = 0,
                                         const vk::Semaphore* pSignalSemaphores_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::BindSparseInfo( waitSemaphoreCount_, pWaitSemaphores_, bufferBindCount_, pBufferBinds_, imageOpaqueBindCount_, pImageOpaqueBinds_, imageBindCount_, pImageBinds_, signalSemaphoreCount_, pSignalSemaphores_ )
    {}

    BindSparseInfo( VkBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BindSparseInfo( rhs )
    {}

    BindSparseInfo& operator=( VkBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BindSparseInfo::operator=(rhs);
      return *this;
    }

    BindSparseInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BindSparseInfo & setWaitSemaphoreCount( uint32_t waitSemaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      waitSemaphoreCount = waitSemaphoreCount_;
      return *this;
    }

    BindSparseInfo & setPWaitSemaphores( const vk::Semaphore* pWaitSemaphores_ ) VULKAN_HPP_NOEXCEPT
    {
      pWaitSemaphores = pWaitSemaphores_;
      return *this;
    }

    BindSparseInfo & setBufferBindCount( uint32_t bufferBindCount_ ) VULKAN_HPP_NOEXCEPT
    {
      bufferBindCount = bufferBindCount_;
      return *this;
    }

    BindSparseInfo & setPBufferBinds( const vk::SparseBufferMemoryBindInfo* pBufferBinds_ ) VULKAN_HPP_NOEXCEPT
    {
      pBufferBinds = pBufferBinds_;
      return *this;
    }

    BindSparseInfo & setImageOpaqueBindCount( uint32_t imageOpaqueBindCount_ ) VULKAN_HPP_NOEXCEPT
    {
      imageOpaqueBindCount = imageOpaqueBindCount_;
      return *this;
    }

    BindSparseInfo & setPImageOpaqueBinds( const vk::SparseImageOpaqueMemoryBindInfo* pImageOpaqueBinds_ ) VULKAN_HPP_NOEXCEPT
    {
      pImageOpaqueBinds = pImageOpaqueBinds_;
      return *this;
    }

    BindSparseInfo & setImageBindCount( uint32_t imageBindCount_ ) VULKAN_HPP_NOEXCEPT
    {
      imageBindCount = imageBindCount_;
      return *this;
    }

    BindSparseInfo & setPImageBinds( const vk::SparseImageMemoryBindInfo* pImageBinds_ ) VULKAN_HPP_NOEXCEPT
    {
      pImageBinds = pImageBinds_;
      return *this;
    }

    BindSparseInfo & setSignalSemaphoreCount( uint32_t signalSemaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      signalSemaphoreCount = signalSemaphoreCount_;
      return *this;
    }

    BindSparseInfo & setPSignalSemaphores( const vk::Semaphore* pSignalSemaphores_ ) VULKAN_HPP_NOEXCEPT
    {
      pSignalSemaphores = pSignalSemaphores_;
      return *this;
    }

    operator VkBindSparseInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBindSparseInfo*>( this );
    }

    operator VkBindSparseInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBindSparseInfo*>( this );
    }

    bool operator==( BindSparseInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( waitSemaphoreCount == rhs.waitSemaphoreCount )
          && ( pWaitSemaphores == rhs.pWaitSemaphores )
          && ( bufferBindCount == rhs.bufferBindCount )
          && ( pBufferBinds == rhs.pBufferBinds )
          && ( imageOpaqueBindCount == rhs.imageOpaqueBindCount )
          && ( pImageOpaqueBinds == rhs.pImageOpaqueBinds )
          && ( imageBindCount == rhs.imageBindCount )
          && ( pImageBinds == rhs.pImageBinds )
          && ( signalSemaphoreCount == rhs.signalSemaphoreCount )
          && ( pSignalSemaphores == rhs.pSignalSemaphores );
    }

    bool operator!=( BindSparseInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BindSparseInfo::sType;
  };
  static_assert( sizeof( BindSparseInfo ) == sizeof( VkBindSparseInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BindSparseInfo>::value, "struct wrapper is not a standard layout!" );

  struct BufferCopy
  {
    VULKAN_HPP_CONSTEXPR BufferCopy( vk::DeviceSize srcOffset_ = 0,
                                     vk::DeviceSize dstOffset_ = 0,
                                     vk::DeviceSize size_ = 0 ) VULKAN_HPP_NOEXCEPT
      : srcOffset( srcOffset_ )
      , dstOffset( dstOffset_ )
      , size( size_ )
    {}

    BufferCopy( VkBufferCopy const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkBufferCopy*>(this) = rhs;
    }

    BufferCopy& operator=( VkBufferCopy const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkBufferCopy*>(this) = rhs;
      return *this;
    }

    BufferCopy & setSrcOffset( vk::DeviceSize srcOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      srcOffset = srcOffset_;
      return *this;
    }

    BufferCopy & setDstOffset( vk::DeviceSize dstOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      dstOffset = dstOffset_;
      return *this;
    }

    BufferCopy & setSize( vk::DeviceSize size_ ) VULKAN_HPP_NOEXCEPT
    {
      size = size_;
      return *this;
    }

    operator VkBufferCopy const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferCopy*>( this );
    }

    operator VkBufferCopy &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferCopy*>( this );
    }

    bool operator==( BufferCopy const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( srcOffset == rhs.srcOffset )
          && ( dstOffset == rhs.dstOffset )
          && ( size == rhs.size );
    }

    bool operator!=( BufferCopy const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DeviceSize srcOffset;
    vk::DeviceSize dstOffset;
    vk::DeviceSize size;
  };
  static_assert( sizeof( BufferCopy ) == sizeof( VkBufferCopy ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferCopy>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BufferCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BufferCreateInfo( vk::BufferCreateFlags flags_ = vk::BufferCreateFlags(),
                                             vk::DeviceSize size_ = 0,
                                             vk::BufferUsageFlags usage_ = vk::BufferUsageFlags(),
                                             vk::SharingMode sharingMode_ = vk::SharingMode::eExclusive,
                                             uint32_t queueFamilyIndexCount_ = 0,
                                             const uint32_t* pQueueFamilyIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , size( size_ )
        , usage( usage_ )
        , sharingMode( sharingMode_ )
        , queueFamilyIndexCount( queueFamilyIndexCount_ )
        , pQueueFamilyIndices( pQueueFamilyIndices_ )
      {}

      BufferCreateInfo( VkBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferCreateInfo*>(this) = rhs;
      }

      BufferCreateInfo& operator=( VkBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBufferCreateInfo;
      const void* pNext = nullptr;
      vk::BufferCreateFlags flags;
      vk::DeviceSize size;
      vk::BufferUsageFlags usage;
      vk::SharingMode sharingMode;
      uint32_t queueFamilyIndexCount;
      const uint32_t* pQueueFamilyIndices;
    };
    static_assert( sizeof( BufferCreateInfo ) == sizeof( VkBufferCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct BufferCreateInfo : public layout::BufferCreateInfo
  {
    VULKAN_HPP_CONSTEXPR BufferCreateInfo( vk::BufferCreateFlags flags_ = vk::BufferCreateFlags(),
                                           vk::DeviceSize size_ = 0,
                                           vk::BufferUsageFlags usage_ = vk::BufferUsageFlags(),
                                           vk::SharingMode sharingMode_ = vk::SharingMode::eExclusive,
                                           uint32_t queueFamilyIndexCount_ = 0,
                                           const uint32_t* pQueueFamilyIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::BufferCreateInfo( flags_, size_, usage_, sharingMode_, queueFamilyIndexCount_, pQueueFamilyIndices_ )
    {}

    BufferCreateInfo( VkBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BufferCreateInfo( rhs )
    {}

    BufferCreateInfo& operator=( VkBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BufferCreateInfo::operator=(rhs);
      return *this;
    }

    BufferCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BufferCreateInfo & setFlags( vk::BufferCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    BufferCreateInfo & setSize( vk::DeviceSize size_ ) VULKAN_HPP_NOEXCEPT
    {
      size = size_;
      return *this;
    }

    BufferCreateInfo & setUsage( vk::BufferUsageFlags usage_ ) VULKAN_HPP_NOEXCEPT
    {
      usage = usage_;
      return *this;
    }

    BufferCreateInfo & setSharingMode( vk::SharingMode sharingMode_ ) VULKAN_HPP_NOEXCEPT
    {
      sharingMode = sharingMode_;
      return *this;
    }

    BufferCreateInfo & setQueueFamilyIndexCount( uint32_t queueFamilyIndexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queueFamilyIndexCount = queueFamilyIndexCount_;
      return *this;
    }

    BufferCreateInfo & setPQueueFamilyIndices( const uint32_t* pQueueFamilyIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pQueueFamilyIndices = pQueueFamilyIndices_;
      return *this;
    }

    operator VkBufferCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferCreateInfo*>( this );
    }

    operator VkBufferCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferCreateInfo*>( this );
    }

    bool operator==( BufferCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( size == rhs.size )
          && ( usage == rhs.usage )
          && ( sharingMode == rhs.sharingMode )
          && ( queueFamilyIndexCount == rhs.queueFamilyIndexCount )
          && ( pQueueFamilyIndices == rhs.pQueueFamilyIndices );
    }

    bool operator!=( BufferCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BufferCreateInfo::sType;
  };
  static_assert( sizeof( BufferCreateInfo ) == sizeof( VkBufferCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BufferDeviceAddressCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR BufferDeviceAddressCreateInfoEXT( vk::DeviceAddress deviceAddress_ = 0 ) VULKAN_HPP_NOEXCEPT
        : deviceAddress( deviceAddress_ )
      {}

      BufferDeviceAddressCreateInfoEXT( VkBufferDeviceAddressCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferDeviceAddressCreateInfoEXT*>(this) = rhs;
      }

      BufferDeviceAddressCreateInfoEXT& operator=( VkBufferDeviceAddressCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferDeviceAddressCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBufferDeviceAddressCreateInfoEXT;
      const void* pNext = nullptr;
      vk::DeviceAddress deviceAddress;
    };
    static_assert( sizeof( BufferDeviceAddressCreateInfoEXT ) == sizeof( VkBufferDeviceAddressCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct BufferDeviceAddressCreateInfoEXT : public layout::BufferDeviceAddressCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR BufferDeviceAddressCreateInfoEXT( vk::DeviceAddress deviceAddress_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::BufferDeviceAddressCreateInfoEXT( deviceAddress_ )
    {}

    BufferDeviceAddressCreateInfoEXT( VkBufferDeviceAddressCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BufferDeviceAddressCreateInfoEXT( rhs )
    {}

    BufferDeviceAddressCreateInfoEXT& operator=( VkBufferDeviceAddressCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BufferDeviceAddressCreateInfoEXT::operator=(rhs);
      return *this;
    }

    BufferDeviceAddressCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BufferDeviceAddressCreateInfoEXT & setDeviceAddress( vk::DeviceAddress deviceAddress_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceAddress = deviceAddress_;
      return *this;
    }

    operator VkBufferDeviceAddressCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferDeviceAddressCreateInfoEXT*>( this );
    }

    operator VkBufferDeviceAddressCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferDeviceAddressCreateInfoEXT*>( this );
    }

    bool operator==( BufferDeviceAddressCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( deviceAddress == rhs.deviceAddress );
    }

    bool operator!=( BufferDeviceAddressCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BufferDeviceAddressCreateInfoEXT::sType;
  };
  static_assert( sizeof( BufferDeviceAddressCreateInfoEXT ) == sizeof( VkBufferDeviceAddressCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferDeviceAddressCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BufferDeviceAddressInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR BufferDeviceAddressInfoEXT( vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
        : buffer( buffer_ )
      {}

      BufferDeviceAddressInfoEXT( VkBufferDeviceAddressInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferDeviceAddressInfoEXT*>(this) = rhs;
      }

      BufferDeviceAddressInfoEXT& operator=( VkBufferDeviceAddressInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferDeviceAddressInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBufferDeviceAddressInfoEXT;
      const void* pNext = nullptr;
      vk::Buffer buffer;
    };
    static_assert( sizeof( BufferDeviceAddressInfoEXT ) == sizeof( VkBufferDeviceAddressInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct BufferDeviceAddressInfoEXT : public layout::BufferDeviceAddressInfoEXT
  {
    VULKAN_HPP_CONSTEXPR BufferDeviceAddressInfoEXT( vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
      : layout::BufferDeviceAddressInfoEXT( buffer_ )
    {}

    BufferDeviceAddressInfoEXT( VkBufferDeviceAddressInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BufferDeviceAddressInfoEXT( rhs )
    {}

    BufferDeviceAddressInfoEXT& operator=( VkBufferDeviceAddressInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BufferDeviceAddressInfoEXT::operator=(rhs);
      return *this;
    }

    BufferDeviceAddressInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BufferDeviceAddressInfoEXT & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    operator VkBufferDeviceAddressInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferDeviceAddressInfoEXT*>( this );
    }

    operator VkBufferDeviceAddressInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferDeviceAddressInfoEXT*>( this );
    }

    bool operator==( BufferDeviceAddressInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( buffer == rhs.buffer );
    }

    bool operator!=( BufferDeviceAddressInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BufferDeviceAddressInfoEXT::sType;
  };
  static_assert( sizeof( BufferDeviceAddressInfoEXT ) == sizeof( VkBufferDeviceAddressInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferDeviceAddressInfoEXT>::value, "struct wrapper is not a standard layout!" );

  struct ImageSubresourceLayers
  {
    VULKAN_HPP_CONSTEXPR ImageSubresourceLayers( vk::ImageAspectFlags aspectMask_ = vk::ImageAspectFlags(),
                                                 uint32_t mipLevel_ = 0,
                                                 uint32_t baseArrayLayer_ = 0,
                                                 uint32_t layerCount_ = 0 ) VULKAN_HPP_NOEXCEPT
      : aspectMask( aspectMask_ )
      , mipLevel( mipLevel_ )
      , baseArrayLayer( baseArrayLayer_ )
      , layerCount( layerCount_ )
    {}

    ImageSubresourceLayers( VkImageSubresourceLayers const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageSubresourceLayers*>(this) = rhs;
    }

    ImageSubresourceLayers& operator=( VkImageSubresourceLayers const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageSubresourceLayers*>(this) = rhs;
      return *this;
    }

    ImageSubresourceLayers & setAspectMask( vk::ImageAspectFlags aspectMask_ ) VULKAN_HPP_NOEXCEPT
    {
      aspectMask = aspectMask_;
      return *this;
    }

    ImageSubresourceLayers & setMipLevel( uint32_t mipLevel_ ) VULKAN_HPP_NOEXCEPT
    {
      mipLevel = mipLevel_;
      return *this;
    }

    ImageSubresourceLayers & setBaseArrayLayer( uint32_t baseArrayLayer_ ) VULKAN_HPP_NOEXCEPT
    {
      baseArrayLayer = baseArrayLayer_;
      return *this;
    }

    ImageSubresourceLayers & setLayerCount( uint32_t layerCount_ ) VULKAN_HPP_NOEXCEPT
    {
      layerCount = layerCount_;
      return *this;
    }

    operator VkImageSubresourceLayers const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageSubresourceLayers*>( this );
    }

    operator VkImageSubresourceLayers &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageSubresourceLayers*>( this );
    }

    bool operator==( ImageSubresourceLayers const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( aspectMask == rhs.aspectMask )
          && ( mipLevel == rhs.mipLevel )
          && ( baseArrayLayer == rhs.baseArrayLayer )
          && ( layerCount == rhs.layerCount );
    }

    bool operator!=( ImageSubresourceLayers const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageAspectFlags aspectMask;
    uint32_t mipLevel;
    uint32_t baseArrayLayer;
    uint32_t layerCount;
  };
  static_assert( sizeof( ImageSubresourceLayers ) == sizeof( VkImageSubresourceLayers ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageSubresourceLayers>::value, "struct wrapper is not a standard layout!" );

  struct BufferImageCopy
  {
    VULKAN_HPP_CONSTEXPR BufferImageCopy( vk::DeviceSize bufferOffset_ = 0,
                                          uint32_t bufferRowLength_ = 0,
                                          uint32_t bufferImageHeight_ = 0,
                                          vk::ImageSubresourceLayers imageSubresource_ = vk::ImageSubresourceLayers(),
                                          vk::Offset3D imageOffset_ = vk::Offset3D(),
                                          vk::Extent3D imageExtent_ = vk::Extent3D() ) VULKAN_HPP_NOEXCEPT
      : bufferOffset( bufferOffset_ )
      , bufferRowLength( bufferRowLength_ )
      , bufferImageHeight( bufferImageHeight_ )
      , imageSubresource( imageSubresource_ )
      , imageOffset( imageOffset_ )
      , imageExtent( imageExtent_ )
    {}

    BufferImageCopy( VkBufferImageCopy const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkBufferImageCopy*>(this) = rhs;
    }

    BufferImageCopy& operator=( VkBufferImageCopy const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkBufferImageCopy*>(this) = rhs;
      return *this;
    }

    BufferImageCopy & setBufferOffset( vk::DeviceSize bufferOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      bufferOffset = bufferOffset_;
      return *this;
    }

    BufferImageCopy & setBufferRowLength( uint32_t bufferRowLength_ ) VULKAN_HPP_NOEXCEPT
    {
      bufferRowLength = bufferRowLength_;
      return *this;
    }

    BufferImageCopy & setBufferImageHeight( uint32_t bufferImageHeight_ ) VULKAN_HPP_NOEXCEPT
    {
      bufferImageHeight = bufferImageHeight_;
      return *this;
    }

    BufferImageCopy & setImageSubresource( vk::ImageSubresourceLayers imageSubresource_ ) VULKAN_HPP_NOEXCEPT
    {
      imageSubresource = imageSubresource_;
      return *this;
    }

    BufferImageCopy & setImageOffset( vk::Offset3D imageOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      imageOffset = imageOffset_;
      return *this;
    }

    BufferImageCopy & setImageExtent( vk::Extent3D imageExtent_ ) VULKAN_HPP_NOEXCEPT
    {
      imageExtent = imageExtent_;
      return *this;
    }

    operator VkBufferImageCopy const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferImageCopy*>( this );
    }

    operator VkBufferImageCopy &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferImageCopy*>( this );
    }

    bool operator==( BufferImageCopy const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( bufferOffset == rhs.bufferOffset )
          && ( bufferRowLength == rhs.bufferRowLength )
          && ( bufferImageHeight == rhs.bufferImageHeight )
          && ( imageSubresource == rhs.imageSubresource )
          && ( imageOffset == rhs.imageOffset )
          && ( imageExtent == rhs.imageExtent );
    }

    bool operator!=( BufferImageCopy const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DeviceSize bufferOffset;
    uint32_t bufferRowLength;
    uint32_t bufferImageHeight;
    vk::ImageSubresourceLayers imageSubresource;
    vk::Offset3D imageOffset;
    vk::Extent3D imageExtent;
  };
  static_assert( sizeof( BufferImageCopy ) == sizeof( VkBufferImageCopy ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferImageCopy>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BufferMemoryBarrier
    {
    protected:
      VULKAN_HPP_CONSTEXPR BufferMemoryBarrier( vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                                vk::AccessFlags dstAccessMask_ = vk::AccessFlags(),
                                                uint32_t srcQueueFamilyIndex_ = 0,
                                                uint32_t dstQueueFamilyIndex_ = 0,
                                                vk::Buffer buffer_ = vk::Buffer(),
                                                vk::DeviceSize offset_ = 0,
                                                vk::DeviceSize size_ = 0 ) VULKAN_HPP_NOEXCEPT
        : srcAccessMask( srcAccessMask_ )
        , dstAccessMask( dstAccessMask_ )
        , srcQueueFamilyIndex( srcQueueFamilyIndex_ )
        , dstQueueFamilyIndex( dstQueueFamilyIndex_ )
        , buffer( buffer_ )
        , offset( offset_ )
        , size( size_ )
      {}

      BufferMemoryBarrier( VkBufferMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferMemoryBarrier*>(this) = rhs;
      }

      BufferMemoryBarrier& operator=( VkBufferMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferMemoryBarrier*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBufferMemoryBarrier;
      const void* pNext = nullptr;
      vk::AccessFlags srcAccessMask;
      vk::AccessFlags dstAccessMask;
      uint32_t srcQueueFamilyIndex;
      uint32_t dstQueueFamilyIndex;
      vk::Buffer buffer;
      vk::DeviceSize offset;
      vk::DeviceSize size;
    };
    static_assert( sizeof( BufferMemoryBarrier ) == sizeof( VkBufferMemoryBarrier ), "layout struct and wrapper have different size!" );
  }

  struct BufferMemoryBarrier : public layout::BufferMemoryBarrier
  {
    VULKAN_HPP_CONSTEXPR BufferMemoryBarrier( vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                              vk::AccessFlags dstAccessMask_ = vk::AccessFlags(),
                                              uint32_t srcQueueFamilyIndex_ = 0,
                                              uint32_t dstQueueFamilyIndex_ = 0,
                                              vk::Buffer buffer_ = vk::Buffer(),
                                              vk::DeviceSize offset_ = 0,
                                              vk::DeviceSize size_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::BufferMemoryBarrier( srcAccessMask_, dstAccessMask_, srcQueueFamilyIndex_, dstQueueFamilyIndex_, buffer_, offset_, size_ )
    {}

    BufferMemoryBarrier( VkBufferMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BufferMemoryBarrier( rhs )
    {}

    BufferMemoryBarrier& operator=( VkBufferMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BufferMemoryBarrier::operator=(rhs);
      return *this;
    }

    BufferMemoryBarrier & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BufferMemoryBarrier & setSrcAccessMask( vk::AccessFlags srcAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      srcAccessMask = srcAccessMask_;
      return *this;
    }

    BufferMemoryBarrier & setDstAccessMask( vk::AccessFlags dstAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      dstAccessMask = dstAccessMask_;
      return *this;
    }

    BufferMemoryBarrier & setSrcQueueFamilyIndex( uint32_t srcQueueFamilyIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      srcQueueFamilyIndex = srcQueueFamilyIndex_;
      return *this;
    }

    BufferMemoryBarrier & setDstQueueFamilyIndex( uint32_t dstQueueFamilyIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      dstQueueFamilyIndex = dstQueueFamilyIndex_;
      return *this;
    }

    BufferMemoryBarrier & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    BufferMemoryBarrier & setOffset( vk::DeviceSize offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    BufferMemoryBarrier & setSize( vk::DeviceSize size_ ) VULKAN_HPP_NOEXCEPT
    {
      size = size_;
      return *this;
    }

    operator VkBufferMemoryBarrier const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferMemoryBarrier*>( this );
    }

    operator VkBufferMemoryBarrier &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferMemoryBarrier*>( this );
    }

    bool operator==( BufferMemoryBarrier const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( srcAccessMask == rhs.srcAccessMask )
          && ( dstAccessMask == rhs.dstAccessMask )
          && ( srcQueueFamilyIndex == rhs.srcQueueFamilyIndex )
          && ( dstQueueFamilyIndex == rhs.dstQueueFamilyIndex )
          && ( buffer == rhs.buffer )
          && ( offset == rhs.offset )
          && ( size == rhs.size );
    }

    bool operator!=( BufferMemoryBarrier const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BufferMemoryBarrier::sType;
  };
  static_assert( sizeof( BufferMemoryBarrier ) == sizeof( VkBufferMemoryBarrier ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferMemoryBarrier>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BufferMemoryRequirementsInfo2
    {
    protected:
      VULKAN_HPP_CONSTEXPR BufferMemoryRequirementsInfo2( vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
        : buffer( buffer_ )
      {}

      BufferMemoryRequirementsInfo2( VkBufferMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferMemoryRequirementsInfo2*>(this) = rhs;
      }

      BufferMemoryRequirementsInfo2& operator=( VkBufferMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferMemoryRequirementsInfo2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBufferMemoryRequirementsInfo2;
      const void* pNext = nullptr;
      vk::Buffer buffer;
    };
    static_assert( sizeof( BufferMemoryRequirementsInfo2 ) == sizeof( VkBufferMemoryRequirementsInfo2 ), "layout struct and wrapper have different size!" );
  }

  struct BufferMemoryRequirementsInfo2 : public layout::BufferMemoryRequirementsInfo2
  {
    VULKAN_HPP_CONSTEXPR BufferMemoryRequirementsInfo2( vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
      : layout::BufferMemoryRequirementsInfo2( buffer_ )
    {}

    BufferMemoryRequirementsInfo2( VkBufferMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BufferMemoryRequirementsInfo2( rhs )
    {}

    BufferMemoryRequirementsInfo2& operator=( VkBufferMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BufferMemoryRequirementsInfo2::operator=(rhs);
      return *this;
    }

    BufferMemoryRequirementsInfo2 & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BufferMemoryRequirementsInfo2 & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    operator VkBufferMemoryRequirementsInfo2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>( this );
    }

    operator VkBufferMemoryRequirementsInfo2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferMemoryRequirementsInfo2*>( this );
    }

    bool operator==( BufferMemoryRequirementsInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( buffer == rhs.buffer );
    }

    bool operator!=( BufferMemoryRequirementsInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BufferMemoryRequirementsInfo2::sType;
  };
  static_assert( sizeof( BufferMemoryRequirementsInfo2 ) == sizeof( VkBufferMemoryRequirementsInfo2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferMemoryRequirementsInfo2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct BufferViewCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR BufferViewCreateInfo( vk::BufferViewCreateFlags flags_ = vk::BufferViewCreateFlags(),
                                                 vk::Buffer buffer_ = vk::Buffer(),
                                                 vk::Format format_ = vk::Format::eUndefined,
                                                 vk::DeviceSize offset_ = 0,
                                                 vk::DeviceSize range_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , buffer( buffer_ )
        , format( format_ )
        , offset( offset_ )
        , range( range_ )
      {}

      BufferViewCreateInfo( VkBufferViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferViewCreateInfo*>(this) = rhs;
      }

      BufferViewCreateInfo& operator=( VkBufferViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkBufferViewCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eBufferViewCreateInfo;
      const void* pNext = nullptr;
      vk::BufferViewCreateFlags flags;
      vk::Buffer buffer;
      vk::Format format;
      vk::DeviceSize offset;
      vk::DeviceSize range;
    };
    static_assert( sizeof( BufferViewCreateInfo ) == sizeof( VkBufferViewCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct BufferViewCreateInfo : public layout::BufferViewCreateInfo
  {
    VULKAN_HPP_CONSTEXPR BufferViewCreateInfo( vk::BufferViewCreateFlags flags_ = vk::BufferViewCreateFlags(),
                                               vk::Buffer buffer_ = vk::Buffer(),
                                               vk::Format format_ = vk::Format::eUndefined,
                                               vk::DeviceSize offset_ = 0,
                                               vk::DeviceSize range_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::BufferViewCreateInfo( flags_, buffer_, format_, offset_, range_ )
    {}

    BufferViewCreateInfo( VkBufferViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::BufferViewCreateInfo( rhs )
    {}

    BufferViewCreateInfo& operator=( VkBufferViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::BufferViewCreateInfo::operator=(rhs);
      return *this;
    }

    BufferViewCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    BufferViewCreateInfo & setFlags( vk::BufferViewCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    BufferViewCreateInfo & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    BufferViewCreateInfo & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    BufferViewCreateInfo & setOffset( vk::DeviceSize offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    BufferViewCreateInfo & setRange( vk::DeviceSize range_ ) VULKAN_HPP_NOEXCEPT
    {
      range = range_;
      return *this;
    }

    operator VkBufferViewCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkBufferViewCreateInfo*>( this );
    }

    operator VkBufferViewCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkBufferViewCreateInfo*>( this );
    }

    bool operator==( BufferViewCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( buffer == rhs.buffer )
          && ( format == rhs.format )
          && ( offset == rhs.offset )
          && ( range == rhs.range );
    }

    bool operator!=( BufferViewCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::BufferViewCreateInfo::sType;
  };
  static_assert( sizeof( BufferViewCreateInfo ) == sizeof( VkBufferViewCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<BufferViewCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CalibratedTimestampInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR CalibratedTimestampInfoEXT( vk::TimeDomainEXT timeDomain_ = vk::TimeDomainEXT::eDevice ) VULKAN_HPP_NOEXCEPT
        : timeDomain( timeDomain_ )
      {}

      CalibratedTimestampInfoEXT( VkCalibratedTimestampInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCalibratedTimestampInfoEXT*>(this) = rhs;
      }

      CalibratedTimestampInfoEXT& operator=( VkCalibratedTimestampInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCalibratedTimestampInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCalibratedTimestampInfoEXT;
      const void* pNext = nullptr;
      vk::TimeDomainEXT timeDomain;
    };
    static_assert( sizeof( CalibratedTimestampInfoEXT ) == sizeof( VkCalibratedTimestampInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct CalibratedTimestampInfoEXT : public layout::CalibratedTimestampInfoEXT
  {
    VULKAN_HPP_CONSTEXPR CalibratedTimestampInfoEXT( vk::TimeDomainEXT timeDomain_ = vk::TimeDomainEXT::eDevice ) VULKAN_HPP_NOEXCEPT
      : layout::CalibratedTimestampInfoEXT( timeDomain_ )
    {}

    CalibratedTimestampInfoEXT( VkCalibratedTimestampInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CalibratedTimestampInfoEXT( rhs )
    {}

    CalibratedTimestampInfoEXT& operator=( VkCalibratedTimestampInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CalibratedTimestampInfoEXT::operator=(rhs);
      return *this;
    }

    CalibratedTimestampInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CalibratedTimestampInfoEXT & setTimeDomain( vk::TimeDomainEXT timeDomain_ ) VULKAN_HPP_NOEXCEPT
    {
      timeDomain = timeDomain_;
      return *this;
    }

    operator VkCalibratedTimestampInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCalibratedTimestampInfoEXT*>( this );
    }

    operator VkCalibratedTimestampInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCalibratedTimestampInfoEXT*>( this );
    }

    bool operator==( CalibratedTimestampInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( timeDomain == rhs.timeDomain );
    }

    bool operator!=( CalibratedTimestampInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CalibratedTimestampInfoEXT::sType;
  };
  static_assert( sizeof( CalibratedTimestampInfoEXT ) == sizeof( VkCalibratedTimestampInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CalibratedTimestampInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CheckpointDataNV
    {
    protected:
      CheckpointDataNV() VULKAN_HPP_NOEXCEPT
      {}

      CheckpointDataNV( VkCheckpointDataNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCheckpointDataNV*>(this) = rhs;
      }

      CheckpointDataNV& operator=( VkCheckpointDataNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCheckpointDataNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCheckpointDataNV;
      void* pNext = nullptr;
      vk::PipelineStageFlagBits stage;
      void* pCheckpointMarker;
    };
    static_assert( sizeof( CheckpointDataNV ) == sizeof( VkCheckpointDataNV ), "layout struct and wrapper have different size!" );
  }

  struct CheckpointDataNV : public layout::CheckpointDataNV
  {
    CheckpointDataNV() VULKAN_HPP_NOEXCEPT
      : layout::CheckpointDataNV()
    {}

    CheckpointDataNV( VkCheckpointDataNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CheckpointDataNV( rhs )
    {}

    CheckpointDataNV& operator=( VkCheckpointDataNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CheckpointDataNV::operator=(rhs);
      return *this;
    }

    operator VkCheckpointDataNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCheckpointDataNV*>( this );
    }

    operator VkCheckpointDataNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCheckpointDataNV*>( this );
    }

    bool operator==( CheckpointDataNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( stage, rhs.stage )
          && ( pCheckpointMarker == rhs.pCheckpointMarker );
    }

    bool operator!=( CheckpointDataNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CheckpointDataNV::sType;
  };
  static_assert( sizeof( CheckpointDataNV ) == sizeof( VkCheckpointDataNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CheckpointDataNV>::value, "struct wrapper is not a standard layout!" );

  union ClearColorValue
  {
    ClearColorValue( const std::array<float,4>& float32_ = { { 0 } } )
    {
      memcpy( float32, float32_.data(), 4 * sizeof( float ) );
    }

    ClearColorValue( const std::array<int32_t,4>& int32_ )
    {
      memcpy( int32, int32_.data(), 4 * sizeof( int32_t ) );
    }

    ClearColorValue( const std::array<uint32_t,4>& uint32_ )
    {
      memcpy( uint32, uint32_.data(), 4 * sizeof( uint32_t ) );
    }

    ClearColorValue & setFloat32( std::array<float,4> float32_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( float32, float32_.data(), 4 * sizeof( float ) );
      return *this;
    }

    ClearColorValue & setInt32( std::array<int32_t,4> int32_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( int32, int32_.data(), 4 * sizeof( int32_t ) );
      return *this;
    }

    ClearColorValue & setUint32( std::array<uint32_t,4> uint32_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( uint32, uint32_.data(), 4 * sizeof( uint32_t ) );
      return *this;
    }
    operator VkClearColorValue const&() const
    {
      return *reinterpret_cast<const VkClearColorValue*>(this);
    }

    operator VkClearColorValue &()
    {
      return *reinterpret_cast<VkClearColorValue*>(this);
    }

    float float32[4];
    int32_t int32[4];
    uint32_t uint32[4];
  };

  struct ClearDepthStencilValue
  {
    VULKAN_HPP_CONSTEXPR ClearDepthStencilValue( float depth_ = 0,
                                                 uint32_t stencil_ = 0 ) VULKAN_HPP_NOEXCEPT
      : depth( depth_ )
      , stencil( stencil_ )
    {}

    ClearDepthStencilValue( VkClearDepthStencilValue const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkClearDepthStencilValue*>(this) = rhs;
    }

    ClearDepthStencilValue& operator=( VkClearDepthStencilValue const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkClearDepthStencilValue*>(this) = rhs;
      return *this;
    }

    ClearDepthStencilValue & setDepth( float depth_ ) VULKAN_HPP_NOEXCEPT
    {
      depth = depth_;
      return *this;
    }

    ClearDepthStencilValue & setStencil( uint32_t stencil_ ) VULKAN_HPP_NOEXCEPT
    {
      stencil = stencil_;
      return *this;
    }

    operator VkClearDepthStencilValue const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkClearDepthStencilValue*>( this );
    }

    operator VkClearDepthStencilValue &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkClearDepthStencilValue*>( this );
    }

    bool operator==( ClearDepthStencilValue const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( depth == rhs.depth )
          && ( stencil == rhs.stencil );
    }

    bool operator!=( ClearDepthStencilValue const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    float depth;
    uint32_t stencil;
  };
  static_assert( sizeof( ClearDepthStencilValue ) == sizeof( VkClearDepthStencilValue ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ClearDepthStencilValue>::value, "struct wrapper is not a standard layout!" );

  union ClearValue
  {
    ClearValue( vk::ClearColorValue color_ = vk::ClearColorValue() )
    {
      color = color_;
    }

    ClearValue( vk::ClearDepthStencilValue depthStencil_ )
    {
      depthStencil = depthStencil_;
    }

    ClearValue & setColor( vk::ClearColorValue color_ ) VULKAN_HPP_NOEXCEPT
    {
      color = color_;
      return *this;
    }

    ClearValue & setDepthStencil( vk::ClearDepthStencilValue depthStencil_ ) VULKAN_HPP_NOEXCEPT
    {
      depthStencil = depthStencil_;
      return *this;
    }
    operator VkClearValue const&() const
    {
      return *reinterpret_cast<const VkClearValue*>(this);
    }

    operator VkClearValue &()
    {
      return *reinterpret_cast<VkClearValue*>(this);
    }

#ifdef VULKAN_HPP_HAS_UNRESTRICTED_UNIONS
    vk::ClearColorValue color;
    vk::ClearDepthStencilValue depthStencil;
#else
    VkClearColorValue color;
    VkClearDepthStencilValue depthStencil;
#endif  /*VULKAN_HPP_HAS_UNRESTRICTED_UNIONS*/
  };

  struct ClearAttachment
  {
    ClearAttachment( vk::ImageAspectFlags aspectMask_ = vk::ImageAspectFlags(),
                     uint32_t colorAttachment_ = 0,
                     vk::ClearValue clearValue_ = vk::ClearValue() ) VULKAN_HPP_NOEXCEPT
      : aspectMask( aspectMask_ )
      , colorAttachment( colorAttachment_ )
      , clearValue( clearValue_ )
    {}

    ClearAttachment( VkClearAttachment const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkClearAttachment*>(this) = rhs;
    }

    ClearAttachment& operator=( VkClearAttachment const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkClearAttachment*>(this) = rhs;
      return *this;
    }

    ClearAttachment & setAspectMask( vk::ImageAspectFlags aspectMask_ ) VULKAN_HPP_NOEXCEPT
    {
      aspectMask = aspectMask_;
      return *this;
    }

    ClearAttachment & setColorAttachment( uint32_t colorAttachment_ ) VULKAN_HPP_NOEXCEPT
    {
      colorAttachment = colorAttachment_;
      return *this;
    }

    ClearAttachment & setClearValue( vk::ClearValue clearValue_ ) VULKAN_HPP_NOEXCEPT
    {
      clearValue = clearValue_;
      return *this;
    }

    operator VkClearAttachment const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkClearAttachment*>( this );
    }

    operator VkClearAttachment &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkClearAttachment*>( this );
    }

  public:
    vk::ImageAspectFlags aspectMask;
    uint32_t colorAttachment;
    vk::ClearValue clearValue;
  };
  static_assert( sizeof( ClearAttachment ) == sizeof( VkClearAttachment ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ClearAttachment>::value, "struct wrapper is not a standard layout!" );

  struct ClearRect
  {
    VULKAN_HPP_CONSTEXPR ClearRect( vk::Rect2D rect_ = vk::Rect2D(),
                                    uint32_t baseArrayLayer_ = 0,
                                    uint32_t layerCount_ = 0 ) VULKAN_HPP_NOEXCEPT
      : rect( rect_ )
      , baseArrayLayer( baseArrayLayer_ )
      , layerCount( layerCount_ )
    {}

    ClearRect( VkClearRect const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkClearRect*>(this) = rhs;
    }

    ClearRect& operator=( VkClearRect const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkClearRect*>(this) = rhs;
      return *this;
    }

    ClearRect & setRect( vk::Rect2D rect_ ) VULKAN_HPP_NOEXCEPT
    {
      rect = rect_;
      return *this;
    }

    ClearRect & setBaseArrayLayer( uint32_t baseArrayLayer_ ) VULKAN_HPP_NOEXCEPT
    {
      baseArrayLayer = baseArrayLayer_;
      return *this;
    }

    ClearRect & setLayerCount( uint32_t layerCount_ ) VULKAN_HPP_NOEXCEPT
    {
      layerCount = layerCount_;
      return *this;
    }

    operator VkClearRect const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkClearRect*>( this );
    }

    operator VkClearRect &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkClearRect*>( this );
    }

    bool operator==( ClearRect const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( rect == rhs.rect )
          && ( baseArrayLayer == rhs.baseArrayLayer )
          && ( layerCount == rhs.layerCount );
    }

    bool operator!=( ClearRect const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Rect2D rect;
    uint32_t baseArrayLayer;
    uint32_t layerCount;
  };
  static_assert( sizeof( ClearRect ) == sizeof( VkClearRect ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ClearRect>::value, "struct wrapper is not a standard layout!" );

  struct IndirectCommandsTokenNVX
  {
    VULKAN_HPP_CONSTEXPR IndirectCommandsTokenNVX( vk::IndirectCommandsTokenTypeNVX tokenType_ = vk::IndirectCommandsTokenTypeNVX::ePipeline,
                                                   vk::Buffer buffer_ = vk::Buffer(),
                                                   vk::DeviceSize offset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : tokenType( tokenType_ )
      , buffer( buffer_ )
      , offset( offset_ )
    {}

    IndirectCommandsTokenNVX( VkIndirectCommandsTokenNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkIndirectCommandsTokenNVX*>(this) = rhs;
    }

    IndirectCommandsTokenNVX& operator=( VkIndirectCommandsTokenNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkIndirectCommandsTokenNVX*>(this) = rhs;
      return *this;
    }

    IndirectCommandsTokenNVX & setTokenType( vk::IndirectCommandsTokenTypeNVX tokenType_ ) VULKAN_HPP_NOEXCEPT
    {
      tokenType = tokenType_;
      return *this;
    }

    IndirectCommandsTokenNVX & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    IndirectCommandsTokenNVX & setOffset( vk::DeviceSize offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    operator VkIndirectCommandsTokenNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkIndirectCommandsTokenNVX*>( this );
    }

    operator VkIndirectCommandsTokenNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkIndirectCommandsTokenNVX*>( this );
    }

    bool operator==( IndirectCommandsTokenNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( tokenType == rhs.tokenType )
          && ( buffer == rhs.buffer )
          && ( offset == rhs.offset );
    }

    bool operator!=( IndirectCommandsTokenNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::IndirectCommandsTokenTypeNVX tokenType;
    vk::Buffer buffer;
    vk::DeviceSize offset;
  };
  static_assert( sizeof( IndirectCommandsTokenNVX ) == sizeof( VkIndirectCommandsTokenNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<IndirectCommandsTokenNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CmdProcessCommandsInfoNVX
    {
    protected:
      VULKAN_HPP_CONSTEXPR CmdProcessCommandsInfoNVX( vk::ObjectTableNVX objectTable_ = vk::ObjectTableNVX(),
                                                      vk::IndirectCommandsLayoutNVX indirectCommandsLayout_ = vk::IndirectCommandsLayoutNVX(),
                                                      uint32_t indirectCommandsTokenCount_ = 0,
                                                      const vk::IndirectCommandsTokenNVX* pIndirectCommandsTokens_ = nullptr,
                                                      uint32_t maxSequencesCount_ = 0,
                                                      vk::CommandBuffer targetCommandBuffer_ = vk::CommandBuffer(),
                                                      vk::Buffer sequencesCountBuffer_ = vk::Buffer(),
                                                      vk::DeviceSize sequencesCountOffset_ = 0,
                                                      vk::Buffer sequencesIndexBuffer_ = vk::Buffer(),
                                                      vk::DeviceSize sequencesIndexOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
        : objectTable( objectTable_ )
        , indirectCommandsLayout( indirectCommandsLayout_ )
        , indirectCommandsTokenCount( indirectCommandsTokenCount_ )
        , pIndirectCommandsTokens( pIndirectCommandsTokens_ )
        , maxSequencesCount( maxSequencesCount_ )
        , targetCommandBuffer( targetCommandBuffer_ )
        , sequencesCountBuffer( sequencesCountBuffer_ )
        , sequencesCountOffset( sequencesCountOffset_ )
        , sequencesIndexBuffer( sequencesIndexBuffer_ )
        , sequencesIndexOffset( sequencesIndexOffset_ )
      {}

      CmdProcessCommandsInfoNVX( VkCmdProcessCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCmdProcessCommandsInfoNVX*>(this) = rhs;
      }

      CmdProcessCommandsInfoNVX& operator=( VkCmdProcessCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCmdProcessCommandsInfoNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCmdProcessCommandsInfoNVX;
      const void* pNext = nullptr;
      vk::ObjectTableNVX objectTable;
      vk::IndirectCommandsLayoutNVX indirectCommandsLayout;
      uint32_t indirectCommandsTokenCount;
      const vk::IndirectCommandsTokenNVX* pIndirectCommandsTokens;
      uint32_t maxSequencesCount;
      vk::CommandBuffer targetCommandBuffer;
      vk::Buffer sequencesCountBuffer;
      vk::DeviceSize sequencesCountOffset;
      vk::Buffer sequencesIndexBuffer;
      vk::DeviceSize sequencesIndexOffset;
    };
    static_assert( sizeof( CmdProcessCommandsInfoNVX ) == sizeof( VkCmdProcessCommandsInfoNVX ), "layout struct and wrapper have different size!" );
  }

  struct CmdProcessCommandsInfoNVX : public layout::CmdProcessCommandsInfoNVX
  {
    VULKAN_HPP_CONSTEXPR CmdProcessCommandsInfoNVX( vk::ObjectTableNVX objectTable_ = vk::ObjectTableNVX(),
                                                    vk::IndirectCommandsLayoutNVX indirectCommandsLayout_ = vk::IndirectCommandsLayoutNVX(),
                                                    uint32_t indirectCommandsTokenCount_ = 0,
                                                    const vk::IndirectCommandsTokenNVX* pIndirectCommandsTokens_ = nullptr,
                                                    uint32_t maxSequencesCount_ = 0,
                                                    vk::CommandBuffer targetCommandBuffer_ = vk::CommandBuffer(),
                                                    vk::Buffer sequencesCountBuffer_ = vk::Buffer(),
                                                    vk::DeviceSize sequencesCountOffset_ = 0,
                                                    vk::Buffer sequencesIndexBuffer_ = vk::Buffer(),
                                                    vk::DeviceSize sequencesIndexOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::CmdProcessCommandsInfoNVX( objectTable_, indirectCommandsLayout_, indirectCommandsTokenCount_, pIndirectCommandsTokens_, maxSequencesCount_, targetCommandBuffer_, sequencesCountBuffer_, sequencesCountOffset_, sequencesIndexBuffer_, sequencesIndexOffset_ )
    {}

    CmdProcessCommandsInfoNVX( VkCmdProcessCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CmdProcessCommandsInfoNVX( rhs )
    {}

    CmdProcessCommandsInfoNVX& operator=( VkCmdProcessCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CmdProcessCommandsInfoNVX::operator=(rhs);
      return *this;
    }

    CmdProcessCommandsInfoNVX & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setObjectTable( vk::ObjectTableNVX objectTable_ ) VULKAN_HPP_NOEXCEPT
    {
      objectTable = objectTable_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setIndirectCommandsLayout( vk::IndirectCommandsLayoutNVX indirectCommandsLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      indirectCommandsLayout = indirectCommandsLayout_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setIndirectCommandsTokenCount( uint32_t indirectCommandsTokenCount_ ) VULKAN_HPP_NOEXCEPT
    {
      indirectCommandsTokenCount = indirectCommandsTokenCount_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setPIndirectCommandsTokens( const vk::IndirectCommandsTokenNVX* pIndirectCommandsTokens_ ) VULKAN_HPP_NOEXCEPT
    {
      pIndirectCommandsTokens = pIndirectCommandsTokens_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setMaxSequencesCount( uint32_t maxSequencesCount_ ) VULKAN_HPP_NOEXCEPT
    {
      maxSequencesCount = maxSequencesCount_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setTargetCommandBuffer( vk::CommandBuffer targetCommandBuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      targetCommandBuffer = targetCommandBuffer_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setSequencesCountBuffer( vk::Buffer sequencesCountBuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      sequencesCountBuffer = sequencesCountBuffer_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setSequencesCountOffset( vk::DeviceSize sequencesCountOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      sequencesCountOffset = sequencesCountOffset_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setSequencesIndexBuffer( vk::Buffer sequencesIndexBuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      sequencesIndexBuffer = sequencesIndexBuffer_;
      return *this;
    }

    CmdProcessCommandsInfoNVX & setSequencesIndexOffset( vk::DeviceSize sequencesIndexOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      sequencesIndexOffset = sequencesIndexOffset_;
      return *this;
    }

    operator VkCmdProcessCommandsInfoNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCmdProcessCommandsInfoNVX*>( this );
    }

    operator VkCmdProcessCommandsInfoNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCmdProcessCommandsInfoNVX*>( this );
    }

    bool operator==( CmdProcessCommandsInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( objectTable == rhs.objectTable )
          && ( indirectCommandsLayout == rhs.indirectCommandsLayout )
          && ( indirectCommandsTokenCount == rhs.indirectCommandsTokenCount )
          && ( pIndirectCommandsTokens == rhs.pIndirectCommandsTokens )
          && ( maxSequencesCount == rhs.maxSequencesCount )
          && ( targetCommandBuffer == rhs.targetCommandBuffer )
          && ( sequencesCountBuffer == rhs.sequencesCountBuffer )
          && ( sequencesCountOffset == rhs.sequencesCountOffset )
          && ( sequencesIndexBuffer == rhs.sequencesIndexBuffer )
          && ( sequencesIndexOffset == rhs.sequencesIndexOffset );
    }

    bool operator!=( CmdProcessCommandsInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CmdProcessCommandsInfoNVX::sType;
  };
  static_assert( sizeof( CmdProcessCommandsInfoNVX ) == sizeof( VkCmdProcessCommandsInfoNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CmdProcessCommandsInfoNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CmdReserveSpaceForCommandsInfoNVX
    {
    protected:
      VULKAN_HPP_CONSTEXPR CmdReserveSpaceForCommandsInfoNVX( vk::ObjectTableNVX objectTable_ = vk::ObjectTableNVX(),
                                                              vk::IndirectCommandsLayoutNVX indirectCommandsLayout_ = vk::IndirectCommandsLayoutNVX(),
                                                              uint32_t maxSequencesCount_ = 0 ) VULKAN_HPP_NOEXCEPT
        : objectTable( objectTable_ )
        , indirectCommandsLayout( indirectCommandsLayout_ )
        , maxSequencesCount( maxSequencesCount_ )
      {}

      CmdReserveSpaceForCommandsInfoNVX( VkCmdReserveSpaceForCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCmdReserveSpaceForCommandsInfoNVX*>(this) = rhs;
      }

      CmdReserveSpaceForCommandsInfoNVX& operator=( VkCmdReserveSpaceForCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCmdReserveSpaceForCommandsInfoNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCmdReserveSpaceForCommandsInfoNVX;
      const void* pNext = nullptr;
      vk::ObjectTableNVX objectTable;
      vk::IndirectCommandsLayoutNVX indirectCommandsLayout;
      uint32_t maxSequencesCount;
    };
    static_assert( sizeof( CmdReserveSpaceForCommandsInfoNVX ) == sizeof( VkCmdReserveSpaceForCommandsInfoNVX ), "layout struct and wrapper have different size!" );
  }

  struct CmdReserveSpaceForCommandsInfoNVX : public layout::CmdReserveSpaceForCommandsInfoNVX
  {
    VULKAN_HPP_CONSTEXPR CmdReserveSpaceForCommandsInfoNVX( vk::ObjectTableNVX objectTable_ = vk::ObjectTableNVX(),
                                                            vk::IndirectCommandsLayoutNVX indirectCommandsLayout_ = vk::IndirectCommandsLayoutNVX(),
                                                            uint32_t maxSequencesCount_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::CmdReserveSpaceForCommandsInfoNVX( objectTable_, indirectCommandsLayout_, maxSequencesCount_ )
    {}

    CmdReserveSpaceForCommandsInfoNVX( VkCmdReserveSpaceForCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CmdReserveSpaceForCommandsInfoNVX( rhs )
    {}

    CmdReserveSpaceForCommandsInfoNVX& operator=( VkCmdReserveSpaceForCommandsInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CmdReserveSpaceForCommandsInfoNVX::operator=(rhs);
      return *this;
    }

    CmdReserveSpaceForCommandsInfoNVX & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CmdReserveSpaceForCommandsInfoNVX & setObjectTable( vk::ObjectTableNVX objectTable_ ) VULKAN_HPP_NOEXCEPT
    {
      objectTable = objectTable_;
      return *this;
    }

    CmdReserveSpaceForCommandsInfoNVX & setIndirectCommandsLayout( vk::IndirectCommandsLayoutNVX indirectCommandsLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      indirectCommandsLayout = indirectCommandsLayout_;
      return *this;
    }

    CmdReserveSpaceForCommandsInfoNVX & setMaxSequencesCount( uint32_t maxSequencesCount_ ) VULKAN_HPP_NOEXCEPT
    {
      maxSequencesCount = maxSequencesCount_;
      return *this;
    }

    operator VkCmdReserveSpaceForCommandsInfoNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCmdReserveSpaceForCommandsInfoNVX*>( this );
    }

    operator VkCmdReserveSpaceForCommandsInfoNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCmdReserveSpaceForCommandsInfoNVX*>( this );
    }

    bool operator==( CmdReserveSpaceForCommandsInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( objectTable == rhs.objectTable )
          && ( indirectCommandsLayout == rhs.indirectCommandsLayout )
          && ( maxSequencesCount == rhs.maxSequencesCount );
    }

    bool operator!=( CmdReserveSpaceForCommandsInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CmdReserveSpaceForCommandsInfoNVX::sType;
  };
  static_assert( sizeof( CmdReserveSpaceForCommandsInfoNVX ) == sizeof( VkCmdReserveSpaceForCommandsInfoNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CmdReserveSpaceForCommandsInfoNVX>::value, "struct wrapper is not a standard layout!" );

  struct CoarseSampleLocationNV
  {
    VULKAN_HPP_CONSTEXPR CoarseSampleLocationNV( uint32_t pixelX_ = 0,
                                                 uint32_t pixelY_ = 0,
                                                 uint32_t sample_ = 0 ) VULKAN_HPP_NOEXCEPT
      : pixelX( pixelX_ )
      , pixelY( pixelY_ )
      , sample( sample_ )
    {}

    CoarseSampleLocationNV( VkCoarseSampleLocationNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkCoarseSampleLocationNV*>(this) = rhs;
    }

    CoarseSampleLocationNV& operator=( VkCoarseSampleLocationNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkCoarseSampleLocationNV*>(this) = rhs;
      return *this;
    }

    CoarseSampleLocationNV & setPixelX( uint32_t pixelX_ ) VULKAN_HPP_NOEXCEPT
    {
      pixelX = pixelX_;
      return *this;
    }

    CoarseSampleLocationNV & setPixelY( uint32_t pixelY_ ) VULKAN_HPP_NOEXCEPT
    {
      pixelY = pixelY_;
      return *this;
    }

    CoarseSampleLocationNV & setSample( uint32_t sample_ ) VULKAN_HPP_NOEXCEPT
    {
      sample = sample_;
      return *this;
    }

    operator VkCoarseSampleLocationNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCoarseSampleLocationNV*>( this );
    }

    operator VkCoarseSampleLocationNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCoarseSampleLocationNV*>( this );
    }

    bool operator==( CoarseSampleLocationNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( pixelX == rhs.pixelX )
          && ( pixelY == rhs.pixelY )
          && ( sample == rhs.sample );
    }

    bool operator!=( CoarseSampleLocationNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t pixelX;
    uint32_t pixelY;
    uint32_t sample;
  };
  static_assert( sizeof( CoarseSampleLocationNV ) == sizeof( VkCoarseSampleLocationNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CoarseSampleLocationNV>::value, "struct wrapper is not a standard layout!" );

  struct CoarseSampleOrderCustomNV
  {
    VULKAN_HPP_CONSTEXPR CoarseSampleOrderCustomNV( vk::ShadingRatePaletteEntryNV shadingRate_ = vk::ShadingRatePaletteEntryNV::eNoInvocations,
                                                    uint32_t sampleCount_ = 0,
                                                    uint32_t sampleLocationCount_ = 0,
                                                    const vk::CoarseSampleLocationNV* pSampleLocations_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : shadingRate( shadingRate_ )
      , sampleCount( sampleCount_ )
      , sampleLocationCount( sampleLocationCount_ )
      , pSampleLocations( pSampleLocations_ )
    {}

    CoarseSampleOrderCustomNV( VkCoarseSampleOrderCustomNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkCoarseSampleOrderCustomNV*>(this) = rhs;
    }

    CoarseSampleOrderCustomNV& operator=( VkCoarseSampleOrderCustomNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkCoarseSampleOrderCustomNV*>(this) = rhs;
      return *this;
    }

    CoarseSampleOrderCustomNV & setShadingRate( vk::ShadingRatePaletteEntryNV shadingRate_ ) VULKAN_HPP_NOEXCEPT
    {
      shadingRate = shadingRate_;
      return *this;
    }

    CoarseSampleOrderCustomNV & setSampleCount( uint32_t sampleCount_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleCount = sampleCount_;
      return *this;
    }

    CoarseSampleOrderCustomNV & setSampleLocationCount( uint32_t sampleLocationCount_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationCount = sampleLocationCount_;
      return *this;
    }

    CoarseSampleOrderCustomNV & setPSampleLocations( const vk::CoarseSampleLocationNV* pSampleLocations_ ) VULKAN_HPP_NOEXCEPT
    {
      pSampleLocations = pSampleLocations_;
      return *this;
    }

    operator VkCoarseSampleOrderCustomNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCoarseSampleOrderCustomNV*>( this );
    }

    operator VkCoarseSampleOrderCustomNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCoarseSampleOrderCustomNV*>( this );
    }

    bool operator==( CoarseSampleOrderCustomNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( shadingRate == rhs.shadingRate )
          && ( sampleCount == rhs.sampleCount )
          && ( sampleLocationCount == rhs.sampleLocationCount )
          && ( pSampleLocations == rhs.pSampleLocations );
    }

    bool operator!=( CoarseSampleOrderCustomNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ShadingRatePaletteEntryNV shadingRate;
    uint32_t sampleCount;
    uint32_t sampleLocationCount;
    const vk::CoarseSampleLocationNV* pSampleLocations;
  };
  static_assert( sizeof( CoarseSampleOrderCustomNV ) == sizeof( VkCoarseSampleOrderCustomNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CoarseSampleOrderCustomNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CommandBufferAllocateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR CommandBufferAllocateInfo( vk::CommandPool commandPool_ = vk::CommandPool(),
                                                      vk::CommandBufferLevel level_ = vk::CommandBufferLevel::ePrimary,
                                                      uint32_t commandBufferCount_ = 0 ) VULKAN_HPP_NOEXCEPT
        : commandPool( commandPool_ )
        , level( level_ )
        , commandBufferCount( commandBufferCount_ )
      {}

      CommandBufferAllocateInfo( VkCommandBufferAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferAllocateInfo*>(this) = rhs;
      }

      CommandBufferAllocateInfo& operator=( VkCommandBufferAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferAllocateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCommandBufferAllocateInfo;
      const void* pNext = nullptr;
      vk::CommandPool commandPool;
      vk::CommandBufferLevel level;
      uint32_t commandBufferCount;
    };
    static_assert( sizeof( CommandBufferAllocateInfo ) == sizeof( VkCommandBufferAllocateInfo ), "layout struct and wrapper have different size!" );
  }

  struct CommandBufferAllocateInfo : public layout::CommandBufferAllocateInfo
  {
    VULKAN_HPP_CONSTEXPR CommandBufferAllocateInfo( vk::CommandPool commandPool_ = vk::CommandPool(),
                                                    vk::CommandBufferLevel level_ = vk::CommandBufferLevel::ePrimary,
                                                    uint32_t commandBufferCount_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferAllocateInfo( commandPool_, level_, commandBufferCount_ )
    {}

    CommandBufferAllocateInfo( VkCommandBufferAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferAllocateInfo( rhs )
    {}

    CommandBufferAllocateInfo& operator=( VkCommandBufferAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CommandBufferAllocateInfo::operator=(rhs);
      return *this;
    }

    CommandBufferAllocateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CommandBufferAllocateInfo & setCommandPool( vk::CommandPool commandPool_ ) VULKAN_HPP_NOEXCEPT
    {
      commandPool = commandPool_;
      return *this;
    }

    CommandBufferAllocateInfo & setLevel( vk::CommandBufferLevel level_ ) VULKAN_HPP_NOEXCEPT
    {
      level = level_;
      return *this;
    }

    CommandBufferAllocateInfo & setCommandBufferCount( uint32_t commandBufferCount_ ) VULKAN_HPP_NOEXCEPT
    {
      commandBufferCount = commandBufferCount_;
      return *this;
    }

    operator VkCommandBufferAllocateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCommandBufferAllocateInfo*>( this );
    }

    operator VkCommandBufferAllocateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCommandBufferAllocateInfo*>( this );
    }

    bool operator==( CommandBufferAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( commandPool == rhs.commandPool )
          && ( level == rhs.level )
          && ( commandBufferCount == rhs.commandBufferCount );
    }

    bool operator!=( CommandBufferAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CommandBufferAllocateInfo::sType;
  };
  static_assert( sizeof( CommandBufferAllocateInfo ) == sizeof( VkCommandBufferAllocateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CommandBufferAllocateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CommandBufferInheritanceInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR CommandBufferInheritanceInfo( vk::RenderPass renderPass_ = vk::RenderPass(),
                                                         uint32_t subpass_ = 0,
                                                         vk::Framebuffer framebuffer_ = vk::Framebuffer(),
                                                         vk::Bool32 occlusionQueryEnable_ = 0,
                                                         vk::QueryControlFlags queryFlags_ = vk::QueryControlFlags(),
                                                         vk::QueryPipelineStatisticFlags pipelineStatistics_ = vk::QueryPipelineStatisticFlags() ) VULKAN_HPP_NOEXCEPT
        : renderPass( renderPass_ )
        , subpass( subpass_ )
        , framebuffer( framebuffer_ )
        , occlusionQueryEnable( occlusionQueryEnable_ )
        , queryFlags( queryFlags_ )
        , pipelineStatistics( pipelineStatistics_ )
      {}

      CommandBufferInheritanceInfo( VkCommandBufferInheritanceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferInheritanceInfo*>(this) = rhs;
      }

      CommandBufferInheritanceInfo& operator=( VkCommandBufferInheritanceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferInheritanceInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCommandBufferInheritanceInfo;
      const void* pNext = nullptr;
      vk::RenderPass renderPass;
      uint32_t subpass;
      vk::Framebuffer framebuffer;
      vk::Bool32 occlusionQueryEnable;
      vk::QueryControlFlags queryFlags;
      vk::QueryPipelineStatisticFlags pipelineStatistics;
    };
    static_assert( sizeof( CommandBufferInheritanceInfo ) == sizeof( VkCommandBufferInheritanceInfo ), "layout struct and wrapper have different size!" );
  }

  struct CommandBufferInheritanceInfo : public layout::CommandBufferInheritanceInfo
  {
    VULKAN_HPP_CONSTEXPR CommandBufferInheritanceInfo( vk::RenderPass renderPass_ = vk::RenderPass(),
                                                       uint32_t subpass_ = 0,
                                                       vk::Framebuffer framebuffer_ = vk::Framebuffer(),
                                                       vk::Bool32 occlusionQueryEnable_ = 0,
                                                       vk::QueryControlFlags queryFlags_ = vk::QueryControlFlags(),
                                                       vk::QueryPipelineStatisticFlags pipelineStatistics_ = vk::QueryPipelineStatisticFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferInheritanceInfo( renderPass_, subpass_, framebuffer_, occlusionQueryEnable_, queryFlags_, pipelineStatistics_ )
    {}

    CommandBufferInheritanceInfo( VkCommandBufferInheritanceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferInheritanceInfo( rhs )
    {}

    CommandBufferInheritanceInfo& operator=( VkCommandBufferInheritanceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CommandBufferInheritanceInfo::operator=(rhs);
      return *this;
    }

    CommandBufferInheritanceInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CommandBufferInheritanceInfo & setRenderPass( vk::RenderPass renderPass_ ) VULKAN_HPP_NOEXCEPT
    {
      renderPass = renderPass_;
      return *this;
    }

    CommandBufferInheritanceInfo & setSubpass( uint32_t subpass_ ) VULKAN_HPP_NOEXCEPT
    {
      subpass = subpass_;
      return *this;
    }

    CommandBufferInheritanceInfo & setFramebuffer( vk::Framebuffer framebuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      framebuffer = framebuffer_;
      return *this;
    }

    CommandBufferInheritanceInfo & setOcclusionQueryEnable( vk::Bool32 occlusionQueryEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      occlusionQueryEnable = occlusionQueryEnable_;
      return *this;
    }

    CommandBufferInheritanceInfo & setQueryFlags( vk::QueryControlFlags queryFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      queryFlags = queryFlags_;
      return *this;
    }

    CommandBufferInheritanceInfo & setPipelineStatistics( vk::QueryPipelineStatisticFlags pipelineStatistics_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineStatistics = pipelineStatistics_;
      return *this;
    }

    operator VkCommandBufferInheritanceInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCommandBufferInheritanceInfo*>( this );
    }

    operator VkCommandBufferInheritanceInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCommandBufferInheritanceInfo*>( this );
    }

    bool operator==( CommandBufferInheritanceInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( renderPass == rhs.renderPass )
          && ( subpass == rhs.subpass )
          && ( framebuffer == rhs.framebuffer )
          && ( occlusionQueryEnable == rhs.occlusionQueryEnable )
          && ( queryFlags == rhs.queryFlags )
          && ( pipelineStatistics == rhs.pipelineStatistics );
    }

    bool operator!=( CommandBufferInheritanceInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CommandBufferInheritanceInfo::sType;
  };
  static_assert( sizeof( CommandBufferInheritanceInfo ) == sizeof( VkCommandBufferInheritanceInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CommandBufferInheritanceInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CommandBufferBeginInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR CommandBufferBeginInfo( vk::CommandBufferUsageFlags flags_ = vk::CommandBufferUsageFlags(),
                                                   const vk::CommandBufferInheritanceInfo* pInheritanceInfo_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pInheritanceInfo( pInheritanceInfo_ )
      {}

      CommandBufferBeginInfo( VkCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferBeginInfo*>(this) = rhs;
      }

      CommandBufferBeginInfo& operator=( VkCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferBeginInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCommandBufferBeginInfo;
      const void* pNext = nullptr;
      vk::CommandBufferUsageFlags flags;
      const vk::CommandBufferInheritanceInfo* pInheritanceInfo;
    };
    static_assert( sizeof( CommandBufferBeginInfo ) == sizeof( VkCommandBufferBeginInfo ), "layout struct and wrapper have different size!" );
  }

  struct CommandBufferBeginInfo : public layout::CommandBufferBeginInfo
  {
    VULKAN_HPP_CONSTEXPR CommandBufferBeginInfo( vk::CommandBufferUsageFlags flags_ = vk::CommandBufferUsageFlags(),
                                                 const vk::CommandBufferInheritanceInfo* pInheritanceInfo_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferBeginInfo( flags_, pInheritanceInfo_ )
    {}

    CommandBufferBeginInfo( VkCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferBeginInfo( rhs )
    {}

    CommandBufferBeginInfo& operator=( VkCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CommandBufferBeginInfo::operator=(rhs);
      return *this;
    }

    CommandBufferBeginInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CommandBufferBeginInfo & setFlags( vk::CommandBufferUsageFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    CommandBufferBeginInfo & setPInheritanceInfo( const vk::CommandBufferInheritanceInfo* pInheritanceInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      pInheritanceInfo = pInheritanceInfo_;
      return *this;
    }

    operator VkCommandBufferBeginInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCommandBufferBeginInfo*>( this );
    }

    operator VkCommandBufferBeginInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCommandBufferBeginInfo*>( this );
    }

    bool operator==( CommandBufferBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pInheritanceInfo == rhs.pInheritanceInfo );
    }

    bool operator!=( CommandBufferBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CommandBufferBeginInfo::sType;
  };
  static_assert( sizeof( CommandBufferBeginInfo ) == sizeof( VkCommandBufferBeginInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CommandBufferBeginInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CommandBufferInheritanceConditionalRenderingInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR CommandBufferInheritanceConditionalRenderingInfoEXT( vk::Bool32 conditionalRenderingEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
        : conditionalRenderingEnable( conditionalRenderingEnable_ )
      {}

      CommandBufferInheritanceConditionalRenderingInfoEXT( VkCommandBufferInheritanceConditionalRenderingInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferInheritanceConditionalRenderingInfoEXT*>(this) = rhs;
      }

      CommandBufferInheritanceConditionalRenderingInfoEXT& operator=( VkCommandBufferInheritanceConditionalRenderingInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandBufferInheritanceConditionalRenderingInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCommandBufferInheritanceConditionalRenderingInfoEXT;
      const void* pNext = nullptr;
      vk::Bool32 conditionalRenderingEnable;
    };
    static_assert( sizeof( CommandBufferInheritanceConditionalRenderingInfoEXT ) == sizeof( VkCommandBufferInheritanceConditionalRenderingInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct CommandBufferInheritanceConditionalRenderingInfoEXT : public layout::CommandBufferInheritanceConditionalRenderingInfoEXT
  {
    VULKAN_HPP_CONSTEXPR CommandBufferInheritanceConditionalRenderingInfoEXT( vk::Bool32 conditionalRenderingEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferInheritanceConditionalRenderingInfoEXT( conditionalRenderingEnable_ )
    {}

    CommandBufferInheritanceConditionalRenderingInfoEXT( VkCommandBufferInheritanceConditionalRenderingInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CommandBufferInheritanceConditionalRenderingInfoEXT( rhs )
    {}

    CommandBufferInheritanceConditionalRenderingInfoEXT& operator=( VkCommandBufferInheritanceConditionalRenderingInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CommandBufferInheritanceConditionalRenderingInfoEXT::operator=(rhs);
      return *this;
    }

    CommandBufferInheritanceConditionalRenderingInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CommandBufferInheritanceConditionalRenderingInfoEXT & setConditionalRenderingEnable( vk::Bool32 conditionalRenderingEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      conditionalRenderingEnable = conditionalRenderingEnable_;
      return *this;
    }

    operator VkCommandBufferInheritanceConditionalRenderingInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCommandBufferInheritanceConditionalRenderingInfoEXT*>( this );
    }

    operator VkCommandBufferInheritanceConditionalRenderingInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCommandBufferInheritanceConditionalRenderingInfoEXT*>( this );
    }

    bool operator==( CommandBufferInheritanceConditionalRenderingInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( conditionalRenderingEnable == rhs.conditionalRenderingEnable );
    }

    bool operator!=( CommandBufferInheritanceConditionalRenderingInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CommandBufferInheritanceConditionalRenderingInfoEXT::sType;
  };
  static_assert( sizeof( CommandBufferInheritanceConditionalRenderingInfoEXT ) == sizeof( VkCommandBufferInheritanceConditionalRenderingInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CommandBufferInheritanceConditionalRenderingInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CommandPoolCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR CommandPoolCreateInfo( vk::CommandPoolCreateFlags flags_ = vk::CommandPoolCreateFlags(),
                                                  uint32_t queueFamilyIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , queueFamilyIndex( queueFamilyIndex_ )
      {}

      CommandPoolCreateInfo( VkCommandPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandPoolCreateInfo*>(this) = rhs;
      }

      CommandPoolCreateInfo& operator=( VkCommandPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCommandPoolCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCommandPoolCreateInfo;
      const void* pNext = nullptr;
      vk::CommandPoolCreateFlags flags;
      uint32_t queueFamilyIndex;
    };
    static_assert( sizeof( CommandPoolCreateInfo ) == sizeof( VkCommandPoolCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct CommandPoolCreateInfo : public layout::CommandPoolCreateInfo
  {
    VULKAN_HPP_CONSTEXPR CommandPoolCreateInfo( vk::CommandPoolCreateFlags flags_ = vk::CommandPoolCreateFlags(),
                                                uint32_t queueFamilyIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::CommandPoolCreateInfo( flags_, queueFamilyIndex_ )
    {}

    CommandPoolCreateInfo( VkCommandPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CommandPoolCreateInfo( rhs )
    {}

    CommandPoolCreateInfo& operator=( VkCommandPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CommandPoolCreateInfo::operator=(rhs);
      return *this;
    }

    CommandPoolCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CommandPoolCreateInfo & setFlags( vk::CommandPoolCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    CommandPoolCreateInfo & setQueueFamilyIndex( uint32_t queueFamilyIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      queueFamilyIndex = queueFamilyIndex_;
      return *this;
    }

    operator VkCommandPoolCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCommandPoolCreateInfo*>( this );
    }

    operator VkCommandPoolCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCommandPoolCreateInfo*>( this );
    }

    bool operator==( CommandPoolCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( queueFamilyIndex == rhs.queueFamilyIndex );
    }

    bool operator!=( CommandPoolCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CommandPoolCreateInfo::sType;
  };
  static_assert( sizeof( CommandPoolCreateInfo ) == sizeof( VkCommandPoolCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CommandPoolCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct SpecializationMapEntry
  {
    VULKAN_HPP_CONSTEXPR SpecializationMapEntry( uint32_t constantID_ = 0,
                                                 uint32_t offset_ = 0,
                                                 size_t size_ = 0 ) VULKAN_HPP_NOEXCEPT
      : constantID( constantID_ )
      , offset( offset_ )
      , size( size_ )
    {}

    SpecializationMapEntry( VkSpecializationMapEntry const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSpecializationMapEntry*>(this) = rhs;
    }

    SpecializationMapEntry& operator=( VkSpecializationMapEntry const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSpecializationMapEntry*>(this) = rhs;
      return *this;
    }

    SpecializationMapEntry & setConstantID( uint32_t constantID_ ) VULKAN_HPP_NOEXCEPT
    {
      constantID = constantID_;
      return *this;
    }

    SpecializationMapEntry & setOffset( uint32_t offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    SpecializationMapEntry & setSize( size_t size_ ) VULKAN_HPP_NOEXCEPT
    {
      size = size_;
      return *this;
    }

    operator VkSpecializationMapEntry const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSpecializationMapEntry*>( this );
    }

    operator VkSpecializationMapEntry &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSpecializationMapEntry*>( this );
    }

    bool operator==( SpecializationMapEntry const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( constantID == rhs.constantID )
          && ( offset == rhs.offset )
          && ( size == rhs.size );
    }

    bool operator!=( SpecializationMapEntry const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t constantID;
    uint32_t offset;
    size_t size;
  };
  static_assert( sizeof( SpecializationMapEntry ) == sizeof( VkSpecializationMapEntry ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SpecializationMapEntry>::value, "struct wrapper is not a standard layout!" );

  struct SpecializationInfo
  {
    VULKAN_HPP_CONSTEXPR SpecializationInfo( uint32_t mapEntryCount_ = 0,
                                             const vk::SpecializationMapEntry* pMapEntries_ = nullptr,
                                             size_t dataSize_ = 0,
                                             const void* pData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : mapEntryCount( mapEntryCount_ )
      , pMapEntries( pMapEntries_ )
      , dataSize( dataSize_ )
      , pData( pData_ )
    {}

    SpecializationInfo( VkSpecializationInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSpecializationInfo*>(this) = rhs;
    }

    SpecializationInfo& operator=( VkSpecializationInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSpecializationInfo*>(this) = rhs;
      return *this;
    }

    SpecializationInfo & setMapEntryCount( uint32_t mapEntryCount_ ) VULKAN_HPP_NOEXCEPT
    {
      mapEntryCount = mapEntryCount_;
      return *this;
    }

    SpecializationInfo & setPMapEntries( const vk::SpecializationMapEntry* pMapEntries_ ) VULKAN_HPP_NOEXCEPT
    {
      pMapEntries = pMapEntries_;
      return *this;
    }

    SpecializationInfo & setDataSize( size_t dataSize_ ) VULKAN_HPP_NOEXCEPT
    {
      dataSize = dataSize_;
      return *this;
    }

    SpecializationInfo & setPData( const void* pData_ ) VULKAN_HPP_NOEXCEPT
    {
      pData = pData_;
      return *this;
    }

    operator VkSpecializationInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSpecializationInfo*>( this );
    }

    operator VkSpecializationInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSpecializationInfo*>( this );
    }

    bool operator==( SpecializationInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( mapEntryCount == rhs.mapEntryCount )
          && ( pMapEntries == rhs.pMapEntries )
          && ( dataSize == rhs.dataSize )
          && ( pData == rhs.pData );
    }

    bool operator!=( SpecializationInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t mapEntryCount;
    const vk::SpecializationMapEntry* pMapEntries;
    size_t dataSize;
    const void* pData;
  };
  static_assert( sizeof( SpecializationInfo ) == sizeof( VkSpecializationInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SpecializationInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineShaderStageCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineShaderStageCreateInfo( vk::PipelineShaderStageCreateFlags flags_ = vk::PipelineShaderStageCreateFlags(),
                                                          vk::ShaderStageFlagBits stage_ = vk::ShaderStageFlagBits::eVertex,
                                                          vk::ShaderModule module_ = vk::ShaderModule(),
                                                          const char* pName_ = nullptr,
                                                          const vk::SpecializationInfo* pSpecializationInfo_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , stage( stage_ )
        , module( module_ )
        , pName( pName_ )
        , pSpecializationInfo( pSpecializationInfo_ )
      {}

      PipelineShaderStageCreateInfo( VkPipelineShaderStageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineShaderStageCreateInfo*>(this) = rhs;
      }

      PipelineShaderStageCreateInfo& operator=( VkPipelineShaderStageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineShaderStageCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineShaderStageCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineShaderStageCreateFlags flags;
      vk::ShaderStageFlagBits stage;
      vk::ShaderModule module;
      const char* pName;
      const vk::SpecializationInfo* pSpecializationInfo;
    };
    static_assert( sizeof( PipelineShaderStageCreateInfo ) == sizeof( VkPipelineShaderStageCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineShaderStageCreateInfo : public layout::PipelineShaderStageCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineShaderStageCreateInfo( vk::PipelineShaderStageCreateFlags flags_ = vk::PipelineShaderStageCreateFlags(),
                                                        vk::ShaderStageFlagBits stage_ = vk::ShaderStageFlagBits::eVertex,
                                                        vk::ShaderModule module_ = vk::ShaderModule(),
                                                        const char* pName_ = nullptr,
                                                        const vk::SpecializationInfo* pSpecializationInfo_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineShaderStageCreateInfo( flags_, stage_, module_, pName_, pSpecializationInfo_ )
    {}

    PipelineShaderStageCreateInfo( VkPipelineShaderStageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineShaderStageCreateInfo( rhs )
    {}

    PipelineShaderStageCreateInfo& operator=( VkPipelineShaderStageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineShaderStageCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineShaderStageCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineShaderStageCreateInfo & setFlags( vk::PipelineShaderStageCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineShaderStageCreateInfo & setStage( vk::ShaderStageFlagBits stage_ ) VULKAN_HPP_NOEXCEPT
    {
      stage = stage_;
      return *this;
    }

    PipelineShaderStageCreateInfo & setModule( vk::ShaderModule module_ ) VULKAN_HPP_NOEXCEPT
    {
      module = module_;
      return *this;
    }

    PipelineShaderStageCreateInfo & setPName( const char* pName_ ) VULKAN_HPP_NOEXCEPT
    {
      pName = pName_;
      return *this;
    }

    PipelineShaderStageCreateInfo & setPSpecializationInfo( const vk::SpecializationInfo* pSpecializationInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      pSpecializationInfo = pSpecializationInfo_;
      return *this;
    }

    operator VkPipelineShaderStageCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineShaderStageCreateInfo*>( this );
    }

    operator VkPipelineShaderStageCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineShaderStageCreateInfo*>( this );
    }

    bool operator==( PipelineShaderStageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && vk::operator==( stage, rhs.stage )
          && ( module == rhs.module )
          && ( pName == rhs.pName )
          && ( pSpecializationInfo == rhs.pSpecializationInfo );
    }

    bool operator!=( PipelineShaderStageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineShaderStageCreateInfo::sType;
  };
  static_assert( sizeof( PipelineShaderStageCreateInfo ) == sizeof( VkPipelineShaderStageCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineShaderStageCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ComputePipelineCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ComputePipelineCreateInfo( vk::PipelineCreateFlags flags_ = vk::PipelineCreateFlags(),
                                                      vk::PipelineShaderStageCreateInfo stage_ = vk::PipelineShaderStageCreateInfo(),
                                                      vk::PipelineLayout layout_ = vk::PipelineLayout(),
                                                      vk::Pipeline basePipelineHandle_ = vk::Pipeline(),
                                                      int32_t basePipelineIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , stage( stage_ )
        , layout( layout_ )
        , basePipelineHandle( basePipelineHandle_ )
        , basePipelineIndex( basePipelineIndex_ )
      {}

      ComputePipelineCreateInfo( VkComputePipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkComputePipelineCreateInfo*>(this) = rhs;
      }

      ComputePipelineCreateInfo& operator=( VkComputePipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkComputePipelineCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eComputePipelineCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineCreateFlags flags;
      vk::PipelineShaderStageCreateInfo stage;
      vk::PipelineLayout layout;
      vk::Pipeline basePipelineHandle;
      int32_t basePipelineIndex;
    };
    static_assert( sizeof( ComputePipelineCreateInfo ) == sizeof( VkComputePipelineCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ComputePipelineCreateInfo : public layout::ComputePipelineCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ComputePipelineCreateInfo( vk::PipelineCreateFlags flags_ = vk::PipelineCreateFlags(),
                                                    vk::PipelineShaderStageCreateInfo stage_ = vk::PipelineShaderStageCreateInfo(),
                                                    vk::PipelineLayout layout_ = vk::PipelineLayout(),
                                                    vk::Pipeline basePipelineHandle_ = vk::Pipeline(),
                                                    int32_t basePipelineIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ComputePipelineCreateInfo( flags_, stage_, layout_, basePipelineHandle_, basePipelineIndex_ )
    {}

    ComputePipelineCreateInfo( VkComputePipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ComputePipelineCreateInfo( rhs )
    {}

    ComputePipelineCreateInfo& operator=( VkComputePipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ComputePipelineCreateInfo::operator=(rhs);
      return *this;
    }

    ComputePipelineCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ComputePipelineCreateInfo & setFlags( vk::PipelineCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ComputePipelineCreateInfo & setStage( vk::PipelineShaderStageCreateInfo stage_ ) VULKAN_HPP_NOEXCEPT
    {
      stage = stage_;
      return *this;
    }

    ComputePipelineCreateInfo & setLayout( vk::PipelineLayout layout_ ) VULKAN_HPP_NOEXCEPT
    {
      layout = layout_;
      return *this;
    }

    ComputePipelineCreateInfo & setBasePipelineHandle( vk::Pipeline basePipelineHandle_ ) VULKAN_HPP_NOEXCEPT
    {
      basePipelineHandle = basePipelineHandle_;
      return *this;
    }

    ComputePipelineCreateInfo & setBasePipelineIndex( int32_t basePipelineIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      basePipelineIndex = basePipelineIndex_;
      return *this;
    }

    operator VkComputePipelineCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkComputePipelineCreateInfo*>( this );
    }

    operator VkComputePipelineCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkComputePipelineCreateInfo*>( this );
    }

    bool operator==( ComputePipelineCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( stage == rhs.stage )
          && ( layout == rhs.layout )
          && ( basePipelineHandle == rhs.basePipelineHandle )
          && ( basePipelineIndex == rhs.basePipelineIndex );
    }

    bool operator!=( ComputePipelineCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ComputePipelineCreateInfo::sType;
  };
  static_assert( sizeof( ComputePipelineCreateInfo ) == sizeof( VkComputePipelineCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ComputePipelineCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ConditionalRenderingBeginInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ConditionalRenderingBeginInfoEXT( vk::Buffer buffer_ = vk::Buffer(),
                                                             vk::DeviceSize offset_ = 0,
                                                             vk::ConditionalRenderingFlagsEXT flags_ = vk::ConditionalRenderingFlagsEXT() ) VULKAN_HPP_NOEXCEPT
        : buffer( buffer_ )
        , offset( offset_ )
        , flags( flags_ )
      {}

      ConditionalRenderingBeginInfoEXT( VkConditionalRenderingBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkConditionalRenderingBeginInfoEXT*>(this) = rhs;
      }

      ConditionalRenderingBeginInfoEXT& operator=( VkConditionalRenderingBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkConditionalRenderingBeginInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eConditionalRenderingBeginInfoEXT;
      const void* pNext = nullptr;
      vk::Buffer buffer;
      vk::DeviceSize offset;
      vk::ConditionalRenderingFlagsEXT flags;
    };
    static_assert( sizeof( ConditionalRenderingBeginInfoEXT ) == sizeof( VkConditionalRenderingBeginInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct ConditionalRenderingBeginInfoEXT : public layout::ConditionalRenderingBeginInfoEXT
  {
    VULKAN_HPP_CONSTEXPR ConditionalRenderingBeginInfoEXT( vk::Buffer buffer_ = vk::Buffer(),
                                                           vk::DeviceSize offset_ = 0,
                                                           vk::ConditionalRenderingFlagsEXT flags_ = vk::ConditionalRenderingFlagsEXT() ) VULKAN_HPP_NOEXCEPT
      : layout::ConditionalRenderingBeginInfoEXT( buffer_, offset_, flags_ )
    {}

    ConditionalRenderingBeginInfoEXT( VkConditionalRenderingBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ConditionalRenderingBeginInfoEXT( rhs )
    {}

    ConditionalRenderingBeginInfoEXT& operator=( VkConditionalRenderingBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ConditionalRenderingBeginInfoEXT::operator=(rhs);
      return *this;
    }

    ConditionalRenderingBeginInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ConditionalRenderingBeginInfoEXT & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    ConditionalRenderingBeginInfoEXT & setOffset( vk::DeviceSize offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    ConditionalRenderingBeginInfoEXT & setFlags( vk::ConditionalRenderingFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkConditionalRenderingBeginInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkConditionalRenderingBeginInfoEXT*>( this );
    }

    operator VkConditionalRenderingBeginInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkConditionalRenderingBeginInfoEXT*>( this );
    }

    bool operator==( ConditionalRenderingBeginInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( buffer == rhs.buffer )
          && ( offset == rhs.offset )
          && ( flags == rhs.flags );
    }

    bool operator!=( ConditionalRenderingBeginInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ConditionalRenderingBeginInfoEXT::sType;
  };
  static_assert( sizeof( ConditionalRenderingBeginInfoEXT ) == sizeof( VkConditionalRenderingBeginInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ConditionalRenderingBeginInfoEXT>::value, "struct wrapper is not a standard layout!" );

  struct ConformanceVersionKHR
  {
    VULKAN_HPP_CONSTEXPR ConformanceVersionKHR( uint8_t major_ = 0,
                                                uint8_t minor_ = 0,
                                                uint8_t subminor_ = 0,
                                                uint8_t patch_ = 0 ) VULKAN_HPP_NOEXCEPT
      : major( major_ )
      , minor( minor_ )
      , subminor( subminor_ )
      , patch( patch_ )
    {}

    ConformanceVersionKHR( VkConformanceVersionKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkConformanceVersionKHR*>(this) = rhs;
    }

    ConformanceVersionKHR& operator=( VkConformanceVersionKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkConformanceVersionKHR*>(this) = rhs;
      return *this;
    }

    ConformanceVersionKHR & setMajor( uint8_t major_ ) VULKAN_HPP_NOEXCEPT
    {
      major = major_;
      return *this;
    }

    ConformanceVersionKHR & setMinor( uint8_t minor_ ) VULKAN_HPP_NOEXCEPT
    {
      minor = minor_;
      return *this;
    }

    ConformanceVersionKHR & setSubminor( uint8_t subminor_ ) VULKAN_HPP_NOEXCEPT
    {
      subminor = subminor_;
      return *this;
    }

    ConformanceVersionKHR & setPatch( uint8_t patch_ ) VULKAN_HPP_NOEXCEPT
    {
      patch = patch_;
      return *this;
    }

    operator VkConformanceVersionKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkConformanceVersionKHR*>( this );
    }

    operator VkConformanceVersionKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkConformanceVersionKHR*>( this );
    }

    bool operator==( ConformanceVersionKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( major == rhs.major )
          && ( minor == rhs.minor )
          && ( subminor == rhs.subminor )
          && ( patch == rhs.patch );
    }

    bool operator!=( ConformanceVersionKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint8_t major;
    uint8_t minor;
    uint8_t subminor;
    uint8_t patch;
  };
  static_assert( sizeof( ConformanceVersionKHR ) == sizeof( VkConformanceVersionKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ConformanceVersionKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CooperativeMatrixPropertiesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR CooperativeMatrixPropertiesNV( uint32_t MSize_ = 0,
                                                          uint32_t NSize_ = 0,
                                                          uint32_t KSize_ = 0,
                                                          vk::ComponentTypeNV AType_ = vk::ComponentTypeNV::eFloat16,
                                                          vk::ComponentTypeNV BType_ = vk::ComponentTypeNV::eFloat16,
                                                          vk::ComponentTypeNV CType_ = vk::ComponentTypeNV::eFloat16,
                                                          vk::ComponentTypeNV DType_ = vk::ComponentTypeNV::eFloat16,
                                                          vk::ScopeNV scope_ = vk::ScopeNV::eDevice ) VULKAN_HPP_NOEXCEPT
        : MSize( MSize_ )
        , NSize( NSize_ )
        , KSize( KSize_ )
        , AType( AType_ )
        , BType( BType_ )
        , CType( CType_ )
        , DType( DType_ )
        , scope( scope_ )
      {}

      CooperativeMatrixPropertiesNV( VkCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCooperativeMatrixPropertiesNV*>(this) = rhs;
      }

      CooperativeMatrixPropertiesNV& operator=( VkCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCooperativeMatrixPropertiesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCooperativeMatrixPropertiesNV;
      void* pNext = nullptr;
      uint32_t MSize;
      uint32_t NSize;
      uint32_t KSize;
      vk::ComponentTypeNV AType;
      vk::ComponentTypeNV BType;
      vk::ComponentTypeNV CType;
      vk::ComponentTypeNV DType;
      vk::ScopeNV scope;
    };
    static_assert( sizeof( CooperativeMatrixPropertiesNV ) == sizeof( VkCooperativeMatrixPropertiesNV ), "layout struct and wrapper have different size!" );
  }

  struct CooperativeMatrixPropertiesNV : public layout::CooperativeMatrixPropertiesNV
  {
    VULKAN_HPP_CONSTEXPR CooperativeMatrixPropertiesNV( uint32_t MSize_ = 0,
                                                        uint32_t NSize_ = 0,
                                                        uint32_t KSize_ = 0,
                                                        vk::ComponentTypeNV AType_ = vk::ComponentTypeNV::eFloat16,
                                                        vk::ComponentTypeNV BType_ = vk::ComponentTypeNV::eFloat16,
                                                        vk::ComponentTypeNV CType_ = vk::ComponentTypeNV::eFloat16,
                                                        vk::ComponentTypeNV DType_ = vk::ComponentTypeNV::eFloat16,
                                                        vk::ScopeNV scope_ = vk::ScopeNV::eDevice ) VULKAN_HPP_NOEXCEPT
      : layout::CooperativeMatrixPropertiesNV( MSize_, NSize_, KSize_, AType_, BType_, CType_, DType_, scope_ )
    {}

    CooperativeMatrixPropertiesNV( VkCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CooperativeMatrixPropertiesNV( rhs )
    {}

    CooperativeMatrixPropertiesNV& operator=( VkCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CooperativeMatrixPropertiesNV::operator=(rhs);
      return *this;
    }

    CooperativeMatrixPropertiesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setMSize( uint32_t MSize_ ) VULKAN_HPP_NOEXCEPT
    {
      MSize = MSize_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setNSize( uint32_t NSize_ ) VULKAN_HPP_NOEXCEPT
    {
      NSize = NSize_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setKSize( uint32_t KSize_ ) VULKAN_HPP_NOEXCEPT
    {
      KSize = KSize_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setAType( vk::ComponentTypeNV AType_ ) VULKAN_HPP_NOEXCEPT
    {
      AType = AType_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setBType( vk::ComponentTypeNV BType_ ) VULKAN_HPP_NOEXCEPT
    {
      BType = BType_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setCType( vk::ComponentTypeNV CType_ ) VULKAN_HPP_NOEXCEPT
    {
      CType = CType_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setDType( vk::ComponentTypeNV DType_ ) VULKAN_HPP_NOEXCEPT
    {
      DType = DType_;
      return *this;
    }

    CooperativeMatrixPropertiesNV & setScope( vk::ScopeNV scope_ ) VULKAN_HPP_NOEXCEPT
    {
      scope = scope_;
      return *this;
    }

    operator VkCooperativeMatrixPropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCooperativeMatrixPropertiesNV*>( this );
    }

    operator VkCooperativeMatrixPropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCooperativeMatrixPropertiesNV*>( this );
    }

    bool operator==( CooperativeMatrixPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( MSize == rhs.MSize )
          && ( NSize == rhs.NSize )
          && ( KSize == rhs.KSize )
          && ( AType == rhs.AType )
          && ( BType == rhs.BType )
          && ( CType == rhs.CType )
          && ( DType == rhs.DType )
          && ( scope == rhs.scope );
    }

    bool operator!=( CooperativeMatrixPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CooperativeMatrixPropertiesNV::sType;
  };
  static_assert( sizeof( CooperativeMatrixPropertiesNV ) == sizeof( VkCooperativeMatrixPropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CooperativeMatrixPropertiesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct CopyDescriptorSet
    {
    protected:
      VULKAN_HPP_CONSTEXPR CopyDescriptorSet( vk::DescriptorSet srcSet_ = vk::DescriptorSet(),
                                              uint32_t srcBinding_ = 0,
                                              uint32_t srcArrayElement_ = 0,
                                              vk::DescriptorSet dstSet_ = vk::DescriptorSet(),
                                              uint32_t dstBinding_ = 0,
                                              uint32_t dstArrayElement_ = 0,
                                              uint32_t descriptorCount_ = 0 ) VULKAN_HPP_NOEXCEPT
        : srcSet( srcSet_ )
        , srcBinding( srcBinding_ )
        , srcArrayElement( srcArrayElement_ )
        , dstSet( dstSet_ )
        , dstBinding( dstBinding_ )
        , dstArrayElement( dstArrayElement_ )
        , descriptorCount( descriptorCount_ )
      {}

      CopyDescriptorSet( VkCopyDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCopyDescriptorSet*>(this) = rhs;
      }

      CopyDescriptorSet& operator=( VkCopyDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkCopyDescriptorSet*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eCopyDescriptorSet;
      const void* pNext = nullptr;
      vk::DescriptorSet srcSet;
      uint32_t srcBinding;
      uint32_t srcArrayElement;
      vk::DescriptorSet dstSet;
      uint32_t dstBinding;
      uint32_t dstArrayElement;
      uint32_t descriptorCount;
    };
    static_assert( sizeof( CopyDescriptorSet ) == sizeof( VkCopyDescriptorSet ), "layout struct and wrapper have different size!" );
  }

  struct CopyDescriptorSet : public layout::CopyDescriptorSet
  {
    VULKAN_HPP_CONSTEXPR CopyDescriptorSet( vk::DescriptorSet srcSet_ = vk::DescriptorSet(),
                                            uint32_t srcBinding_ = 0,
                                            uint32_t srcArrayElement_ = 0,
                                            vk::DescriptorSet dstSet_ = vk::DescriptorSet(),
                                            uint32_t dstBinding_ = 0,
                                            uint32_t dstArrayElement_ = 0,
                                            uint32_t descriptorCount_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::CopyDescriptorSet( srcSet_, srcBinding_, srcArrayElement_, dstSet_, dstBinding_, dstArrayElement_, descriptorCount_ )
    {}

    CopyDescriptorSet( VkCopyDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::CopyDescriptorSet( rhs )
    {}

    CopyDescriptorSet& operator=( VkCopyDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::CopyDescriptorSet::operator=(rhs);
      return *this;
    }

    CopyDescriptorSet & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    CopyDescriptorSet & setSrcSet( vk::DescriptorSet srcSet_ ) VULKAN_HPP_NOEXCEPT
    {
      srcSet = srcSet_;
      return *this;
    }

    CopyDescriptorSet & setSrcBinding( uint32_t srcBinding_ ) VULKAN_HPP_NOEXCEPT
    {
      srcBinding = srcBinding_;
      return *this;
    }

    CopyDescriptorSet & setSrcArrayElement( uint32_t srcArrayElement_ ) VULKAN_HPP_NOEXCEPT
    {
      srcArrayElement = srcArrayElement_;
      return *this;
    }

    CopyDescriptorSet & setDstSet( vk::DescriptorSet dstSet_ ) VULKAN_HPP_NOEXCEPT
    {
      dstSet = dstSet_;
      return *this;
    }

    CopyDescriptorSet & setDstBinding( uint32_t dstBinding_ ) VULKAN_HPP_NOEXCEPT
    {
      dstBinding = dstBinding_;
      return *this;
    }

    CopyDescriptorSet & setDstArrayElement( uint32_t dstArrayElement_ ) VULKAN_HPP_NOEXCEPT
    {
      dstArrayElement = dstArrayElement_;
      return *this;
    }

    CopyDescriptorSet & setDescriptorCount( uint32_t descriptorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorCount = descriptorCount_;
      return *this;
    }

    operator VkCopyDescriptorSet const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkCopyDescriptorSet*>( this );
    }

    operator VkCopyDescriptorSet &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkCopyDescriptorSet*>( this );
    }

    bool operator==( CopyDescriptorSet const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( srcSet == rhs.srcSet )
          && ( srcBinding == rhs.srcBinding )
          && ( srcArrayElement == rhs.srcArrayElement )
          && ( dstSet == rhs.dstSet )
          && ( dstBinding == rhs.dstBinding )
          && ( dstArrayElement == rhs.dstArrayElement )
          && ( descriptorCount == rhs.descriptorCount );
    }

    bool operator!=( CopyDescriptorSet const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::CopyDescriptorSet::sType;
  };
  static_assert( sizeof( CopyDescriptorSet ) == sizeof( VkCopyDescriptorSet ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<CopyDescriptorSet>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct D3D12FenceSubmitInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR D3D12FenceSubmitInfoKHR( uint32_t waitSemaphoreValuesCount_ = 0,
                                                    const uint64_t* pWaitSemaphoreValues_ = nullptr,
                                                    uint32_t signalSemaphoreValuesCount_ = 0,
                                                    const uint64_t* pSignalSemaphoreValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : waitSemaphoreValuesCount( waitSemaphoreValuesCount_ )
        , pWaitSemaphoreValues( pWaitSemaphoreValues_ )
        , signalSemaphoreValuesCount( signalSemaphoreValuesCount_ )
        , pSignalSemaphoreValues( pSignalSemaphoreValues_ )
      {}

      D3D12FenceSubmitInfoKHR( VkD3D12FenceSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkD3D12FenceSubmitInfoKHR*>(this) = rhs;
      }

      D3D12FenceSubmitInfoKHR& operator=( VkD3D12FenceSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkD3D12FenceSubmitInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eD3D12FenceSubmitInfoKHR;
      const void* pNext = nullptr;
      uint32_t waitSemaphoreValuesCount;
      const uint64_t* pWaitSemaphoreValues;
      uint32_t signalSemaphoreValuesCount;
      const uint64_t* pSignalSemaphoreValues;
    };
    static_assert( sizeof( D3D12FenceSubmitInfoKHR ) == sizeof( VkD3D12FenceSubmitInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct D3D12FenceSubmitInfoKHR : public layout::D3D12FenceSubmitInfoKHR
  {
    VULKAN_HPP_CONSTEXPR D3D12FenceSubmitInfoKHR( uint32_t waitSemaphoreValuesCount_ = 0,
                                                  const uint64_t* pWaitSemaphoreValues_ = nullptr,
                                                  uint32_t signalSemaphoreValuesCount_ = 0,
                                                  const uint64_t* pSignalSemaphoreValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::D3D12FenceSubmitInfoKHR( waitSemaphoreValuesCount_, pWaitSemaphoreValues_, signalSemaphoreValuesCount_, pSignalSemaphoreValues_ )
    {}

    D3D12FenceSubmitInfoKHR( VkD3D12FenceSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::D3D12FenceSubmitInfoKHR( rhs )
    {}

    D3D12FenceSubmitInfoKHR& operator=( VkD3D12FenceSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::D3D12FenceSubmitInfoKHR::operator=(rhs);
      return *this;
    }

    D3D12FenceSubmitInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    D3D12FenceSubmitInfoKHR & setWaitSemaphoreValuesCount( uint32_t waitSemaphoreValuesCount_ ) VULKAN_HPP_NOEXCEPT
    {
      waitSemaphoreValuesCount = waitSemaphoreValuesCount_;
      return *this;
    }

    D3D12FenceSubmitInfoKHR & setPWaitSemaphoreValues( const uint64_t* pWaitSemaphoreValues_ ) VULKAN_HPP_NOEXCEPT
    {
      pWaitSemaphoreValues = pWaitSemaphoreValues_;
      return *this;
    }

    D3D12FenceSubmitInfoKHR & setSignalSemaphoreValuesCount( uint32_t signalSemaphoreValuesCount_ ) VULKAN_HPP_NOEXCEPT
    {
      signalSemaphoreValuesCount = signalSemaphoreValuesCount_;
      return *this;
    }

    D3D12FenceSubmitInfoKHR & setPSignalSemaphoreValues( const uint64_t* pSignalSemaphoreValues_ ) VULKAN_HPP_NOEXCEPT
    {
      pSignalSemaphoreValues = pSignalSemaphoreValues_;
      return *this;
    }

    operator VkD3D12FenceSubmitInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkD3D12FenceSubmitInfoKHR*>( this );
    }

    operator VkD3D12FenceSubmitInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkD3D12FenceSubmitInfoKHR*>( this );
    }

    bool operator==( D3D12FenceSubmitInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( waitSemaphoreValuesCount == rhs.waitSemaphoreValuesCount )
          && ( pWaitSemaphoreValues == rhs.pWaitSemaphoreValues )
          && ( signalSemaphoreValuesCount == rhs.signalSemaphoreValuesCount )
          && ( pSignalSemaphoreValues == rhs.pSignalSemaphoreValues );
    }

    bool operator!=( D3D12FenceSubmitInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::D3D12FenceSubmitInfoKHR::sType;
  };
  static_assert( sizeof( D3D12FenceSubmitInfoKHR ) == sizeof( VkD3D12FenceSubmitInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<D3D12FenceSubmitInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct DebugMarkerMarkerInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR_14 DebugMarkerMarkerInfoEXT( const char* pMarkerName_ = nullptr,
                                                        std::array<float,4> const& color_ = { { 0 } } ) VULKAN_HPP_NOEXCEPT
        : pMarkerName( pMarkerName_ )
        , color{}
      {
        vk::ConstExpressionArrayCopy<float,4,4>::copy( color, color_ );
      }

      DebugMarkerMarkerInfoEXT( VkDebugMarkerMarkerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugMarkerMarkerInfoEXT*>(this) = rhs;
      }

      DebugMarkerMarkerInfoEXT& operator=( VkDebugMarkerMarkerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugMarkerMarkerInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugMarkerMarkerInfoEXT;
      const void* pNext = nullptr;
      const char* pMarkerName;
      float color[4];
    };
    static_assert( sizeof( DebugMarkerMarkerInfoEXT ) == sizeof( VkDebugMarkerMarkerInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugMarkerMarkerInfoEXT : public layout::DebugMarkerMarkerInfoEXT
  {
    VULKAN_HPP_CONSTEXPR_14 DebugMarkerMarkerInfoEXT( const char* pMarkerName_ = nullptr,
                                                      std::array<float,4> const& color_ = { { 0 } } ) VULKAN_HPP_NOEXCEPT
      : layout::DebugMarkerMarkerInfoEXT( pMarkerName_, color_ )
    {}

    DebugMarkerMarkerInfoEXT( VkDebugMarkerMarkerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugMarkerMarkerInfoEXT( rhs )
    {}

    DebugMarkerMarkerInfoEXT& operator=( VkDebugMarkerMarkerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugMarkerMarkerInfoEXT::operator=(rhs);
      return *this;
    }

    DebugMarkerMarkerInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugMarkerMarkerInfoEXT & setPMarkerName( const char* pMarkerName_ ) VULKAN_HPP_NOEXCEPT
    {
      pMarkerName = pMarkerName_;
      return *this;
    }

    DebugMarkerMarkerInfoEXT & setColor( std::array<float,4> color_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( color, color_.data(), 4 * sizeof( float ) );
      return *this;
    }

    operator VkDebugMarkerMarkerInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>( this );
    }

    operator VkDebugMarkerMarkerInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugMarkerMarkerInfoEXT*>( this );
    }

    bool operator==( DebugMarkerMarkerInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pMarkerName == rhs.pMarkerName )
          && ( memcmp( color, rhs.color, 4 * sizeof( float ) ) == 0 );
    }

    bool operator!=( DebugMarkerMarkerInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugMarkerMarkerInfoEXT::sType;
  };
  static_assert( sizeof( DebugMarkerMarkerInfoEXT ) == sizeof( VkDebugMarkerMarkerInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugMarkerMarkerInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugMarkerObjectNameInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DebugMarkerObjectNameInfoEXT( vk::DebugReportObjectTypeEXT objectType_ = vk::DebugReportObjectTypeEXT::eUnknown,
                                                         uint64_t object_ = 0,
                                                         const char* pObjectName_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : objectType( objectType_ )
        , object( object_ )
        , pObjectName( pObjectName_ )
      {}

      DebugMarkerObjectNameInfoEXT( VkDebugMarkerObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugMarkerObjectNameInfoEXT*>(this) = rhs;
      }

      DebugMarkerObjectNameInfoEXT& operator=( VkDebugMarkerObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugMarkerObjectNameInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugMarkerObjectNameInfoEXT;
      const void* pNext = nullptr;
      vk::DebugReportObjectTypeEXT objectType;
      uint64_t object;
      const char* pObjectName;
    };
    static_assert( sizeof( DebugMarkerObjectNameInfoEXT ) == sizeof( VkDebugMarkerObjectNameInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugMarkerObjectNameInfoEXT : public layout::DebugMarkerObjectNameInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DebugMarkerObjectNameInfoEXT( vk::DebugReportObjectTypeEXT objectType_ = vk::DebugReportObjectTypeEXT::eUnknown,
                                                       uint64_t object_ = 0,
                                                       const char* pObjectName_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DebugMarkerObjectNameInfoEXT( objectType_, object_, pObjectName_ )
    {}

    DebugMarkerObjectNameInfoEXT( VkDebugMarkerObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugMarkerObjectNameInfoEXT( rhs )
    {}

    DebugMarkerObjectNameInfoEXT& operator=( VkDebugMarkerObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugMarkerObjectNameInfoEXT::operator=(rhs);
      return *this;
    }

    DebugMarkerObjectNameInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugMarkerObjectNameInfoEXT & setObjectType( vk::DebugReportObjectTypeEXT objectType_ ) VULKAN_HPP_NOEXCEPT
    {
      objectType = objectType_;
      return *this;
    }

    DebugMarkerObjectNameInfoEXT & setObject( uint64_t object_ ) VULKAN_HPP_NOEXCEPT
    {
      object = object_;
      return *this;
    }

    DebugMarkerObjectNameInfoEXT & setPObjectName( const char* pObjectName_ ) VULKAN_HPP_NOEXCEPT
    {
      pObjectName = pObjectName_;
      return *this;
    }

    operator VkDebugMarkerObjectNameInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugMarkerObjectNameInfoEXT*>( this );
    }

    operator VkDebugMarkerObjectNameInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugMarkerObjectNameInfoEXT*>( this );
    }

    bool operator==( DebugMarkerObjectNameInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( objectType == rhs.objectType )
          && ( object == rhs.object )
          && ( pObjectName == rhs.pObjectName );
    }

    bool operator!=( DebugMarkerObjectNameInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugMarkerObjectNameInfoEXT::sType;
  };
  static_assert( sizeof( DebugMarkerObjectNameInfoEXT ) == sizeof( VkDebugMarkerObjectNameInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugMarkerObjectNameInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugMarkerObjectTagInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DebugMarkerObjectTagInfoEXT( vk::DebugReportObjectTypeEXT objectType_ = vk::DebugReportObjectTypeEXT::eUnknown,
                                                        uint64_t object_ = 0,
                                                        uint64_t tagName_ = 0,
                                                        size_t tagSize_ = 0,
                                                        const void* pTag_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : objectType( objectType_ )
        , object( object_ )
        , tagName( tagName_ )
        , tagSize( tagSize_ )
        , pTag( pTag_ )
      {}

      DebugMarkerObjectTagInfoEXT( VkDebugMarkerObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugMarkerObjectTagInfoEXT*>(this) = rhs;
      }

      DebugMarkerObjectTagInfoEXT& operator=( VkDebugMarkerObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugMarkerObjectTagInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugMarkerObjectTagInfoEXT;
      const void* pNext = nullptr;
      vk::DebugReportObjectTypeEXT objectType;
      uint64_t object;
      uint64_t tagName;
      size_t tagSize;
      const void* pTag;
    };
    static_assert( sizeof( DebugMarkerObjectTagInfoEXT ) == sizeof( VkDebugMarkerObjectTagInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugMarkerObjectTagInfoEXT : public layout::DebugMarkerObjectTagInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DebugMarkerObjectTagInfoEXT( vk::DebugReportObjectTypeEXT objectType_ = vk::DebugReportObjectTypeEXT::eUnknown,
                                                      uint64_t object_ = 0,
                                                      uint64_t tagName_ = 0,
                                                      size_t tagSize_ = 0,
                                                      const void* pTag_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DebugMarkerObjectTagInfoEXT( objectType_, object_, tagName_, tagSize_, pTag_ )
    {}

    DebugMarkerObjectTagInfoEXT( VkDebugMarkerObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugMarkerObjectTagInfoEXT( rhs )
    {}

    DebugMarkerObjectTagInfoEXT& operator=( VkDebugMarkerObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugMarkerObjectTagInfoEXT::operator=(rhs);
      return *this;
    }

    DebugMarkerObjectTagInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugMarkerObjectTagInfoEXT & setObjectType( vk::DebugReportObjectTypeEXT objectType_ ) VULKAN_HPP_NOEXCEPT
    {
      objectType = objectType_;
      return *this;
    }

    DebugMarkerObjectTagInfoEXT & setObject( uint64_t object_ ) VULKAN_HPP_NOEXCEPT
    {
      object = object_;
      return *this;
    }

    DebugMarkerObjectTagInfoEXT & setTagName( uint64_t tagName_ ) VULKAN_HPP_NOEXCEPT
    {
      tagName = tagName_;
      return *this;
    }

    DebugMarkerObjectTagInfoEXT & setTagSize( size_t tagSize_ ) VULKAN_HPP_NOEXCEPT
    {
      tagSize = tagSize_;
      return *this;
    }

    DebugMarkerObjectTagInfoEXT & setPTag( const void* pTag_ ) VULKAN_HPP_NOEXCEPT
    {
      pTag = pTag_;
      return *this;
    }

    operator VkDebugMarkerObjectTagInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugMarkerObjectTagInfoEXT*>( this );
    }

    operator VkDebugMarkerObjectTagInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugMarkerObjectTagInfoEXT*>( this );
    }

    bool operator==( DebugMarkerObjectTagInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( objectType == rhs.objectType )
          && ( object == rhs.object )
          && ( tagName == rhs.tagName )
          && ( tagSize == rhs.tagSize )
          && ( pTag == rhs.pTag );
    }

    bool operator!=( DebugMarkerObjectTagInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugMarkerObjectTagInfoEXT::sType;
  };
  static_assert( sizeof( DebugMarkerObjectTagInfoEXT ) == sizeof( VkDebugMarkerObjectTagInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugMarkerObjectTagInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugReportCallbackCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DebugReportCallbackCreateInfoEXT( vk::DebugReportFlagsEXT flags_ = vk::DebugReportFlagsEXT(),
                                                             PFN_vkDebugReportCallbackEXT pfnCallback_ = nullptr,
                                                             void* pUserData_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pfnCallback( pfnCallback_ )
        , pUserData( pUserData_ )
      {}

      DebugReportCallbackCreateInfoEXT( VkDebugReportCallbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugReportCallbackCreateInfoEXT*>(this) = rhs;
      }

      DebugReportCallbackCreateInfoEXT& operator=( VkDebugReportCallbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugReportCallbackCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugReportCallbackCreateInfoEXT;
      const void* pNext = nullptr;
      vk::DebugReportFlagsEXT flags;
      PFN_vkDebugReportCallbackEXT pfnCallback;
      void* pUserData;
    };
    static_assert( sizeof( DebugReportCallbackCreateInfoEXT ) == sizeof( VkDebugReportCallbackCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugReportCallbackCreateInfoEXT : public layout::DebugReportCallbackCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DebugReportCallbackCreateInfoEXT( vk::DebugReportFlagsEXT flags_ = vk::DebugReportFlagsEXT(),
                                                           PFN_vkDebugReportCallbackEXT pfnCallback_ = nullptr,
                                                           void* pUserData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DebugReportCallbackCreateInfoEXT( flags_, pfnCallback_, pUserData_ )
    {}

    DebugReportCallbackCreateInfoEXT( VkDebugReportCallbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugReportCallbackCreateInfoEXT( rhs )
    {}

    DebugReportCallbackCreateInfoEXT& operator=( VkDebugReportCallbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugReportCallbackCreateInfoEXT::operator=(rhs);
      return *this;
    }

    DebugReportCallbackCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugReportCallbackCreateInfoEXT & setFlags( vk::DebugReportFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DebugReportCallbackCreateInfoEXT & setPfnCallback( PFN_vkDebugReportCallbackEXT pfnCallback_ ) VULKAN_HPP_NOEXCEPT
    {
      pfnCallback = pfnCallback_;
      return *this;
    }

    DebugReportCallbackCreateInfoEXT & setPUserData( void* pUserData_ ) VULKAN_HPP_NOEXCEPT
    {
      pUserData = pUserData_;
      return *this;
    }

    operator VkDebugReportCallbackCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugReportCallbackCreateInfoEXT*>( this );
    }

    operator VkDebugReportCallbackCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugReportCallbackCreateInfoEXT*>( this );
    }

    bool operator==( DebugReportCallbackCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pfnCallback == rhs.pfnCallback )
          && ( pUserData == rhs.pUserData );
    }

    bool operator!=( DebugReportCallbackCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugReportCallbackCreateInfoEXT::sType;
  };
  static_assert( sizeof( DebugReportCallbackCreateInfoEXT ) == sizeof( VkDebugReportCallbackCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugReportCallbackCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugUtilsLabelEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR_14 DebugUtilsLabelEXT( const char* pLabelName_ = nullptr,
                                                  std::array<float,4> const& color_ = { { 0 } } ) VULKAN_HPP_NOEXCEPT
        : pLabelName( pLabelName_ )
        , color{}
      {
        vk::ConstExpressionArrayCopy<float,4,4>::copy( color, color_ );
      }

      DebugUtilsLabelEXT( VkDebugUtilsLabelEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsLabelEXT*>(this) = rhs;
      }

      DebugUtilsLabelEXT& operator=( VkDebugUtilsLabelEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsLabelEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugUtilsLabelEXT;
      const void* pNext = nullptr;
      const char* pLabelName;
      float color[4];
    };
    static_assert( sizeof( DebugUtilsLabelEXT ) == sizeof( VkDebugUtilsLabelEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugUtilsLabelEXT : public layout::DebugUtilsLabelEXT
  {
    VULKAN_HPP_CONSTEXPR_14 DebugUtilsLabelEXT( const char* pLabelName_ = nullptr,
                                                std::array<float,4> const& color_ = { { 0 } } ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsLabelEXT( pLabelName_, color_ )
    {}

    DebugUtilsLabelEXT( VkDebugUtilsLabelEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsLabelEXT( rhs )
    {}

    DebugUtilsLabelEXT& operator=( VkDebugUtilsLabelEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugUtilsLabelEXT::operator=(rhs);
      return *this;
    }

    DebugUtilsLabelEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugUtilsLabelEXT & setPLabelName( const char* pLabelName_ ) VULKAN_HPP_NOEXCEPT
    {
      pLabelName = pLabelName_;
      return *this;
    }

    DebugUtilsLabelEXT & setColor( std::array<float,4> color_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( color, color_.data(), 4 * sizeof( float ) );
      return *this;
    }

    operator VkDebugUtilsLabelEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugUtilsLabelEXT*>( this );
    }

    operator VkDebugUtilsLabelEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugUtilsLabelEXT*>( this );
    }

    bool operator==( DebugUtilsLabelEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pLabelName == rhs.pLabelName )
          && ( memcmp( color, rhs.color, 4 * sizeof( float ) ) == 0 );
    }

    bool operator!=( DebugUtilsLabelEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugUtilsLabelEXT::sType;
  };
  static_assert( sizeof( DebugUtilsLabelEXT ) == sizeof( VkDebugUtilsLabelEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugUtilsLabelEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugUtilsObjectNameInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DebugUtilsObjectNameInfoEXT( vk::ObjectType objectType_ = vk::ObjectType::eUnknown,
                                                        uint64_t objectHandle_ = 0,
                                                        const char* pObjectName_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : objectType( objectType_ )
        , objectHandle( objectHandle_ )
        , pObjectName( pObjectName_ )
      {}

      DebugUtilsObjectNameInfoEXT( VkDebugUtilsObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsObjectNameInfoEXT*>(this) = rhs;
      }

      DebugUtilsObjectNameInfoEXT& operator=( VkDebugUtilsObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsObjectNameInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugUtilsObjectNameInfoEXT;
      const void* pNext = nullptr;
      vk::ObjectType objectType;
      uint64_t objectHandle;
      const char* pObjectName;
    };
    static_assert( sizeof( DebugUtilsObjectNameInfoEXT ) == sizeof( VkDebugUtilsObjectNameInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugUtilsObjectNameInfoEXT : public layout::DebugUtilsObjectNameInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DebugUtilsObjectNameInfoEXT( vk::ObjectType objectType_ = vk::ObjectType::eUnknown,
                                                      uint64_t objectHandle_ = 0,
                                                      const char* pObjectName_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsObjectNameInfoEXT( objectType_, objectHandle_, pObjectName_ )
    {}

    DebugUtilsObjectNameInfoEXT( VkDebugUtilsObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsObjectNameInfoEXT( rhs )
    {}

    DebugUtilsObjectNameInfoEXT& operator=( VkDebugUtilsObjectNameInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugUtilsObjectNameInfoEXT::operator=(rhs);
      return *this;
    }

    DebugUtilsObjectNameInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugUtilsObjectNameInfoEXT & setObjectType( vk::ObjectType objectType_ ) VULKAN_HPP_NOEXCEPT
    {
      objectType = objectType_;
      return *this;
    }

    DebugUtilsObjectNameInfoEXT & setObjectHandle( uint64_t objectHandle_ ) VULKAN_HPP_NOEXCEPT
    {
      objectHandle = objectHandle_;
      return *this;
    }

    DebugUtilsObjectNameInfoEXT & setPObjectName( const char* pObjectName_ ) VULKAN_HPP_NOEXCEPT
    {
      pObjectName = pObjectName_;
      return *this;
    }

    operator VkDebugUtilsObjectNameInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugUtilsObjectNameInfoEXT*>( this );
    }

    operator VkDebugUtilsObjectNameInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugUtilsObjectNameInfoEXT*>( this );
    }

    bool operator==( DebugUtilsObjectNameInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( objectType == rhs.objectType )
          && ( objectHandle == rhs.objectHandle )
          && ( pObjectName == rhs.pObjectName );
    }

    bool operator!=( DebugUtilsObjectNameInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugUtilsObjectNameInfoEXT::sType;
  };
  static_assert( sizeof( DebugUtilsObjectNameInfoEXT ) == sizeof( VkDebugUtilsObjectNameInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugUtilsObjectNameInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugUtilsMessengerCallbackDataEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DebugUtilsMessengerCallbackDataEXT( vk::DebugUtilsMessengerCallbackDataFlagsEXT flags_ = vk::DebugUtilsMessengerCallbackDataFlagsEXT(),
                                                               const char* pMessageIdName_ = nullptr,
                                                               int32_t messageIdNumber_ = 0,
                                                               const char* pMessage_ = nullptr,
                                                               uint32_t queueLabelCount_ = 0,
                                                               const vk::DebugUtilsLabelEXT* pQueueLabels_ = nullptr,
                                                               uint32_t cmdBufLabelCount_ = 0,
                                                               const vk::DebugUtilsLabelEXT* pCmdBufLabels_ = nullptr,
                                                               uint32_t objectCount_ = 0,
                                                               const vk::DebugUtilsObjectNameInfoEXT* pObjects_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pMessageIdName( pMessageIdName_ )
        , messageIdNumber( messageIdNumber_ )
        , pMessage( pMessage_ )
        , queueLabelCount( queueLabelCount_ )
        , pQueueLabels( pQueueLabels_ )
        , cmdBufLabelCount( cmdBufLabelCount_ )
        , pCmdBufLabels( pCmdBufLabels_ )
        , objectCount( objectCount_ )
        , pObjects( pObjects_ )
      {}

      DebugUtilsMessengerCallbackDataEXT( VkDebugUtilsMessengerCallbackDataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsMessengerCallbackDataEXT*>(this) = rhs;
      }

      DebugUtilsMessengerCallbackDataEXT& operator=( VkDebugUtilsMessengerCallbackDataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsMessengerCallbackDataEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugUtilsMessengerCallbackDataEXT;
      const void* pNext = nullptr;
      vk::DebugUtilsMessengerCallbackDataFlagsEXT flags;
      const char* pMessageIdName;
      int32_t messageIdNumber;
      const char* pMessage;
      uint32_t queueLabelCount;
      const vk::DebugUtilsLabelEXT* pQueueLabels;
      uint32_t cmdBufLabelCount;
      const vk::DebugUtilsLabelEXT* pCmdBufLabels;
      uint32_t objectCount;
      const vk::DebugUtilsObjectNameInfoEXT* pObjects;
    };
    static_assert( sizeof( DebugUtilsMessengerCallbackDataEXT ) == sizeof( VkDebugUtilsMessengerCallbackDataEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugUtilsMessengerCallbackDataEXT : public layout::DebugUtilsMessengerCallbackDataEXT
  {
    VULKAN_HPP_CONSTEXPR DebugUtilsMessengerCallbackDataEXT( vk::DebugUtilsMessengerCallbackDataFlagsEXT flags_ = vk::DebugUtilsMessengerCallbackDataFlagsEXT(),
                                                             const char* pMessageIdName_ = nullptr,
                                                             int32_t messageIdNumber_ = 0,
                                                             const char* pMessage_ = nullptr,
                                                             uint32_t queueLabelCount_ = 0,
                                                             const vk::DebugUtilsLabelEXT* pQueueLabels_ = nullptr,
                                                             uint32_t cmdBufLabelCount_ = 0,
                                                             const vk::DebugUtilsLabelEXT* pCmdBufLabels_ = nullptr,
                                                             uint32_t objectCount_ = 0,
                                                             const vk::DebugUtilsObjectNameInfoEXT* pObjects_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsMessengerCallbackDataEXT( flags_, pMessageIdName_, messageIdNumber_, pMessage_, queueLabelCount_, pQueueLabels_, cmdBufLabelCount_, pCmdBufLabels_, objectCount_, pObjects_ )
    {}

    DebugUtilsMessengerCallbackDataEXT( VkDebugUtilsMessengerCallbackDataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsMessengerCallbackDataEXT( rhs )
    {}

    DebugUtilsMessengerCallbackDataEXT& operator=( VkDebugUtilsMessengerCallbackDataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugUtilsMessengerCallbackDataEXT::operator=(rhs);
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setFlags( vk::DebugUtilsMessengerCallbackDataFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setPMessageIdName( const char* pMessageIdName_ ) VULKAN_HPP_NOEXCEPT
    {
      pMessageIdName = pMessageIdName_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setMessageIdNumber( int32_t messageIdNumber_ ) VULKAN_HPP_NOEXCEPT
    {
      messageIdNumber = messageIdNumber_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setPMessage( const char* pMessage_ ) VULKAN_HPP_NOEXCEPT
    {
      pMessage = pMessage_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setQueueLabelCount( uint32_t queueLabelCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queueLabelCount = queueLabelCount_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setPQueueLabels( const vk::DebugUtilsLabelEXT* pQueueLabels_ ) VULKAN_HPP_NOEXCEPT
    {
      pQueueLabels = pQueueLabels_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setCmdBufLabelCount( uint32_t cmdBufLabelCount_ ) VULKAN_HPP_NOEXCEPT
    {
      cmdBufLabelCount = cmdBufLabelCount_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setPCmdBufLabels( const vk::DebugUtilsLabelEXT* pCmdBufLabels_ ) VULKAN_HPP_NOEXCEPT
    {
      pCmdBufLabels = pCmdBufLabels_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setObjectCount( uint32_t objectCount_ ) VULKAN_HPP_NOEXCEPT
    {
      objectCount = objectCount_;
      return *this;
    }

    DebugUtilsMessengerCallbackDataEXT & setPObjects( const vk::DebugUtilsObjectNameInfoEXT* pObjects_ ) VULKAN_HPP_NOEXCEPT
    {
      pObjects = pObjects_;
      return *this;
    }

    operator VkDebugUtilsMessengerCallbackDataEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugUtilsMessengerCallbackDataEXT*>( this );
    }

    operator VkDebugUtilsMessengerCallbackDataEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugUtilsMessengerCallbackDataEXT*>( this );
    }

    bool operator==( DebugUtilsMessengerCallbackDataEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pMessageIdName == rhs.pMessageIdName )
          && ( messageIdNumber == rhs.messageIdNumber )
          && ( pMessage == rhs.pMessage )
          && ( queueLabelCount == rhs.queueLabelCount )
          && ( pQueueLabels == rhs.pQueueLabels )
          && ( cmdBufLabelCount == rhs.cmdBufLabelCount )
          && ( pCmdBufLabels == rhs.pCmdBufLabels )
          && ( objectCount == rhs.objectCount )
          && ( pObjects == rhs.pObjects );
    }

    bool operator!=( DebugUtilsMessengerCallbackDataEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugUtilsMessengerCallbackDataEXT::sType;
  };
  static_assert( sizeof( DebugUtilsMessengerCallbackDataEXT ) == sizeof( VkDebugUtilsMessengerCallbackDataEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugUtilsMessengerCallbackDataEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugUtilsMessengerCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DebugUtilsMessengerCreateInfoEXT( vk::DebugUtilsMessengerCreateFlagsEXT flags_ = vk::DebugUtilsMessengerCreateFlagsEXT(),
                                                             vk::DebugUtilsMessageSeverityFlagsEXT messageSeverity_ = vk::DebugUtilsMessageSeverityFlagsEXT(),
                                                             vk::DebugUtilsMessageTypeFlagsEXT messageType_ = vk::DebugUtilsMessageTypeFlagsEXT(),
                                                             PFN_vkDebugUtilsMessengerCallbackEXT pfnUserCallback_ = nullptr,
                                                             void* pUserData_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , messageSeverity( messageSeverity_ )
        , messageType( messageType_ )
        , pfnUserCallback( pfnUserCallback_ )
        , pUserData( pUserData_ )
      {}

      DebugUtilsMessengerCreateInfoEXT( VkDebugUtilsMessengerCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsMessengerCreateInfoEXT*>(this) = rhs;
      }

      DebugUtilsMessengerCreateInfoEXT& operator=( VkDebugUtilsMessengerCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsMessengerCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugUtilsMessengerCreateInfoEXT;
      const void* pNext = nullptr;
      vk::DebugUtilsMessengerCreateFlagsEXT flags;
      vk::DebugUtilsMessageSeverityFlagsEXT messageSeverity;
      vk::DebugUtilsMessageTypeFlagsEXT messageType;
      PFN_vkDebugUtilsMessengerCallbackEXT pfnUserCallback;
      void* pUserData;
    };
    static_assert( sizeof( DebugUtilsMessengerCreateInfoEXT ) == sizeof( VkDebugUtilsMessengerCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugUtilsMessengerCreateInfoEXT : public layout::DebugUtilsMessengerCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DebugUtilsMessengerCreateInfoEXT( vk::DebugUtilsMessengerCreateFlagsEXT flags_ = vk::DebugUtilsMessengerCreateFlagsEXT(),
                                                           vk::DebugUtilsMessageSeverityFlagsEXT messageSeverity_ = vk::DebugUtilsMessageSeverityFlagsEXT(),
                                                           vk::DebugUtilsMessageTypeFlagsEXT messageType_ = vk::DebugUtilsMessageTypeFlagsEXT(),
                                                           PFN_vkDebugUtilsMessengerCallbackEXT pfnUserCallback_ = nullptr,
                                                           void* pUserData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsMessengerCreateInfoEXT( flags_, messageSeverity_, messageType_, pfnUserCallback_, pUserData_ )
    {}

    DebugUtilsMessengerCreateInfoEXT( VkDebugUtilsMessengerCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsMessengerCreateInfoEXT( rhs )
    {}

    DebugUtilsMessengerCreateInfoEXT& operator=( VkDebugUtilsMessengerCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugUtilsMessengerCreateInfoEXT::operator=(rhs);
      return *this;
    }

    DebugUtilsMessengerCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugUtilsMessengerCreateInfoEXT & setFlags( vk::DebugUtilsMessengerCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DebugUtilsMessengerCreateInfoEXT & setMessageSeverity( vk::DebugUtilsMessageSeverityFlagsEXT messageSeverity_ ) VULKAN_HPP_NOEXCEPT
    {
      messageSeverity = messageSeverity_;
      return *this;
    }

    DebugUtilsMessengerCreateInfoEXT & setMessageType( vk::DebugUtilsMessageTypeFlagsEXT messageType_ ) VULKAN_HPP_NOEXCEPT
    {
      messageType = messageType_;
      return *this;
    }

    DebugUtilsMessengerCreateInfoEXT & setPfnUserCallback( PFN_vkDebugUtilsMessengerCallbackEXT pfnUserCallback_ ) VULKAN_HPP_NOEXCEPT
    {
      pfnUserCallback = pfnUserCallback_;
      return *this;
    }

    DebugUtilsMessengerCreateInfoEXT & setPUserData( void* pUserData_ ) VULKAN_HPP_NOEXCEPT
    {
      pUserData = pUserData_;
      return *this;
    }

    operator VkDebugUtilsMessengerCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugUtilsMessengerCreateInfoEXT*>( this );
    }

    operator VkDebugUtilsMessengerCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugUtilsMessengerCreateInfoEXT*>( this );
    }

    bool operator==( DebugUtilsMessengerCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( messageSeverity == rhs.messageSeverity )
          && ( messageType == rhs.messageType )
          && ( pfnUserCallback == rhs.pfnUserCallback )
          && ( pUserData == rhs.pUserData );
    }

    bool operator!=( DebugUtilsMessengerCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugUtilsMessengerCreateInfoEXT::sType;
  };
  static_assert( sizeof( DebugUtilsMessengerCreateInfoEXT ) == sizeof( VkDebugUtilsMessengerCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugUtilsMessengerCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DebugUtilsObjectTagInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DebugUtilsObjectTagInfoEXT( vk::ObjectType objectType_ = vk::ObjectType::eUnknown,
                                                       uint64_t objectHandle_ = 0,
                                                       uint64_t tagName_ = 0,
                                                       size_t tagSize_ = 0,
                                                       const void* pTag_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : objectType( objectType_ )
        , objectHandle( objectHandle_ )
        , tagName( tagName_ )
        , tagSize( tagSize_ )
        , pTag( pTag_ )
      {}

      DebugUtilsObjectTagInfoEXT( VkDebugUtilsObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsObjectTagInfoEXT*>(this) = rhs;
      }

      DebugUtilsObjectTagInfoEXT& operator=( VkDebugUtilsObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDebugUtilsObjectTagInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDebugUtilsObjectTagInfoEXT;
      const void* pNext = nullptr;
      vk::ObjectType objectType;
      uint64_t objectHandle;
      uint64_t tagName;
      size_t tagSize;
      const void* pTag;
    };
    static_assert( sizeof( DebugUtilsObjectTagInfoEXT ) == sizeof( VkDebugUtilsObjectTagInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DebugUtilsObjectTagInfoEXT : public layout::DebugUtilsObjectTagInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DebugUtilsObjectTagInfoEXT( vk::ObjectType objectType_ = vk::ObjectType::eUnknown,
                                                     uint64_t objectHandle_ = 0,
                                                     uint64_t tagName_ = 0,
                                                     size_t tagSize_ = 0,
                                                     const void* pTag_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsObjectTagInfoEXT( objectType_, objectHandle_, tagName_, tagSize_, pTag_ )
    {}

    DebugUtilsObjectTagInfoEXT( VkDebugUtilsObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DebugUtilsObjectTagInfoEXT( rhs )
    {}

    DebugUtilsObjectTagInfoEXT& operator=( VkDebugUtilsObjectTagInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DebugUtilsObjectTagInfoEXT::operator=(rhs);
      return *this;
    }

    DebugUtilsObjectTagInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DebugUtilsObjectTagInfoEXT & setObjectType( vk::ObjectType objectType_ ) VULKAN_HPP_NOEXCEPT
    {
      objectType = objectType_;
      return *this;
    }

    DebugUtilsObjectTagInfoEXT & setObjectHandle( uint64_t objectHandle_ ) VULKAN_HPP_NOEXCEPT
    {
      objectHandle = objectHandle_;
      return *this;
    }

    DebugUtilsObjectTagInfoEXT & setTagName( uint64_t tagName_ ) VULKAN_HPP_NOEXCEPT
    {
      tagName = tagName_;
      return *this;
    }

    DebugUtilsObjectTagInfoEXT & setTagSize( size_t tagSize_ ) VULKAN_HPP_NOEXCEPT
    {
      tagSize = tagSize_;
      return *this;
    }

    DebugUtilsObjectTagInfoEXT & setPTag( const void* pTag_ ) VULKAN_HPP_NOEXCEPT
    {
      pTag = pTag_;
      return *this;
    }

    operator VkDebugUtilsObjectTagInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDebugUtilsObjectTagInfoEXT*>( this );
    }

    operator VkDebugUtilsObjectTagInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDebugUtilsObjectTagInfoEXT*>( this );
    }

    bool operator==( DebugUtilsObjectTagInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( objectType == rhs.objectType )
          && ( objectHandle == rhs.objectHandle )
          && ( tagName == rhs.tagName )
          && ( tagSize == rhs.tagSize )
          && ( pTag == rhs.pTag );
    }

    bool operator!=( DebugUtilsObjectTagInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DebugUtilsObjectTagInfoEXT::sType;
  };
  static_assert( sizeof( DebugUtilsObjectTagInfoEXT ) == sizeof( VkDebugUtilsObjectTagInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DebugUtilsObjectTagInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DedicatedAllocationBufferCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR DedicatedAllocationBufferCreateInfoNV( vk::Bool32 dedicatedAllocation_ = 0 ) VULKAN_HPP_NOEXCEPT
        : dedicatedAllocation( dedicatedAllocation_ )
      {}

      DedicatedAllocationBufferCreateInfoNV( VkDedicatedAllocationBufferCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDedicatedAllocationBufferCreateInfoNV*>(this) = rhs;
      }

      DedicatedAllocationBufferCreateInfoNV& operator=( VkDedicatedAllocationBufferCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDedicatedAllocationBufferCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDedicatedAllocationBufferCreateInfoNV;
      const void* pNext = nullptr;
      vk::Bool32 dedicatedAllocation;
    };
    static_assert( sizeof( DedicatedAllocationBufferCreateInfoNV ) == sizeof( VkDedicatedAllocationBufferCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct DedicatedAllocationBufferCreateInfoNV : public layout::DedicatedAllocationBufferCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR DedicatedAllocationBufferCreateInfoNV( vk::Bool32 dedicatedAllocation_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DedicatedAllocationBufferCreateInfoNV( dedicatedAllocation_ )
    {}

    DedicatedAllocationBufferCreateInfoNV( VkDedicatedAllocationBufferCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DedicatedAllocationBufferCreateInfoNV( rhs )
    {}

    DedicatedAllocationBufferCreateInfoNV& operator=( VkDedicatedAllocationBufferCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DedicatedAllocationBufferCreateInfoNV::operator=(rhs);
      return *this;
    }

    DedicatedAllocationBufferCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DedicatedAllocationBufferCreateInfoNV & setDedicatedAllocation( vk::Bool32 dedicatedAllocation_ ) VULKAN_HPP_NOEXCEPT
    {
      dedicatedAllocation = dedicatedAllocation_;
      return *this;
    }

    operator VkDedicatedAllocationBufferCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDedicatedAllocationBufferCreateInfoNV*>( this );
    }

    operator VkDedicatedAllocationBufferCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDedicatedAllocationBufferCreateInfoNV*>( this );
    }

    bool operator==( DedicatedAllocationBufferCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( dedicatedAllocation == rhs.dedicatedAllocation );
    }

    bool operator!=( DedicatedAllocationBufferCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DedicatedAllocationBufferCreateInfoNV::sType;
  };
  static_assert( sizeof( DedicatedAllocationBufferCreateInfoNV ) == sizeof( VkDedicatedAllocationBufferCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DedicatedAllocationBufferCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DedicatedAllocationImageCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR DedicatedAllocationImageCreateInfoNV( vk::Bool32 dedicatedAllocation_ = 0 ) VULKAN_HPP_NOEXCEPT
        : dedicatedAllocation( dedicatedAllocation_ )
      {}

      DedicatedAllocationImageCreateInfoNV( VkDedicatedAllocationImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDedicatedAllocationImageCreateInfoNV*>(this) = rhs;
      }

      DedicatedAllocationImageCreateInfoNV& operator=( VkDedicatedAllocationImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDedicatedAllocationImageCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDedicatedAllocationImageCreateInfoNV;
      const void* pNext = nullptr;
      vk::Bool32 dedicatedAllocation;
    };
    static_assert( sizeof( DedicatedAllocationImageCreateInfoNV ) == sizeof( VkDedicatedAllocationImageCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct DedicatedAllocationImageCreateInfoNV : public layout::DedicatedAllocationImageCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR DedicatedAllocationImageCreateInfoNV( vk::Bool32 dedicatedAllocation_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DedicatedAllocationImageCreateInfoNV( dedicatedAllocation_ )
    {}

    DedicatedAllocationImageCreateInfoNV( VkDedicatedAllocationImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DedicatedAllocationImageCreateInfoNV( rhs )
    {}

    DedicatedAllocationImageCreateInfoNV& operator=( VkDedicatedAllocationImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DedicatedAllocationImageCreateInfoNV::operator=(rhs);
      return *this;
    }

    DedicatedAllocationImageCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DedicatedAllocationImageCreateInfoNV & setDedicatedAllocation( vk::Bool32 dedicatedAllocation_ ) VULKAN_HPP_NOEXCEPT
    {
      dedicatedAllocation = dedicatedAllocation_;
      return *this;
    }

    operator VkDedicatedAllocationImageCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDedicatedAllocationImageCreateInfoNV*>( this );
    }

    operator VkDedicatedAllocationImageCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDedicatedAllocationImageCreateInfoNV*>( this );
    }

    bool operator==( DedicatedAllocationImageCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( dedicatedAllocation == rhs.dedicatedAllocation );
    }

    bool operator!=( DedicatedAllocationImageCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DedicatedAllocationImageCreateInfoNV::sType;
  };
  static_assert( sizeof( DedicatedAllocationImageCreateInfoNV ) == sizeof( VkDedicatedAllocationImageCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DedicatedAllocationImageCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DedicatedAllocationMemoryAllocateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR DedicatedAllocationMemoryAllocateInfoNV( vk::Image image_ = vk::Image(),
                                                                    vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
        : image( image_ )
        , buffer( buffer_ )
      {}

      DedicatedAllocationMemoryAllocateInfoNV( VkDedicatedAllocationMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDedicatedAllocationMemoryAllocateInfoNV*>(this) = rhs;
      }

      DedicatedAllocationMemoryAllocateInfoNV& operator=( VkDedicatedAllocationMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDedicatedAllocationMemoryAllocateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDedicatedAllocationMemoryAllocateInfoNV;
      const void* pNext = nullptr;
      vk::Image image;
      vk::Buffer buffer;
    };
    static_assert( sizeof( DedicatedAllocationMemoryAllocateInfoNV ) == sizeof( VkDedicatedAllocationMemoryAllocateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct DedicatedAllocationMemoryAllocateInfoNV : public layout::DedicatedAllocationMemoryAllocateInfoNV
  {
    VULKAN_HPP_CONSTEXPR DedicatedAllocationMemoryAllocateInfoNV( vk::Image image_ = vk::Image(),
                                                                  vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
      : layout::DedicatedAllocationMemoryAllocateInfoNV( image_, buffer_ )
    {}

    DedicatedAllocationMemoryAllocateInfoNV( VkDedicatedAllocationMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DedicatedAllocationMemoryAllocateInfoNV( rhs )
    {}

    DedicatedAllocationMemoryAllocateInfoNV& operator=( VkDedicatedAllocationMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DedicatedAllocationMemoryAllocateInfoNV::operator=(rhs);
      return *this;
    }

    DedicatedAllocationMemoryAllocateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DedicatedAllocationMemoryAllocateInfoNV & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    DedicatedAllocationMemoryAllocateInfoNV & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    operator VkDedicatedAllocationMemoryAllocateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDedicatedAllocationMemoryAllocateInfoNV*>( this );
    }

    operator VkDedicatedAllocationMemoryAllocateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDedicatedAllocationMemoryAllocateInfoNV*>( this );
    }

    bool operator==( DedicatedAllocationMemoryAllocateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( image == rhs.image )
          && ( buffer == rhs.buffer );
    }

    bool operator!=( DedicatedAllocationMemoryAllocateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DedicatedAllocationMemoryAllocateInfoNV::sType;
  };
  static_assert( sizeof( DedicatedAllocationMemoryAllocateInfoNV ) == sizeof( VkDedicatedAllocationMemoryAllocateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DedicatedAllocationMemoryAllocateInfoNV>::value, "struct wrapper is not a standard layout!" );

  struct DescriptorBufferInfo
  {
    VULKAN_HPP_CONSTEXPR DescriptorBufferInfo( vk::Buffer buffer_ = vk::Buffer(),
                                               vk::DeviceSize offset_ = 0,
                                               vk::DeviceSize range_ = 0 ) VULKAN_HPP_NOEXCEPT
      : buffer( buffer_ )
      , offset( offset_ )
      , range( range_ )
    {}

    DescriptorBufferInfo( VkDescriptorBufferInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorBufferInfo*>(this) = rhs;
    }

    DescriptorBufferInfo& operator=( VkDescriptorBufferInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorBufferInfo*>(this) = rhs;
      return *this;
    }

    DescriptorBufferInfo & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    DescriptorBufferInfo & setOffset( vk::DeviceSize offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    DescriptorBufferInfo & setRange( vk::DeviceSize range_ ) VULKAN_HPP_NOEXCEPT
    {
      range = range_;
      return *this;
    }

    operator VkDescriptorBufferInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorBufferInfo*>( this );
    }

    operator VkDescriptorBufferInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorBufferInfo*>( this );
    }

    bool operator==( DescriptorBufferInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( buffer == rhs.buffer )
          && ( offset == rhs.offset )
          && ( range == rhs.range );
    }

    bool operator!=( DescriptorBufferInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Buffer buffer;
    vk::DeviceSize offset;
    vk::DeviceSize range;
  };
  static_assert( sizeof( DescriptorBufferInfo ) == sizeof( VkDescriptorBufferInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorBufferInfo>::value, "struct wrapper is not a standard layout!" );

  struct DescriptorImageInfo
  {
    VULKAN_HPP_CONSTEXPR DescriptorImageInfo( vk::Sampler sampler_ = vk::Sampler(),
                                              vk::ImageView imageView_ = vk::ImageView(),
                                              vk::ImageLayout imageLayout_ = vk::ImageLayout::eUndefined ) VULKAN_HPP_NOEXCEPT
      : sampler( sampler_ )
      , imageView( imageView_ )
      , imageLayout( imageLayout_ )
    {}

    DescriptorImageInfo( VkDescriptorImageInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorImageInfo*>(this) = rhs;
    }

    DescriptorImageInfo& operator=( VkDescriptorImageInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorImageInfo*>(this) = rhs;
      return *this;
    }

    DescriptorImageInfo & setSampler( vk::Sampler sampler_ ) VULKAN_HPP_NOEXCEPT
    {
      sampler = sampler_;
      return *this;
    }

    DescriptorImageInfo & setImageView( vk::ImageView imageView_ ) VULKAN_HPP_NOEXCEPT
    {
      imageView = imageView_;
      return *this;
    }

    DescriptorImageInfo & setImageLayout( vk::ImageLayout imageLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      imageLayout = imageLayout_;
      return *this;
    }

    operator VkDescriptorImageInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorImageInfo*>( this );
    }

    operator VkDescriptorImageInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorImageInfo*>( this );
    }

    bool operator==( DescriptorImageInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sampler == rhs.sampler )
          && ( imageView == rhs.imageView )
          && ( imageLayout == rhs.imageLayout );
    }

    bool operator!=( DescriptorImageInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Sampler sampler;
    vk::ImageView imageView;
    vk::ImageLayout imageLayout;
  };
  static_assert( sizeof( DescriptorImageInfo ) == sizeof( VkDescriptorImageInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorImageInfo>::value, "struct wrapper is not a standard layout!" );

  struct DescriptorPoolSize
  {
    VULKAN_HPP_CONSTEXPR DescriptorPoolSize( vk::DescriptorType type_ = vk::DescriptorType::eSampler,
                                             uint32_t descriptorCount_ = 0 ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , descriptorCount( descriptorCount_ )
    {}

    DescriptorPoolSize( VkDescriptorPoolSize const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorPoolSize*>(this) = rhs;
    }

    DescriptorPoolSize& operator=( VkDescriptorPoolSize const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorPoolSize*>(this) = rhs;
      return *this;
    }

    DescriptorPoolSize & setType( vk::DescriptorType type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    DescriptorPoolSize & setDescriptorCount( uint32_t descriptorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorCount = descriptorCount_;
      return *this;
    }

    operator VkDescriptorPoolSize const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorPoolSize*>( this );
    }

    operator VkDescriptorPoolSize &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorPoolSize*>( this );
    }

    bool operator==( DescriptorPoolSize const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( type == rhs.type )
          && ( descriptorCount == rhs.descriptorCount );
    }

    bool operator!=( DescriptorPoolSize const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DescriptorType type;
    uint32_t descriptorCount;
  };
  static_assert( sizeof( DescriptorPoolSize ) == sizeof( VkDescriptorPoolSize ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorPoolSize>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorPoolCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DescriptorPoolCreateInfo( vk::DescriptorPoolCreateFlags flags_ = vk::DescriptorPoolCreateFlags(),
                                                     uint32_t maxSets_ = 0,
                                                     uint32_t poolSizeCount_ = 0,
                                                     const vk::DescriptorPoolSize* pPoolSizes_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , maxSets( maxSets_ )
        , poolSizeCount( poolSizeCount_ )
        , pPoolSizes( pPoolSizes_ )
      {}

      DescriptorPoolCreateInfo( VkDescriptorPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorPoolCreateInfo*>(this) = rhs;
      }

      DescriptorPoolCreateInfo& operator=( VkDescriptorPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorPoolCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorPoolCreateInfo;
      const void* pNext = nullptr;
      vk::DescriptorPoolCreateFlags flags;
      uint32_t maxSets;
      uint32_t poolSizeCount;
      const vk::DescriptorPoolSize* pPoolSizes;
    };
    static_assert( sizeof( DescriptorPoolCreateInfo ) == sizeof( VkDescriptorPoolCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorPoolCreateInfo : public layout::DescriptorPoolCreateInfo
  {
    VULKAN_HPP_CONSTEXPR DescriptorPoolCreateInfo( vk::DescriptorPoolCreateFlags flags_ = vk::DescriptorPoolCreateFlags(),
                                                   uint32_t maxSets_ = 0,
                                                   uint32_t poolSizeCount_ = 0,
                                                   const vk::DescriptorPoolSize* pPoolSizes_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorPoolCreateInfo( flags_, maxSets_, poolSizeCount_, pPoolSizes_ )
    {}

    DescriptorPoolCreateInfo( VkDescriptorPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorPoolCreateInfo( rhs )
    {}

    DescriptorPoolCreateInfo& operator=( VkDescriptorPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorPoolCreateInfo::operator=(rhs);
      return *this;
    }

    DescriptorPoolCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DescriptorPoolCreateInfo & setFlags( vk::DescriptorPoolCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DescriptorPoolCreateInfo & setMaxSets( uint32_t maxSets_ ) VULKAN_HPP_NOEXCEPT
    {
      maxSets = maxSets_;
      return *this;
    }

    DescriptorPoolCreateInfo & setPoolSizeCount( uint32_t poolSizeCount_ ) VULKAN_HPP_NOEXCEPT
    {
      poolSizeCount = poolSizeCount_;
      return *this;
    }

    DescriptorPoolCreateInfo & setPPoolSizes( const vk::DescriptorPoolSize* pPoolSizes_ ) VULKAN_HPP_NOEXCEPT
    {
      pPoolSizes = pPoolSizes_;
      return *this;
    }

    operator VkDescriptorPoolCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorPoolCreateInfo*>( this );
    }

    operator VkDescriptorPoolCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorPoolCreateInfo*>( this );
    }

    bool operator==( DescriptorPoolCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( maxSets == rhs.maxSets )
          && ( poolSizeCount == rhs.poolSizeCount )
          && ( pPoolSizes == rhs.pPoolSizes );
    }

    bool operator!=( DescriptorPoolCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorPoolCreateInfo::sType;
  };
  static_assert( sizeof( DescriptorPoolCreateInfo ) == sizeof( VkDescriptorPoolCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorPoolCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorPoolInlineUniformBlockCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DescriptorPoolInlineUniformBlockCreateInfoEXT( uint32_t maxInlineUniformBlockBindings_ = 0 ) VULKAN_HPP_NOEXCEPT
        : maxInlineUniformBlockBindings( maxInlineUniformBlockBindings_ )
      {}

      DescriptorPoolInlineUniformBlockCreateInfoEXT( VkDescriptorPoolInlineUniformBlockCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorPoolInlineUniformBlockCreateInfoEXT*>(this) = rhs;
      }

      DescriptorPoolInlineUniformBlockCreateInfoEXT& operator=( VkDescriptorPoolInlineUniformBlockCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorPoolInlineUniformBlockCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorPoolInlineUniformBlockCreateInfoEXT;
      const void* pNext = nullptr;
      uint32_t maxInlineUniformBlockBindings;
    };
    static_assert( sizeof( DescriptorPoolInlineUniformBlockCreateInfoEXT ) == sizeof( VkDescriptorPoolInlineUniformBlockCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorPoolInlineUniformBlockCreateInfoEXT : public layout::DescriptorPoolInlineUniformBlockCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DescriptorPoolInlineUniformBlockCreateInfoEXT( uint32_t maxInlineUniformBlockBindings_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorPoolInlineUniformBlockCreateInfoEXT( maxInlineUniformBlockBindings_ )
    {}

    DescriptorPoolInlineUniformBlockCreateInfoEXT( VkDescriptorPoolInlineUniformBlockCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorPoolInlineUniformBlockCreateInfoEXT( rhs )
    {}

    DescriptorPoolInlineUniformBlockCreateInfoEXT& operator=( VkDescriptorPoolInlineUniformBlockCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorPoolInlineUniformBlockCreateInfoEXT::operator=(rhs);
      return *this;
    }

    DescriptorPoolInlineUniformBlockCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DescriptorPoolInlineUniformBlockCreateInfoEXT & setMaxInlineUniformBlockBindings( uint32_t maxInlineUniformBlockBindings_ ) VULKAN_HPP_NOEXCEPT
    {
      maxInlineUniformBlockBindings = maxInlineUniformBlockBindings_;
      return *this;
    }

    operator VkDescriptorPoolInlineUniformBlockCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorPoolInlineUniformBlockCreateInfoEXT*>( this );
    }

    operator VkDescriptorPoolInlineUniformBlockCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorPoolInlineUniformBlockCreateInfoEXT*>( this );
    }

    bool operator==( DescriptorPoolInlineUniformBlockCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxInlineUniformBlockBindings == rhs.maxInlineUniformBlockBindings );
    }

    bool operator!=( DescriptorPoolInlineUniformBlockCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorPoolInlineUniformBlockCreateInfoEXT::sType;
  };
  static_assert( sizeof( DescriptorPoolInlineUniformBlockCreateInfoEXT ) == sizeof( VkDescriptorPoolInlineUniformBlockCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorPoolInlineUniformBlockCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorSetAllocateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DescriptorSetAllocateInfo( vk::DescriptorPool descriptorPool_ = vk::DescriptorPool(),
                                                      uint32_t descriptorSetCount_ = 0,
                                                      const vk::DescriptorSetLayout* pSetLayouts_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : descriptorPool( descriptorPool_ )
        , descriptorSetCount( descriptorSetCount_ )
        , pSetLayouts( pSetLayouts_ )
      {}

      DescriptorSetAllocateInfo( VkDescriptorSetAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetAllocateInfo*>(this) = rhs;
      }

      DescriptorSetAllocateInfo& operator=( VkDescriptorSetAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetAllocateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorSetAllocateInfo;
      const void* pNext = nullptr;
      vk::DescriptorPool descriptorPool;
      uint32_t descriptorSetCount;
      const vk::DescriptorSetLayout* pSetLayouts;
    };
    static_assert( sizeof( DescriptorSetAllocateInfo ) == sizeof( VkDescriptorSetAllocateInfo ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorSetAllocateInfo : public layout::DescriptorSetAllocateInfo
  {
    VULKAN_HPP_CONSTEXPR DescriptorSetAllocateInfo( vk::DescriptorPool descriptorPool_ = vk::DescriptorPool(),
                                                    uint32_t descriptorSetCount_ = 0,
                                                    const vk::DescriptorSetLayout* pSetLayouts_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetAllocateInfo( descriptorPool_, descriptorSetCount_, pSetLayouts_ )
    {}

    DescriptorSetAllocateInfo( VkDescriptorSetAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetAllocateInfo( rhs )
    {}

    DescriptorSetAllocateInfo& operator=( VkDescriptorSetAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorSetAllocateInfo::operator=(rhs);
      return *this;
    }

    DescriptorSetAllocateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DescriptorSetAllocateInfo & setDescriptorPool( vk::DescriptorPool descriptorPool_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorPool = descriptorPool_;
      return *this;
    }

    DescriptorSetAllocateInfo & setDescriptorSetCount( uint32_t descriptorSetCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorSetCount = descriptorSetCount_;
      return *this;
    }

    DescriptorSetAllocateInfo & setPSetLayouts( const vk::DescriptorSetLayout* pSetLayouts_ ) VULKAN_HPP_NOEXCEPT
    {
      pSetLayouts = pSetLayouts_;
      return *this;
    }

    operator VkDescriptorSetAllocateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorSetAllocateInfo*>( this );
    }

    operator VkDescriptorSetAllocateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorSetAllocateInfo*>( this );
    }

    bool operator==( DescriptorSetAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( descriptorPool == rhs.descriptorPool )
          && ( descriptorSetCount == rhs.descriptorSetCount )
          && ( pSetLayouts == rhs.pSetLayouts );
    }

    bool operator!=( DescriptorSetAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorSetAllocateInfo::sType;
  };
  static_assert( sizeof( DescriptorSetAllocateInfo ) == sizeof( VkDescriptorSetAllocateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorSetAllocateInfo>::value, "struct wrapper is not a standard layout!" );

  struct DescriptorSetLayoutBinding
  {
    VULKAN_HPP_CONSTEXPR DescriptorSetLayoutBinding( uint32_t binding_ = 0,
                                                     vk::DescriptorType descriptorType_ = vk::DescriptorType::eSampler,
                                                     uint32_t descriptorCount_ = 0,
                                                     vk::ShaderStageFlags stageFlags_ = vk::ShaderStageFlags(),
                                                     const vk::Sampler* pImmutableSamplers_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : binding( binding_ )
      , descriptorType( descriptorType_ )
      , descriptorCount( descriptorCount_ )
      , stageFlags( stageFlags_ )
      , pImmutableSamplers( pImmutableSamplers_ )
    {}

    DescriptorSetLayoutBinding( VkDescriptorSetLayoutBinding const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorSetLayoutBinding*>(this) = rhs;
    }

    DescriptorSetLayoutBinding& operator=( VkDescriptorSetLayoutBinding const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorSetLayoutBinding*>(this) = rhs;
      return *this;
    }

    DescriptorSetLayoutBinding & setBinding( uint32_t binding_ ) VULKAN_HPP_NOEXCEPT
    {
      binding = binding_;
      return *this;
    }

    DescriptorSetLayoutBinding & setDescriptorType( vk::DescriptorType descriptorType_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorType = descriptorType_;
      return *this;
    }

    DescriptorSetLayoutBinding & setDescriptorCount( uint32_t descriptorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorCount = descriptorCount_;
      return *this;
    }

    DescriptorSetLayoutBinding & setStageFlags( vk::ShaderStageFlags stageFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      stageFlags = stageFlags_;
      return *this;
    }

    DescriptorSetLayoutBinding & setPImmutableSamplers( const vk::Sampler* pImmutableSamplers_ ) VULKAN_HPP_NOEXCEPT
    {
      pImmutableSamplers = pImmutableSamplers_;
      return *this;
    }

    operator VkDescriptorSetLayoutBinding const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorSetLayoutBinding*>( this );
    }

    operator VkDescriptorSetLayoutBinding &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorSetLayoutBinding*>( this );
    }

    bool operator==( DescriptorSetLayoutBinding const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( binding == rhs.binding )
          && ( descriptorType == rhs.descriptorType )
          && ( descriptorCount == rhs.descriptorCount )
          && ( stageFlags == rhs.stageFlags )
          && ( pImmutableSamplers == rhs.pImmutableSamplers );
    }

    bool operator!=( DescriptorSetLayoutBinding const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t binding;
    vk::DescriptorType descriptorType;
    uint32_t descriptorCount;
    vk::ShaderStageFlags stageFlags;
    const vk::Sampler* pImmutableSamplers;
  };
  static_assert( sizeof( DescriptorSetLayoutBinding ) == sizeof( VkDescriptorSetLayoutBinding ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorSetLayoutBinding>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorSetLayoutBindingFlagsCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DescriptorSetLayoutBindingFlagsCreateInfoEXT( uint32_t bindingCount_ = 0,
                                                                         const vk::DescriptorBindingFlagsEXT* pBindingFlags_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : bindingCount( bindingCount_ )
        , pBindingFlags( pBindingFlags_ )
      {}

      DescriptorSetLayoutBindingFlagsCreateInfoEXT( VkDescriptorSetLayoutBindingFlagsCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetLayoutBindingFlagsCreateInfoEXT*>(this) = rhs;
      }

      DescriptorSetLayoutBindingFlagsCreateInfoEXT& operator=( VkDescriptorSetLayoutBindingFlagsCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetLayoutBindingFlagsCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorSetLayoutBindingFlagsCreateInfoEXT;
      const void* pNext = nullptr;
      uint32_t bindingCount;
      const vk::DescriptorBindingFlagsEXT* pBindingFlags;
    };
    static_assert( sizeof( DescriptorSetLayoutBindingFlagsCreateInfoEXT ) == sizeof( VkDescriptorSetLayoutBindingFlagsCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorSetLayoutBindingFlagsCreateInfoEXT : public layout::DescriptorSetLayoutBindingFlagsCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DescriptorSetLayoutBindingFlagsCreateInfoEXT( uint32_t bindingCount_ = 0,
                                                                       const vk::DescriptorBindingFlagsEXT* pBindingFlags_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetLayoutBindingFlagsCreateInfoEXT( bindingCount_, pBindingFlags_ )
    {}

    DescriptorSetLayoutBindingFlagsCreateInfoEXT( VkDescriptorSetLayoutBindingFlagsCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetLayoutBindingFlagsCreateInfoEXT( rhs )
    {}

    DescriptorSetLayoutBindingFlagsCreateInfoEXT& operator=( VkDescriptorSetLayoutBindingFlagsCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorSetLayoutBindingFlagsCreateInfoEXT::operator=(rhs);
      return *this;
    }

    DescriptorSetLayoutBindingFlagsCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DescriptorSetLayoutBindingFlagsCreateInfoEXT & setBindingCount( uint32_t bindingCount_ ) VULKAN_HPP_NOEXCEPT
    {
      bindingCount = bindingCount_;
      return *this;
    }

    DescriptorSetLayoutBindingFlagsCreateInfoEXT & setPBindingFlags( const vk::DescriptorBindingFlagsEXT* pBindingFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      pBindingFlags = pBindingFlags_;
      return *this;
    }

    operator VkDescriptorSetLayoutBindingFlagsCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorSetLayoutBindingFlagsCreateInfoEXT*>( this );
    }

    operator VkDescriptorSetLayoutBindingFlagsCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorSetLayoutBindingFlagsCreateInfoEXT*>( this );
    }

    bool operator==( DescriptorSetLayoutBindingFlagsCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( bindingCount == rhs.bindingCount )
          && ( pBindingFlags == rhs.pBindingFlags );
    }

    bool operator!=( DescriptorSetLayoutBindingFlagsCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorSetLayoutBindingFlagsCreateInfoEXT::sType;
  };
  static_assert( sizeof( DescriptorSetLayoutBindingFlagsCreateInfoEXT ) == sizeof( VkDescriptorSetLayoutBindingFlagsCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorSetLayoutBindingFlagsCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorSetLayoutCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DescriptorSetLayoutCreateInfo( vk::DescriptorSetLayoutCreateFlags flags_ = vk::DescriptorSetLayoutCreateFlags(),
                                                          uint32_t bindingCount_ = 0,
                                                          const vk::DescriptorSetLayoutBinding* pBindings_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , bindingCount( bindingCount_ )
        , pBindings( pBindings_ )
      {}

      DescriptorSetLayoutCreateInfo( VkDescriptorSetLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetLayoutCreateInfo*>(this) = rhs;
      }

      DescriptorSetLayoutCreateInfo& operator=( VkDescriptorSetLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetLayoutCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorSetLayoutCreateInfo;
      const void* pNext = nullptr;
      vk::DescriptorSetLayoutCreateFlags flags;
      uint32_t bindingCount;
      const vk::DescriptorSetLayoutBinding* pBindings;
    };
    static_assert( sizeof( DescriptorSetLayoutCreateInfo ) == sizeof( VkDescriptorSetLayoutCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorSetLayoutCreateInfo : public layout::DescriptorSetLayoutCreateInfo
  {
    VULKAN_HPP_CONSTEXPR DescriptorSetLayoutCreateInfo( vk::DescriptorSetLayoutCreateFlags flags_ = vk::DescriptorSetLayoutCreateFlags(),
                                                        uint32_t bindingCount_ = 0,
                                                        const vk::DescriptorSetLayoutBinding* pBindings_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetLayoutCreateInfo( flags_, bindingCount_, pBindings_ )
    {}

    DescriptorSetLayoutCreateInfo( VkDescriptorSetLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetLayoutCreateInfo( rhs )
    {}

    DescriptorSetLayoutCreateInfo& operator=( VkDescriptorSetLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorSetLayoutCreateInfo::operator=(rhs);
      return *this;
    }

    DescriptorSetLayoutCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DescriptorSetLayoutCreateInfo & setFlags( vk::DescriptorSetLayoutCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DescriptorSetLayoutCreateInfo & setBindingCount( uint32_t bindingCount_ ) VULKAN_HPP_NOEXCEPT
    {
      bindingCount = bindingCount_;
      return *this;
    }

    DescriptorSetLayoutCreateInfo & setPBindings( const vk::DescriptorSetLayoutBinding* pBindings_ ) VULKAN_HPP_NOEXCEPT
    {
      pBindings = pBindings_;
      return *this;
    }

    operator VkDescriptorSetLayoutCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( this );
    }

    operator VkDescriptorSetLayoutCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorSetLayoutCreateInfo*>( this );
    }

    bool operator==( DescriptorSetLayoutCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( bindingCount == rhs.bindingCount )
          && ( pBindings == rhs.pBindings );
    }

    bool operator!=( DescriptorSetLayoutCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorSetLayoutCreateInfo::sType;
  };
  static_assert( sizeof( DescriptorSetLayoutCreateInfo ) == sizeof( VkDescriptorSetLayoutCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorSetLayoutCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorSetLayoutSupport
    {
    protected:
      DescriptorSetLayoutSupport() VULKAN_HPP_NOEXCEPT
      {}

      DescriptorSetLayoutSupport( VkDescriptorSetLayoutSupport const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetLayoutSupport*>(this) = rhs;
      }

      DescriptorSetLayoutSupport& operator=( VkDescriptorSetLayoutSupport const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetLayoutSupport*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorSetLayoutSupport;
      void* pNext = nullptr;
      vk::Bool32 supported;
    };
    static_assert( sizeof( DescriptorSetLayoutSupport ) == sizeof( VkDescriptorSetLayoutSupport ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorSetLayoutSupport : public layout::DescriptorSetLayoutSupport
  {
    DescriptorSetLayoutSupport() VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetLayoutSupport()
    {}

    DescriptorSetLayoutSupport( VkDescriptorSetLayoutSupport const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetLayoutSupport( rhs )
    {}

    DescriptorSetLayoutSupport& operator=( VkDescriptorSetLayoutSupport const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorSetLayoutSupport::operator=(rhs);
      return *this;
    }

    operator VkDescriptorSetLayoutSupport const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorSetLayoutSupport*>( this );
    }

    operator VkDescriptorSetLayoutSupport &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorSetLayoutSupport*>( this );
    }

    bool operator==( DescriptorSetLayoutSupport const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( supported == rhs.supported );
    }

    bool operator!=( DescriptorSetLayoutSupport const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorSetLayoutSupport::sType;
  };
  static_assert( sizeof( DescriptorSetLayoutSupport ) == sizeof( VkDescriptorSetLayoutSupport ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorSetLayoutSupport>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorSetVariableDescriptorCountAllocateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DescriptorSetVariableDescriptorCountAllocateInfoEXT( uint32_t descriptorSetCount_ = 0,
                                                                                const uint32_t* pDescriptorCounts_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : descriptorSetCount( descriptorSetCount_ )
        , pDescriptorCounts( pDescriptorCounts_ )
      {}

      DescriptorSetVariableDescriptorCountAllocateInfoEXT( VkDescriptorSetVariableDescriptorCountAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetVariableDescriptorCountAllocateInfoEXT*>(this) = rhs;
      }

      DescriptorSetVariableDescriptorCountAllocateInfoEXT& operator=( VkDescriptorSetVariableDescriptorCountAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetVariableDescriptorCountAllocateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorSetVariableDescriptorCountAllocateInfoEXT;
      const void* pNext = nullptr;
      uint32_t descriptorSetCount;
      const uint32_t* pDescriptorCounts;
    };
    static_assert( sizeof( DescriptorSetVariableDescriptorCountAllocateInfoEXT ) == sizeof( VkDescriptorSetVariableDescriptorCountAllocateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorSetVariableDescriptorCountAllocateInfoEXT : public layout::DescriptorSetVariableDescriptorCountAllocateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DescriptorSetVariableDescriptorCountAllocateInfoEXT( uint32_t descriptorSetCount_ = 0,
                                                                              const uint32_t* pDescriptorCounts_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetVariableDescriptorCountAllocateInfoEXT( descriptorSetCount_, pDescriptorCounts_ )
    {}

    DescriptorSetVariableDescriptorCountAllocateInfoEXT( VkDescriptorSetVariableDescriptorCountAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetVariableDescriptorCountAllocateInfoEXT( rhs )
    {}

    DescriptorSetVariableDescriptorCountAllocateInfoEXT& operator=( VkDescriptorSetVariableDescriptorCountAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorSetVariableDescriptorCountAllocateInfoEXT::operator=(rhs);
      return *this;
    }

    DescriptorSetVariableDescriptorCountAllocateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DescriptorSetVariableDescriptorCountAllocateInfoEXT & setDescriptorSetCount( uint32_t descriptorSetCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorSetCount = descriptorSetCount_;
      return *this;
    }

    DescriptorSetVariableDescriptorCountAllocateInfoEXT & setPDescriptorCounts( const uint32_t* pDescriptorCounts_ ) VULKAN_HPP_NOEXCEPT
    {
      pDescriptorCounts = pDescriptorCounts_;
      return *this;
    }

    operator VkDescriptorSetVariableDescriptorCountAllocateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorSetVariableDescriptorCountAllocateInfoEXT*>( this );
    }

    operator VkDescriptorSetVariableDescriptorCountAllocateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorSetVariableDescriptorCountAllocateInfoEXT*>( this );
    }

    bool operator==( DescriptorSetVariableDescriptorCountAllocateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( descriptorSetCount == rhs.descriptorSetCount )
          && ( pDescriptorCounts == rhs.pDescriptorCounts );
    }

    bool operator!=( DescriptorSetVariableDescriptorCountAllocateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorSetVariableDescriptorCountAllocateInfoEXT::sType;
  };
  static_assert( sizeof( DescriptorSetVariableDescriptorCountAllocateInfoEXT ) == sizeof( VkDescriptorSetVariableDescriptorCountAllocateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorSetVariableDescriptorCountAllocateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorSetVariableDescriptorCountLayoutSupportEXT
    {
    protected:
      DescriptorSetVariableDescriptorCountLayoutSupportEXT() VULKAN_HPP_NOEXCEPT
      {}

      DescriptorSetVariableDescriptorCountLayoutSupportEXT( VkDescriptorSetVariableDescriptorCountLayoutSupportEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetVariableDescriptorCountLayoutSupportEXT*>(this) = rhs;
      }

      DescriptorSetVariableDescriptorCountLayoutSupportEXT& operator=( VkDescriptorSetVariableDescriptorCountLayoutSupportEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorSetVariableDescriptorCountLayoutSupportEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorSetVariableDescriptorCountLayoutSupportEXT;
      void* pNext = nullptr;
      uint32_t maxVariableDescriptorCount;
    };
    static_assert( sizeof( DescriptorSetVariableDescriptorCountLayoutSupportEXT ) == sizeof( VkDescriptorSetVariableDescriptorCountLayoutSupportEXT ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorSetVariableDescriptorCountLayoutSupportEXT : public layout::DescriptorSetVariableDescriptorCountLayoutSupportEXT
  {
    DescriptorSetVariableDescriptorCountLayoutSupportEXT() VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetVariableDescriptorCountLayoutSupportEXT()
    {}

    DescriptorSetVariableDescriptorCountLayoutSupportEXT( VkDescriptorSetVariableDescriptorCountLayoutSupportEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorSetVariableDescriptorCountLayoutSupportEXT( rhs )
    {}

    DescriptorSetVariableDescriptorCountLayoutSupportEXT& operator=( VkDescriptorSetVariableDescriptorCountLayoutSupportEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorSetVariableDescriptorCountLayoutSupportEXT::operator=(rhs);
      return *this;
    }

    operator VkDescriptorSetVariableDescriptorCountLayoutSupportEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorSetVariableDescriptorCountLayoutSupportEXT*>( this );
    }

    operator VkDescriptorSetVariableDescriptorCountLayoutSupportEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorSetVariableDescriptorCountLayoutSupportEXT*>( this );
    }

    bool operator==( DescriptorSetVariableDescriptorCountLayoutSupportEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxVariableDescriptorCount == rhs.maxVariableDescriptorCount );
    }

    bool operator!=( DescriptorSetVariableDescriptorCountLayoutSupportEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorSetVariableDescriptorCountLayoutSupportEXT::sType;
  };
  static_assert( sizeof( DescriptorSetVariableDescriptorCountLayoutSupportEXT ) == sizeof( VkDescriptorSetVariableDescriptorCountLayoutSupportEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorSetVariableDescriptorCountLayoutSupportEXT>::value, "struct wrapper is not a standard layout!" );

  struct DescriptorUpdateTemplateEntry
  {
    VULKAN_HPP_CONSTEXPR DescriptorUpdateTemplateEntry( uint32_t dstBinding_ = 0,
                                                        uint32_t dstArrayElement_ = 0,
                                                        uint32_t descriptorCount_ = 0,
                                                        vk::DescriptorType descriptorType_ = vk::DescriptorType::eSampler,
                                                        size_t offset_ = 0,
                                                        size_t stride_ = 0 ) VULKAN_HPP_NOEXCEPT
      : dstBinding( dstBinding_ )
      , dstArrayElement( dstArrayElement_ )
      , descriptorCount( descriptorCount_ )
      , descriptorType( descriptorType_ )
      , offset( offset_ )
      , stride( stride_ )
    {}

    DescriptorUpdateTemplateEntry( VkDescriptorUpdateTemplateEntry const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorUpdateTemplateEntry*>(this) = rhs;
    }

    DescriptorUpdateTemplateEntry& operator=( VkDescriptorUpdateTemplateEntry const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDescriptorUpdateTemplateEntry*>(this) = rhs;
      return *this;
    }

    DescriptorUpdateTemplateEntry & setDstBinding( uint32_t dstBinding_ ) VULKAN_HPP_NOEXCEPT
    {
      dstBinding = dstBinding_;
      return *this;
    }

    DescriptorUpdateTemplateEntry & setDstArrayElement( uint32_t dstArrayElement_ ) VULKAN_HPP_NOEXCEPT
    {
      dstArrayElement = dstArrayElement_;
      return *this;
    }

    DescriptorUpdateTemplateEntry & setDescriptorCount( uint32_t descriptorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorCount = descriptorCount_;
      return *this;
    }

    DescriptorUpdateTemplateEntry & setDescriptorType( vk::DescriptorType descriptorType_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorType = descriptorType_;
      return *this;
    }

    DescriptorUpdateTemplateEntry & setOffset( size_t offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    DescriptorUpdateTemplateEntry & setStride( size_t stride_ ) VULKAN_HPP_NOEXCEPT
    {
      stride = stride_;
      return *this;
    }

    operator VkDescriptorUpdateTemplateEntry const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorUpdateTemplateEntry*>( this );
    }

    operator VkDescriptorUpdateTemplateEntry &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorUpdateTemplateEntry*>( this );
    }

    bool operator==( DescriptorUpdateTemplateEntry const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( dstBinding == rhs.dstBinding )
          && ( dstArrayElement == rhs.dstArrayElement )
          && ( descriptorCount == rhs.descriptorCount )
          && ( descriptorType == rhs.descriptorType )
          && ( offset == rhs.offset )
          && ( stride == rhs.stride );
    }

    bool operator!=( DescriptorUpdateTemplateEntry const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t dstBinding;
    uint32_t dstArrayElement;
    uint32_t descriptorCount;
    vk::DescriptorType descriptorType;
    size_t offset;
    size_t stride;
  };
  static_assert( sizeof( DescriptorUpdateTemplateEntry ) == sizeof( VkDescriptorUpdateTemplateEntry ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorUpdateTemplateEntry>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DescriptorUpdateTemplateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DescriptorUpdateTemplateCreateInfo( vk::DescriptorUpdateTemplateCreateFlags flags_ = vk::DescriptorUpdateTemplateCreateFlags(),
                                                               uint32_t descriptorUpdateEntryCount_ = 0,
                                                               const vk::DescriptorUpdateTemplateEntry* pDescriptorUpdateEntries_ = nullptr,
                                                               vk::DescriptorUpdateTemplateType templateType_ = vk::DescriptorUpdateTemplateType::eDescriptorSet,
                                                               vk::DescriptorSetLayout descriptorSetLayout_ = vk::DescriptorSetLayout(),
                                                               vk::PipelineBindPoint pipelineBindPoint_ = vk::PipelineBindPoint::eGraphics,
                                                               vk::PipelineLayout pipelineLayout_ = vk::PipelineLayout(),
                                                               uint32_t set_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , descriptorUpdateEntryCount( descriptorUpdateEntryCount_ )
        , pDescriptorUpdateEntries( pDescriptorUpdateEntries_ )
        , templateType( templateType_ )
        , descriptorSetLayout( descriptorSetLayout_ )
        , pipelineBindPoint( pipelineBindPoint_ )
        , pipelineLayout( pipelineLayout_ )
        , set( set_ )
      {}

      DescriptorUpdateTemplateCreateInfo( VkDescriptorUpdateTemplateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorUpdateTemplateCreateInfo*>(this) = rhs;
      }

      DescriptorUpdateTemplateCreateInfo& operator=( VkDescriptorUpdateTemplateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDescriptorUpdateTemplateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDescriptorUpdateTemplateCreateInfo;
      const void* pNext = nullptr;
      vk::DescriptorUpdateTemplateCreateFlags flags;
      uint32_t descriptorUpdateEntryCount;
      const vk::DescriptorUpdateTemplateEntry* pDescriptorUpdateEntries;
      vk::DescriptorUpdateTemplateType templateType;
      vk::DescriptorSetLayout descriptorSetLayout;
      vk::PipelineBindPoint pipelineBindPoint;
      vk::PipelineLayout pipelineLayout;
      uint32_t set;
    };
    static_assert( sizeof( DescriptorUpdateTemplateCreateInfo ) == sizeof( VkDescriptorUpdateTemplateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct DescriptorUpdateTemplateCreateInfo : public layout::DescriptorUpdateTemplateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR DescriptorUpdateTemplateCreateInfo( vk::DescriptorUpdateTemplateCreateFlags flags_ = vk::DescriptorUpdateTemplateCreateFlags(),
                                                             uint32_t descriptorUpdateEntryCount_ = 0,
                                                             const vk::DescriptorUpdateTemplateEntry* pDescriptorUpdateEntries_ = nullptr,
                                                             vk::DescriptorUpdateTemplateType templateType_ = vk::DescriptorUpdateTemplateType::eDescriptorSet,
                                                             vk::DescriptorSetLayout descriptorSetLayout_ = vk::DescriptorSetLayout(),
                                                             vk::PipelineBindPoint pipelineBindPoint_ = vk::PipelineBindPoint::eGraphics,
                                                             vk::PipelineLayout pipelineLayout_ = vk::PipelineLayout(),
                                                             uint32_t set_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorUpdateTemplateCreateInfo( flags_, descriptorUpdateEntryCount_, pDescriptorUpdateEntries_, templateType_, descriptorSetLayout_, pipelineBindPoint_, pipelineLayout_, set_ )
    {}

    DescriptorUpdateTemplateCreateInfo( VkDescriptorUpdateTemplateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DescriptorUpdateTemplateCreateInfo( rhs )
    {}

    DescriptorUpdateTemplateCreateInfo& operator=( VkDescriptorUpdateTemplateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DescriptorUpdateTemplateCreateInfo::operator=(rhs);
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setFlags( vk::DescriptorUpdateTemplateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setDescriptorUpdateEntryCount( uint32_t descriptorUpdateEntryCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorUpdateEntryCount = descriptorUpdateEntryCount_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setPDescriptorUpdateEntries( const vk::DescriptorUpdateTemplateEntry* pDescriptorUpdateEntries_ ) VULKAN_HPP_NOEXCEPT
    {
      pDescriptorUpdateEntries = pDescriptorUpdateEntries_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setTemplateType( vk::DescriptorUpdateTemplateType templateType_ ) VULKAN_HPP_NOEXCEPT
    {
      templateType = templateType_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setDescriptorSetLayout( vk::DescriptorSetLayout descriptorSetLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorSetLayout = descriptorSetLayout_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setPipelineBindPoint( vk::PipelineBindPoint pipelineBindPoint_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineBindPoint = pipelineBindPoint_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setPipelineLayout( vk::PipelineLayout pipelineLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineLayout = pipelineLayout_;
      return *this;
    }

    DescriptorUpdateTemplateCreateInfo & setSet( uint32_t set_ ) VULKAN_HPP_NOEXCEPT
    {
      set = set_;
      return *this;
    }

    operator VkDescriptorUpdateTemplateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>( this );
    }

    operator VkDescriptorUpdateTemplateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDescriptorUpdateTemplateCreateInfo*>( this );
    }

    bool operator==( DescriptorUpdateTemplateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( descriptorUpdateEntryCount == rhs.descriptorUpdateEntryCount )
          && ( pDescriptorUpdateEntries == rhs.pDescriptorUpdateEntries )
          && ( templateType == rhs.templateType )
          && ( descriptorSetLayout == rhs.descriptorSetLayout )
          && ( pipelineBindPoint == rhs.pipelineBindPoint )
          && ( pipelineLayout == rhs.pipelineLayout )
          && ( set == rhs.set );
    }

    bool operator!=( DescriptorUpdateTemplateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DescriptorUpdateTemplateCreateInfo::sType;
  };
  static_assert( sizeof( DescriptorUpdateTemplateCreateInfo ) == sizeof( VkDescriptorUpdateTemplateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DescriptorUpdateTemplateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceQueueCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceQueueCreateInfo( vk::DeviceQueueCreateFlags flags_ = vk::DeviceQueueCreateFlags(),
                                                  uint32_t queueFamilyIndex_ = 0,
                                                  uint32_t queueCount_ = 0,
                                                  const float* pQueuePriorities_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , queueFamilyIndex( queueFamilyIndex_ )
        , queueCount( queueCount_ )
        , pQueuePriorities( pQueuePriorities_ )
      {}

      DeviceQueueCreateInfo( VkDeviceQueueCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceQueueCreateInfo*>(this) = rhs;
      }

      DeviceQueueCreateInfo& operator=( VkDeviceQueueCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceQueueCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceQueueCreateInfo;
      const void* pNext = nullptr;
      vk::DeviceQueueCreateFlags flags;
      uint32_t queueFamilyIndex;
      uint32_t queueCount;
      const float* pQueuePriorities;
    };
    static_assert( sizeof( DeviceQueueCreateInfo ) == sizeof( VkDeviceQueueCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct DeviceQueueCreateInfo : public layout::DeviceQueueCreateInfo
  {
    VULKAN_HPP_CONSTEXPR DeviceQueueCreateInfo( vk::DeviceQueueCreateFlags flags_ = vk::DeviceQueueCreateFlags(),
                                                uint32_t queueFamilyIndex_ = 0,
                                                uint32_t queueCount_ = 0,
                                                const float* pQueuePriorities_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceQueueCreateInfo( flags_, queueFamilyIndex_, queueCount_, pQueuePriorities_ )
    {}

    DeviceQueueCreateInfo( VkDeviceQueueCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceQueueCreateInfo( rhs )
    {}

    DeviceQueueCreateInfo& operator=( VkDeviceQueueCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceQueueCreateInfo::operator=(rhs);
      return *this;
    }

    DeviceQueueCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceQueueCreateInfo & setFlags( vk::DeviceQueueCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DeviceQueueCreateInfo & setQueueFamilyIndex( uint32_t queueFamilyIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      queueFamilyIndex = queueFamilyIndex_;
      return *this;
    }

    DeviceQueueCreateInfo & setQueueCount( uint32_t queueCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queueCount = queueCount_;
      return *this;
    }

    DeviceQueueCreateInfo & setPQueuePriorities( const float* pQueuePriorities_ ) VULKAN_HPP_NOEXCEPT
    {
      pQueuePriorities = pQueuePriorities_;
      return *this;
    }

    operator VkDeviceQueueCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceQueueCreateInfo*>( this );
    }

    operator VkDeviceQueueCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceQueueCreateInfo*>( this );
    }

    bool operator==( DeviceQueueCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( queueFamilyIndex == rhs.queueFamilyIndex )
          && ( queueCount == rhs.queueCount )
          && ( pQueuePriorities == rhs.pQueuePriorities );
    }

    bool operator!=( DeviceQueueCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceQueueCreateInfo::sType;
  };
  static_assert( sizeof( DeviceQueueCreateInfo ) == sizeof( VkDeviceQueueCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceQueueCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct PhysicalDeviceFeatures
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceFeatures( vk::Bool32 robustBufferAccess_ = 0,
                                                 vk::Bool32 fullDrawIndexUint32_ = 0,
                                                 vk::Bool32 imageCubeArray_ = 0,
                                                 vk::Bool32 independentBlend_ = 0,
                                                 vk::Bool32 geometryShader_ = 0,
                                                 vk::Bool32 tessellationShader_ = 0,
                                                 vk::Bool32 sampleRateShading_ = 0,
                                                 vk::Bool32 dualSrcBlend_ = 0,
                                                 vk::Bool32 logicOp_ = 0,
                                                 vk::Bool32 multiDrawIndirect_ = 0,
                                                 vk::Bool32 drawIndirectFirstInstance_ = 0,
                                                 vk::Bool32 depthClamp_ = 0,
                                                 vk::Bool32 depthBiasClamp_ = 0,
                                                 vk::Bool32 fillModeNonSolid_ = 0,
                                                 vk::Bool32 depthBounds_ = 0,
                                                 vk::Bool32 wideLines_ = 0,
                                                 vk::Bool32 largePoints_ = 0,
                                                 vk::Bool32 alphaToOne_ = 0,
                                                 vk::Bool32 multiViewport_ = 0,
                                                 vk::Bool32 samplerAnisotropy_ = 0,
                                                 vk::Bool32 textureCompressionETC2_ = 0,
                                                 vk::Bool32 textureCompressionASTC_LDR_ = 0,
                                                 vk::Bool32 textureCompressionBC_ = 0,
                                                 vk::Bool32 occlusionQueryPrecise_ = 0,
                                                 vk::Bool32 pipelineStatisticsQuery_ = 0,
                                                 vk::Bool32 vertexPipelineStoresAndAtomics_ = 0,
                                                 vk::Bool32 fragmentStoresAndAtomics_ = 0,
                                                 vk::Bool32 shaderTessellationAndGeometryPointSize_ = 0,
                                                 vk::Bool32 shaderImageGatherExtended_ = 0,
                                                 vk::Bool32 shaderStorageImageExtendedFormats_ = 0,
                                                 vk::Bool32 shaderStorageImageMultisample_ = 0,
                                                 vk::Bool32 shaderStorageImageReadWithoutFormat_ = 0,
                                                 vk::Bool32 shaderStorageImageWriteWithoutFormat_ = 0,
                                                 vk::Bool32 shaderUniformBufferArrayDynamicIndexing_ = 0,
                                                 vk::Bool32 shaderSampledImageArrayDynamicIndexing_ = 0,
                                                 vk::Bool32 shaderStorageBufferArrayDynamicIndexing_ = 0,
                                                 vk::Bool32 shaderStorageImageArrayDynamicIndexing_ = 0,
                                                 vk::Bool32 shaderClipDistance_ = 0,
                                                 vk::Bool32 shaderCullDistance_ = 0,
                                                 vk::Bool32 shaderFloat64_ = 0,
                                                 vk::Bool32 shaderInt64_ = 0,
                                                 vk::Bool32 shaderInt16_ = 0,
                                                 vk::Bool32 shaderResourceResidency_ = 0,
                                                 vk::Bool32 shaderResourceMinLod_ = 0,
                                                 vk::Bool32 sparseBinding_ = 0,
                                                 vk::Bool32 sparseResidencyBuffer_ = 0,
                                                 vk::Bool32 sparseResidencyImage2D_ = 0,
                                                 vk::Bool32 sparseResidencyImage3D_ = 0,
                                                 vk::Bool32 sparseResidency2Samples_ = 0,
                                                 vk::Bool32 sparseResidency4Samples_ = 0,
                                                 vk::Bool32 sparseResidency8Samples_ = 0,
                                                 vk::Bool32 sparseResidency16Samples_ = 0,
                                                 vk::Bool32 sparseResidencyAliased_ = 0,
                                                 vk::Bool32 variableMultisampleRate_ = 0,
                                                 vk::Bool32 inheritedQueries_ = 0 ) VULKAN_HPP_NOEXCEPT
      : robustBufferAccess( robustBufferAccess_ )
      , fullDrawIndexUint32( fullDrawIndexUint32_ )
      , imageCubeArray( imageCubeArray_ )
      , independentBlend( independentBlend_ )
      , geometryShader( geometryShader_ )
      , tessellationShader( tessellationShader_ )
      , sampleRateShading( sampleRateShading_ )
      , dualSrcBlend( dualSrcBlend_ )
      , logicOp( logicOp_ )
      , multiDrawIndirect( multiDrawIndirect_ )
      , drawIndirectFirstInstance( drawIndirectFirstInstance_ )
      , depthClamp( depthClamp_ )
      , depthBiasClamp( depthBiasClamp_ )
      , fillModeNonSolid( fillModeNonSolid_ )
      , depthBounds( depthBounds_ )
      , wideLines( wideLines_ )
      , largePoints( largePoints_ )
      , alphaToOne( alphaToOne_ )
      , multiViewport( multiViewport_ )
      , samplerAnisotropy( samplerAnisotropy_ )
      , textureCompressionETC2( textureCompressionETC2_ )
      , textureCompressionASTC_LDR( textureCompressionASTC_LDR_ )
      , textureCompressionBC( textureCompressionBC_ )
      , occlusionQueryPrecise( occlusionQueryPrecise_ )
      , pipelineStatisticsQuery( pipelineStatisticsQuery_ )
      , vertexPipelineStoresAndAtomics( vertexPipelineStoresAndAtomics_ )
      , fragmentStoresAndAtomics( fragmentStoresAndAtomics_ )
      , shaderTessellationAndGeometryPointSize( shaderTessellationAndGeometryPointSize_ )
      , shaderImageGatherExtended( shaderImageGatherExtended_ )
      , shaderStorageImageExtendedFormats( shaderStorageImageExtendedFormats_ )
      , shaderStorageImageMultisample( shaderStorageImageMultisample_ )
      , shaderStorageImageReadWithoutFormat( shaderStorageImageReadWithoutFormat_ )
      , shaderStorageImageWriteWithoutFormat( shaderStorageImageWriteWithoutFormat_ )
      , shaderUniformBufferArrayDynamicIndexing( shaderUniformBufferArrayDynamicIndexing_ )
      , shaderSampledImageArrayDynamicIndexing( shaderSampledImageArrayDynamicIndexing_ )
      , shaderStorageBufferArrayDynamicIndexing( shaderStorageBufferArrayDynamicIndexing_ )
      , shaderStorageImageArrayDynamicIndexing( shaderStorageImageArrayDynamicIndexing_ )
      , shaderClipDistance( shaderClipDistance_ )
      , shaderCullDistance( shaderCullDistance_ )
      , shaderFloat64( shaderFloat64_ )
      , shaderInt64( shaderInt64_ )
      , shaderInt16( shaderInt16_ )
      , shaderResourceResidency( shaderResourceResidency_ )
      , shaderResourceMinLod( shaderResourceMinLod_ )
      , sparseBinding( sparseBinding_ )
      , sparseResidencyBuffer( sparseResidencyBuffer_ )
      , sparseResidencyImage2D( sparseResidencyImage2D_ )
      , sparseResidencyImage3D( sparseResidencyImage3D_ )
      , sparseResidency2Samples( sparseResidency2Samples_ )
      , sparseResidency4Samples( sparseResidency4Samples_ )
      , sparseResidency8Samples( sparseResidency8Samples_ )
      , sparseResidency16Samples( sparseResidency16Samples_ )
      , sparseResidencyAliased( sparseResidencyAliased_ )
      , variableMultisampleRate( variableMultisampleRate_ )
      , inheritedQueries( inheritedQueries_ )
    {}

    PhysicalDeviceFeatures( VkPhysicalDeviceFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceFeatures*>(this) = rhs;
    }

    PhysicalDeviceFeatures& operator=( VkPhysicalDeviceFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceFeatures*>(this) = rhs;
      return *this;
    }

    PhysicalDeviceFeatures & setRobustBufferAccess( vk::Bool32 robustBufferAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      robustBufferAccess = robustBufferAccess_;
      return *this;
    }

    PhysicalDeviceFeatures & setFullDrawIndexUint32( vk::Bool32 fullDrawIndexUint32_ ) VULKAN_HPP_NOEXCEPT
    {
      fullDrawIndexUint32 = fullDrawIndexUint32_;
      return *this;
    }

    PhysicalDeviceFeatures & setImageCubeArray( vk::Bool32 imageCubeArray_ ) VULKAN_HPP_NOEXCEPT
    {
      imageCubeArray = imageCubeArray_;
      return *this;
    }

    PhysicalDeviceFeatures & setIndependentBlend( vk::Bool32 independentBlend_ ) VULKAN_HPP_NOEXCEPT
    {
      independentBlend = independentBlend_;
      return *this;
    }

    PhysicalDeviceFeatures & setGeometryShader( vk::Bool32 geometryShader_ ) VULKAN_HPP_NOEXCEPT
    {
      geometryShader = geometryShader_;
      return *this;
    }

    PhysicalDeviceFeatures & setTessellationShader( vk::Bool32 tessellationShader_ ) VULKAN_HPP_NOEXCEPT
    {
      tessellationShader = tessellationShader_;
      return *this;
    }

    PhysicalDeviceFeatures & setSampleRateShading( vk::Bool32 sampleRateShading_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleRateShading = sampleRateShading_;
      return *this;
    }

    PhysicalDeviceFeatures & setDualSrcBlend( vk::Bool32 dualSrcBlend_ ) VULKAN_HPP_NOEXCEPT
    {
      dualSrcBlend = dualSrcBlend_;
      return *this;
    }

    PhysicalDeviceFeatures & setLogicOp( vk::Bool32 logicOp_ ) VULKAN_HPP_NOEXCEPT
    {
      logicOp = logicOp_;
      return *this;
    }

    PhysicalDeviceFeatures & setMultiDrawIndirect( vk::Bool32 multiDrawIndirect_ ) VULKAN_HPP_NOEXCEPT
    {
      multiDrawIndirect = multiDrawIndirect_;
      return *this;
    }

    PhysicalDeviceFeatures & setDrawIndirectFirstInstance( vk::Bool32 drawIndirectFirstInstance_ ) VULKAN_HPP_NOEXCEPT
    {
      drawIndirectFirstInstance = drawIndirectFirstInstance_;
      return *this;
    }

    PhysicalDeviceFeatures & setDepthClamp( vk::Bool32 depthClamp_ ) VULKAN_HPP_NOEXCEPT
    {
      depthClamp = depthClamp_;
      return *this;
    }

    PhysicalDeviceFeatures & setDepthBiasClamp( vk::Bool32 depthBiasClamp_ ) VULKAN_HPP_NOEXCEPT
    {
      depthBiasClamp = depthBiasClamp_;
      return *this;
    }

    PhysicalDeviceFeatures & setFillModeNonSolid( vk::Bool32 fillModeNonSolid_ ) VULKAN_HPP_NOEXCEPT
    {
      fillModeNonSolid = fillModeNonSolid_;
      return *this;
    }

    PhysicalDeviceFeatures & setDepthBounds( vk::Bool32 depthBounds_ ) VULKAN_HPP_NOEXCEPT
    {
      depthBounds = depthBounds_;
      return *this;
    }

    PhysicalDeviceFeatures & setWideLines( vk::Bool32 wideLines_ ) VULKAN_HPP_NOEXCEPT
    {
      wideLines = wideLines_;
      return *this;
    }

    PhysicalDeviceFeatures & setLargePoints( vk::Bool32 largePoints_ ) VULKAN_HPP_NOEXCEPT
    {
      largePoints = largePoints_;
      return *this;
    }

    PhysicalDeviceFeatures & setAlphaToOne( vk::Bool32 alphaToOne_ ) VULKAN_HPP_NOEXCEPT
    {
      alphaToOne = alphaToOne_;
      return *this;
    }

    PhysicalDeviceFeatures & setMultiViewport( vk::Bool32 multiViewport_ ) VULKAN_HPP_NOEXCEPT
    {
      multiViewport = multiViewport_;
      return *this;
    }

    PhysicalDeviceFeatures & setSamplerAnisotropy( vk::Bool32 samplerAnisotropy_ ) VULKAN_HPP_NOEXCEPT
    {
      samplerAnisotropy = samplerAnisotropy_;
      return *this;
    }

    PhysicalDeviceFeatures & setTextureCompressionETC2( vk::Bool32 textureCompressionETC2_ ) VULKAN_HPP_NOEXCEPT
    {
      textureCompressionETC2 = textureCompressionETC2_;
      return *this;
    }

    PhysicalDeviceFeatures & setTextureCompressionASTC_LDR( vk::Bool32 textureCompressionASTC_LDR_ ) VULKAN_HPP_NOEXCEPT
    {
      textureCompressionASTC_LDR = textureCompressionASTC_LDR_;
      return *this;
    }

    PhysicalDeviceFeatures & setTextureCompressionBC( vk::Bool32 textureCompressionBC_ ) VULKAN_HPP_NOEXCEPT
    {
      textureCompressionBC = textureCompressionBC_;
      return *this;
    }

    PhysicalDeviceFeatures & setOcclusionQueryPrecise( vk::Bool32 occlusionQueryPrecise_ ) VULKAN_HPP_NOEXCEPT
    {
      occlusionQueryPrecise = occlusionQueryPrecise_;
      return *this;
    }

    PhysicalDeviceFeatures & setPipelineStatisticsQuery( vk::Bool32 pipelineStatisticsQuery_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineStatisticsQuery = pipelineStatisticsQuery_;
      return *this;
    }

    PhysicalDeviceFeatures & setVertexPipelineStoresAndAtomics( vk::Bool32 vertexPipelineStoresAndAtomics_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexPipelineStoresAndAtomics = vertexPipelineStoresAndAtomics_;
      return *this;
    }

    PhysicalDeviceFeatures & setFragmentStoresAndAtomics( vk::Bool32 fragmentStoresAndAtomics_ ) VULKAN_HPP_NOEXCEPT
    {
      fragmentStoresAndAtomics = fragmentStoresAndAtomics_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderTessellationAndGeometryPointSize( vk::Bool32 shaderTessellationAndGeometryPointSize_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderTessellationAndGeometryPointSize = shaderTessellationAndGeometryPointSize_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderImageGatherExtended( vk::Bool32 shaderImageGatherExtended_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderImageGatherExtended = shaderImageGatherExtended_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderStorageImageExtendedFormats( vk::Bool32 shaderStorageImageExtendedFormats_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageImageExtendedFormats = shaderStorageImageExtendedFormats_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderStorageImageMultisample( vk::Bool32 shaderStorageImageMultisample_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageImageMultisample = shaderStorageImageMultisample_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderStorageImageReadWithoutFormat( vk::Bool32 shaderStorageImageReadWithoutFormat_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageImageReadWithoutFormat = shaderStorageImageReadWithoutFormat_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderStorageImageWriteWithoutFormat( vk::Bool32 shaderStorageImageWriteWithoutFormat_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageImageWriteWithoutFormat = shaderStorageImageWriteWithoutFormat_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderUniformBufferArrayDynamicIndexing( vk::Bool32 shaderUniformBufferArrayDynamicIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderUniformBufferArrayDynamicIndexing = shaderUniformBufferArrayDynamicIndexing_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderSampledImageArrayDynamicIndexing( vk::Bool32 shaderSampledImageArrayDynamicIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderSampledImageArrayDynamicIndexing = shaderSampledImageArrayDynamicIndexing_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderStorageBufferArrayDynamicIndexing( vk::Bool32 shaderStorageBufferArrayDynamicIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageBufferArrayDynamicIndexing = shaderStorageBufferArrayDynamicIndexing_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderStorageImageArrayDynamicIndexing( vk::Bool32 shaderStorageImageArrayDynamicIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageImageArrayDynamicIndexing = shaderStorageImageArrayDynamicIndexing_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderClipDistance( vk::Bool32 shaderClipDistance_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderClipDistance = shaderClipDistance_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderCullDistance( vk::Bool32 shaderCullDistance_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderCullDistance = shaderCullDistance_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderFloat64( vk::Bool32 shaderFloat64_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderFloat64 = shaderFloat64_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderInt64( vk::Bool32 shaderInt64_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderInt64 = shaderInt64_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderInt16( vk::Bool32 shaderInt16_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderInt16 = shaderInt16_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderResourceResidency( vk::Bool32 shaderResourceResidency_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderResourceResidency = shaderResourceResidency_;
      return *this;
    }

    PhysicalDeviceFeatures & setShaderResourceMinLod( vk::Bool32 shaderResourceMinLod_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderResourceMinLod = shaderResourceMinLod_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseBinding( vk::Bool32 sparseBinding_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseBinding = sparseBinding_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidencyBuffer( vk::Bool32 sparseResidencyBuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidencyBuffer = sparseResidencyBuffer_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidencyImage2D( vk::Bool32 sparseResidencyImage2D_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidencyImage2D = sparseResidencyImage2D_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidencyImage3D( vk::Bool32 sparseResidencyImage3D_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidencyImage3D = sparseResidencyImage3D_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidency2Samples( vk::Bool32 sparseResidency2Samples_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidency2Samples = sparseResidency2Samples_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidency4Samples( vk::Bool32 sparseResidency4Samples_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidency4Samples = sparseResidency4Samples_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidency8Samples( vk::Bool32 sparseResidency8Samples_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidency8Samples = sparseResidency8Samples_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidency16Samples( vk::Bool32 sparseResidency16Samples_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidency16Samples = sparseResidency16Samples_;
      return *this;
    }

    PhysicalDeviceFeatures & setSparseResidencyAliased( vk::Bool32 sparseResidencyAliased_ ) VULKAN_HPP_NOEXCEPT
    {
      sparseResidencyAliased = sparseResidencyAliased_;
      return *this;
    }

    PhysicalDeviceFeatures & setVariableMultisampleRate( vk::Bool32 variableMultisampleRate_ ) VULKAN_HPP_NOEXCEPT
    {
      variableMultisampleRate = variableMultisampleRate_;
      return *this;
    }

    PhysicalDeviceFeatures & setInheritedQueries( vk::Bool32 inheritedQueries_ ) VULKAN_HPP_NOEXCEPT
    {
      inheritedQueries = inheritedQueries_;
      return *this;
    }

    operator VkPhysicalDeviceFeatures const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceFeatures*>( this );
    }

    operator VkPhysicalDeviceFeatures &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceFeatures*>( this );
    }

    bool operator==( PhysicalDeviceFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( robustBufferAccess == rhs.robustBufferAccess )
          && ( fullDrawIndexUint32 == rhs.fullDrawIndexUint32 )
          && ( imageCubeArray == rhs.imageCubeArray )
          && ( independentBlend == rhs.independentBlend )
          && ( geometryShader == rhs.geometryShader )
          && ( tessellationShader == rhs.tessellationShader )
          && ( sampleRateShading == rhs.sampleRateShading )
          && ( dualSrcBlend == rhs.dualSrcBlend )
          && ( logicOp == rhs.logicOp )
          && ( multiDrawIndirect == rhs.multiDrawIndirect )
          && ( drawIndirectFirstInstance == rhs.drawIndirectFirstInstance )
          && ( depthClamp == rhs.depthClamp )
          && ( depthBiasClamp == rhs.depthBiasClamp )
          && ( fillModeNonSolid == rhs.fillModeNonSolid )
          && ( depthBounds == rhs.depthBounds )
          && ( wideLines == rhs.wideLines )
          && ( largePoints == rhs.largePoints )
          && ( alphaToOne == rhs.alphaToOne )
          && ( multiViewport == rhs.multiViewport )
          && ( samplerAnisotropy == rhs.samplerAnisotropy )
          && ( textureCompressionETC2 == rhs.textureCompressionETC2 )
          && ( textureCompressionASTC_LDR == rhs.textureCompressionASTC_LDR )
          && ( textureCompressionBC == rhs.textureCompressionBC )
          && ( occlusionQueryPrecise == rhs.occlusionQueryPrecise )
          && ( pipelineStatisticsQuery == rhs.pipelineStatisticsQuery )
          && ( vertexPipelineStoresAndAtomics == rhs.vertexPipelineStoresAndAtomics )
          && ( fragmentStoresAndAtomics == rhs.fragmentStoresAndAtomics )
          && ( shaderTessellationAndGeometryPointSize == rhs.shaderTessellationAndGeometryPointSize )
          && ( shaderImageGatherExtended == rhs.shaderImageGatherExtended )
          && ( shaderStorageImageExtendedFormats == rhs.shaderStorageImageExtendedFormats )
          && ( shaderStorageImageMultisample == rhs.shaderStorageImageMultisample )
          && ( shaderStorageImageReadWithoutFormat == rhs.shaderStorageImageReadWithoutFormat )
          && ( shaderStorageImageWriteWithoutFormat == rhs.shaderStorageImageWriteWithoutFormat )
          && ( shaderUniformBufferArrayDynamicIndexing == rhs.shaderUniformBufferArrayDynamicIndexing )
          && ( shaderSampledImageArrayDynamicIndexing == rhs.shaderSampledImageArrayDynamicIndexing )
          && ( shaderStorageBufferArrayDynamicIndexing == rhs.shaderStorageBufferArrayDynamicIndexing )
          && ( shaderStorageImageArrayDynamicIndexing == rhs.shaderStorageImageArrayDynamicIndexing )
          && ( shaderClipDistance == rhs.shaderClipDistance )
          && ( shaderCullDistance == rhs.shaderCullDistance )
          && ( shaderFloat64 == rhs.shaderFloat64 )
          && ( shaderInt64 == rhs.shaderInt64 )
          && ( shaderInt16 == rhs.shaderInt16 )
          && ( shaderResourceResidency == rhs.shaderResourceResidency )
          && ( shaderResourceMinLod == rhs.shaderResourceMinLod )
          && ( sparseBinding == rhs.sparseBinding )
          && ( sparseResidencyBuffer == rhs.sparseResidencyBuffer )
          && ( sparseResidencyImage2D == rhs.sparseResidencyImage2D )
          && ( sparseResidencyImage3D == rhs.sparseResidencyImage3D )
          && ( sparseResidency2Samples == rhs.sparseResidency2Samples )
          && ( sparseResidency4Samples == rhs.sparseResidency4Samples )
          && ( sparseResidency8Samples == rhs.sparseResidency8Samples )
          && ( sparseResidency16Samples == rhs.sparseResidency16Samples )
          && ( sparseResidencyAliased == rhs.sparseResidencyAliased )
          && ( variableMultisampleRate == rhs.variableMultisampleRate )
          && ( inheritedQueries == rhs.inheritedQueries );
    }

    bool operator!=( PhysicalDeviceFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Bool32 robustBufferAccess;
    vk::Bool32 fullDrawIndexUint32;
    vk::Bool32 imageCubeArray;
    vk::Bool32 independentBlend;
    vk::Bool32 geometryShader;
    vk::Bool32 tessellationShader;
    vk::Bool32 sampleRateShading;
    vk::Bool32 dualSrcBlend;
    vk::Bool32 logicOp;
    vk::Bool32 multiDrawIndirect;
    vk::Bool32 drawIndirectFirstInstance;
    vk::Bool32 depthClamp;
    vk::Bool32 depthBiasClamp;
    vk::Bool32 fillModeNonSolid;
    vk::Bool32 depthBounds;
    vk::Bool32 wideLines;
    vk::Bool32 largePoints;
    vk::Bool32 alphaToOne;
    vk::Bool32 multiViewport;
    vk::Bool32 samplerAnisotropy;
    vk::Bool32 textureCompressionETC2;
    vk::Bool32 textureCompressionASTC_LDR;
    vk::Bool32 textureCompressionBC;
    vk::Bool32 occlusionQueryPrecise;
    vk::Bool32 pipelineStatisticsQuery;
    vk::Bool32 vertexPipelineStoresAndAtomics;
    vk::Bool32 fragmentStoresAndAtomics;
    vk::Bool32 shaderTessellationAndGeometryPointSize;
    vk::Bool32 shaderImageGatherExtended;
    vk::Bool32 shaderStorageImageExtendedFormats;
    vk::Bool32 shaderStorageImageMultisample;
    vk::Bool32 shaderStorageImageReadWithoutFormat;
    vk::Bool32 shaderStorageImageWriteWithoutFormat;
    vk::Bool32 shaderUniformBufferArrayDynamicIndexing;
    vk::Bool32 shaderSampledImageArrayDynamicIndexing;
    vk::Bool32 shaderStorageBufferArrayDynamicIndexing;
    vk::Bool32 shaderStorageImageArrayDynamicIndexing;
    vk::Bool32 shaderClipDistance;
    vk::Bool32 shaderCullDistance;
    vk::Bool32 shaderFloat64;
    vk::Bool32 shaderInt64;
    vk::Bool32 shaderInt16;
    vk::Bool32 shaderResourceResidency;
    vk::Bool32 shaderResourceMinLod;
    vk::Bool32 sparseBinding;
    vk::Bool32 sparseResidencyBuffer;
    vk::Bool32 sparseResidencyImage2D;
    vk::Bool32 sparseResidencyImage3D;
    vk::Bool32 sparseResidency2Samples;
    vk::Bool32 sparseResidency4Samples;
    vk::Bool32 sparseResidency8Samples;
    vk::Bool32 sparseResidency16Samples;
    vk::Bool32 sparseResidencyAliased;
    vk::Bool32 variableMultisampleRate;
    vk::Bool32 inheritedQueries;
  };
  static_assert( sizeof( PhysicalDeviceFeatures ) == sizeof( VkPhysicalDeviceFeatures ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceFeatures>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceCreateInfo( vk::DeviceCreateFlags flags_ = vk::DeviceCreateFlags(),
                                             uint32_t queueCreateInfoCount_ = 0,
                                             const vk::DeviceQueueCreateInfo* pQueueCreateInfos_ = nullptr,
                                             uint32_t enabledLayerCount_ = 0,
                                             const char* const* ppEnabledLayerNames_ = nullptr,
                                             uint32_t enabledExtensionCount_ = 0,
                                             const char* const* ppEnabledExtensionNames_ = nullptr,
                                             const vk::PhysicalDeviceFeatures* pEnabledFeatures_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , queueCreateInfoCount( queueCreateInfoCount_ )
        , pQueueCreateInfos( pQueueCreateInfos_ )
        , enabledLayerCount( enabledLayerCount_ )
        , ppEnabledLayerNames( ppEnabledLayerNames_ )
        , enabledExtensionCount( enabledExtensionCount_ )
        , ppEnabledExtensionNames( ppEnabledExtensionNames_ )
        , pEnabledFeatures( pEnabledFeatures_ )
      {}

      DeviceCreateInfo( VkDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceCreateInfo*>(this) = rhs;
      }

      DeviceCreateInfo& operator=( VkDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceCreateInfo;
      const void* pNext = nullptr;
      vk::DeviceCreateFlags flags;
      uint32_t queueCreateInfoCount;
      const vk::DeviceQueueCreateInfo* pQueueCreateInfos;
      uint32_t enabledLayerCount;
      const char* const* ppEnabledLayerNames;
      uint32_t enabledExtensionCount;
      const char* const* ppEnabledExtensionNames;
      const vk::PhysicalDeviceFeatures* pEnabledFeatures;
    };
    static_assert( sizeof( DeviceCreateInfo ) == sizeof( VkDeviceCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct DeviceCreateInfo : public layout::DeviceCreateInfo
  {
    VULKAN_HPP_CONSTEXPR DeviceCreateInfo( vk::DeviceCreateFlags flags_ = vk::DeviceCreateFlags(),
                                           uint32_t queueCreateInfoCount_ = 0,
                                           const vk::DeviceQueueCreateInfo* pQueueCreateInfos_ = nullptr,
                                           uint32_t enabledLayerCount_ = 0,
                                           const char* const* ppEnabledLayerNames_ = nullptr,
                                           uint32_t enabledExtensionCount_ = 0,
                                           const char* const* ppEnabledExtensionNames_ = nullptr,
                                           const vk::PhysicalDeviceFeatures* pEnabledFeatures_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceCreateInfo( flags_, queueCreateInfoCount_, pQueueCreateInfos_, enabledLayerCount_, ppEnabledLayerNames_, enabledExtensionCount_, ppEnabledExtensionNames_, pEnabledFeatures_ )
    {}

    DeviceCreateInfo( VkDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceCreateInfo( rhs )
    {}

    DeviceCreateInfo& operator=( VkDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceCreateInfo::operator=(rhs);
      return *this;
    }

    DeviceCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceCreateInfo & setFlags( vk::DeviceCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DeviceCreateInfo & setQueueCreateInfoCount( uint32_t queueCreateInfoCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queueCreateInfoCount = queueCreateInfoCount_;
      return *this;
    }

    DeviceCreateInfo & setPQueueCreateInfos( const vk::DeviceQueueCreateInfo* pQueueCreateInfos_ ) VULKAN_HPP_NOEXCEPT
    {
      pQueueCreateInfos = pQueueCreateInfos_;
      return *this;
    }

    DeviceCreateInfo & setEnabledLayerCount( uint32_t enabledLayerCount_ ) VULKAN_HPP_NOEXCEPT
    {
      enabledLayerCount = enabledLayerCount_;
      return *this;
    }

    DeviceCreateInfo & setPpEnabledLayerNames( const char* const* ppEnabledLayerNames_ ) VULKAN_HPP_NOEXCEPT
    {
      ppEnabledLayerNames = ppEnabledLayerNames_;
      return *this;
    }

    DeviceCreateInfo & setEnabledExtensionCount( uint32_t enabledExtensionCount_ ) VULKAN_HPP_NOEXCEPT
    {
      enabledExtensionCount = enabledExtensionCount_;
      return *this;
    }

    DeviceCreateInfo & setPpEnabledExtensionNames( const char* const* ppEnabledExtensionNames_ ) VULKAN_HPP_NOEXCEPT
    {
      ppEnabledExtensionNames = ppEnabledExtensionNames_;
      return *this;
    }

    DeviceCreateInfo & setPEnabledFeatures( const vk::PhysicalDeviceFeatures* pEnabledFeatures_ ) VULKAN_HPP_NOEXCEPT
    {
      pEnabledFeatures = pEnabledFeatures_;
      return *this;
    }

    operator VkDeviceCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceCreateInfo*>( this );
    }

    operator VkDeviceCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceCreateInfo*>( this );
    }

    bool operator==( DeviceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( queueCreateInfoCount == rhs.queueCreateInfoCount )
          && ( pQueueCreateInfos == rhs.pQueueCreateInfos )
          && ( enabledLayerCount == rhs.enabledLayerCount )
          && ( ppEnabledLayerNames == rhs.ppEnabledLayerNames )
          && ( enabledExtensionCount == rhs.enabledExtensionCount )
          && ( ppEnabledExtensionNames == rhs.ppEnabledExtensionNames )
          && ( pEnabledFeatures == rhs.pEnabledFeatures );
    }

    bool operator!=( DeviceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceCreateInfo::sType;
  };
  static_assert( sizeof( DeviceCreateInfo ) == sizeof( VkDeviceCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceEventInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceEventInfoEXT( vk::DeviceEventTypeEXT deviceEvent_ = vk::DeviceEventTypeEXT::eDisplayHotplug ) VULKAN_HPP_NOEXCEPT
        : deviceEvent( deviceEvent_ )
      {}

      DeviceEventInfoEXT( VkDeviceEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceEventInfoEXT*>(this) = rhs;
      }

      DeviceEventInfoEXT& operator=( VkDeviceEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceEventInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceEventInfoEXT;
      const void* pNext = nullptr;
      vk::DeviceEventTypeEXT deviceEvent;
    };
    static_assert( sizeof( DeviceEventInfoEXT ) == sizeof( VkDeviceEventInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DeviceEventInfoEXT : public layout::DeviceEventInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DeviceEventInfoEXT( vk::DeviceEventTypeEXT deviceEvent_ = vk::DeviceEventTypeEXT::eDisplayHotplug ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceEventInfoEXT( deviceEvent_ )
    {}

    DeviceEventInfoEXT( VkDeviceEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceEventInfoEXT( rhs )
    {}

    DeviceEventInfoEXT& operator=( VkDeviceEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceEventInfoEXT::operator=(rhs);
      return *this;
    }

    DeviceEventInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceEventInfoEXT & setDeviceEvent( vk::DeviceEventTypeEXT deviceEvent_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceEvent = deviceEvent_;
      return *this;
    }

    operator VkDeviceEventInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceEventInfoEXT*>( this );
    }

    operator VkDeviceEventInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceEventInfoEXT*>( this );
    }

    bool operator==( DeviceEventInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( deviceEvent == rhs.deviceEvent );
    }

    bool operator!=( DeviceEventInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceEventInfoEXT::sType;
  };
  static_assert( sizeof( DeviceEventInfoEXT ) == sizeof( VkDeviceEventInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceEventInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGeneratedCommandsFeaturesNVX
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGeneratedCommandsFeaturesNVX( vk::Bool32 computeBindingPointSupport_ = 0 ) VULKAN_HPP_NOEXCEPT
        : computeBindingPointSupport( computeBindingPointSupport_ )
      {}

      DeviceGeneratedCommandsFeaturesNVX( VkDeviceGeneratedCommandsFeaturesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGeneratedCommandsFeaturesNVX*>(this) = rhs;
      }

      DeviceGeneratedCommandsFeaturesNVX& operator=( VkDeviceGeneratedCommandsFeaturesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGeneratedCommandsFeaturesNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGeneratedCommandsFeaturesNVX;
      const void* pNext = nullptr;
      vk::Bool32 computeBindingPointSupport;
    };
    static_assert( sizeof( DeviceGeneratedCommandsFeaturesNVX ) == sizeof( VkDeviceGeneratedCommandsFeaturesNVX ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGeneratedCommandsFeaturesNVX : public layout::DeviceGeneratedCommandsFeaturesNVX
  {
    VULKAN_HPP_CONSTEXPR DeviceGeneratedCommandsFeaturesNVX( vk::Bool32 computeBindingPointSupport_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGeneratedCommandsFeaturesNVX( computeBindingPointSupport_ )
    {}

    DeviceGeneratedCommandsFeaturesNVX( VkDeviceGeneratedCommandsFeaturesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGeneratedCommandsFeaturesNVX( rhs )
    {}

    DeviceGeneratedCommandsFeaturesNVX& operator=( VkDeviceGeneratedCommandsFeaturesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGeneratedCommandsFeaturesNVX::operator=(rhs);
      return *this;
    }

    DeviceGeneratedCommandsFeaturesNVX & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGeneratedCommandsFeaturesNVX & setComputeBindingPointSupport( vk::Bool32 computeBindingPointSupport_ ) VULKAN_HPP_NOEXCEPT
    {
      computeBindingPointSupport = computeBindingPointSupport_;
      return *this;
    }

    operator VkDeviceGeneratedCommandsFeaturesNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGeneratedCommandsFeaturesNVX*>( this );
    }

    operator VkDeviceGeneratedCommandsFeaturesNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGeneratedCommandsFeaturesNVX*>( this );
    }

    bool operator==( DeviceGeneratedCommandsFeaturesNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( computeBindingPointSupport == rhs.computeBindingPointSupport );
    }

    bool operator!=( DeviceGeneratedCommandsFeaturesNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGeneratedCommandsFeaturesNVX::sType;
  };
  static_assert( sizeof( DeviceGeneratedCommandsFeaturesNVX ) == sizeof( VkDeviceGeneratedCommandsFeaturesNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGeneratedCommandsFeaturesNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGeneratedCommandsLimitsNVX
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGeneratedCommandsLimitsNVX( uint32_t maxIndirectCommandsLayoutTokenCount_ = 0,
                                                             uint32_t maxObjectEntryCounts_ = 0,
                                                             uint32_t minSequenceCountBufferOffsetAlignment_ = 0,
                                                             uint32_t minSequenceIndexBufferOffsetAlignment_ = 0,
                                                             uint32_t minCommandsTokenBufferOffsetAlignment_ = 0 ) VULKAN_HPP_NOEXCEPT
        : maxIndirectCommandsLayoutTokenCount( maxIndirectCommandsLayoutTokenCount_ )
        , maxObjectEntryCounts( maxObjectEntryCounts_ )
        , minSequenceCountBufferOffsetAlignment( minSequenceCountBufferOffsetAlignment_ )
        , minSequenceIndexBufferOffsetAlignment( minSequenceIndexBufferOffsetAlignment_ )
        , minCommandsTokenBufferOffsetAlignment( minCommandsTokenBufferOffsetAlignment_ )
      {}

      DeviceGeneratedCommandsLimitsNVX( VkDeviceGeneratedCommandsLimitsNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGeneratedCommandsLimitsNVX*>(this) = rhs;
      }

      DeviceGeneratedCommandsLimitsNVX& operator=( VkDeviceGeneratedCommandsLimitsNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGeneratedCommandsLimitsNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGeneratedCommandsLimitsNVX;
      const void* pNext = nullptr;
      uint32_t maxIndirectCommandsLayoutTokenCount;
      uint32_t maxObjectEntryCounts;
      uint32_t minSequenceCountBufferOffsetAlignment;
      uint32_t minSequenceIndexBufferOffsetAlignment;
      uint32_t minCommandsTokenBufferOffsetAlignment;
    };
    static_assert( sizeof( DeviceGeneratedCommandsLimitsNVX ) == sizeof( VkDeviceGeneratedCommandsLimitsNVX ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGeneratedCommandsLimitsNVX : public layout::DeviceGeneratedCommandsLimitsNVX
  {
    VULKAN_HPP_CONSTEXPR DeviceGeneratedCommandsLimitsNVX( uint32_t maxIndirectCommandsLayoutTokenCount_ = 0,
                                                           uint32_t maxObjectEntryCounts_ = 0,
                                                           uint32_t minSequenceCountBufferOffsetAlignment_ = 0,
                                                           uint32_t minSequenceIndexBufferOffsetAlignment_ = 0,
                                                           uint32_t minCommandsTokenBufferOffsetAlignment_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGeneratedCommandsLimitsNVX( maxIndirectCommandsLayoutTokenCount_, maxObjectEntryCounts_, minSequenceCountBufferOffsetAlignment_, minSequenceIndexBufferOffsetAlignment_, minCommandsTokenBufferOffsetAlignment_ )
    {}

    DeviceGeneratedCommandsLimitsNVX( VkDeviceGeneratedCommandsLimitsNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGeneratedCommandsLimitsNVX( rhs )
    {}

    DeviceGeneratedCommandsLimitsNVX& operator=( VkDeviceGeneratedCommandsLimitsNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGeneratedCommandsLimitsNVX::operator=(rhs);
      return *this;
    }

    DeviceGeneratedCommandsLimitsNVX & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGeneratedCommandsLimitsNVX & setMaxIndirectCommandsLayoutTokenCount( uint32_t maxIndirectCommandsLayoutTokenCount_ ) VULKAN_HPP_NOEXCEPT
    {
      maxIndirectCommandsLayoutTokenCount = maxIndirectCommandsLayoutTokenCount_;
      return *this;
    }

    DeviceGeneratedCommandsLimitsNVX & setMaxObjectEntryCounts( uint32_t maxObjectEntryCounts_ ) VULKAN_HPP_NOEXCEPT
    {
      maxObjectEntryCounts = maxObjectEntryCounts_;
      return *this;
    }

    DeviceGeneratedCommandsLimitsNVX & setMinSequenceCountBufferOffsetAlignment( uint32_t minSequenceCountBufferOffsetAlignment_ ) VULKAN_HPP_NOEXCEPT
    {
      minSequenceCountBufferOffsetAlignment = minSequenceCountBufferOffsetAlignment_;
      return *this;
    }

    DeviceGeneratedCommandsLimitsNVX & setMinSequenceIndexBufferOffsetAlignment( uint32_t minSequenceIndexBufferOffsetAlignment_ ) VULKAN_HPP_NOEXCEPT
    {
      minSequenceIndexBufferOffsetAlignment = minSequenceIndexBufferOffsetAlignment_;
      return *this;
    }

    DeviceGeneratedCommandsLimitsNVX & setMinCommandsTokenBufferOffsetAlignment( uint32_t minCommandsTokenBufferOffsetAlignment_ ) VULKAN_HPP_NOEXCEPT
    {
      minCommandsTokenBufferOffsetAlignment = minCommandsTokenBufferOffsetAlignment_;
      return *this;
    }

    operator VkDeviceGeneratedCommandsLimitsNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGeneratedCommandsLimitsNVX*>( this );
    }

    operator VkDeviceGeneratedCommandsLimitsNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGeneratedCommandsLimitsNVX*>( this );
    }

    bool operator==( DeviceGeneratedCommandsLimitsNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxIndirectCommandsLayoutTokenCount == rhs.maxIndirectCommandsLayoutTokenCount )
          && ( maxObjectEntryCounts == rhs.maxObjectEntryCounts )
          && ( minSequenceCountBufferOffsetAlignment == rhs.minSequenceCountBufferOffsetAlignment )
          && ( minSequenceIndexBufferOffsetAlignment == rhs.minSequenceIndexBufferOffsetAlignment )
          && ( minCommandsTokenBufferOffsetAlignment == rhs.minCommandsTokenBufferOffsetAlignment );
    }

    bool operator!=( DeviceGeneratedCommandsLimitsNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGeneratedCommandsLimitsNVX::sType;
  };
  static_assert( sizeof( DeviceGeneratedCommandsLimitsNVX ) == sizeof( VkDeviceGeneratedCommandsLimitsNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGeneratedCommandsLimitsNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupBindSparseInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGroupBindSparseInfo( uint32_t resourceDeviceIndex_ = 0,
                                                      uint32_t memoryDeviceIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : resourceDeviceIndex( resourceDeviceIndex_ )
        , memoryDeviceIndex( memoryDeviceIndex_ )
      {}

      DeviceGroupBindSparseInfo( VkDeviceGroupBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupBindSparseInfo*>(this) = rhs;
      }

      DeviceGroupBindSparseInfo& operator=( VkDeviceGroupBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupBindSparseInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupBindSparseInfo;
      const void* pNext = nullptr;
      uint32_t resourceDeviceIndex;
      uint32_t memoryDeviceIndex;
    };
    static_assert( sizeof( DeviceGroupBindSparseInfo ) == sizeof( VkDeviceGroupBindSparseInfo ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupBindSparseInfo : public layout::DeviceGroupBindSparseInfo
  {
    VULKAN_HPP_CONSTEXPR DeviceGroupBindSparseInfo( uint32_t resourceDeviceIndex_ = 0,
                                                    uint32_t memoryDeviceIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupBindSparseInfo( resourceDeviceIndex_, memoryDeviceIndex_ )
    {}

    DeviceGroupBindSparseInfo( VkDeviceGroupBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupBindSparseInfo( rhs )
    {}

    DeviceGroupBindSparseInfo& operator=( VkDeviceGroupBindSparseInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupBindSparseInfo::operator=(rhs);
      return *this;
    }

    DeviceGroupBindSparseInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGroupBindSparseInfo & setResourceDeviceIndex( uint32_t resourceDeviceIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      resourceDeviceIndex = resourceDeviceIndex_;
      return *this;
    }

    DeviceGroupBindSparseInfo & setMemoryDeviceIndex( uint32_t memoryDeviceIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryDeviceIndex = memoryDeviceIndex_;
      return *this;
    }

    operator VkDeviceGroupBindSparseInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupBindSparseInfo*>( this );
    }

    operator VkDeviceGroupBindSparseInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupBindSparseInfo*>( this );
    }

    bool operator==( DeviceGroupBindSparseInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( resourceDeviceIndex == rhs.resourceDeviceIndex )
          && ( memoryDeviceIndex == rhs.memoryDeviceIndex );
    }

    bool operator!=( DeviceGroupBindSparseInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupBindSparseInfo::sType;
  };
  static_assert( sizeof( DeviceGroupBindSparseInfo ) == sizeof( VkDeviceGroupBindSparseInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupBindSparseInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupCommandBufferBeginInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGroupCommandBufferBeginInfo( uint32_t deviceMask_ = 0 ) VULKAN_HPP_NOEXCEPT
        : deviceMask( deviceMask_ )
      {}

      DeviceGroupCommandBufferBeginInfo( VkDeviceGroupCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupCommandBufferBeginInfo*>(this) = rhs;
      }

      DeviceGroupCommandBufferBeginInfo& operator=( VkDeviceGroupCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupCommandBufferBeginInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupCommandBufferBeginInfo;
      const void* pNext = nullptr;
      uint32_t deviceMask;
    };
    static_assert( sizeof( DeviceGroupCommandBufferBeginInfo ) == sizeof( VkDeviceGroupCommandBufferBeginInfo ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupCommandBufferBeginInfo : public layout::DeviceGroupCommandBufferBeginInfo
  {
    VULKAN_HPP_CONSTEXPR DeviceGroupCommandBufferBeginInfo( uint32_t deviceMask_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupCommandBufferBeginInfo( deviceMask_ )
    {}

    DeviceGroupCommandBufferBeginInfo( VkDeviceGroupCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupCommandBufferBeginInfo( rhs )
    {}

    DeviceGroupCommandBufferBeginInfo& operator=( VkDeviceGroupCommandBufferBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupCommandBufferBeginInfo::operator=(rhs);
      return *this;
    }

    DeviceGroupCommandBufferBeginInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGroupCommandBufferBeginInfo & setDeviceMask( uint32_t deviceMask_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceMask = deviceMask_;
      return *this;
    }

    operator VkDeviceGroupCommandBufferBeginInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupCommandBufferBeginInfo*>( this );
    }

    operator VkDeviceGroupCommandBufferBeginInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupCommandBufferBeginInfo*>( this );
    }

    bool operator==( DeviceGroupCommandBufferBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( deviceMask == rhs.deviceMask );
    }

    bool operator!=( DeviceGroupCommandBufferBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupCommandBufferBeginInfo::sType;
  };
  static_assert( sizeof( DeviceGroupCommandBufferBeginInfo ) == sizeof( VkDeviceGroupCommandBufferBeginInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupCommandBufferBeginInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupDeviceCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGroupDeviceCreateInfo( uint32_t physicalDeviceCount_ = 0,
                                                        const vk::PhysicalDevice* pPhysicalDevices_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : physicalDeviceCount( physicalDeviceCount_ )
        , pPhysicalDevices( pPhysicalDevices_ )
      {}

      DeviceGroupDeviceCreateInfo( VkDeviceGroupDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupDeviceCreateInfo*>(this) = rhs;
      }

      DeviceGroupDeviceCreateInfo& operator=( VkDeviceGroupDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupDeviceCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupDeviceCreateInfo;
      const void* pNext = nullptr;
      uint32_t physicalDeviceCount;
      const vk::PhysicalDevice* pPhysicalDevices;
    };
    static_assert( sizeof( DeviceGroupDeviceCreateInfo ) == sizeof( VkDeviceGroupDeviceCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupDeviceCreateInfo : public layout::DeviceGroupDeviceCreateInfo
  {
    VULKAN_HPP_CONSTEXPR DeviceGroupDeviceCreateInfo( uint32_t physicalDeviceCount_ = 0,
                                                      const vk::PhysicalDevice* pPhysicalDevices_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupDeviceCreateInfo( physicalDeviceCount_, pPhysicalDevices_ )
    {}

    DeviceGroupDeviceCreateInfo( VkDeviceGroupDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupDeviceCreateInfo( rhs )
    {}

    DeviceGroupDeviceCreateInfo& operator=( VkDeviceGroupDeviceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupDeviceCreateInfo::operator=(rhs);
      return *this;
    }

    DeviceGroupDeviceCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGroupDeviceCreateInfo & setPhysicalDeviceCount( uint32_t physicalDeviceCount_ ) VULKAN_HPP_NOEXCEPT
    {
      physicalDeviceCount = physicalDeviceCount_;
      return *this;
    }

    DeviceGroupDeviceCreateInfo & setPPhysicalDevices( const vk::PhysicalDevice* pPhysicalDevices_ ) VULKAN_HPP_NOEXCEPT
    {
      pPhysicalDevices = pPhysicalDevices_;
      return *this;
    }

    operator VkDeviceGroupDeviceCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupDeviceCreateInfo*>( this );
    }

    operator VkDeviceGroupDeviceCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupDeviceCreateInfo*>( this );
    }

    bool operator==( DeviceGroupDeviceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( physicalDeviceCount == rhs.physicalDeviceCount )
          && ( pPhysicalDevices == rhs.pPhysicalDevices );
    }

    bool operator!=( DeviceGroupDeviceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupDeviceCreateInfo::sType;
  };
  static_assert( sizeof( DeviceGroupDeviceCreateInfo ) == sizeof( VkDeviceGroupDeviceCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupDeviceCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupPresentCapabilitiesKHR
    {
    protected:
      DeviceGroupPresentCapabilitiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      DeviceGroupPresentCapabilitiesKHR( VkDeviceGroupPresentCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupPresentCapabilitiesKHR*>(this) = rhs;
      }

      DeviceGroupPresentCapabilitiesKHR& operator=( VkDeviceGroupPresentCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupPresentCapabilitiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupPresentCapabilitiesKHR;
      const void* pNext = nullptr;
      uint32_t presentMask[VK_MAX_DEVICE_GROUP_SIZE];
      vk::DeviceGroupPresentModeFlagsKHR modes;
    };
    static_assert( sizeof( DeviceGroupPresentCapabilitiesKHR ) == sizeof( VkDeviceGroupPresentCapabilitiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupPresentCapabilitiesKHR : public layout::DeviceGroupPresentCapabilitiesKHR
  {
    DeviceGroupPresentCapabilitiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupPresentCapabilitiesKHR()
    {}

    DeviceGroupPresentCapabilitiesKHR( VkDeviceGroupPresentCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupPresentCapabilitiesKHR( rhs )
    {}

    DeviceGroupPresentCapabilitiesKHR& operator=( VkDeviceGroupPresentCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupPresentCapabilitiesKHR::operator=(rhs);
      return *this;
    }

    operator VkDeviceGroupPresentCapabilitiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupPresentCapabilitiesKHR*>( this );
    }

    operator VkDeviceGroupPresentCapabilitiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupPresentCapabilitiesKHR*>( this );
    }

    bool operator==( DeviceGroupPresentCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memcmp( presentMask, rhs.presentMask, VK_MAX_DEVICE_GROUP_SIZE * sizeof( uint32_t ) ) == 0 )
          && ( modes == rhs.modes );
    }

    bool operator!=( DeviceGroupPresentCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupPresentCapabilitiesKHR::sType;
  };
  static_assert( sizeof( DeviceGroupPresentCapabilitiesKHR ) == sizeof( VkDeviceGroupPresentCapabilitiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupPresentCapabilitiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupPresentInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGroupPresentInfoKHR( uint32_t swapchainCount_ = 0,
                                                      const uint32_t* pDeviceMasks_ = nullptr,
                                                      vk::DeviceGroupPresentModeFlagBitsKHR mode_ = vk::DeviceGroupPresentModeFlagBitsKHR::eLocal ) VULKAN_HPP_NOEXCEPT
        : swapchainCount( swapchainCount_ )
        , pDeviceMasks( pDeviceMasks_ )
        , mode( mode_ )
      {}

      DeviceGroupPresentInfoKHR( VkDeviceGroupPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupPresentInfoKHR*>(this) = rhs;
      }

      DeviceGroupPresentInfoKHR& operator=( VkDeviceGroupPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupPresentInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupPresentInfoKHR;
      const void* pNext = nullptr;
      uint32_t swapchainCount;
      const uint32_t* pDeviceMasks;
      vk::DeviceGroupPresentModeFlagBitsKHR mode;
    };
    static_assert( sizeof( DeviceGroupPresentInfoKHR ) == sizeof( VkDeviceGroupPresentInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupPresentInfoKHR : public layout::DeviceGroupPresentInfoKHR
  {
    VULKAN_HPP_CONSTEXPR DeviceGroupPresentInfoKHR( uint32_t swapchainCount_ = 0,
                                                    const uint32_t* pDeviceMasks_ = nullptr,
                                                    vk::DeviceGroupPresentModeFlagBitsKHR mode_ = vk::DeviceGroupPresentModeFlagBitsKHR::eLocal ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupPresentInfoKHR( swapchainCount_, pDeviceMasks_, mode_ )
    {}

    DeviceGroupPresentInfoKHR( VkDeviceGroupPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupPresentInfoKHR( rhs )
    {}

    DeviceGroupPresentInfoKHR& operator=( VkDeviceGroupPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupPresentInfoKHR::operator=(rhs);
      return *this;
    }

    DeviceGroupPresentInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGroupPresentInfoKHR & setSwapchainCount( uint32_t swapchainCount_ ) VULKAN_HPP_NOEXCEPT
    {
      swapchainCount = swapchainCount_;
      return *this;
    }

    DeviceGroupPresentInfoKHR & setPDeviceMasks( const uint32_t* pDeviceMasks_ ) VULKAN_HPP_NOEXCEPT
    {
      pDeviceMasks = pDeviceMasks_;
      return *this;
    }

    DeviceGroupPresentInfoKHR & setMode( vk::DeviceGroupPresentModeFlagBitsKHR mode_ ) VULKAN_HPP_NOEXCEPT
    {
      mode = mode_;
      return *this;
    }

    operator VkDeviceGroupPresentInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupPresentInfoKHR*>( this );
    }

    operator VkDeviceGroupPresentInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupPresentInfoKHR*>( this );
    }

    bool operator==( DeviceGroupPresentInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( swapchainCount == rhs.swapchainCount )
          && ( pDeviceMasks == rhs.pDeviceMasks )
          && vk::operator==( mode, rhs.mode );
    }

    bool operator!=( DeviceGroupPresentInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupPresentInfoKHR::sType;
  };
  static_assert( sizeof( DeviceGroupPresentInfoKHR ) == sizeof( VkDeviceGroupPresentInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupPresentInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupRenderPassBeginInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGroupRenderPassBeginInfo( uint32_t deviceMask_ = 0,
                                                           uint32_t deviceRenderAreaCount_ = 0,
                                                           const vk::Rect2D* pDeviceRenderAreas_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : deviceMask( deviceMask_ )
        , deviceRenderAreaCount( deviceRenderAreaCount_ )
        , pDeviceRenderAreas( pDeviceRenderAreas_ )
      {}

      DeviceGroupRenderPassBeginInfo( VkDeviceGroupRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupRenderPassBeginInfo*>(this) = rhs;
      }

      DeviceGroupRenderPassBeginInfo& operator=( VkDeviceGroupRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupRenderPassBeginInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupRenderPassBeginInfo;
      const void* pNext = nullptr;
      uint32_t deviceMask;
      uint32_t deviceRenderAreaCount;
      const vk::Rect2D* pDeviceRenderAreas;
    };
    static_assert( sizeof( DeviceGroupRenderPassBeginInfo ) == sizeof( VkDeviceGroupRenderPassBeginInfo ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupRenderPassBeginInfo : public layout::DeviceGroupRenderPassBeginInfo
  {
    VULKAN_HPP_CONSTEXPR DeviceGroupRenderPassBeginInfo( uint32_t deviceMask_ = 0,
                                                         uint32_t deviceRenderAreaCount_ = 0,
                                                         const vk::Rect2D* pDeviceRenderAreas_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupRenderPassBeginInfo( deviceMask_, deviceRenderAreaCount_, pDeviceRenderAreas_ )
    {}

    DeviceGroupRenderPassBeginInfo( VkDeviceGroupRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupRenderPassBeginInfo( rhs )
    {}

    DeviceGroupRenderPassBeginInfo& operator=( VkDeviceGroupRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupRenderPassBeginInfo::operator=(rhs);
      return *this;
    }

    DeviceGroupRenderPassBeginInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGroupRenderPassBeginInfo & setDeviceMask( uint32_t deviceMask_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceMask = deviceMask_;
      return *this;
    }

    DeviceGroupRenderPassBeginInfo & setDeviceRenderAreaCount( uint32_t deviceRenderAreaCount_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceRenderAreaCount = deviceRenderAreaCount_;
      return *this;
    }

    DeviceGroupRenderPassBeginInfo & setPDeviceRenderAreas( const vk::Rect2D* pDeviceRenderAreas_ ) VULKAN_HPP_NOEXCEPT
    {
      pDeviceRenderAreas = pDeviceRenderAreas_;
      return *this;
    }

    operator VkDeviceGroupRenderPassBeginInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupRenderPassBeginInfo*>( this );
    }

    operator VkDeviceGroupRenderPassBeginInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupRenderPassBeginInfo*>( this );
    }

    bool operator==( DeviceGroupRenderPassBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( deviceMask == rhs.deviceMask )
          && ( deviceRenderAreaCount == rhs.deviceRenderAreaCount )
          && ( pDeviceRenderAreas == rhs.pDeviceRenderAreas );
    }

    bool operator!=( DeviceGroupRenderPassBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupRenderPassBeginInfo::sType;
  };
  static_assert( sizeof( DeviceGroupRenderPassBeginInfo ) == sizeof( VkDeviceGroupRenderPassBeginInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupRenderPassBeginInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupSubmitInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGroupSubmitInfo( uint32_t waitSemaphoreCount_ = 0,
                                                  const uint32_t* pWaitSemaphoreDeviceIndices_ = nullptr,
                                                  uint32_t commandBufferCount_ = 0,
                                                  const uint32_t* pCommandBufferDeviceMasks_ = nullptr,
                                                  uint32_t signalSemaphoreCount_ = 0,
                                                  const uint32_t* pSignalSemaphoreDeviceIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : waitSemaphoreCount( waitSemaphoreCount_ )
        , pWaitSemaphoreDeviceIndices( pWaitSemaphoreDeviceIndices_ )
        , commandBufferCount( commandBufferCount_ )
        , pCommandBufferDeviceMasks( pCommandBufferDeviceMasks_ )
        , signalSemaphoreCount( signalSemaphoreCount_ )
        , pSignalSemaphoreDeviceIndices( pSignalSemaphoreDeviceIndices_ )
      {}

      DeviceGroupSubmitInfo( VkDeviceGroupSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupSubmitInfo*>(this) = rhs;
      }

      DeviceGroupSubmitInfo& operator=( VkDeviceGroupSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupSubmitInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupSubmitInfo;
      const void* pNext = nullptr;
      uint32_t waitSemaphoreCount;
      const uint32_t* pWaitSemaphoreDeviceIndices;
      uint32_t commandBufferCount;
      const uint32_t* pCommandBufferDeviceMasks;
      uint32_t signalSemaphoreCount;
      const uint32_t* pSignalSemaphoreDeviceIndices;
    };
    static_assert( sizeof( DeviceGroupSubmitInfo ) == sizeof( VkDeviceGroupSubmitInfo ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupSubmitInfo : public layout::DeviceGroupSubmitInfo
  {
    VULKAN_HPP_CONSTEXPR DeviceGroupSubmitInfo( uint32_t waitSemaphoreCount_ = 0,
                                                const uint32_t* pWaitSemaphoreDeviceIndices_ = nullptr,
                                                uint32_t commandBufferCount_ = 0,
                                                const uint32_t* pCommandBufferDeviceMasks_ = nullptr,
                                                uint32_t signalSemaphoreCount_ = 0,
                                                const uint32_t* pSignalSemaphoreDeviceIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupSubmitInfo( waitSemaphoreCount_, pWaitSemaphoreDeviceIndices_, commandBufferCount_, pCommandBufferDeviceMasks_, signalSemaphoreCount_, pSignalSemaphoreDeviceIndices_ )
    {}

    DeviceGroupSubmitInfo( VkDeviceGroupSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupSubmitInfo( rhs )
    {}

    DeviceGroupSubmitInfo& operator=( VkDeviceGroupSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupSubmitInfo::operator=(rhs);
      return *this;
    }

    DeviceGroupSubmitInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGroupSubmitInfo & setWaitSemaphoreCount( uint32_t waitSemaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      waitSemaphoreCount = waitSemaphoreCount_;
      return *this;
    }

    DeviceGroupSubmitInfo & setPWaitSemaphoreDeviceIndices( const uint32_t* pWaitSemaphoreDeviceIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pWaitSemaphoreDeviceIndices = pWaitSemaphoreDeviceIndices_;
      return *this;
    }

    DeviceGroupSubmitInfo & setCommandBufferCount( uint32_t commandBufferCount_ ) VULKAN_HPP_NOEXCEPT
    {
      commandBufferCount = commandBufferCount_;
      return *this;
    }

    DeviceGroupSubmitInfo & setPCommandBufferDeviceMasks( const uint32_t* pCommandBufferDeviceMasks_ ) VULKAN_HPP_NOEXCEPT
    {
      pCommandBufferDeviceMasks = pCommandBufferDeviceMasks_;
      return *this;
    }

    DeviceGroupSubmitInfo & setSignalSemaphoreCount( uint32_t signalSemaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      signalSemaphoreCount = signalSemaphoreCount_;
      return *this;
    }

    DeviceGroupSubmitInfo & setPSignalSemaphoreDeviceIndices( const uint32_t* pSignalSemaphoreDeviceIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pSignalSemaphoreDeviceIndices = pSignalSemaphoreDeviceIndices_;
      return *this;
    }

    operator VkDeviceGroupSubmitInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupSubmitInfo*>( this );
    }

    operator VkDeviceGroupSubmitInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupSubmitInfo*>( this );
    }

    bool operator==( DeviceGroupSubmitInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( waitSemaphoreCount == rhs.waitSemaphoreCount )
          && ( pWaitSemaphoreDeviceIndices == rhs.pWaitSemaphoreDeviceIndices )
          && ( commandBufferCount == rhs.commandBufferCount )
          && ( pCommandBufferDeviceMasks == rhs.pCommandBufferDeviceMasks )
          && ( signalSemaphoreCount == rhs.signalSemaphoreCount )
          && ( pSignalSemaphoreDeviceIndices == rhs.pSignalSemaphoreDeviceIndices );
    }

    bool operator!=( DeviceGroupSubmitInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupSubmitInfo::sType;
  };
  static_assert( sizeof( DeviceGroupSubmitInfo ) == sizeof( VkDeviceGroupSubmitInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupSubmitInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceGroupSwapchainCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceGroupSwapchainCreateInfoKHR( vk::DeviceGroupPresentModeFlagsKHR modes_ = vk::DeviceGroupPresentModeFlagsKHR() ) VULKAN_HPP_NOEXCEPT
        : modes( modes_ )
      {}

      DeviceGroupSwapchainCreateInfoKHR( VkDeviceGroupSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupSwapchainCreateInfoKHR*>(this) = rhs;
      }

      DeviceGroupSwapchainCreateInfoKHR& operator=( VkDeviceGroupSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceGroupSwapchainCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceGroupSwapchainCreateInfoKHR;
      const void* pNext = nullptr;
      vk::DeviceGroupPresentModeFlagsKHR modes;
    };
    static_assert( sizeof( DeviceGroupSwapchainCreateInfoKHR ) == sizeof( VkDeviceGroupSwapchainCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct DeviceGroupSwapchainCreateInfoKHR : public layout::DeviceGroupSwapchainCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR DeviceGroupSwapchainCreateInfoKHR( vk::DeviceGroupPresentModeFlagsKHR modes_ = vk::DeviceGroupPresentModeFlagsKHR() ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupSwapchainCreateInfoKHR( modes_ )
    {}

    DeviceGroupSwapchainCreateInfoKHR( VkDeviceGroupSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceGroupSwapchainCreateInfoKHR( rhs )
    {}

    DeviceGroupSwapchainCreateInfoKHR& operator=( VkDeviceGroupSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceGroupSwapchainCreateInfoKHR::operator=(rhs);
      return *this;
    }

    DeviceGroupSwapchainCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceGroupSwapchainCreateInfoKHR & setModes( vk::DeviceGroupPresentModeFlagsKHR modes_ ) VULKAN_HPP_NOEXCEPT
    {
      modes = modes_;
      return *this;
    }

    operator VkDeviceGroupSwapchainCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceGroupSwapchainCreateInfoKHR*>( this );
    }

    operator VkDeviceGroupSwapchainCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceGroupSwapchainCreateInfoKHR*>( this );
    }

    bool operator==( DeviceGroupSwapchainCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( modes == rhs.modes );
    }

    bool operator!=( DeviceGroupSwapchainCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceGroupSwapchainCreateInfoKHR::sType;
  };
  static_assert( sizeof( DeviceGroupSwapchainCreateInfoKHR ) == sizeof( VkDeviceGroupSwapchainCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceGroupSwapchainCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceMemoryOverallocationCreateInfoAMD
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceMemoryOverallocationCreateInfoAMD( vk::MemoryOverallocationBehaviorAMD overallocationBehavior_ = vk::MemoryOverallocationBehaviorAMD::eDefault ) VULKAN_HPP_NOEXCEPT
        : overallocationBehavior( overallocationBehavior_ )
      {}

      DeviceMemoryOverallocationCreateInfoAMD( VkDeviceMemoryOverallocationCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceMemoryOverallocationCreateInfoAMD*>(this) = rhs;
      }

      DeviceMemoryOverallocationCreateInfoAMD& operator=( VkDeviceMemoryOverallocationCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceMemoryOverallocationCreateInfoAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceMemoryOverallocationCreateInfoAMD;
      const void* pNext = nullptr;
      vk::MemoryOverallocationBehaviorAMD overallocationBehavior;
    };
    static_assert( sizeof( DeviceMemoryOverallocationCreateInfoAMD ) == sizeof( VkDeviceMemoryOverallocationCreateInfoAMD ), "layout struct and wrapper have different size!" );
  }

  struct DeviceMemoryOverallocationCreateInfoAMD : public layout::DeviceMemoryOverallocationCreateInfoAMD
  {
    VULKAN_HPP_CONSTEXPR DeviceMemoryOverallocationCreateInfoAMD( vk::MemoryOverallocationBehaviorAMD overallocationBehavior_ = vk::MemoryOverallocationBehaviorAMD::eDefault ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceMemoryOverallocationCreateInfoAMD( overallocationBehavior_ )
    {}

    DeviceMemoryOverallocationCreateInfoAMD( VkDeviceMemoryOverallocationCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceMemoryOverallocationCreateInfoAMD( rhs )
    {}

    DeviceMemoryOverallocationCreateInfoAMD& operator=( VkDeviceMemoryOverallocationCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceMemoryOverallocationCreateInfoAMD::operator=(rhs);
      return *this;
    }

    DeviceMemoryOverallocationCreateInfoAMD & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceMemoryOverallocationCreateInfoAMD & setOverallocationBehavior( vk::MemoryOverallocationBehaviorAMD overallocationBehavior_ ) VULKAN_HPP_NOEXCEPT
    {
      overallocationBehavior = overallocationBehavior_;
      return *this;
    }

    operator VkDeviceMemoryOverallocationCreateInfoAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceMemoryOverallocationCreateInfoAMD*>( this );
    }

    operator VkDeviceMemoryOverallocationCreateInfoAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceMemoryOverallocationCreateInfoAMD*>( this );
    }

    bool operator==( DeviceMemoryOverallocationCreateInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( overallocationBehavior == rhs.overallocationBehavior );
    }

    bool operator!=( DeviceMemoryOverallocationCreateInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceMemoryOverallocationCreateInfoAMD::sType;
  };
  static_assert( sizeof( DeviceMemoryOverallocationCreateInfoAMD ) == sizeof( VkDeviceMemoryOverallocationCreateInfoAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceMemoryOverallocationCreateInfoAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceQueueGlobalPriorityCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceQueueGlobalPriorityCreateInfoEXT( vk::QueueGlobalPriorityEXT globalPriority_ = vk::QueueGlobalPriorityEXT::eLow ) VULKAN_HPP_NOEXCEPT
        : globalPriority( globalPriority_ )
      {}

      DeviceQueueGlobalPriorityCreateInfoEXT( VkDeviceQueueGlobalPriorityCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceQueueGlobalPriorityCreateInfoEXT*>(this) = rhs;
      }

      DeviceQueueGlobalPriorityCreateInfoEXT& operator=( VkDeviceQueueGlobalPriorityCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceQueueGlobalPriorityCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceQueueGlobalPriorityCreateInfoEXT;
      const void* pNext = nullptr;
      vk::QueueGlobalPriorityEXT globalPriority;
    };
    static_assert( sizeof( DeviceQueueGlobalPriorityCreateInfoEXT ) == sizeof( VkDeviceQueueGlobalPriorityCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DeviceQueueGlobalPriorityCreateInfoEXT : public layout::DeviceQueueGlobalPriorityCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DeviceQueueGlobalPriorityCreateInfoEXT( vk::QueueGlobalPriorityEXT globalPriority_ = vk::QueueGlobalPriorityEXT::eLow ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceQueueGlobalPriorityCreateInfoEXT( globalPriority_ )
    {}

    DeviceQueueGlobalPriorityCreateInfoEXT( VkDeviceQueueGlobalPriorityCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceQueueGlobalPriorityCreateInfoEXT( rhs )
    {}

    DeviceQueueGlobalPriorityCreateInfoEXT& operator=( VkDeviceQueueGlobalPriorityCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceQueueGlobalPriorityCreateInfoEXT::operator=(rhs);
      return *this;
    }

    DeviceQueueGlobalPriorityCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceQueueGlobalPriorityCreateInfoEXT & setGlobalPriority( vk::QueueGlobalPriorityEXT globalPriority_ ) VULKAN_HPP_NOEXCEPT
    {
      globalPriority = globalPriority_;
      return *this;
    }

    operator VkDeviceQueueGlobalPriorityCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceQueueGlobalPriorityCreateInfoEXT*>( this );
    }

    operator VkDeviceQueueGlobalPriorityCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceQueueGlobalPriorityCreateInfoEXT*>( this );
    }

    bool operator==( DeviceQueueGlobalPriorityCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( globalPriority == rhs.globalPriority );
    }

    bool operator!=( DeviceQueueGlobalPriorityCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceQueueGlobalPriorityCreateInfoEXT::sType;
  };
  static_assert( sizeof( DeviceQueueGlobalPriorityCreateInfoEXT ) == sizeof( VkDeviceQueueGlobalPriorityCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceQueueGlobalPriorityCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DeviceQueueInfo2
    {
    protected:
      VULKAN_HPP_CONSTEXPR DeviceQueueInfo2( vk::DeviceQueueCreateFlags flags_ = vk::DeviceQueueCreateFlags(),
                                             uint32_t queueFamilyIndex_ = 0,
                                             uint32_t queueIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , queueFamilyIndex( queueFamilyIndex_ )
        , queueIndex( queueIndex_ )
      {}

      DeviceQueueInfo2( VkDeviceQueueInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceQueueInfo2*>(this) = rhs;
      }

      DeviceQueueInfo2& operator=( VkDeviceQueueInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDeviceQueueInfo2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDeviceQueueInfo2;
      const void* pNext = nullptr;
      vk::DeviceQueueCreateFlags flags;
      uint32_t queueFamilyIndex;
      uint32_t queueIndex;
    };
    static_assert( sizeof( DeviceQueueInfo2 ) == sizeof( VkDeviceQueueInfo2 ), "layout struct and wrapper have different size!" );
  }

  struct DeviceQueueInfo2 : public layout::DeviceQueueInfo2
  {
    VULKAN_HPP_CONSTEXPR DeviceQueueInfo2( vk::DeviceQueueCreateFlags flags_ = vk::DeviceQueueCreateFlags(),
                                           uint32_t queueFamilyIndex_ = 0,
                                           uint32_t queueIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceQueueInfo2( flags_, queueFamilyIndex_, queueIndex_ )
    {}

    DeviceQueueInfo2( VkDeviceQueueInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DeviceQueueInfo2( rhs )
    {}

    DeviceQueueInfo2& operator=( VkDeviceQueueInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DeviceQueueInfo2::operator=(rhs);
      return *this;
    }

    DeviceQueueInfo2 & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DeviceQueueInfo2 & setFlags( vk::DeviceQueueCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DeviceQueueInfo2 & setQueueFamilyIndex( uint32_t queueFamilyIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      queueFamilyIndex = queueFamilyIndex_;
      return *this;
    }

    DeviceQueueInfo2 & setQueueIndex( uint32_t queueIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      queueIndex = queueIndex_;
      return *this;
    }

    operator VkDeviceQueueInfo2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDeviceQueueInfo2*>( this );
    }

    operator VkDeviceQueueInfo2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDeviceQueueInfo2*>( this );
    }

    bool operator==( DeviceQueueInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( queueFamilyIndex == rhs.queueFamilyIndex )
          && ( queueIndex == rhs.queueIndex );
    }

    bool operator!=( DeviceQueueInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DeviceQueueInfo2::sType;
  };
  static_assert( sizeof( DeviceQueueInfo2 ) == sizeof( VkDeviceQueueInfo2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DeviceQueueInfo2>::value, "struct wrapper is not a standard layout!" );

  struct DispatchIndirectCommand
  {
    VULKAN_HPP_CONSTEXPR DispatchIndirectCommand( uint32_t x_ = 0,
                                                  uint32_t y_ = 0,
                                                  uint32_t z_ = 0 ) VULKAN_HPP_NOEXCEPT
      : x( x_ )
      , y( y_ )
      , z( z_ )
    {}

    DispatchIndirectCommand( VkDispatchIndirectCommand const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDispatchIndirectCommand*>(this) = rhs;
    }

    DispatchIndirectCommand& operator=( VkDispatchIndirectCommand const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDispatchIndirectCommand*>(this) = rhs;
      return *this;
    }

    DispatchIndirectCommand & setX( uint32_t x_ ) VULKAN_HPP_NOEXCEPT
    {
      x = x_;
      return *this;
    }

    DispatchIndirectCommand & setY( uint32_t y_ ) VULKAN_HPP_NOEXCEPT
    {
      y = y_;
      return *this;
    }

    DispatchIndirectCommand & setZ( uint32_t z_ ) VULKAN_HPP_NOEXCEPT
    {
      z = z_;
      return *this;
    }

    operator VkDispatchIndirectCommand const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDispatchIndirectCommand*>( this );
    }

    operator VkDispatchIndirectCommand &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDispatchIndirectCommand*>( this );
    }

    bool operator==( DispatchIndirectCommand const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( x == rhs.x )
          && ( y == rhs.y )
          && ( z == rhs.z );
    }

    bool operator!=( DispatchIndirectCommand const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t x;
    uint32_t y;
    uint32_t z;
  };
  static_assert( sizeof( DispatchIndirectCommand ) == sizeof( VkDispatchIndirectCommand ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DispatchIndirectCommand>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayEventInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DisplayEventInfoEXT( vk::DisplayEventTypeEXT displayEvent_ = vk::DisplayEventTypeEXT::eFirstPixelOut ) VULKAN_HPP_NOEXCEPT
        : displayEvent( displayEvent_ )
      {}

      DisplayEventInfoEXT( VkDisplayEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayEventInfoEXT*>(this) = rhs;
      }

      DisplayEventInfoEXT& operator=( VkDisplayEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayEventInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayEventInfoEXT;
      const void* pNext = nullptr;
      vk::DisplayEventTypeEXT displayEvent;
    };
    static_assert( sizeof( DisplayEventInfoEXT ) == sizeof( VkDisplayEventInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DisplayEventInfoEXT : public layout::DisplayEventInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DisplayEventInfoEXT( vk::DisplayEventTypeEXT displayEvent_ = vk::DisplayEventTypeEXT::eFirstPixelOut ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayEventInfoEXT( displayEvent_ )
    {}

    DisplayEventInfoEXT( VkDisplayEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayEventInfoEXT( rhs )
    {}

    DisplayEventInfoEXT& operator=( VkDisplayEventInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayEventInfoEXT::operator=(rhs);
      return *this;
    }

    DisplayEventInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DisplayEventInfoEXT & setDisplayEvent( vk::DisplayEventTypeEXT displayEvent_ ) VULKAN_HPP_NOEXCEPT
    {
      displayEvent = displayEvent_;
      return *this;
    }

    operator VkDisplayEventInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayEventInfoEXT*>( this );
    }

    operator VkDisplayEventInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayEventInfoEXT*>( this );
    }

    bool operator==( DisplayEventInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( displayEvent == rhs.displayEvent );
    }

    bool operator!=( DisplayEventInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayEventInfoEXT::sType;
  };
  static_assert( sizeof( DisplayEventInfoEXT ) == sizeof( VkDisplayEventInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayEventInfoEXT>::value, "struct wrapper is not a standard layout!" );

  struct DisplayModeParametersKHR
  {
    VULKAN_HPP_CONSTEXPR DisplayModeParametersKHR( vk::Extent2D visibleRegion_ = vk::Extent2D(),
                                                   uint32_t refreshRate_ = 0 ) VULKAN_HPP_NOEXCEPT
      : visibleRegion( visibleRegion_ )
      , refreshRate( refreshRate_ )
    {}

    DisplayModeParametersKHR( VkDisplayModeParametersKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayModeParametersKHR*>(this) = rhs;
    }

    DisplayModeParametersKHR& operator=( VkDisplayModeParametersKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayModeParametersKHR*>(this) = rhs;
      return *this;
    }

    DisplayModeParametersKHR & setVisibleRegion( vk::Extent2D visibleRegion_ ) VULKAN_HPP_NOEXCEPT
    {
      visibleRegion = visibleRegion_;
      return *this;
    }

    DisplayModeParametersKHR & setRefreshRate( uint32_t refreshRate_ ) VULKAN_HPP_NOEXCEPT
    {
      refreshRate = refreshRate_;
      return *this;
    }

    operator VkDisplayModeParametersKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayModeParametersKHR*>( this );
    }

    operator VkDisplayModeParametersKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayModeParametersKHR*>( this );
    }

    bool operator==( DisplayModeParametersKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( visibleRegion == rhs.visibleRegion )
          && ( refreshRate == rhs.refreshRate );
    }

    bool operator!=( DisplayModeParametersKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Extent2D visibleRegion;
    uint32_t refreshRate;
  };
  static_assert( sizeof( DisplayModeParametersKHR ) == sizeof( VkDisplayModeParametersKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayModeParametersKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayModeCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR DisplayModeCreateInfoKHR( vk::DisplayModeCreateFlagsKHR flags_ = vk::DisplayModeCreateFlagsKHR(),
                                                     vk::DisplayModeParametersKHR parameters_ = vk::DisplayModeParametersKHR() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , parameters( parameters_ )
      {}

      DisplayModeCreateInfoKHR( VkDisplayModeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayModeCreateInfoKHR*>(this) = rhs;
      }

      DisplayModeCreateInfoKHR& operator=( VkDisplayModeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayModeCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayModeCreateInfoKHR;
      const void* pNext = nullptr;
      vk::DisplayModeCreateFlagsKHR flags;
      vk::DisplayModeParametersKHR parameters;
    };
    static_assert( sizeof( DisplayModeCreateInfoKHR ) == sizeof( VkDisplayModeCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplayModeCreateInfoKHR : public layout::DisplayModeCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR DisplayModeCreateInfoKHR( vk::DisplayModeCreateFlagsKHR flags_ = vk::DisplayModeCreateFlagsKHR(),
                                                   vk::DisplayModeParametersKHR parameters_ = vk::DisplayModeParametersKHR() ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayModeCreateInfoKHR( flags_, parameters_ )
    {}

    DisplayModeCreateInfoKHR( VkDisplayModeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayModeCreateInfoKHR( rhs )
    {}

    DisplayModeCreateInfoKHR& operator=( VkDisplayModeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayModeCreateInfoKHR::operator=(rhs);
      return *this;
    }

    DisplayModeCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DisplayModeCreateInfoKHR & setFlags( vk::DisplayModeCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DisplayModeCreateInfoKHR & setParameters( vk::DisplayModeParametersKHR parameters_ ) VULKAN_HPP_NOEXCEPT
    {
      parameters = parameters_;
      return *this;
    }

    operator VkDisplayModeCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayModeCreateInfoKHR*>( this );
    }

    operator VkDisplayModeCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayModeCreateInfoKHR*>( this );
    }

    bool operator==( DisplayModeCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( parameters == rhs.parameters );
    }

    bool operator!=( DisplayModeCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayModeCreateInfoKHR::sType;
  };
  static_assert( sizeof( DisplayModeCreateInfoKHR ) == sizeof( VkDisplayModeCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayModeCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  struct DisplayModePropertiesKHR
  {
    DisplayModePropertiesKHR() VULKAN_HPP_NOEXCEPT
    {}

    DisplayModePropertiesKHR( VkDisplayModePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayModePropertiesKHR*>(this) = rhs;
    }

    DisplayModePropertiesKHR& operator=( VkDisplayModePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayModePropertiesKHR*>(this) = rhs;
      return *this;
    }

    operator VkDisplayModePropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayModePropertiesKHR*>( this );
    }

    operator VkDisplayModePropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayModePropertiesKHR*>( this );
    }

    bool operator==( DisplayModePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( displayMode == rhs.displayMode )
          && ( parameters == rhs.parameters );
    }

    bool operator!=( DisplayModePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DisplayModeKHR displayMode;
    vk::DisplayModeParametersKHR parameters;
  };
  static_assert( sizeof( DisplayModePropertiesKHR ) == sizeof( VkDisplayModePropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayModePropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayModeProperties2KHR
    {
    protected:
      DisplayModeProperties2KHR() VULKAN_HPP_NOEXCEPT
      {}

      DisplayModeProperties2KHR( VkDisplayModeProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayModeProperties2KHR*>(this) = rhs;
      }

      DisplayModeProperties2KHR& operator=( VkDisplayModeProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayModeProperties2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayModeProperties2KHR;
      void* pNext = nullptr;
      vk::DisplayModePropertiesKHR displayModeProperties;
    };
    static_assert( sizeof( DisplayModeProperties2KHR ) == sizeof( VkDisplayModeProperties2KHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplayModeProperties2KHR : public layout::DisplayModeProperties2KHR
  {
    DisplayModeProperties2KHR() VULKAN_HPP_NOEXCEPT
      : layout::DisplayModeProperties2KHR()
    {}

    DisplayModeProperties2KHR( VkDisplayModeProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayModeProperties2KHR( rhs )
    {}

    DisplayModeProperties2KHR& operator=( VkDisplayModeProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayModeProperties2KHR::operator=(rhs);
      return *this;
    }

    operator VkDisplayModeProperties2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayModeProperties2KHR*>( this );
    }

    operator VkDisplayModeProperties2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayModeProperties2KHR*>( this );
    }

    bool operator==( DisplayModeProperties2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( displayModeProperties == rhs.displayModeProperties );
    }

    bool operator!=( DisplayModeProperties2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayModeProperties2KHR::sType;
  };
  static_assert( sizeof( DisplayModeProperties2KHR ) == sizeof( VkDisplayModeProperties2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayModeProperties2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayNativeHdrSurfaceCapabilitiesAMD
    {
    protected:
      DisplayNativeHdrSurfaceCapabilitiesAMD() VULKAN_HPP_NOEXCEPT
      {}

      DisplayNativeHdrSurfaceCapabilitiesAMD( VkDisplayNativeHdrSurfaceCapabilitiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayNativeHdrSurfaceCapabilitiesAMD*>(this) = rhs;
      }

      DisplayNativeHdrSurfaceCapabilitiesAMD& operator=( VkDisplayNativeHdrSurfaceCapabilitiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayNativeHdrSurfaceCapabilitiesAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayNativeHdrSurfaceCapabilitiesAMD;
      void* pNext = nullptr;
      vk::Bool32 localDimmingSupport;
    };
    static_assert( sizeof( DisplayNativeHdrSurfaceCapabilitiesAMD ) == sizeof( VkDisplayNativeHdrSurfaceCapabilitiesAMD ), "layout struct and wrapper have different size!" );
  }

  struct DisplayNativeHdrSurfaceCapabilitiesAMD : public layout::DisplayNativeHdrSurfaceCapabilitiesAMD
  {
    DisplayNativeHdrSurfaceCapabilitiesAMD() VULKAN_HPP_NOEXCEPT
      : layout::DisplayNativeHdrSurfaceCapabilitiesAMD()
    {}

    DisplayNativeHdrSurfaceCapabilitiesAMD( VkDisplayNativeHdrSurfaceCapabilitiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayNativeHdrSurfaceCapabilitiesAMD( rhs )
    {}

    DisplayNativeHdrSurfaceCapabilitiesAMD& operator=( VkDisplayNativeHdrSurfaceCapabilitiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayNativeHdrSurfaceCapabilitiesAMD::operator=(rhs);
      return *this;
    }

    operator VkDisplayNativeHdrSurfaceCapabilitiesAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayNativeHdrSurfaceCapabilitiesAMD*>( this );
    }

    operator VkDisplayNativeHdrSurfaceCapabilitiesAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayNativeHdrSurfaceCapabilitiesAMD*>( this );
    }

    bool operator==( DisplayNativeHdrSurfaceCapabilitiesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( localDimmingSupport == rhs.localDimmingSupport );
    }

    bool operator!=( DisplayNativeHdrSurfaceCapabilitiesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayNativeHdrSurfaceCapabilitiesAMD::sType;
  };
  static_assert( sizeof( DisplayNativeHdrSurfaceCapabilitiesAMD ) == sizeof( VkDisplayNativeHdrSurfaceCapabilitiesAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayNativeHdrSurfaceCapabilitiesAMD>::value, "struct wrapper is not a standard layout!" );

  struct DisplayPlaneCapabilitiesKHR
  {
    DisplayPlaneCapabilitiesKHR() VULKAN_HPP_NOEXCEPT
    {}

    DisplayPlaneCapabilitiesKHR( VkDisplayPlaneCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayPlaneCapabilitiesKHR*>(this) = rhs;
    }

    DisplayPlaneCapabilitiesKHR& operator=( VkDisplayPlaneCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayPlaneCapabilitiesKHR*>(this) = rhs;
      return *this;
    }

    operator VkDisplayPlaneCapabilitiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPlaneCapabilitiesKHR*>( this );
    }

    operator VkDisplayPlaneCapabilitiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPlaneCapabilitiesKHR*>( this );
    }

    bool operator==( DisplayPlaneCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( supportedAlpha == rhs.supportedAlpha )
          && ( minSrcPosition == rhs.minSrcPosition )
          && ( maxSrcPosition == rhs.maxSrcPosition )
          && ( minSrcExtent == rhs.minSrcExtent )
          && ( maxSrcExtent == rhs.maxSrcExtent )
          && ( minDstPosition == rhs.minDstPosition )
          && ( maxDstPosition == rhs.maxDstPosition )
          && ( minDstExtent == rhs.minDstExtent )
          && ( maxDstExtent == rhs.maxDstExtent );
    }

    bool operator!=( DisplayPlaneCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DisplayPlaneAlphaFlagsKHR supportedAlpha;
    vk::Offset2D minSrcPosition;
    vk::Offset2D maxSrcPosition;
    vk::Extent2D minSrcExtent;
    vk::Extent2D maxSrcExtent;
    vk::Offset2D minDstPosition;
    vk::Offset2D maxDstPosition;
    vk::Extent2D minDstExtent;
    vk::Extent2D maxDstExtent;
  };
  static_assert( sizeof( DisplayPlaneCapabilitiesKHR ) == sizeof( VkDisplayPlaneCapabilitiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPlaneCapabilitiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayPlaneCapabilities2KHR
    {
    protected:
      DisplayPlaneCapabilities2KHR() VULKAN_HPP_NOEXCEPT
      {}

      DisplayPlaneCapabilities2KHR( VkDisplayPlaneCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPlaneCapabilities2KHR*>(this) = rhs;
      }

      DisplayPlaneCapabilities2KHR& operator=( VkDisplayPlaneCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPlaneCapabilities2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayPlaneCapabilities2KHR;
      void* pNext = nullptr;
      vk::DisplayPlaneCapabilitiesKHR capabilities;
    };
    static_assert( sizeof( DisplayPlaneCapabilities2KHR ) == sizeof( VkDisplayPlaneCapabilities2KHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplayPlaneCapabilities2KHR : public layout::DisplayPlaneCapabilities2KHR
  {
    DisplayPlaneCapabilities2KHR() VULKAN_HPP_NOEXCEPT
      : layout::DisplayPlaneCapabilities2KHR()
    {}

    DisplayPlaneCapabilities2KHR( VkDisplayPlaneCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPlaneCapabilities2KHR( rhs )
    {}

    DisplayPlaneCapabilities2KHR& operator=( VkDisplayPlaneCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayPlaneCapabilities2KHR::operator=(rhs);
      return *this;
    }

    operator VkDisplayPlaneCapabilities2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPlaneCapabilities2KHR*>( this );
    }

    operator VkDisplayPlaneCapabilities2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPlaneCapabilities2KHR*>( this );
    }

    bool operator==( DisplayPlaneCapabilities2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( capabilities == rhs.capabilities );
    }

    bool operator!=( DisplayPlaneCapabilities2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayPlaneCapabilities2KHR::sType;
  };
  static_assert( sizeof( DisplayPlaneCapabilities2KHR ) == sizeof( VkDisplayPlaneCapabilities2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPlaneCapabilities2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayPlaneInfo2KHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR DisplayPlaneInfo2KHR( vk::DisplayModeKHR mode_ = vk::DisplayModeKHR(),
                                                 uint32_t planeIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : mode( mode_ )
        , planeIndex( planeIndex_ )
      {}

      DisplayPlaneInfo2KHR( VkDisplayPlaneInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPlaneInfo2KHR*>(this) = rhs;
      }

      DisplayPlaneInfo2KHR& operator=( VkDisplayPlaneInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPlaneInfo2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayPlaneInfo2KHR;
      const void* pNext = nullptr;
      vk::DisplayModeKHR mode;
      uint32_t planeIndex;
    };
    static_assert( sizeof( DisplayPlaneInfo2KHR ) == sizeof( VkDisplayPlaneInfo2KHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplayPlaneInfo2KHR : public layout::DisplayPlaneInfo2KHR
  {
    VULKAN_HPP_CONSTEXPR DisplayPlaneInfo2KHR( vk::DisplayModeKHR mode_ = vk::DisplayModeKHR(),
                                               uint32_t planeIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPlaneInfo2KHR( mode_, planeIndex_ )
    {}

    DisplayPlaneInfo2KHR( VkDisplayPlaneInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPlaneInfo2KHR( rhs )
    {}

    DisplayPlaneInfo2KHR& operator=( VkDisplayPlaneInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayPlaneInfo2KHR::operator=(rhs);
      return *this;
    }

    DisplayPlaneInfo2KHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DisplayPlaneInfo2KHR & setMode( vk::DisplayModeKHR mode_ ) VULKAN_HPP_NOEXCEPT
    {
      mode = mode_;
      return *this;
    }

    DisplayPlaneInfo2KHR & setPlaneIndex( uint32_t planeIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      planeIndex = planeIndex_;
      return *this;
    }

    operator VkDisplayPlaneInfo2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPlaneInfo2KHR*>( this );
    }

    operator VkDisplayPlaneInfo2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPlaneInfo2KHR*>( this );
    }

    bool operator==( DisplayPlaneInfo2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( mode == rhs.mode )
          && ( planeIndex == rhs.planeIndex );
    }

    bool operator!=( DisplayPlaneInfo2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayPlaneInfo2KHR::sType;
  };
  static_assert( sizeof( DisplayPlaneInfo2KHR ) == sizeof( VkDisplayPlaneInfo2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPlaneInfo2KHR>::value, "struct wrapper is not a standard layout!" );

  struct DisplayPlanePropertiesKHR
  {
    DisplayPlanePropertiesKHR() VULKAN_HPP_NOEXCEPT
    {}

    DisplayPlanePropertiesKHR( VkDisplayPlanePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayPlanePropertiesKHR*>(this) = rhs;
    }

    DisplayPlanePropertiesKHR& operator=( VkDisplayPlanePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayPlanePropertiesKHR*>(this) = rhs;
      return *this;
    }

    operator VkDisplayPlanePropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPlanePropertiesKHR*>( this );
    }

    operator VkDisplayPlanePropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPlanePropertiesKHR*>( this );
    }

    bool operator==( DisplayPlanePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( currentDisplay == rhs.currentDisplay )
          && ( currentStackIndex == rhs.currentStackIndex );
    }

    bool operator!=( DisplayPlanePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DisplayKHR currentDisplay;
    uint32_t currentStackIndex;
  };
  static_assert( sizeof( DisplayPlanePropertiesKHR ) == sizeof( VkDisplayPlanePropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPlanePropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayPlaneProperties2KHR
    {
    protected:
      DisplayPlaneProperties2KHR() VULKAN_HPP_NOEXCEPT
      {}

      DisplayPlaneProperties2KHR( VkDisplayPlaneProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPlaneProperties2KHR*>(this) = rhs;
      }

      DisplayPlaneProperties2KHR& operator=( VkDisplayPlaneProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPlaneProperties2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayPlaneProperties2KHR;
      void* pNext = nullptr;
      vk::DisplayPlanePropertiesKHR displayPlaneProperties;
    };
    static_assert( sizeof( DisplayPlaneProperties2KHR ) == sizeof( VkDisplayPlaneProperties2KHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplayPlaneProperties2KHR : public layout::DisplayPlaneProperties2KHR
  {
    DisplayPlaneProperties2KHR() VULKAN_HPP_NOEXCEPT
      : layout::DisplayPlaneProperties2KHR()
    {}

    DisplayPlaneProperties2KHR( VkDisplayPlaneProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPlaneProperties2KHR( rhs )
    {}

    DisplayPlaneProperties2KHR& operator=( VkDisplayPlaneProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayPlaneProperties2KHR::operator=(rhs);
      return *this;
    }

    operator VkDisplayPlaneProperties2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPlaneProperties2KHR*>( this );
    }

    operator VkDisplayPlaneProperties2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPlaneProperties2KHR*>( this );
    }

    bool operator==( DisplayPlaneProperties2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( displayPlaneProperties == rhs.displayPlaneProperties );
    }

    bool operator!=( DisplayPlaneProperties2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayPlaneProperties2KHR::sType;
  };
  static_assert( sizeof( DisplayPlaneProperties2KHR ) == sizeof( VkDisplayPlaneProperties2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPlaneProperties2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayPowerInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR DisplayPowerInfoEXT( vk::DisplayPowerStateEXT powerState_ = vk::DisplayPowerStateEXT::eOff ) VULKAN_HPP_NOEXCEPT
        : powerState( powerState_ )
      {}

      DisplayPowerInfoEXT( VkDisplayPowerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPowerInfoEXT*>(this) = rhs;
      }

      DisplayPowerInfoEXT& operator=( VkDisplayPowerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPowerInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayPowerInfoEXT;
      const void* pNext = nullptr;
      vk::DisplayPowerStateEXT powerState;
    };
    static_assert( sizeof( DisplayPowerInfoEXT ) == sizeof( VkDisplayPowerInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct DisplayPowerInfoEXT : public layout::DisplayPowerInfoEXT
  {
    VULKAN_HPP_CONSTEXPR DisplayPowerInfoEXT( vk::DisplayPowerStateEXT powerState_ = vk::DisplayPowerStateEXT::eOff ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPowerInfoEXT( powerState_ )
    {}

    DisplayPowerInfoEXT( VkDisplayPowerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPowerInfoEXT( rhs )
    {}

    DisplayPowerInfoEXT& operator=( VkDisplayPowerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayPowerInfoEXT::operator=(rhs);
      return *this;
    }

    DisplayPowerInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DisplayPowerInfoEXT & setPowerState( vk::DisplayPowerStateEXT powerState_ ) VULKAN_HPP_NOEXCEPT
    {
      powerState = powerState_;
      return *this;
    }

    operator VkDisplayPowerInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPowerInfoEXT*>( this );
    }

    operator VkDisplayPowerInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPowerInfoEXT*>( this );
    }

    bool operator==( DisplayPowerInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( powerState == rhs.powerState );
    }

    bool operator!=( DisplayPowerInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayPowerInfoEXT::sType;
  };
  static_assert( sizeof( DisplayPowerInfoEXT ) == sizeof( VkDisplayPowerInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPowerInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayPresentInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR DisplayPresentInfoKHR( vk::Rect2D srcRect_ = vk::Rect2D(),
                                                  vk::Rect2D dstRect_ = vk::Rect2D(),
                                                  vk::Bool32 persistent_ = 0 ) VULKAN_HPP_NOEXCEPT
        : srcRect( srcRect_ )
        , dstRect( dstRect_ )
        , persistent( persistent_ )
      {}

      DisplayPresentInfoKHR( VkDisplayPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPresentInfoKHR*>(this) = rhs;
      }

      DisplayPresentInfoKHR& operator=( VkDisplayPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayPresentInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayPresentInfoKHR;
      const void* pNext = nullptr;
      vk::Rect2D srcRect;
      vk::Rect2D dstRect;
      vk::Bool32 persistent;
    };
    static_assert( sizeof( DisplayPresentInfoKHR ) == sizeof( VkDisplayPresentInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplayPresentInfoKHR : public layout::DisplayPresentInfoKHR
  {
    VULKAN_HPP_CONSTEXPR DisplayPresentInfoKHR( vk::Rect2D srcRect_ = vk::Rect2D(),
                                                vk::Rect2D dstRect_ = vk::Rect2D(),
                                                vk::Bool32 persistent_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPresentInfoKHR( srcRect_, dstRect_, persistent_ )
    {}

    DisplayPresentInfoKHR( VkDisplayPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayPresentInfoKHR( rhs )
    {}

    DisplayPresentInfoKHR& operator=( VkDisplayPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayPresentInfoKHR::operator=(rhs);
      return *this;
    }

    DisplayPresentInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DisplayPresentInfoKHR & setSrcRect( vk::Rect2D srcRect_ ) VULKAN_HPP_NOEXCEPT
    {
      srcRect = srcRect_;
      return *this;
    }

    DisplayPresentInfoKHR & setDstRect( vk::Rect2D dstRect_ ) VULKAN_HPP_NOEXCEPT
    {
      dstRect = dstRect_;
      return *this;
    }

    DisplayPresentInfoKHR & setPersistent( vk::Bool32 persistent_ ) VULKAN_HPP_NOEXCEPT
    {
      persistent = persistent_;
      return *this;
    }

    operator VkDisplayPresentInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPresentInfoKHR*>( this );
    }

    operator VkDisplayPresentInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPresentInfoKHR*>( this );
    }

    bool operator==( DisplayPresentInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( srcRect == rhs.srcRect )
          && ( dstRect == rhs.dstRect )
          && ( persistent == rhs.persistent );
    }

    bool operator!=( DisplayPresentInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayPresentInfoKHR::sType;
  };
  static_assert( sizeof( DisplayPresentInfoKHR ) == sizeof( VkDisplayPresentInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPresentInfoKHR>::value, "struct wrapper is not a standard layout!" );

  struct DisplayPropertiesKHR
  {
    DisplayPropertiesKHR() VULKAN_HPP_NOEXCEPT
    {}

    DisplayPropertiesKHR( VkDisplayPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayPropertiesKHR*>(this) = rhs;
    }

    DisplayPropertiesKHR& operator=( VkDisplayPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDisplayPropertiesKHR*>(this) = rhs;
      return *this;
    }

    operator VkDisplayPropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayPropertiesKHR*>( this );
    }

    operator VkDisplayPropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayPropertiesKHR*>( this );
    }

    bool operator==( DisplayPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( display == rhs.display )
          && ( displayName == rhs.displayName )
          && ( physicalDimensions == rhs.physicalDimensions )
          && ( physicalResolution == rhs.physicalResolution )
          && ( supportedTransforms == rhs.supportedTransforms )
          && ( planeReorderPossible == rhs.planeReorderPossible )
          && ( persistentContent == rhs.persistentContent );
    }

    bool operator!=( DisplayPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DisplayKHR display;
    const char* displayName;
    vk::Extent2D physicalDimensions;
    vk::Extent2D physicalResolution;
    vk::SurfaceTransformFlagsKHR supportedTransforms;
    vk::Bool32 planeReorderPossible;
    vk::Bool32 persistentContent;
  };
  static_assert( sizeof( DisplayPropertiesKHR ) == sizeof( VkDisplayPropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayPropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplayProperties2KHR
    {
    protected:
      DisplayProperties2KHR() VULKAN_HPP_NOEXCEPT
      {}

      DisplayProperties2KHR( VkDisplayProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayProperties2KHR*>(this) = rhs;
      }

      DisplayProperties2KHR& operator=( VkDisplayProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplayProperties2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplayProperties2KHR;
      void* pNext = nullptr;
      vk::DisplayPropertiesKHR displayProperties;
    };
    static_assert( sizeof( DisplayProperties2KHR ) == sizeof( VkDisplayProperties2KHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplayProperties2KHR : public layout::DisplayProperties2KHR
  {
    DisplayProperties2KHR() VULKAN_HPP_NOEXCEPT
      : layout::DisplayProperties2KHR()
    {}

    DisplayProperties2KHR( VkDisplayProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplayProperties2KHR( rhs )
    {}

    DisplayProperties2KHR& operator=( VkDisplayProperties2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplayProperties2KHR::operator=(rhs);
      return *this;
    }

    operator VkDisplayProperties2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplayProperties2KHR*>( this );
    }

    operator VkDisplayProperties2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplayProperties2KHR*>( this );
    }

    bool operator==( DisplayProperties2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( displayProperties == rhs.displayProperties );
    }

    bool operator!=( DisplayProperties2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplayProperties2KHR::sType;
  };
  static_assert( sizeof( DisplayProperties2KHR ) == sizeof( VkDisplayProperties2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplayProperties2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DisplaySurfaceCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR DisplaySurfaceCreateInfoKHR( vk::DisplaySurfaceCreateFlagsKHR flags_ = vk::DisplaySurfaceCreateFlagsKHR(),
                                                        vk::DisplayModeKHR displayMode_ = vk::DisplayModeKHR(),
                                                        uint32_t planeIndex_ = 0,
                                                        uint32_t planeStackIndex_ = 0,
                                                        vk::SurfaceTransformFlagBitsKHR transform_ = vk::SurfaceTransformFlagBitsKHR::eIdentity,
                                                        float globalAlpha_ = 0,
                                                        vk::DisplayPlaneAlphaFlagBitsKHR alphaMode_ = vk::DisplayPlaneAlphaFlagBitsKHR::eOpaque,
                                                        vk::Extent2D imageExtent_ = vk::Extent2D() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , displayMode( displayMode_ )
        , planeIndex( planeIndex_ )
        , planeStackIndex( planeStackIndex_ )
        , transform( transform_ )
        , globalAlpha( globalAlpha_ )
        , alphaMode( alphaMode_ )
        , imageExtent( imageExtent_ )
      {}

      DisplaySurfaceCreateInfoKHR( VkDisplaySurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplaySurfaceCreateInfoKHR*>(this) = rhs;
      }

      DisplaySurfaceCreateInfoKHR& operator=( VkDisplaySurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDisplaySurfaceCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDisplaySurfaceCreateInfoKHR;
      const void* pNext = nullptr;
      vk::DisplaySurfaceCreateFlagsKHR flags;
      vk::DisplayModeKHR displayMode;
      uint32_t planeIndex;
      uint32_t planeStackIndex;
      vk::SurfaceTransformFlagBitsKHR transform;
      float globalAlpha;
      vk::DisplayPlaneAlphaFlagBitsKHR alphaMode;
      vk::Extent2D imageExtent;
    };
    static_assert( sizeof( DisplaySurfaceCreateInfoKHR ) == sizeof( VkDisplaySurfaceCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct DisplaySurfaceCreateInfoKHR : public layout::DisplaySurfaceCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR DisplaySurfaceCreateInfoKHR( vk::DisplaySurfaceCreateFlagsKHR flags_ = vk::DisplaySurfaceCreateFlagsKHR(),
                                                      vk::DisplayModeKHR displayMode_ = vk::DisplayModeKHR(),
                                                      uint32_t planeIndex_ = 0,
                                                      uint32_t planeStackIndex_ = 0,
                                                      vk::SurfaceTransformFlagBitsKHR transform_ = vk::SurfaceTransformFlagBitsKHR::eIdentity,
                                                      float globalAlpha_ = 0,
                                                      vk::DisplayPlaneAlphaFlagBitsKHR alphaMode_ = vk::DisplayPlaneAlphaFlagBitsKHR::eOpaque,
                                                      vk::Extent2D imageExtent_ = vk::Extent2D() ) VULKAN_HPP_NOEXCEPT
      : layout::DisplaySurfaceCreateInfoKHR( flags_, displayMode_, planeIndex_, planeStackIndex_, transform_, globalAlpha_, alphaMode_, imageExtent_ )
    {}

    DisplaySurfaceCreateInfoKHR( VkDisplaySurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DisplaySurfaceCreateInfoKHR( rhs )
    {}

    DisplaySurfaceCreateInfoKHR& operator=( VkDisplaySurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DisplaySurfaceCreateInfoKHR::operator=(rhs);
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setFlags( vk::DisplaySurfaceCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setDisplayMode( vk::DisplayModeKHR displayMode_ ) VULKAN_HPP_NOEXCEPT
    {
      displayMode = displayMode_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setPlaneIndex( uint32_t planeIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      planeIndex = planeIndex_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setPlaneStackIndex( uint32_t planeStackIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      planeStackIndex = planeStackIndex_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setTransform( vk::SurfaceTransformFlagBitsKHR transform_ ) VULKAN_HPP_NOEXCEPT
    {
      transform = transform_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setGlobalAlpha( float globalAlpha_ ) VULKAN_HPP_NOEXCEPT
    {
      globalAlpha = globalAlpha_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setAlphaMode( vk::DisplayPlaneAlphaFlagBitsKHR alphaMode_ ) VULKAN_HPP_NOEXCEPT
    {
      alphaMode = alphaMode_;
      return *this;
    }

    DisplaySurfaceCreateInfoKHR & setImageExtent( vk::Extent2D imageExtent_ ) VULKAN_HPP_NOEXCEPT
    {
      imageExtent = imageExtent_;
      return *this;
    }

    operator VkDisplaySurfaceCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDisplaySurfaceCreateInfoKHR*>( this );
    }

    operator VkDisplaySurfaceCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDisplaySurfaceCreateInfoKHR*>( this );
    }

    bool operator==( DisplaySurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( displayMode == rhs.displayMode )
          && ( planeIndex == rhs.planeIndex )
          && ( planeStackIndex == rhs.planeStackIndex )
          && vk::operator==( transform, rhs.transform )
          && ( globalAlpha == rhs.globalAlpha )
          && vk::operator==( alphaMode, rhs.alphaMode )
          && ( imageExtent == rhs.imageExtent );
    }

    bool operator!=( DisplaySurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DisplaySurfaceCreateInfoKHR::sType;
  };
  static_assert( sizeof( DisplaySurfaceCreateInfoKHR ) == sizeof( VkDisplaySurfaceCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DisplaySurfaceCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  struct DrawIndexedIndirectCommand
  {
    VULKAN_HPP_CONSTEXPR DrawIndexedIndirectCommand( uint32_t indexCount_ = 0,
                                                     uint32_t instanceCount_ = 0,
                                                     uint32_t firstIndex_ = 0,
                                                     int32_t vertexOffset_ = 0,
                                                     uint32_t firstInstance_ = 0 ) VULKAN_HPP_NOEXCEPT
      : indexCount( indexCount_ )
      , instanceCount( instanceCount_ )
      , firstIndex( firstIndex_ )
      , vertexOffset( vertexOffset_ )
      , firstInstance( firstInstance_ )
    {}

    DrawIndexedIndirectCommand( VkDrawIndexedIndirectCommand const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrawIndexedIndirectCommand*>(this) = rhs;
    }

    DrawIndexedIndirectCommand& operator=( VkDrawIndexedIndirectCommand const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrawIndexedIndirectCommand*>(this) = rhs;
      return *this;
    }

    DrawIndexedIndirectCommand & setIndexCount( uint32_t indexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      indexCount = indexCount_;
      return *this;
    }

    DrawIndexedIndirectCommand & setInstanceCount( uint32_t instanceCount_ ) VULKAN_HPP_NOEXCEPT
    {
      instanceCount = instanceCount_;
      return *this;
    }

    DrawIndexedIndirectCommand & setFirstIndex( uint32_t firstIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      firstIndex = firstIndex_;
      return *this;
    }

    DrawIndexedIndirectCommand & setVertexOffset( int32_t vertexOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexOffset = vertexOffset_;
      return *this;
    }

    DrawIndexedIndirectCommand & setFirstInstance( uint32_t firstInstance_ ) VULKAN_HPP_NOEXCEPT
    {
      firstInstance = firstInstance_;
      return *this;
    }

    operator VkDrawIndexedIndirectCommand const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDrawIndexedIndirectCommand*>( this );
    }

    operator VkDrawIndexedIndirectCommand &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDrawIndexedIndirectCommand*>( this );
    }

    bool operator==( DrawIndexedIndirectCommand const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( indexCount == rhs.indexCount )
          && ( instanceCount == rhs.instanceCount )
          && ( firstIndex == rhs.firstIndex )
          && ( vertexOffset == rhs.vertexOffset )
          && ( firstInstance == rhs.firstInstance );
    }

    bool operator!=( DrawIndexedIndirectCommand const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t indexCount;
    uint32_t instanceCount;
    uint32_t firstIndex;
    int32_t vertexOffset;
    uint32_t firstInstance;
  };
  static_assert( sizeof( DrawIndexedIndirectCommand ) == sizeof( VkDrawIndexedIndirectCommand ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DrawIndexedIndirectCommand>::value, "struct wrapper is not a standard layout!" );

  struct DrawIndirectCommand
  {
    VULKAN_HPP_CONSTEXPR DrawIndirectCommand( uint32_t vertexCount_ = 0,
                                              uint32_t instanceCount_ = 0,
                                              uint32_t firstVertex_ = 0,
                                              uint32_t firstInstance_ = 0 ) VULKAN_HPP_NOEXCEPT
      : vertexCount( vertexCount_ )
      , instanceCount( instanceCount_ )
      , firstVertex( firstVertex_ )
      , firstInstance( firstInstance_ )
    {}

    DrawIndirectCommand( VkDrawIndirectCommand const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrawIndirectCommand*>(this) = rhs;
    }

    DrawIndirectCommand& operator=( VkDrawIndirectCommand const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrawIndirectCommand*>(this) = rhs;
      return *this;
    }

    DrawIndirectCommand & setVertexCount( uint32_t vertexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexCount = vertexCount_;
      return *this;
    }

    DrawIndirectCommand & setInstanceCount( uint32_t instanceCount_ ) VULKAN_HPP_NOEXCEPT
    {
      instanceCount = instanceCount_;
      return *this;
    }

    DrawIndirectCommand & setFirstVertex( uint32_t firstVertex_ ) VULKAN_HPP_NOEXCEPT
    {
      firstVertex = firstVertex_;
      return *this;
    }

    DrawIndirectCommand & setFirstInstance( uint32_t firstInstance_ ) VULKAN_HPP_NOEXCEPT
    {
      firstInstance = firstInstance_;
      return *this;
    }

    operator VkDrawIndirectCommand const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDrawIndirectCommand*>( this );
    }

    operator VkDrawIndirectCommand &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDrawIndirectCommand*>( this );
    }

    bool operator==( DrawIndirectCommand const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( vertexCount == rhs.vertexCount )
          && ( instanceCount == rhs.instanceCount )
          && ( firstVertex == rhs.firstVertex )
          && ( firstInstance == rhs.firstInstance );
    }

    bool operator!=( DrawIndirectCommand const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t vertexCount;
    uint32_t instanceCount;
    uint32_t firstVertex;
    uint32_t firstInstance;
  };
  static_assert( sizeof( DrawIndirectCommand ) == sizeof( VkDrawIndirectCommand ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DrawIndirectCommand>::value, "struct wrapper is not a standard layout!" );

  struct DrawMeshTasksIndirectCommandNV
  {
    VULKAN_HPP_CONSTEXPR DrawMeshTasksIndirectCommandNV( uint32_t taskCount_ = 0,
                                                         uint32_t firstTask_ = 0 ) VULKAN_HPP_NOEXCEPT
      : taskCount( taskCount_ )
      , firstTask( firstTask_ )
    {}

    DrawMeshTasksIndirectCommandNV( VkDrawMeshTasksIndirectCommandNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrawMeshTasksIndirectCommandNV*>(this) = rhs;
    }

    DrawMeshTasksIndirectCommandNV& operator=( VkDrawMeshTasksIndirectCommandNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrawMeshTasksIndirectCommandNV*>(this) = rhs;
      return *this;
    }

    DrawMeshTasksIndirectCommandNV & setTaskCount( uint32_t taskCount_ ) VULKAN_HPP_NOEXCEPT
    {
      taskCount = taskCount_;
      return *this;
    }

    DrawMeshTasksIndirectCommandNV & setFirstTask( uint32_t firstTask_ ) VULKAN_HPP_NOEXCEPT
    {
      firstTask = firstTask_;
      return *this;
    }

    operator VkDrawMeshTasksIndirectCommandNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDrawMeshTasksIndirectCommandNV*>( this );
    }

    operator VkDrawMeshTasksIndirectCommandNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDrawMeshTasksIndirectCommandNV*>( this );
    }

    bool operator==( DrawMeshTasksIndirectCommandNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( taskCount == rhs.taskCount )
          && ( firstTask == rhs.firstTask );
    }

    bool operator!=( DrawMeshTasksIndirectCommandNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t taskCount;
    uint32_t firstTask;
  };
  static_assert( sizeof( DrawMeshTasksIndirectCommandNV ) == sizeof( VkDrawMeshTasksIndirectCommandNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DrawMeshTasksIndirectCommandNV>::value, "struct wrapper is not a standard layout!" );

  struct DrmFormatModifierPropertiesEXT
  {
    DrmFormatModifierPropertiesEXT() VULKAN_HPP_NOEXCEPT
    {}

    DrmFormatModifierPropertiesEXT( VkDrmFormatModifierPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrmFormatModifierPropertiesEXT*>(this) = rhs;
    }

    DrmFormatModifierPropertiesEXT& operator=( VkDrmFormatModifierPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkDrmFormatModifierPropertiesEXT*>(this) = rhs;
      return *this;
    }

    operator VkDrmFormatModifierPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDrmFormatModifierPropertiesEXT*>( this );
    }

    operator VkDrmFormatModifierPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDrmFormatModifierPropertiesEXT*>( this );
    }

    bool operator==( DrmFormatModifierPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( drmFormatModifier == rhs.drmFormatModifier )
          && ( drmFormatModifierPlaneCount == rhs.drmFormatModifierPlaneCount )
          && ( drmFormatModifierTilingFeatures == rhs.drmFormatModifierTilingFeatures );
    }

    bool operator!=( DrmFormatModifierPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint64_t drmFormatModifier;
    uint32_t drmFormatModifierPlaneCount;
    vk::FormatFeatureFlags drmFormatModifierTilingFeatures;
  };
  static_assert( sizeof( DrmFormatModifierPropertiesEXT ) == sizeof( VkDrmFormatModifierPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DrmFormatModifierPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct DrmFormatModifierPropertiesListEXT
    {
    protected:
      DrmFormatModifierPropertiesListEXT() VULKAN_HPP_NOEXCEPT
      {}

      DrmFormatModifierPropertiesListEXT( VkDrmFormatModifierPropertiesListEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDrmFormatModifierPropertiesListEXT*>(this) = rhs;
      }

      DrmFormatModifierPropertiesListEXT& operator=( VkDrmFormatModifierPropertiesListEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkDrmFormatModifierPropertiesListEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eDrmFormatModifierPropertiesListEXT;
      void* pNext = nullptr;
      uint32_t drmFormatModifierCount;
      vk::DrmFormatModifierPropertiesEXT* pDrmFormatModifierProperties;
    };
    static_assert( sizeof( DrmFormatModifierPropertiesListEXT ) == sizeof( VkDrmFormatModifierPropertiesListEXT ), "layout struct and wrapper have different size!" );
  }

  struct DrmFormatModifierPropertiesListEXT : public layout::DrmFormatModifierPropertiesListEXT
  {
    DrmFormatModifierPropertiesListEXT() VULKAN_HPP_NOEXCEPT
      : layout::DrmFormatModifierPropertiesListEXT()
    {}

    DrmFormatModifierPropertiesListEXT( VkDrmFormatModifierPropertiesListEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::DrmFormatModifierPropertiesListEXT( rhs )
    {}

    DrmFormatModifierPropertiesListEXT& operator=( VkDrmFormatModifierPropertiesListEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::DrmFormatModifierPropertiesListEXT::operator=(rhs);
      return *this;
    }

    operator VkDrmFormatModifierPropertiesListEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkDrmFormatModifierPropertiesListEXT*>( this );
    }

    operator VkDrmFormatModifierPropertiesListEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkDrmFormatModifierPropertiesListEXT*>( this );
    }

    bool operator==( DrmFormatModifierPropertiesListEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( drmFormatModifierCount == rhs.drmFormatModifierCount )
          && ( pDrmFormatModifierProperties == rhs.pDrmFormatModifierProperties );
    }

    bool operator!=( DrmFormatModifierPropertiesListEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::DrmFormatModifierPropertiesListEXT::sType;
  };
  static_assert( sizeof( DrmFormatModifierPropertiesListEXT ) == sizeof( VkDrmFormatModifierPropertiesListEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<DrmFormatModifierPropertiesListEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct EventCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR EventCreateInfo( vk::EventCreateFlags flags_ = vk::EventCreateFlags() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
      {}

      EventCreateInfo( VkEventCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkEventCreateInfo*>(this) = rhs;
      }

      EventCreateInfo& operator=( VkEventCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkEventCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eEventCreateInfo;
      const void* pNext = nullptr;
      vk::EventCreateFlags flags;
    };
    static_assert( sizeof( EventCreateInfo ) == sizeof( VkEventCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct EventCreateInfo : public layout::EventCreateInfo
  {
    VULKAN_HPP_CONSTEXPR EventCreateInfo( vk::EventCreateFlags flags_ = vk::EventCreateFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::EventCreateInfo( flags_ )
    {}

    EventCreateInfo( VkEventCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::EventCreateInfo( rhs )
    {}

    EventCreateInfo& operator=( VkEventCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::EventCreateInfo::operator=(rhs);
      return *this;
    }

    EventCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    EventCreateInfo & setFlags( vk::EventCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkEventCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkEventCreateInfo*>( this );
    }

    operator VkEventCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkEventCreateInfo*>( this );
    }

    bool operator==( EventCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags );
    }

    bool operator!=( EventCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::EventCreateInfo::sType;
  };
  static_assert( sizeof( EventCreateInfo ) == sizeof( VkEventCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<EventCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExportFenceCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportFenceCreateInfo( vk::ExternalFenceHandleTypeFlags handleTypes_ = vk::ExternalFenceHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
        : handleTypes( handleTypes_ )
      {}

      ExportFenceCreateInfo( VkExportFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportFenceCreateInfo*>(this) = rhs;
      }

      ExportFenceCreateInfo& operator=( VkExportFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportFenceCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportFenceCreateInfo;
      const void* pNext = nullptr;
      vk::ExternalFenceHandleTypeFlags handleTypes;
    };
    static_assert( sizeof( ExportFenceCreateInfo ) == sizeof( VkExportFenceCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ExportFenceCreateInfo : public layout::ExportFenceCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ExportFenceCreateInfo( vk::ExternalFenceHandleTypeFlags handleTypes_ = vk::ExternalFenceHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::ExportFenceCreateInfo( handleTypes_ )
    {}

    ExportFenceCreateInfo( VkExportFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportFenceCreateInfo( rhs )
    {}

    ExportFenceCreateInfo& operator=( VkExportFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportFenceCreateInfo::operator=(rhs);
      return *this;
    }

    ExportFenceCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportFenceCreateInfo & setHandleTypes( vk::ExternalFenceHandleTypeFlags handleTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      handleTypes = handleTypes_;
      return *this;
    }

    operator VkExportFenceCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportFenceCreateInfo*>( this );
    }

    operator VkExportFenceCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportFenceCreateInfo*>( this );
    }

    bool operator==( ExportFenceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleTypes == rhs.handleTypes );
    }

    bool operator!=( ExportFenceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportFenceCreateInfo::sType;
  };
  static_assert( sizeof( ExportFenceCreateInfo ) == sizeof( VkExportFenceCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportFenceCreateInfo>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ExportFenceWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportFenceWin32HandleInfoKHR( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                          DWORD dwAccess_ = 0,
                                                          LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : pAttributes( pAttributes_ )
        , dwAccess( dwAccess_ )
        , name( name_ )
      {}

      ExportFenceWin32HandleInfoKHR( VkExportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportFenceWin32HandleInfoKHR*>(this) = rhs;
      }

      ExportFenceWin32HandleInfoKHR& operator=( VkExportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportFenceWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportFenceWin32HandleInfoKHR;
      const void* pNext = nullptr;
      const SECURITY_ATTRIBUTES* pAttributes;
      DWORD dwAccess;
      LPCWSTR name;
    };
    static_assert( sizeof( ExportFenceWin32HandleInfoKHR ) == sizeof( VkExportFenceWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ExportFenceWin32HandleInfoKHR : public layout::ExportFenceWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ExportFenceWin32HandleInfoKHR( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                        DWORD dwAccess_ = 0,
                                                        LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ExportFenceWin32HandleInfoKHR( pAttributes_, dwAccess_, name_ )
    {}

    ExportFenceWin32HandleInfoKHR( VkExportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportFenceWin32HandleInfoKHR( rhs )
    {}

    ExportFenceWin32HandleInfoKHR& operator=( VkExportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportFenceWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    ExportFenceWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportFenceWin32HandleInfoKHR & setPAttributes( const SECURITY_ATTRIBUTES* pAttributes_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttributes = pAttributes_;
      return *this;
    }

    ExportFenceWin32HandleInfoKHR & setDwAccess( DWORD dwAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      dwAccess = dwAccess_;
      return *this;
    }

    ExportFenceWin32HandleInfoKHR & setName( LPCWSTR name_ ) VULKAN_HPP_NOEXCEPT
    {
      name = name_;
      return *this;
    }

    operator VkExportFenceWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportFenceWin32HandleInfoKHR*>( this );
    }

    operator VkExportFenceWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportFenceWin32HandleInfoKHR*>( this );
    }

    bool operator==( ExportFenceWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pAttributes == rhs.pAttributes )
          && ( dwAccess == rhs.dwAccess )
          && ( name == rhs.name );
    }

    bool operator!=( ExportFenceWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportFenceWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( ExportFenceWin32HandleInfoKHR ) == sizeof( VkExportFenceWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportFenceWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct ExportMemoryAllocateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportMemoryAllocateInfo( vk::ExternalMemoryHandleTypeFlags handleTypes_ = vk::ExternalMemoryHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
        : handleTypes( handleTypes_ )
      {}

      ExportMemoryAllocateInfo( VkExportMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryAllocateInfo*>(this) = rhs;
      }

      ExportMemoryAllocateInfo& operator=( VkExportMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryAllocateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportMemoryAllocateInfo;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlags handleTypes;
    };
    static_assert( sizeof( ExportMemoryAllocateInfo ) == sizeof( VkExportMemoryAllocateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ExportMemoryAllocateInfo : public layout::ExportMemoryAllocateInfo
  {
    VULKAN_HPP_CONSTEXPR ExportMemoryAllocateInfo( vk::ExternalMemoryHandleTypeFlags handleTypes_ = vk::ExternalMemoryHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryAllocateInfo( handleTypes_ )
    {}

    ExportMemoryAllocateInfo( VkExportMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryAllocateInfo( rhs )
    {}

    ExportMemoryAllocateInfo& operator=( VkExportMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportMemoryAllocateInfo::operator=(rhs);
      return *this;
    }

    ExportMemoryAllocateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportMemoryAllocateInfo & setHandleTypes( vk::ExternalMemoryHandleTypeFlags handleTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      handleTypes = handleTypes_;
      return *this;
    }

    operator VkExportMemoryAllocateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportMemoryAllocateInfo*>( this );
    }

    operator VkExportMemoryAllocateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportMemoryAllocateInfo*>( this );
    }

    bool operator==( ExportMemoryAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleTypes == rhs.handleTypes );
    }

    bool operator!=( ExportMemoryAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportMemoryAllocateInfo::sType;
  };
  static_assert( sizeof( ExportMemoryAllocateInfo ) == sizeof( VkExportMemoryAllocateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportMemoryAllocateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExportMemoryAllocateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportMemoryAllocateInfoNV( vk::ExternalMemoryHandleTypeFlagsNV handleTypes_ = vk::ExternalMemoryHandleTypeFlagsNV() ) VULKAN_HPP_NOEXCEPT
        : handleTypes( handleTypes_ )
      {}

      ExportMemoryAllocateInfoNV( VkExportMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryAllocateInfoNV*>(this) = rhs;
      }

      ExportMemoryAllocateInfoNV& operator=( VkExportMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryAllocateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportMemoryAllocateInfoNV;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlagsNV handleTypes;
    };
    static_assert( sizeof( ExportMemoryAllocateInfoNV ) == sizeof( VkExportMemoryAllocateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct ExportMemoryAllocateInfoNV : public layout::ExportMemoryAllocateInfoNV
  {
    VULKAN_HPP_CONSTEXPR ExportMemoryAllocateInfoNV( vk::ExternalMemoryHandleTypeFlagsNV handleTypes_ = vk::ExternalMemoryHandleTypeFlagsNV() ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryAllocateInfoNV( handleTypes_ )
    {}

    ExportMemoryAllocateInfoNV( VkExportMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryAllocateInfoNV( rhs )
    {}

    ExportMemoryAllocateInfoNV& operator=( VkExportMemoryAllocateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportMemoryAllocateInfoNV::operator=(rhs);
      return *this;
    }

    ExportMemoryAllocateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportMemoryAllocateInfoNV & setHandleTypes( vk::ExternalMemoryHandleTypeFlagsNV handleTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      handleTypes = handleTypes_;
      return *this;
    }

    operator VkExportMemoryAllocateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportMemoryAllocateInfoNV*>( this );
    }

    operator VkExportMemoryAllocateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportMemoryAllocateInfoNV*>( this );
    }

    bool operator==( ExportMemoryAllocateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleTypes == rhs.handleTypes );
    }

    bool operator!=( ExportMemoryAllocateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportMemoryAllocateInfoNV::sType;
  };
  static_assert( sizeof( ExportMemoryAllocateInfoNV ) == sizeof( VkExportMemoryAllocateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportMemoryAllocateInfoNV>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ExportMemoryWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportMemoryWin32HandleInfoKHR( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                           DWORD dwAccess_ = 0,
                                                           LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : pAttributes( pAttributes_ )
        , dwAccess( dwAccess_ )
        , name( name_ )
      {}

      ExportMemoryWin32HandleInfoKHR( VkExportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryWin32HandleInfoKHR*>(this) = rhs;
      }

      ExportMemoryWin32HandleInfoKHR& operator=( VkExportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportMemoryWin32HandleInfoKHR;
      const void* pNext = nullptr;
      const SECURITY_ATTRIBUTES* pAttributes;
      DWORD dwAccess;
      LPCWSTR name;
    };
    static_assert( sizeof( ExportMemoryWin32HandleInfoKHR ) == sizeof( VkExportMemoryWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ExportMemoryWin32HandleInfoKHR : public layout::ExportMemoryWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ExportMemoryWin32HandleInfoKHR( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                         DWORD dwAccess_ = 0,
                                                         LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryWin32HandleInfoKHR( pAttributes_, dwAccess_, name_ )
    {}

    ExportMemoryWin32HandleInfoKHR( VkExportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryWin32HandleInfoKHR( rhs )
    {}

    ExportMemoryWin32HandleInfoKHR& operator=( VkExportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportMemoryWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    ExportMemoryWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportMemoryWin32HandleInfoKHR & setPAttributes( const SECURITY_ATTRIBUTES* pAttributes_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttributes = pAttributes_;
      return *this;
    }

    ExportMemoryWin32HandleInfoKHR & setDwAccess( DWORD dwAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      dwAccess = dwAccess_;
      return *this;
    }

    ExportMemoryWin32HandleInfoKHR & setName( LPCWSTR name_ ) VULKAN_HPP_NOEXCEPT
    {
      name = name_;
      return *this;
    }

    operator VkExportMemoryWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportMemoryWin32HandleInfoKHR*>( this );
    }

    operator VkExportMemoryWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportMemoryWin32HandleInfoKHR*>( this );
    }

    bool operator==( ExportMemoryWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pAttributes == rhs.pAttributes )
          && ( dwAccess == rhs.dwAccess )
          && ( name == rhs.name );
    }

    bool operator!=( ExportMemoryWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportMemoryWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( ExportMemoryWin32HandleInfoKHR ) == sizeof( VkExportMemoryWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportMemoryWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ExportMemoryWin32HandleInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportMemoryWin32HandleInfoNV( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                          DWORD dwAccess_ = 0 ) VULKAN_HPP_NOEXCEPT
        : pAttributes( pAttributes_ )
        , dwAccess( dwAccess_ )
      {}

      ExportMemoryWin32HandleInfoNV( VkExportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryWin32HandleInfoNV*>(this) = rhs;
      }

      ExportMemoryWin32HandleInfoNV& operator=( VkExportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportMemoryWin32HandleInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportMemoryWin32HandleInfoNV;
      const void* pNext = nullptr;
      const SECURITY_ATTRIBUTES* pAttributes;
      DWORD dwAccess;
    };
    static_assert( sizeof( ExportMemoryWin32HandleInfoNV ) == sizeof( VkExportMemoryWin32HandleInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct ExportMemoryWin32HandleInfoNV : public layout::ExportMemoryWin32HandleInfoNV
  {
    VULKAN_HPP_CONSTEXPR ExportMemoryWin32HandleInfoNV( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                        DWORD dwAccess_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryWin32HandleInfoNV( pAttributes_, dwAccess_ )
    {}

    ExportMemoryWin32HandleInfoNV( VkExportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportMemoryWin32HandleInfoNV( rhs )
    {}

    ExportMemoryWin32HandleInfoNV& operator=( VkExportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportMemoryWin32HandleInfoNV::operator=(rhs);
      return *this;
    }

    ExportMemoryWin32HandleInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportMemoryWin32HandleInfoNV & setPAttributes( const SECURITY_ATTRIBUTES* pAttributes_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttributes = pAttributes_;
      return *this;
    }

    ExportMemoryWin32HandleInfoNV & setDwAccess( DWORD dwAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      dwAccess = dwAccess_;
      return *this;
    }

    operator VkExportMemoryWin32HandleInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportMemoryWin32HandleInfoNV*>( this );
    }

    operator VkExportMemoryWin32HandleInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportMemoryWin32HandleInfoNV*>( this );
    }

    bool operator==( ExportMemoryWin32HandleInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pAttributes == rhs.pAttributes )
          && ( dwAccess == rhs.dwAccess );
    }

    bool operator!=( ExportMemoryWin32HandleInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportMemoryWin32HandleInfoNV::sType;
  };
  static_assert( sizeof( ExportMemoryWin32HandleInfoNV ) == sizeof( VkExportMemoryWin32HandleInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportMemoryWin32HandleInfoNV>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct ExportSemaphoreCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportSemaphoreCreateInfo( vk::ExternalSemaphoreHandleTypeFlags handleTypes_ = vk::ExternalSemaphoreHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
        : handleTypes( handleTypes_ )
      {}

      ExportSemaphoreCreateInfo( VkExportSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportSemaphoreCreateInfo*>(this) = rhs;
      }

      ExportSemaphoreCreateInfo& operator=( VkExportSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportSemaphoreCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportSemaphoreCreateInfo;
      const void* pNext = nullptr;
      vk::ExternalSemaphoreHandleTypeFlags handleTypes;
    };
    static_assert( sizeof( ExportSemaphoreCreateInfo ) == sizeof( VkExportSemaphoreCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ExportSemaphoreCreateInfo : public layout::ExportSemaphoreCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ExportSemaphoreCreateInfo( vk::ExternalSemaphoreHandleTypeFlags handleTypes_ = vk::ExternalSemaphoreHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::ExportSemaphoreCreateInfo( handleTypes_ )
    {}

    ExportSemaphoreCreateInfo( VkExportSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportSemaphoreCreateInfo( rhs )
    {}

    ExportSemaphoreCreateInfo& operator=( VkExportSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportSemaphoreCreateInfo::operator=(rhs);
      return *this;
    }

    ExportSemaphoreCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportSemaphoreCreateInfo & setHandleTypes( vk::ExternalSemaphoreHandleTypeFlags handleTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      handleTypes = handleTypes_;
      return *this;
    }

    operator VkExportSemaphoreCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportSemaphoreCreateInfo*>( this );
    }

    operator VkExportSemaphoreCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportSemaphoreCreateInfo*>( this );
    }

    bool operator==( ExportSemaphoreCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleTypes == rhs.handleTypes );
    }

    bool operator!=( ExportSemaphoreCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportSemaphoreCreateInfo::sType;
  };
  static_assert( sizeof( ExportSemaphoreCreateInfo ) == sizeof( VkExportSemaphoreCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportSemaphoreCreateInfo>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ExportSemaphoreWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExportSemaphoreWin32HandleInfoKHR( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                              DWORD dwAccess_ = 0,
                                                              LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : pAttributes( pAttributes_ )
        , dwAccess( dwAccess_ )
        , name( name_ )
      {}

      ExportSemaphoreWin32HandleInfoKHR( VkExportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportSemaphoreWin32HandleInfoKHR*>(this) = rhs;
      }

      ExportSemaphoreWin32HandleInfoKHR& operator=( VkExportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExportSemaphoreWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExportSemaphoreWin32HandleInfoKHR;
      const void* pNext = nullptr;
      const SECURITY_ATTRIBUTES* pAttributes;
      DWORD dwAccess;
      LPCWSTR name;
    };
    static_assert( sizeof( ExportSemaphoreWin32HandleInfoKHR ) == sizeof( VkExportSemaphoreWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ExportSemaphoreWin32HandleInfoKHR : public layout::ExportSemaphoreWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ExportSemaphoreWin32HandleInfoKHR( const SECURITY_ATTRIBUTES* pAttributes_ = nullptr,
                                                            DWORD dwAccess_ = 0,
                                                            LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ExportSemaphoreWin32HandleInfoKHR( pAttributes_, dwAccess_, name_ )
    {}

    ExportSemaphoreWin32HandleInfoKHR( VkExportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExportSemaphoreWin32HandleInfoKHR( rhs )
    {}

    ExportSemaphoreWin32HandleInfoKHR& operator=( VkExportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExportSemaphoreWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    ExportSemaphoreWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExportSemaphoreWin32HandleInfoKHR & setPAttributes( const SECURITY_ATTRIBUTES* pAttributes_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttributes = pAttributes_;
      return *this;
    }

    ExportSemaphoreWin32HandleInfoKHR & setDwAccess( DWORD dwAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      dwAccess = dwAccess_;
      return *this;
    }

    ExportSemaphoreWin32HandleInfoKHR & setName( LPCWSTR name_ ) VULKAN_HPP_NOEXCEPT
    {
      name = name_;
      return *this;
    }

    operator VkExportSemaphoreWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExportSemaphoreWin32HandleInfoKHR*>( this );
    }

    operator VkExportSemaphoreWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExportSemaphoreWin32HandleInfoKHR*>( this );
    }

    bool operator==( ExportSemaphoreWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pAttributes == rhs.pAttributes )
          && ( dwAccess == rhs.dwAccess )
          && ( name == rhs.name );
    }

    bool operator!=( ExportSemaphoreWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExportSemaphoreWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( ExportSemaphoreWin32HandleInfoKHR ) == sizeof( VkExportSemaphoreWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExportSemaphoreWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  struct ExtensionProperties
  {
    ExtensionProperties() VULKAN_HPP_NOEXCEPT
    {}

    ExtensionProperties( VkExtensionProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExtensionProperties*>(this) = rhs;
    }

    ExtensionProperties& operator=( VkExtensionProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExtensionProperties*>(this) = rhs;
      return *this;
    }

    operator VkExtensionProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExtensionProperties*>( this );
    }

    operator VkExtensionProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExtensionProperties*>( this );
    }

    bool operator==( ExtensionProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( memcmp( extensionName, rhs.extensionName, VK_MAX_EXTENSION_NAME_SIZE * sizeof( char ) ) == 0 )
          && ( specVersion == rhs.specVersion );
    }

    bool operator!=( ExtensionProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    char extensionName[VK_MAX_EXTENSION_NAME_SIZE];
    uint32_t specVersion;
  };
  static_assert( sizeof( ExtensionProperties ) == sizeof( VkExtensionProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExtensionProperties>::value, "struct wrapper is not a standard layout!" );

  struct ExternalMemoryProperties
  {
    ExternalMemoryProperties() VULKAN_HPP_NOEXCEPT
    {}

    ExternalMemoryProperties( VkExternalMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExternalMemoryProperties*>(this) = rhs;
    }

    ExternalMemoryProperties& operator=( VkExternalMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExternalMemoryProperties*>(this) = rhs;
      return *this;
    }

    operator VkExternalMemoryProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalMemoryProperties*>( this );
    }

    operator VkExternalMemoryProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalMemoryProperties*>( this );
    }

    bool operator==( ExternalMemoryProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( externalMemoryFeatures == rhs.externalMemoryFeatures )
          && ( exportFromImportedHandleTypes == rhs.exportFromImportedHandleTypes )
          && ( compatibleHandleTypes == rhs.compatibleHandleTypes );
    }

    bool operator!=( ExternalMemoryProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ExternalMemoryFeatureFlags externalMemoryFeatures;
    vk::ExternalMemoryHandleTypeFlags exportFromImportedHandleTypes;
    vk::ExternalMemoryHandleTypeFlags compatibleHandleTypes;
  };
  static_assert( sizeof( ExternalMemoryProperties ) == sizeof( VkExternalMemoryProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalMemoryProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExternalBufferProperties
    {
    protected:
      ExternalBufferProperties() VULKAN_HPP_NOEXCEPT
      {}

      ExternalBufferProperties( VkExternalBufferProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalBufferProperties*>(this) = rhs;
      }

      ExternalBufferProperties& operator=( VkExternalBufferProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalBufferProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalBufferProperties;
      void* pNext = nullptr;
      vk::ExternalMemoryProperties externalMemoryProperties;
    };
    static_assert( sizeof( ExternalBufferProperties ) == sizeof( VkExternalBufferProperties ), "layout struct and wrapper have different size!" );
  }

  struct ExternalBufferProperties : public layout::ExternalBufferProperties
  {
    ExternalBufferProperties() VULKAN_HPP_NOEXCEPT
      : layout::ExternalBufferProperties()
    {}

    ExternalBufferProperties( VkExternalBufferProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalBufferProperties( rhs )
    {}

    ExternalBufferProperties& operator=( VkExternalBufferProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalBufferProperties::operator=(rhs);
      return *this;
    }

    operator VkExternalBufferProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalBufferProperties*>( this );
    }

    operator VkExternalBufferProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalBufferProperties*>( this );
    }

    bool operator==( ExternalBufferProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( externalMemoryProperties == rhs.externalMemoryProperties );
    }

    bool operator!=( ExternalBufferProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalBufferProperties::sType;
  };
  static_assert( sizeof( ExternalBufferProperties ) == sizeof( VkExternalBufferProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalBufferProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExternalFenceProperties
    {
    protected:
      ExternalFenceProperties() VULKAN_HPP_NOEXCEPT
      {}

      ExternalFenceProperties( VkExternalFenceProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalFenceProperties*>(this) = rhs;
      }

      ExternalFenceProperties& operator=( VkExternalFenceProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalFenceProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalFenceProperties;
      void* pNext = nullptr;
      vk::ExternalFenceHandleTypeFlags exportFromImportedHandleTypes;
      vk::ExternalFenceHandleTypeFlags compatibleHandleTypes;
      vk::ExternalFenceFeatureFlags externalFenceFeatures;
    };
    static_assert( sizeof( ExternalFenceProperties ) == sizeof( VkExternalFenceProperties ), "layout struct and wrapper have different size!" );
  }

  struct ExternalFenceProperties : public layout::ExternalFenceProperties
  {
    ExternalFenceProperties() VULKAN_HPP_NOEXCEPT
      : layout::ExternalFenceProperties()
    {}

    ExternalFenceProperties( VkExternalFenceProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalFenceProperties( rhs )
    {}

    ExternalFenceProperties& operator=( VkExternalFenceProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalFenceProperties::operator=(rhs);
      return *this;
    }

    operator VkExternalFenceProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalFenceProperties*>( this );
    }

    operator VkExternalFenceProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalFenceProperties*>( this );
    }

    bool operator==( ExternalFenceProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( exportFromImportedHandleTypes == rhs.exportFromImportedHandleTypes )
          && ( compatibleHandleTypes == rhs.compatibleHandleTypes )
          && ( externalFenceFeatures == rhs.externalFenceFeatures );
    }

    bool operator!=( ExternalFenceProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalFenceProperties::sType;
  };
  static_assert( sizeof( ExternalFenceProperties ) == sizeof( VkExternalFenceProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalFenceProperties>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_ANDROID_KHR

  namespace layout
  {
    struct ExternalFormatANDROID
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExternalFormatANDROID( uint64_t externalFormat_ = 0 ) VULKAN_HPP_NOEXCEPT
        : externalFormat( externalFormat_ )
      {}

      ExternalFormatANDROID( VkExternalFormatANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalFormatANDROID*>(this) = rhs;
      }

      ExternalFormatANDROID& operator=( VkExternalFormatANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalFormatANDROID*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalFormatANDROID;
      void* pNext = nullptr;
      uint64_t externalFormat;
    };
    static_assert( sizeof( ExternalFormatANDROID ) == sizeof( VkExternalFormatANDROID ), "layout struct and wrapper have different size!" );
  }

  struct ExternalFormatANDROID : public layout::ExternalFormatANDROID
  {
    VULKAN_HPP_CONSTEXPR ExternalFormatANDROID( uint64_t externalFormat_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalFormatANDROID( externalFormat_ )
    {}

    ExternalFormatANDROID( VkExternalFormatANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalFormatANDROID( rhs )
    {}

    ExternalFormatANDROID& operator=( VkExternalFormatANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalFormatANDROID::operator=(rhs);
      return *this;
    }

    ExternalFormatANDROID & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExternalFormatANDROID & setExternalFormat( uint64_t externalFormat_ ) VULKAN_HPP_NOEXCEPT
    {
      externalFormat = externalFormat_;
      return *this;
    }

    operator VkExternalFormatANDROID const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalFormatANDROID*>( this );
    }

    operator VkExternalFormatANDROID &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalFormatANDROID*>( this );
    }

    bool operator==( ExternalFormatANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( externalFormat == rhs.externalFormat );
    }

    bool operator!=( ExternalFormatANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalFormatANDROID::sType;
  };
  static_assert( sizeof( ExternalFormatANDROID ) == sizeof( VkExternalFormatANDROID ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalFormatANDROID>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  namespace layout
  {
    struct ExternalImageFormatProperties
    {
    protected:
      ExternalImageFormatProperties() VULKAN_HPP_NOEXCEPT
      {}

      ExternalImageFormatProperties( VkExternalImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalImageFormatProperties*>(this) = rhs;
      }

      ExternalImageFormatProperties& operator=( VkExternalImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalImageFormatProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalImageFormatProperties;
      void* pNext = nullptr;
      vk::ExternalMemoryProperties externalMemoryProperties;
    };
    static_assert( sizeof( ExternalImageFormatProperties ) == sizeof( VkExternalImageFormatProperties ), "layout struct and wrapper have different size!" );
  }

  struct ExternalImageFormatProperties : public layout::ExternalImageFormatProperties
  {
    ExternalImageFormatProperties() VULKAN_HPP_NOEXCEPT
      : layout::ExternalImageFormatProperties()
    {}

    ExternalImageFormatProperties( VkExternalImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalImageFormatProperties( rhs )
    {}

    ExternalImageFormatProperties& operator=( VkExternalImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalImageFormatProperties::operator=(rhs);
      return *this;
    }

    operator VkExternalImageFormatProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalImageFormatProperties*>( this );
    }

    operator VkExternalImageFormatProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalImageFormatProperties*>( this );
    }

    bool operator==( ExternalImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( externalMemoryProperties == rhs.externalMemoryProperties );
    }

    bool operator!=( ExternalImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalImageFormatProperties::sType;
  };
  static_assert( sizeof( ExternalImageFormatProperties ) == sizeof( VkExternalImageFormatProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalImageFormatProperties>::value, "struct wrapper is not a standard layout!" );

  struct ImageFormatProperties
  {
    ImageFormatProperties() VULKAN_HPP_NOEXCEPT
    {}

    ImageFormatProperties( VkImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageFormatProperties*>(this) = rhs;
    }

    ImageFormatProperties& operator=( VkImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageFormatProperties*>(this) = rhs;
      return *this;
    }

    operator VkImageFormatProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageFormatProperties*>( this );
    }

    operator VkImageFormatProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageFormatProperties*>( this );
    }

    bool operator==( ImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( maxExtent == rhs.maxExtent )
          && ( maxMipLevels == rhs.maxMipLevels )
          && ( maxArrayLayers == rhs.maxArrayLayers )
          && ( sampleCounts == rhs.sampleCounts )
          && ( maxResourceSize == rhs.maxResourceSize );
    }

    bool operator!=( ImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Extent3D maxExtent;
    uint32_t maxMipLevels;
    uint32_t maxArrayLayers;
    vk::SampleCountFlags sampleCounts;
    vk::DeviceSize maxResourceSize;
  };
  static_assert( sizeof( ImageFormatProperties ) == sizeof( VkImageFormatProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageFormatProperties>::value, "struct wrapper is not a standard layout!" );

  struct ExternalImageFormatPropertiesNV
  {
    ExternalImageFormatPropertiesNV() VULKAN_HPP_NOEXCEPT
    {}

    ExternalImageFormatPropertiesNV( VkExternalImageFormatPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExternalImageFormatPropertiesNV*>(this) = rhs;
    }

    ExternalImageFormatPropertiesNV& operator=( VkExternalImageFormatPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkExternalImageFormatPropertiesNV*>(this) = rhs;
      return *this;
    }

    operator VkExternalImageFormatPropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalImageFormatPropertiesNV*>( this );
    }

    operator VkExternalImageFormatPropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalImageFormatPropertiesNV*>( this );
    }

    bool operator==( ExternalImageFormatPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( imageFormatProperties == rhs.imageFormatProperties )
          && ( externalMemoryFeatures == rhs.externalMemoryFeatures )
          && ( exportFromImportedHandleTypes == rhs.exportFromImportedHandleTypes )
          && ( compatibleHandleTypes == rhs.compatibleHandleTypes );
    }

    bool operator!=( ExternalImageFormatPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageFormatProperties imageFormatProperties;
    vk::ExternalMemoryFeatureFlagsNV externalMemoryFeatures;
    vk::ExternalMemoryHandleTypeFlagsNV exportFromImportedHandleTypes;
    vk::ExternalMemoryHandleTypeFlagsNV compatibleHandleTypes;
  };
  static_assert( sizeof( ExternalImageFormatPropertiesNV ) == sizeof( VkExternalImageFormatPropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalImageFormatPropertiesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExternalMemoryBufferCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExternalMemoryBufferCreateInfo( vk::ExternalMemoryHandleTypeFlags handleTypes_ = vk::ExternalMemoryHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
        : handleTypes( handleTypes_ )
      {}

      ExternalMemoryBufferCreateInfo( VkExternalMemoryBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalMemoryBufferCreateInfo*>(this) = rhs;
      }

      ExternalMemoryBufferCreateInfo& operator=( VkExternalMemoryBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalMemoryBufferCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalMemoryBufferCreateInfo;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlags handleTypes;
    };
    static_assert( sizeof( ExternalMemoryBufferCreateInfo ) == sizeof( VkExternalMemoryBufferCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ExternalMemoryBufferCreateInfo : public layout::ExternalMemoryBufferCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ExternalMemoryBufferCreateInfo( vk::ExternalMemoryHandleTypeFlags handleTypes_ = vk::ExternalMemoryHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalMemoryBufferCreateInfo( handleTypes_ )
    {}

    ExternalMemoryBufferCreateInfo( VkExternalMemoryBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalMemoryBufferCreateInfo( rhs )
    {}

    ExternalMemoryBufferCreateInfo& operator=( VkExternalMemoryBufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalMemoryBufferCreateInfo::operator=(rhs);
      return *this;
    }

    ExternalMemoryBufferCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExternalMemoryBufferCreateInfo & setHandleTypes( vk::ExternalMemoryHandleTypeFlags handleTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      handleTypes = handleTypes_;
      return *this;
    }

    operator VkExternalMemoryBufferCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalMemoryBufferCreateInfo*>( this );
    }

    operator VkExternalMemoryBufferCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalMemoryBufferCreateInfo*>( this );
    }

    bool operator==( ExternalMemoryBufferCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleTypes == rhs.handleTypes );
    }

    bool operator!=( ExternalMemoryBufferCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalMemoryBufferCreateInfo::sType;
  };
  static_assert( sizeof( ExternalMemoryBufferCreateInfo ) == sizeof( VkExternalMemoryBufferCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalMemoryBufferCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExternalMemoryImageCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExternalMemoryImageCreateInfo( vk::ExternalMemoryHandleTypeFlags handleTypes_ = vk::ExternalMemoryHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
        : handleTypes( handleTypes_ )
      {}

      ExternalMemoryImageCreateInfo( VkExternalMemoryImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalMemoryImageCreateInfo*>(this) = rhs;
      }

      ExternalMemoryImageCreateInfo& operator=( VkExternalMemoryImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalMemoryImageCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalMemoryImageCreateInfo;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlags handleTypes;
    };
    static_assert( sizeof( ExternalMemoryImageCreateInfo ) == sizeof( VkExternalMemoryImageCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ExternalMemoryImageCreateInfo : public layout::ExternalMemoryImageCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ExternalMemoryImageCreateInfo( vk::ExternalMemoryHandleTypeFlags handleTypes_ = vk::ExternalMemoryHandleTypeFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalMemoryImageCreateInfo( handleTypes_ )
    {}

    ExternalMemoryImageCreateInfo( VkExternalMemoryImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalMemoryImageCreateInfo( rhs )
    {}

    ExternalMemoryImageCreateInfo& operator=( VkExternalMemoryImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalMemoryImageCreateInfo::operator=(rhs);
      return *this;
    }

    ExternalMemoryImageCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExternalMemoryImageCreateInfo & setHandleTypes( vk::ExternalMemoryHandleTypeFlags handleTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      handleTypes = handleTypes_;
      return *this;
    }

    operator VkExternalMemoryImageCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalMemoryImageCreateInfo*>( this );
    }

    operator VkExternalMemoryImageCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalMemoryImageCreateInfo*>( this );
    }

    bool operator==( ExternalMemoryImageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleTypes == rhs.handleTypes );
    }

    bool operator!=( ExternalMemoryImageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalMemoryImageCreateInfo::sType;
  };
  static_assert( sizeof( ExternalMemoryImageCreateInfo ) == sizeof( VkExternalMemoryImageCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalMemoryImageCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExternalMemoryImageCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR ExternalMemoryImageCreateInfoNV( vk::ExternalMemoryHandleTypeFlagsNV handleTypes_ = vk::ExternalMemoryHandleTypeFlagsNV() ) VULKAN_HPP_NOEXCEPT
        : handleTypes( handleTypes_ )
      {}

      ExternalMemoryImageCreateInfoNV( VkExternalMemoryImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalMemoryImageCreateInfoNV*>(this) = rhs;
      }

      ExternalMemoryImageCreateInfoNV& operator=( VkExternalMemoryImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalMemoryImageCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalMemoryImageCreateInfoNV;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlagsNV handleTypes;
    };
    static_assert( sizeof( ExternalMemoryImageCreateInfoNV ) == sizeof( VkExternalMemoryImageCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct ExternalMemoryImageCreateInfoNV : public layout::ExternalMemoryImageCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR ExternalMemoryImageCreateInfoNV( vk::ExternalMemoryHandleTypeFlagsNV handleTypes_ = vk::ExternalMemoryHandleTypeFlagsNV() ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalMemoryImageCreateInfoNV( handleTypes_ )
    {}

    ExternalMemoryImageCreateInfoNV( VkExternalMemoryImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalMemoryImageCreateInfoNV( rhs )
    {}

    ExternalMemoryImageCreateInfoNV& operator=( VkExternalMemoryImageCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalMemoryImageCreateInfoNV::operator=(rhs);
      return *this;
    }

    ExternalMemoryImageCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ExternalMemoryImageCreateInfoNV & setHandleTypes( vk::ExternalMemoryHandleTypeFlagsNV handleTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      handleTypes = handleTypes_;
      return *this;
    }

    operator VkExternalMemoryImageCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalMemoryImageCreateInfoNV*>( this );
    }

    operator VkExternalMemoryImageCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalMemoryImageCreateInfoNV*>( this );
    }

    bool operator==( ExternalMemoryImageCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleTypes == rhs.handleTypes );
    }

    bool operator!=( ExternalMemoryImageCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalMemoryImageCreateInfoNV::sType;
  };
  static_assert( sizeof( ExternalMemoryImageCreateInfoNV ) == sizeof( VkExternalMemoryImageCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalMemoryImageCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ExternalSemaphoreProperties
    {
    protected:
      ExternalSemaphoreProperties() VULKAN_HPP_NOEXCEPT
      {}

      ExternalSemaphoreProperties( VkExternalSemaphoreProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalSemaphoreProperties*>(this) = rhs;
      }

      ExternalSemaphoreProperties& operator=( VkExternalSemaphoreProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkExternalSemaphoreProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eExternalSemaphoreProperties;
      void* pNext = nullptr;
      vk::ExternalSemaphoreHandleTypeFlags exportFromImportedHandleTypes;
      vk::ExternalSemaphoreHandleTypeFlags compatibleHandleTypes;
      vk::ExternalSemaphoreFeatureFlags externalSemaphoreFeatures;
    };
    static_assert( sizeof( ExternalSemaphoreProperties ) == sizeof( VkExternalSemaphoreProperties ), "layout struct and wrapper have different size!" );
  }

  struct ExternalSemaphoreProperties : public layout::ExternalSemaphoreProperties
  {
    ExternalSemaphoreProperties() VULKAN_HPP_NOEXCEPT
      : layout::ExternalSemaphoreProperties()
    {}

    ExternalSemaphoreProperties( VkExternalSemaphoreProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ExternalSemaphoreProperties( rhs )
    {}

    ExternalSemaphoreProperties& operator=( VkExternalSemaphoreProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ExternalSemaphoreProperties::operator=(rhs);
      return *this;
    }

    operator VkExternalSemaphoreProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkExternalSemaphoreProperties*>( this );
    }

    operator VkExternalSemaphoreProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkExternalSemaphoreProperties*>( this );
    }

    bool operator==( ExternalSemaphoreProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( exportFromImportedHandleTypes == rhs.exportFromImportedHandleTypes )
          && ( compatibleHandleTypes == rhs.compatibleHandleTypes )
          && ( externalSemaphoreFeatures == rhs.externalSemaphoreFeatures );
    }

    bool operator!=( ExternalSemaphoreProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ExternalSemaphoreProperties::sType;
  };
  static_assert( sizeof( ExternalSemaphoreProperties ) == sizeof( VkExternalSemaphoreProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ExternalSemaphoreProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct FenceCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR FenceCreateInfo( vk::FenceCreateFlags flags_ = vk::FenceCreateFlags() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
      {}

      FenceCreateInfo( VkFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFenceCreateInfo*>(this) = rhs;
      }

      FenceCreateInfo& operator=( VkFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFenceCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFenceCreateInfo;
      const void* pNext = nullptr;
      vk::FenceCreateFlags flags;
    };
    static_assert( sizeof( FenceCreateInfo ) == sizeof( VkFenceCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct FenceCreateInfo : public layout::FenceCreateInfo
  {
    VULKAN_HPP_CONSTEXPR FenceCreateInfo( vk::FenceCreateFlags flags_ = vk::FenceCreateFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::FenceCreateInfo( flags_ )
    {}

    FenceCreateInfo( VkFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FenceCreateInfo( rhs )
    {}

    FenceCreateInfo& operator=( VkFenceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FenceCreateInfo::operator=(rhs);
      return *this;
    }

    FenceCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    FenceCreateInfo & setFlags( vk::FenceCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkFenceCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFenceCreateInfo*>( this );
    }

    operator VkFenceCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFenceCreateInfo*>( this );
    }

    bool operator==( FenceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags );
    }

    bool operator!=( FenceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FenceCreateInfo::sType;
  };
  static_assert( sizeof( FenceCreateInfo ) == sizeof( VkFenceCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FenceCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct FenceGetFdInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR FenceGetFdInfoKHR( vk::Fence fence_ = vk::Fence(),
                                              vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : fence( fence_ )
        , handleType( handleType_ )
      {}

      FenceGetFdInfoKHR( VkFenceGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFenceGetFdInfoKHR*>(this) = rhs;
      }

      FenceGetFdInfoKHR& operator=( VkFenceGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFenceGetFdInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFenceGetFdInfoKHR;
      const void* pNext = nullptr;
      vk::Fence fence;
      vk::ExternalFenceHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( FenceGetFdInfoKHR ) == sizeof( VkFenceGetFdInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct FenceGetFdInfoKHR : public layout::FenceGetFdInfoKHR
  {
    VULKAN_HPP_CONSTEXPR FenceGetFdInfoKHR( vk::Fence fence_ = vk::Fence(),
                                            vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::FenceGetFdInfoKHR( fence_, handleType_ )
    {}

    FenceGetFdInfoKHR( VkFenceGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FenceGetFdInfoKHR( rhs )
    {}

    FenceGetFdInfoKHR& operator=( VkFenceGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FenceGetFdInfoKHR::operator=(rhs);
      return *this;
    }

    FenceGetFdInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    FenceGetFdInfoKHR & setFence( vk::Fence fence_ ) VULKAN_HPP_NOEXCEPT
    {
      fence = fence_;
      return *this;
    }

    FenceGetFdInfoKHR & setHandleType( vk::ExternalFenceHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkFenceGetFdInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFenceGetFdInfoKHR*>( this );
    }

    operator VkFenceGetFdInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFenceGetFdInfoKHR*>( this );
    }

    bool operator==( FenceGetFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fence == rhs.fence )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( FenceGetFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FenceGetFdInfoKHR::sType;
  };
  static_assert( sizeof( FenceGetFdInfoKHR ) == sizeof( VkFenceGetFdInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FenceGetFdInfoKHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct FenceGetWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR FenceGetWin32HandleInfoKHR( vk::Fence fence_ = vk::Fence(),
                                                       vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : fence( fence_ )
        , handleType( handleType_ )
      {}

      FenceGetWin32HandleInfoKHR( VkFenceGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFenceGetWin32HandleInfoKHR*>(this) = rhs;
      }

      FenceGetWin32HandleInfoKHR& operator=( VkFenceGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFenceGetWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFenceGetWin32HandleInfoKHR;
      const void* pNext = nullptr;
      vk::Fence fence;
      vk::ExternalFenceHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( FenceGetWin32HandleInfoKHR ) == sizeof( VkFenceGetWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct FenceGetWin32HandleInfoKHR : public layout::FenceGetWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR FenceGetWin32HandleInfoKHR( vk::Fence fence_ = vk::Fence(),
                                                     vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::FenceGetWin32HandleInfoKHR( fence_, handleType_ )
    {}

    FenceGetWin32HandleInfoKHR( VkFenceGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FenceGetWin32HandleInfoKHR( rhs )
    {}

    FenceGetWin32HandleInfoKHR& operator=( VkFenceGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FenceGetWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    FenceGetWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    FenceGetWin32HandleInfoKHR & setFence( vk::Fence fence_ ) VULKAN_HPP_NOEXCEPT
    {
      fence = fence_;
      return *this;
    }

    FenceGetWin32HandleInfoKHR & setHandleType( vk::ExternalFenceHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkFenceGetWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFenceGetWin32HandleInfoKHR*>( this );
    }

    operator VkFenceGetWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFenceGetWin32HandleInfoKHR*>( this );
    }

    bool operator==( FenceGetWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fence == rhs.fence )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( FenceGetWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FenceGetWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( FenceGetWin32HandleInfoKHR ) == sizeof( VkFenceGetWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FenceGetWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct FilterCubicImageViewImageFormatPropertiesEXT
    {
    protected:
      FilterCubicImageViewImageFormatPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      FilterCubicImageViewImageFormatPropertiesEXT( VkFilterCubicImageViewImageFormatPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFilterCubicImageViewImageFormatPropertiesEXT*>(this) = rhs;
      }

      FilterCubicImageViewImageFormatPropertiesEXT& operator=( VkFilterCubicImageViewImageFormatPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFilterCubicImageViewImageFormatPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFilterCubicImageViewImageFormatPropertiesEXT;
      void* pNext = nullptr;
      vk::Bool32 filterCubic;
      vk::Bool32 filterCubicMinmax;
    };
    static_assert( sizeof( FilterCubicImageViewImageFormatPropertiesEXT ) == sizeof( VkFilterCubicImageViewImageFormatPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct FilterCubicImageViewImageFormatPropertiesEXT : public layout::FilterCubicImageViewImageFormatPropertiesEXT
  {
    FilterCubicImageViewImageFormatPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::FilterCubicImageViewImageFormatPropertiesEXT()
    {}

    FilterCubicImageViewImageFormatPropertiesEXT( VkFilterCubicImageViewImageFormatPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FilterCubicImageViewImageFormatPropertiesEXT( rhs )
    {}

    FilterCubicImageViewImageFormatPropertiesEXT& operator=( VkFilterCubicImageViewImageFormatPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FilterCubicImageViewImageFormatPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkFilterCubicImageViewImageFormatPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFilterCubicImageViewImageFormatPropertiesEXT*>( this );
    }

    operator VkFilterCubicImageViewImageFormatPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFilterCubicImageViewImageFormatPropertiesEXT*>( this );
    }

    bool operator==( FilterCubicImageViewImageFormatPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( filterCubic == rhs.filterCubic )
          && ( filterCubicMinmax == rhs.filterCubicMinmax );
    }

    bool operator!=( FilterCubicImageViewImageFormatPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FilterCubicImageViewImageFormatPropertiesEXT::sType;
  };
  static_assert( sizeof( FilterCubicImageViewImageFormatPropertiesEXT ) == sizeof( VkFilterCubicImageViewImageFormatPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FilterCubicImageViewImageFormatPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  struct FormatProperties
  {
    FormatProperties() VULKAN_HPP_NOEXCEPT
    {}

    FormatProperties( VkFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkFormatProperties*>(this) = rhs;
    }

    FormatProperties& operator=( VkFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkFormatProperties*>(this) = rhs;
      return *this;
    }

    operator VkFormatProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFormatProperties*>( this );
    }

    operator VkFormatProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFormatProperties*>( this );
    }

    bool operator==( FormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( linearTilingFeatures == rhs.linearTilingFeatures )
          && ( optimalTilingFeatures == rhs.optimalTilingFeatures )
          && ( bufferFeatures == rhs.bufferFeatures );
    }

    bool operator!=( FormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::FormatFeatureFlags linearTilingFeatures;
    vk::FormatFeatureFlags optimalTilingFeatures;
    vk::FormatFeatureFlags bufferFeatures;
  };
  static_assert( sizeof( FormatProperties ) == sizeof( VkFormatProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FormatProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct FormatProperties2
    {
    protected:
      FormatProperties2() VULKAN_HPP_NOEXCEPT
      {}

      FormatProperties2( VkFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFormatProperties2*>(this) = rhs;
      }

      FormatProperties2& operator=( VkFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFormatProperties2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFormatProperties2;
      void* pNext = nullptr;
      vk::FormatProperties formatProperties;
    };
    static_assert( sizeof( FormatProperties2 ) == sizeof( VkFormatProperties2 ), "layout struct and wrapper have different size!" );
  }

  struct FormatProperties2 : public layout::FormatProperties2
  {
    FormatProperties2() VULKAN_HPP_NOEXCEPT
      : layout::FormatProperties2()
    {}

    FormatProperties2( VkFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FormatProperties2( rhs )
    {}

    FormatProperties2& operator=( VkFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FormatProperties2::operator=(rhs);
      return *this;
    }

    operator VkFormatProperties2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFormatProperties2*>( this );
    }

    operator VkFormatProperties2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFormatProperties2*>( this );
    }

    bool operator==( FormatProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( formatProperties == rhs.formatProperties );
    }

    bool operator!=( FormatProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FormatProperties2::sType;
  };
  static_assert( sizeof( FormatProperties2 ) == sizeof( VkFormatProperties2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FormatProperties2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct FramebufferAttachmentImageInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR FramebufferAttachmentImageInfoKHR( vk::ImageCreateFlags flags_ = vk::ImageCreateFlags(),
                                                              vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                                              uint32_t width_ = 0,
                                                              uint32_t height_ = 0,
                                                              uint32_t layerCount_ = 0,
                                                              uint32_t viewFormatCount_ = 0,
                                                              const vk::Format* pViewFormats_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , usage( usage_ )
        , width( width_ )
        , height( height_ )
        , layerCount( layerCount_ )
        , viewFormatCount( viewFormatCount_ )
        , pViewFormats( pViewFormats_ )
      {}

      FramebufferAttachmentImageInfoKHR( VkFramebufferAttachmentImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferAttachmentImageInfoKHR*>(this) = rhs;
      }

      FramebufferAttachmentImageInfoKHR& operator=( VkFramebufferAttachmentImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferAttachmentImageInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFramebufferAttachmentImageInfoKHR;
      const void* pNext = nullptr;
      vk::ImageCreateFlags flags;
      vk::ImageUsageFlags usage;
      uint32_t width;
      uint32_t height;
      uint32_t layerCount;
      uint32_t viewFormatCount;
      const vk::Format* pViewFormats;
    };
    static_assert( sizeof( FramebufferAttachmentImageInfoKHR ) == sizeof( VkFramebufferAttachmentImageInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct FramebufferAttachmentImageInfoKHR : public layout::FramebufferAttachmentImageInfoKHR
  {
    VULKAN_HPP_CONSTEXPR FramebufferAttachmentImageInfoKHR( vk::ImageCreateFlags flags_ = vk::ImageCreateFlags(),
                                                            vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                                            uint32_t width_ = 0,
                                                            uint32_t height_ = 0,
                                                            uint32_t layerCount_ = 0,
                                                            uint32_t viewFormatCount_ = 0,
                                                            const vk::Format* pViewFormats_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::FramebufferAttachmentImageInfoKHR( flags_, usage_, width_, height_, layerCount_, viewFormatCount_, pViewFormats_ )
    {}

    FramebufferAttachmentImageInfoKHR( VkFramebufferAttachmentImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FramebufferAttachmentImageInfoKHR( rhs )
    {}

    FramebufferAttachmentImageInfoKHR& operator=( VkFramebufferAttachmentImageInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FramebufferAttachmentImageInfoKHR::operator=(rhs);
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setFlags( vk::ImageCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setUsage( vk::ImageUsageFlags usage_ ) VULKAN_HPP_NOEXCEPT
    {
      usage = usage_;
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setWidth( uint32_t width_ ) VULKAN_HPP_NOEXCEPT
    {
      width = width_;
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setHeight( uint32_t height_ ) VULKAN_HPP_NOEXCEPT
    {
      height = height_;
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setLayerCount( uint32_t layerCount_ ) VULKAN_HPP_NOEXCEPT
    {
      layerCount = layerCount_;
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setViewFormatCount( uint32_t viewFormatCount_ ) VULKAN_HPP_NOEXCEPT
    {
      viewFormatCount = viewFormatCount_;
      return *this;
    }

    FramebufferAttachmentImageInfoKHR & setPViewFormats( const vk::Format* pViewFormats_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewFormats = pViewFormats_;
      return *this;
    }

    operator VkFramebufferAttachmentImageInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFramebufferAttachmentImageInfoKHR*>( this );
    }

    operator VkFramebufferAttachmentImageInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFramebufferAttachmentImageInfoKHR*>( this );
    }

    bool operator==( FramebufferAttachmentImageInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( usage == rhs.usage )
          && ( width == rhs.width )
          && ( height == rhs.height )
          && ( layerCount == rhs.layerCount )
          && ( viewFormatCount == rhs.viewFormatCount )
          && ( pViewFormats == rhs.pViewFormats );
    }

    bool operator!=( FramebufferAttachmentImageInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FramebufferAttachmentImageInfoKHR::sType;
  };
  static_assert( sizeof( FramebufferAttachmentImageInfoKHR ) == sizeof( VkFramebufferAttachmentImageInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FramebufferAttachmentImageInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct FramebufferAttachmentsCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR FramebufferAttachmentsCreateInfoKHR( uint32_t attachmentImageInfoCount_ = 0,
                                                                const vk::FramebufferAttachmentImageInfoKHR* pAttachmentImageInfos_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : attachmentImageInfoCount( attachmentImageInfoCount_ )
        , pAttachmentImageInfos( pAttachmentImageInfos_ )
      {}

      FramebufferAttachmentsCreateInfoKHR( VkFramebufferAttachmentsCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferAttachmentsCreateInfoKHR*>(this) = rhs;
      }

      FramebufferAttachmentsCreateInfoKHR& operator=( VkFramebufferAttachmentsCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferAttachmentsCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFramebufferAttachmentsCreateInfoKHR;
      const void* pNext = nullptr;
      uint32_t attachmentImageInfoCount;
      const vk::FramebufferAttachmentImageInfoKHR* pAttachmentImageInfos;
    };
    static_assert( sizeof( FramebufferAttachmentsCreateInfoKHR ) == sizeof( VkFramebufferAttachmentsCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct FramebufferAttachmentsCreateInfoKHR : public layout::FramebufferAttachmentsCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR FramebufferAttachmentsCreateInfoKHR( uint32_t attachmentImageInfoCount_ = 0,
                                                              const vk::FramebufferAttachmentImageInfoKHR* pAttachmentImageInfos_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::FramebufferAttachmentsCreateInfoKHR( attachmentImageInfoCount_, pAttachmentImageInfos_ )
    {}

    FramebufferAttachmentsCreateInfoKHR( VkFramebufferAttachmentsCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FramebufferAttachmentsCreateInfoKHR( rhs )
    {}

    FramebufferAttachmentsCreateInfoKHR& operator=( VkFramebufferAttachmentsCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FramebufferAttachmentsCreateInfoKHR::operator=(rhs);
      return *this;
    }

    FramebufferAttachmentsCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    FramebufferAttachmentsCreateInfoKHR & setAttachmentImageInfoCount( uint32_t attachmentImageInfoCount_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentImageInfoCount = attachmentImageInfoCount_;
      return *this;
    }

    FramebufferAttachmentsCreateInfoKHR & setPAttachmentImageInfos( const vk::FramebufferAttachmentImageInfoKHR* pAttachmentImageInfos_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttachmentImageInfos = pAttachmentImageInfos_;
      return *this;
    }

    operator VkFramebufferAttachmentsCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFramebufferAttachmentsCreateInfoKHR*>( this );
    }

    operator VkFramebufferAttachmentsCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFramebufferAttachmentsCreateInfoKHR*>( this );
    }

    bool operator==( FramebufferAttachmentsCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( attachmentImageInfoCount == rhs.attachmentImageInfoCount )
          && ( pAttachmentImageInfos == rhs.pAttachmentImageInfos );
    }

    bool operator!=( FramebufferAttachmentsCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FramebufferAttachmentsCreateInfoKHR::sType;
  };
  static_assert( sizeof( FramebufferAttachmentsCreateInfoKHR ) == sizeof( VkFramebufferAttachmentsCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FramebufferAttachmentsCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct FramebufferCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR FramebufferCreateInfo( vk::FramebufferCreateFlags flags_ = vk::FramebufferCreateFlags(),
                                                  vk::RenderPass renderPass_ = vk::RenderPass(),
                                                  uint32_t attachmentCount_ = 0,
                                                  const vk::ImageView* pAttachments_ = nullptr,
                                                  uint32_t width_ = 0,
                                                  uint32_t height_ = 0,
                                                  uint32_t layers_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , renderPass( renderPass_ )
        , attachmentCount( attachmentCount_ )
        , pAttachments( pAttachments_ )
        , width( width_ )
        , height( height_ )
        , layers( layers_ )
      {}

      FramebufferCreateInfo( VkFramebufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferCreateInfo*>(this) = rhs;
      }

      FramebufferCreateInfo& operator=( VkFramebufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFramebufferCreateInfo;
      const void* pNext = nullptr;
      vk::FramebufferCreateFlags flags;
      vk::RenderPass renderPass;
      uint32_t attachmentCount;
      const vk::ImageView* pAttachments;
      uint32_t width;
      uint32_t height;
      uint32_t layers;
    };
    static_assert( sizeof( FramebufferCreateInfo ) == sizeof( VkFramebufferCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct FramebufferCreateInfo : public layout::FramebufferCreateInfo
  {
    VULKAN_HPP_CONSTEXPR FramebufferCreateInfo( vk::FramebufferCreateFlags flags_ = vk::FramebufferCreateFlags(),
                                                vk::RenderPass renderPass_ = vk::RenderPass(),
                                                uint32_t attachmentCount_ = 0,
                                                const vk::ImageView* pAttachments_ = nullptr,
                                                uint32_t width_ = 0,
                                                uint32_t height_ = 0,
                                                uint32_t layers_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::FramebufferCreateInfo( flags_, renderPass_, attachmentCount_, pAttachments_, width_, height_, layers_ )
    {}

    FramebufferCreateInfo( VkFramebufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FramebufferCreateInfo( rhs )
    {}

    FramebufferCreateInfo& operator=( VkFramebufferCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FramebufferCreateInfo::operator=(rhs);
      return *this;
    }

    FramebufferCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    FramebufferCreateInfo & setFlags( vk::FramebufferCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    FramebufferCreateInfo & setRenderPass( vk::RenderPass renderPass_ ) VULKAN_HPP_NOEXCEPT
    {
      renderPass = renderPass_;
      return *this;
    }

    FramebufferCreateInfo & setAttachmentCount( uint32_t attachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentCount = attachmentCount_;
      return *this;
    }

    FramebufferCreateInfo & setPAttachments( const vk::ImageView* pAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttachments = pAttachments_;
      return *this;
    }

    FramebufferCreateInfo & setWidth( uint32_t width_ ) VULKAN_HPP_NOEXCEPT
    {
      width = width_;
      return *this;
    }

    FramebufferCreateInfo & setHeight( uint32_t height_ ) VULKAN_HPP_NOEXCEPT
    {
      height = height_;
      return *this;
    }

    FramebufferCreateInfo & setLayers( uint32_t layers_ ) VULKAN_HPP_NOEXCEPT
    {
      layers = layers_;
      return *this;
    }

    operator VkFramebufferCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFramebufferCreateInfo*>( this );
    }

    operator VkFramebufferCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFramebufferCreateInfo*>( this );
    }

    bool operator==( FramebufferCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( renderPass == rhs.renderPass )
          && ( attachmentCount == rhs.attachmentCount )
          && ( pAttachments == rhs.pAttachments )
          && ( width == rhs.width )
          && ( height == rhs.height )
          && ( layers == rhs.layers );
    }

    bool operator!=( FramebufferCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FramebufferCreateInfo::sType;
  };
  static_assert( sizeof( FramebufferCreateInfo ) == sizeof( VkFramebufferCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FramebufferCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct FramebufferMixedSamplesCombinationNV
    {
    protected:
      FramebufferMixedSamplesCombinationNV() VULKAN_HPP_NOEXCEPT
      {}

      FramebufferMixedSamplesCombinationNV( VkFramebufferMixedSamplesCombinationNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferMixedSamplesCombinationNV*>(this) = rhs;
      }

      FramebufferMixedSamplesCombinationNV& operator=( VkFramebufferMixedSamplesCombinationNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkFramebufferMixedSamplesCombinationNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eFramebufferMixedSamplesCombinationNV;
      void* pNext = nullptr;
      vk::CoverageReductionModeNV coverageReductionMode;
      vk::SampleCountFlagBits rasterizationSamples;
      vk::SampleCountFlags depthStencilSamples;
      vk::SampleCountFlags colorSamples;
    };
    static_assert( sizeof( FramebufferMixedSamplesCombinationNV ) == sizeof( VkFramebufferMixedSamplesCombinationNV ), "layout struct and wrapper have different size!" );
  }

  struct FramebufferMixedSamplesCombinationNV : public layout::FramebufferMixedSamplesCombinationNV
  {
    FramebufferMixedSamplesCombinationNV() VULKAN_HPP_NOEXCEPT
      : layout::FramebufferMixedSamplesCombinationNV()
    {}

    FramebufferMixedSamplesCombinationNV( VkFramebufferMixedSamplesCombinationNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::FramebufferMixedSamplesCombinationNV( rhs )
    {}

    FramebufferMixedSamplesCombinationNV& operator=( VkFramebufferMixedSamplesCombinationNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::FramebufferMixedSamplesCombinationNV::operator=(rhs);
      return *this;
    }

    operator VkFramebufferMixedSamplesCombinationNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkFramebufferMixedSamplesCombinationNV*>( this );
    }

    operator VkFramebufferMixedSamplesCombinationNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkFramebufferMixedSamplesCombinationNV*>( this );
    }

    bool operator==( FramebufferMixedSamplesCombinationNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( coverageReductionMode == rhs.coverageReductionMode )
          && vk::operator==( rasterizationSamples, rhs.rasterizationSamples )
          && ( depthStencilSamples == rhs.depthStencilSamples )
          && ( colorSamples == rhs.colorSamples );
    }

    bool operator!=( FramebufferMixedSamplesCombinationNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::FramebufferMixedSamplesCombinationNV::sType;
  };
  static_assert( sizeof( FramebufferMixedSamplesCombinationNV ) == sizeof( VkFramebufferMixedSamplesCombinationNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<FramebufferMixedSamplesCombinationNV>::value, "struct wrapper is not a standard layout!" );

  struct VertexInputBindingDescription
  {
    VULKAN_HPP_CONSTEXPR VertexInputBindingDescription( uint32_t binding_ = 0,
                                                        uint32_t stride_ = 0,
                                                        vk::VertexInputRate inputRate_ = vk::VertexInputRate::eVertex ) VULKAN_HPP_NOEXCEPT
      : binding( binding_ )
      , stride( stride_ )
      , inputRate( inputRate_ )
    {}

    VertexInputBindingDescription( VkVertexInputBindingDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkVertexInputBindingDescription*>(this) = rhs;
    }

    VertexInputBindingDescription& operator=( VkVertexInputBindingDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkVertexInputBindingDescription*>(this) = rhs;
      return *this;
    }

    VertexInputBindingDescription & setBinding( uint32_t binding_ ) VULKAN_HPP_NOEXCEPT
    {
      binding = binding_;
      return *this;
    }

    VertexInputBindingDescription & setStride( uint32_t stride_ ) VULKAN_HPP_NOEXCEPT
    {
      stride = stride_;
      return *this;
    }

    VertexInputBindingDescription & setInputRate( vk::VertexInputRate inputRate_ ) VULKAN_HPP_NOEXCEPT
    {
      inputRate = inputRate_;
      return *this;
    }

    operator VkVertexInputBindingDescription const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkVertexInputBindingDescription*>( this );
    }

    operator VkVertexInputBindingDescription &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkVertexInputBindingDescription*>( this );
    }

    bool operator==( VertexInputBindingDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( binding == rhs.binding )
          && ( stride == rhs.stride )
          && ( inputRate == rhs.inputRate );
    }

    bool operator!=( VertexInputBindingDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t binding;
    uint32_t stride;
    vk::VertexInputRate inputRate;
  };
  static_assert( sizeof( VertexInputBindingDescription ) == sizeof( VkVertexInputBindingDescription ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<VertexInputBindingDescription>::value, "struct wrapper is not a standard layout!" );

  struct VertexInputAttributeDescription
  {
    VULKAN_HPP_CONSTEXPR VertexInputAttributeDescription( uint32_t location_ = 0,
                                                          uint32_t binding_ = 0,
                                                          vk::Format format_ = vk::Format::eUndefined,
                                                          uint32_t offset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : location( location_ )
      , binding( binding_ )
      , format( format_ )
      , offset( offset_ )
    {}

    VertexInputAttributeDescription( VkVertexInputAttributeDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkVertexInputAttributeDescription*>(this) = rhs;
    }

    VertexInputAttributeDescription& operator=( VkVertexInputAttributeDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkVertexInputAttributeDescription*>(this) = rhs;
      return *this;
    }

    VertexInputAttributeDescription & setLocation( uint32_t location_ ) VULKAN_HPP_NOEXCEPT
    {
      location = location_;
      return *this;
    }

    VertexInputAttributeDescription & setBinding( uint32_t binding_ ) VULKAN_HPP_NOEXCEPT
    {
      binding = binding_;
      return *this;
    }

    VertexInputAttributeDescription & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    VertexInputAttributeDescription & setOffset( uint32_t offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    operator VkVertexInputAttributeDescription const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkVertexInputAttributeDescription*>( this );
    }

    operator VkVertexInputAttributeDescription &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkVertexInputAttributeDescription*>( this );
    }

    bool operator==( VertexInputAttributeDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( location == rhs.location )
          && ( binding == rhs.binding )
          && ( format == rhs.format )
          && ( offset == rhs.offset );
    }

    bool operator!=( VertexInputAttributeDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t location;
    uint32_t binding;
    vk::Format format;
    uint32_t offset;
  };
  static_assert( sizeof( VertexInputAttributeDescription ) == sizeof( VkVertexInputAttributeDescription ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<VertexInputAttributeDescription>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineVertexInputStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineVertexInputStateCreateInfo( vk::PipelineVertexInputStateCreateFlags flags_ = vk::PipelineVertexInputStateCreateFlags(),
                                                               uint32_t vertexBindingDescriptionCount_ = 0,
                                                               const vk::VertexInputBindingDescription* pVertexBindingDescriptions_ = nullptr,
                                                               uint32_t vertexAttributeDescriptionCount_ = 0,
                                                               const vk::VertexInputAttributeDescription* pVertexAttributeDescriptions_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , vertexBindingDescriptionCount( vertexBindingDescriptionCount_ )
        , pVertexBindingDescriptions( pVertexBindingDescriptions_ )
        , vertexAttributeDescriptionCount( vertexAttributeDescriptionCount_ )
        , pVertexAttributeDescriptions( pVertexAttributeDescriptions_ )
      {}

      PipelineVertexInputStateCreateInfo( VkPipelineVertexInputStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineVertexInputStateCreateInfo*>(this) = rhs;
      }

      PipelineVertexInputStateCreateInfo& operator=( VkPipelineVertexInputStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineVertexInputStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineVertexInputStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineVertexInputStateCreateFlags flags;
      uint32_t vertexBindingDescriptionCount;
      const vk::VertexInputBindingDescription* pVertexBindingDescriptions;
      uint32_t vertexAttributeDescriptionCount;
      const vk::VertexInputAttributeDescription* pVertexAttributeDescriptions;
    };
    static_assert( sizeof( PipelineVertexInputStateCreateInfo ) == sizeof( VkPipelineVertexInputStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineVertexInputStateCreateInfo : public layout::PipelineVertexInputStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineVertexInputStateCreateInfo( vk::PipelineVertexInputStateCreateFlags flags_ = vk::PipelineVertexInputStateCreateFlags(),
                                                             uint32_t vertexBindingDescriptionCount_ = 0,
                                                             const vk::VertexInputBindingDescription* pVertexBindingDescriptions_ = nullptr,
                                                             uint32_t vertexAttributeDescriptionCount_ = 0,
                                                             const vk::VertexInputAttributeDescription* pVertexAttributeDescriptions_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineVertexInputStateCreateInfo( flags_, vertexBindingDescriptionCount_, pVertexBindingDescriptions_, vertexAttributeDescriptionCount_, pVertexAttributeDescriptions_ )
    {}

    PipelineVertexInputStateCreateInfo( VkPipelineVertexInputStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineVertexInputStateCreateInfo( rhs )
    {}

    PipelineVertexInputStateCreateInfo& operator=( VkPipelineVertexInputStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineVertexInputStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineVertexInputStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineVertexInputStateCreateInfo & setFlags( vk::PipelineVertexInputStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineVertexInputStateCreateInfo & setVertexBindingDescriptionCount( uint32_t vertexBindingDescriptionCount_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexBindingDescriptionCount = vertexBindingDescriptionCount_;
      return *this;
    }

    PipelineVertexInputStateCreateInfo & setPVertexBindingDescriptions( const vk::VertexInputBindingDescription* pVertexBindingDescriptions_ ) VULKAN_HPP_NOEXCEPT
    {
      pVertexBindingDescriptions = pVertexBindingDescriptions_;
      return *this;
    }

    PipelineVertexInputStateCreateInfo & setVertexAttributeDescriptionCount( uint32_t vertexAttributeDescriptionCount_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexAttributeDescriptionCount = vertexAttributeDescriptionCount_;
      return *this;
    }

    PipelineVertexInputStateCreateInfo & setPVertexAttributeDescriptions( const vk::VertexInputAttributeDescription* pVertexAttributeDescriptions_ ) VULKAN_HPP_NOEXCEPT
    {
      pVertexAttributeDescriptions = pVertexAttributeDescriptions_;
      return *this;
    }

    operator VkPipelineVertexInputStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineVertexInputStateCreateInfo*>( this );
    }

    operator VkPipelineVertexInputStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineVertexInputStateCreateInfo*>( this );
    }

    bool operator==( PipelineVertexInputStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( vertexBindingDescriptionCount == rhs.vertexBindingDescriptionCount )
          && ( pVertexBindingDescriptions == rhs.pVertexBindingDescriptions )
          && ( vertexAttributeDescriptionCount == rhs.vertexAttributeDescriptionCount )
          && ( pVertexAttributeDescriptions == rhs.pVertexAttributeDescriptions );
    }

    bool operator!=( PipelineVertexInputStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineVertexInputStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineVertexInputStateCreateInfo ) == sizeof( VkPipelineVertexInputStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineVertexInputStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineInputAssemblyStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineInputAssemblyStateCreateInfo( vk::PipelineInputAssemblyStateCreateFlags flags_ = vk::PipelineInputAssemblyStateCreateFlags(),
                                                                 vk::PrimitiveTopology topology_ = vk::PrimitiveTopology::ePointList,
                                                                 vk::Bool32 primitiveRestartEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , topology( topology_ )
        , primitiveRestartEnable( primitiveRestartEnable_ )
      {}

      PipelineInputAssemblyStateCreateInfo( VkPipelineInputAssemblyStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineInputAssemblyStateCreateInfo*>(this) = rhs;
      }

      PipelineInputAssemblyStateCreateInfo& operator=( VkPipelineInputAssemblyStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineInputAssemblyStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineInputAssemblyStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineInputAssemblyStateCreateFlags flags;
      vk::PrimitiveTopology topology;
      vk::Bool32 primitiveRestartEnable;
    };
    static_assert( sizeof( PipelineInputAssemblyStateCreateInfo ) == sizeof( VkPipelineInputAssemblyStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineInputAssemblyStateCreateInfo : public layout::PipelineInputAssemblyStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineInputAssemblyStateCreateInfo( vk::PipelineInputAssemblyStateCreateFlags flags_ = vk::PipelineInputAssemblyStateCreateFlags(),
                                                               vk::PrimitiveTopology topology_ = vk::PrimitiveTopology::ePointList,
                                                               vk::Bool32 primitiveRestartEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineInputAssemblyStateCreateInfo( flags_, topology_, primitiveRestartEnable_ )
    {}

    PipelineInputAssemblyStateCreateInfo( VkPipelineInputAssemblyStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineInputAssemblyStateCreateInfo( rhs )
    {}

    PipelineInputAssemblyStateCreateInfo& operator=( VkPipelineInputAssemblyStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineInputAssemblyStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineInputAssemblyStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineInputAssemblyStateCreateInfo & setFlags( vk::PipelineInputAssemblyStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineInputAssemblyStateCreateInfo & setTopology( vk::PrimitiveTopology topology_ ) VULKAN_HPP_NOEXCEPT
    {
      topology = topology_;
      return *this;
    }

    PipelineInputAssemblyStateCreateInfo & setPrimitiveRestartEnable( vk::Bool32 primitiveRestartEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      primitiveRestartEnable = primitiveRestartEnable_;
      return *this;
    }

    operator VkPipelineInputAssemblyStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineInputAssemblyStateCreateInfo*>( this );
    }

    operator VkPipelineInputAssemblyStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineInputAssemblyStateCreateInfo*>( this );
    }

    bool operator==( PipelineInputAssemblyStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( topology == rhs.topology )
          && ( primitiveRestartEnable == rhs.primitiveRestartEnable );
    }

    bool operator!=( PipelineInputAssemblyStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineInputAssemblyStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineInputAssemblyStateCreateInfo ) == sizeof( VkPipelineInputAssemblyStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineInputAssemblyStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineTessellationStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineTessellationStateCreateInfo( vk::PipelineTessellationStateCreateFlags flags_ = vk::PipelineTessellationStateCreateFlags(),
                                                                uint32_t patchControlPoints_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , patchControlPoints( patchControlPoints_ )
      {}

      PipelineTessellationStateCreateInfo( VkPipelineTessellationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineTessellationStateCreateInfo*>(this) = rhs;
      }

      PipelineTessellationStateCreateInfo& operator=( VkPipelineTessellationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineTessellationStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineTessellationStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineTessellationStateCreateFlags flags;
      uint32_t patchControlPoints;
    };
    static_assert( sizeof( PipelineTessellationStateCreateInfo ) == sizeof( VkPipelineTessellationStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineTessellationStateCreateInfo : public layout::PipelineTessellationStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineTessellationStateCreateInfo( vk::PipelineTessellationStateCreateFlags flags_ = vk::PipelineTessellationStateCreateFlags(),
                                                              uint32_t patchControlPoints_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineTessellationStateCreateInfo( flags_, patchControlPoints_ )
    {}

    PipelineTessellationStateCreateInfo( VkPipelineTessellationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineTessellationStateCreateInfo( rhs )
    {}

    PipelineTessellationStateCreateInfo& operator=( VkPipelineTessellationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineTessellationStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineTessellationStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineTessellationStateCreateInfo & setFlags( vk::PipelineTessellationStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineTessellationStateCreateInfo & setPatchControlPoints( uint32_t patchControlPoints_ ) VULKAN_HPP_NOEXCEPT
    {
      patchControlPoints = patchControlPoints_;
      return *this;
    }

    operator VkPipelineTessellationStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineTessellationStateCreateInfo*>( this );
    }

    operator VkPipelineTessellationStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineTessellationStateCreateInfo*>( this );
    }

    bool operator==( PipelineTessellationStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( patchControlPoints == rhs.patchControlPoints );
    }

    bool operator!=( PipelineTessellationStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineTessellationStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineTessellationStateCreateInfo ) == sizeof( VkPipelineTessellationStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineTessellationStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct Viewport
  {
    VULKAN_HPP_CONSTEXPR Viewport( float x_ = 0,
                                   float y_ = 0,
                                   float width_ = 0,
                                   float height_ = 0,
                                   float minDepth_ = 0,
                                   float maxDepth_ = 0 ) VULKAN_HPP_NOEXCEPT
      : x( x_ )
      , y( y_ )
      , width( width_ )
      , height( height_ )
      , minDepth( minDepth_ )
      , maxDepth( maxDepth_ )
    {}

    Viewport( VkViewport const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkViewport*>(this) = rhs;
    }

    Viewport& operator=( VkViewport const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkViewport*>(this) = rhs;
      return *this;
    }

    Viewport & setX( float x_ ) VULKAN_HPP_NOEXCEPT
    {
      x = x_;
      return *this;
    }

    Viewport & setY( float y_ ) VULKAN_HPP_NOEXCEPT
    {
      y = y_;
      return *this;
    }

    Viewport & setWidth( float width_ ) VULKAN_HPP_NOEXCEPT
    {
      width = width_;
      return *this;
    }

    Viewport & setHeight( float height_ ) VULKAN_HPP_NOEXCEPT
    {
      height = height_;
      return *this;
    }

    Viewport & setMinDepth( float minDepth_ ) VULKAN_HPP_NOEXCEPT
    {
      minDepth = minDepth_;
      return *this;
    }

    Viewport & setMaxDepth( float maxDepth_ ) VULKAN_HPP_NOEXCEPT
    {
      maxDepth = maxDepth_;
      return *this;
    }

    operator VkViewport const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkViewport*>( this );
    }

    operator VkViewport &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkViewport*>( this );
    }

    bool operator==( Viewport const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( x == rhs.x )
          && ( y == rhs.y )
          && ( width == rhs.width )
          && ( height == rhs.height )
          && ( minDepth == rhs.minDepth )
          && ( maxDepth == rhs.maxDepth );
    }

    bool operator!=( Viewport const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    float x;
    float y;
    float width;
    float height;
    float minDepth;
    float maxDepth;
  };
  static_assert( sizeof( Viewport ) == sizeof( VkViewport ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Viewport>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineViewportStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineViewportStateCreateInfo( vk::PipelineViewportStateCreateFlags flags_ = vk::PipelineViewportStateCreateFlags(),
                                                            uint32_t viewportCount_ = 0,
                                                            const vk::Viewport* pViewports_ = nullptr,
                                                            uint32_t scissorCount_ = 0,
                                                            const vk::Rect2D* pScissors_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , viewportCount( viewportCount_ )
        , pViewports( pViewports_ )
        , scissorCount( scissorCount_ )
        , pScissors( pScissors_ )
      {}

      PipelineViewportStateCreateInfo( VkPipelineViewportStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportStateCreateInfo*>(this) = rhs;
      }

      PipelineViewportStateCreateInfo& operator=( VkPipelineViewportStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineViewportStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineViewportStateCreateFlags flags;
      uint32_t viewportCount;
      const vk::Viewport* pViewports;
      uint32_t scissorCount;
      const vk::Rect2D* pScissors;
    };
    static_assert( sizeof( PipelineViewportStateCreateInfo ) == sizeof( VkPipelineViewportStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineViewportStateCreateInfo : public layout::PipelineViewportStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineViewportStateCreateInfo( vk::PipelineViewportStateCreateFlags flags_ = vk::PipelineViewportStateCreateFlags(),
                                                          uint32_t viewportCount_ = 0,
                                                          const vk::Viewport* pViewports_ = nullptr,
                                                          uint32_t scissorCount_ = 0,
                                                          const vk::Rect2D* pScissors_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportStateCreateInfo( flags_, viewportCount_, pViewports_, scissorCount_, pScissors_ )
    {}

    PipelineViewportStateCreateInfo( VkPipelineViewportStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportStateCreateInfo( rhs )
    {}

    PipelineViewportStateCreateInfo& operator=( VkPipelineViewportStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineViewportStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineViewportStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineViewportStateCreateInfo & setFlags( vk::PipelineViewportStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineViewportStateCreateInfo & setViewportCount( uint32_t viewportCount_ ) VULKAN_HPP_NOEXCEPT
    {
      viewportCount = viewportCount_;
      return *this;
    }

    PipelineViewportStateCreateInfo & setPViewports( const vk::Viewport* pViewports_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewports = pViewports_;
      return *this;
    }

    PipelineViewportStateCreateInfo & setScissorCount( uint32_t scissorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      scissorCount = scissorCount_;
      return *this;
    }

    PipelineViewportStateCreateInfo & setPScissors( const vk::Rect2D* pScissors_ ) VULKAN_HPP_NOEXCEPT
    {
      pScissors = pScissors_;
      return *this;
    }

    operator VkPipelineViewportStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineViewportStateCreateInfo*>( this );
    }

    operator VkPipelineViewportStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineViewportStateCreateInfo*>( this );
    }

    bool operator==( PipelineViewportStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( viewportCount == rhs.viewportCount )
          && ( pViewports == rhs.pViewports )
          && ( scissorCount == rhs.scissorCount )
          && ( pScissors == rhs.pScissors );
    }

    bool operator!=( PipelineViewportStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineViewportStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineViewportStateCreateInfo ) == sizeof( VkPipelineViewportStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineViewportStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineRasterizationStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineRasterizationStateCreateInfo( vk::PipelineRasterizationStateCreateFlags flags_ = vk::PipelineRasterizationStateCreateFlags(),
                                                                 vk::Bool32 depthClampEnable_ = 0,
                                                                 vk::Bool32 rasterizerDiscardEnable_ = 0,
                                                                 vk::PolygonMode polygonMode_ = vk::PolygonMode::eFill,
                                                                 vk::CullModeFlags cullMode_ = vk::CullModeFlags(),
                                                                 vk::FrontFace frontFace_ = vk::FrontFace::eCounterClockwise,
                                                                 vk::Bool32 depthBiasEnable_ = 0,
                                                                 float depthBiasConstantFactor_ = 0,
                                                                 float depthBiasClamp_ = 0,
                                                                 float depthBiasSlopeFactor_ = 0,
                                                                 float lineWidth_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , depthClampEnable( depthClampEnable_ )
        , rasterizerDiscardEnable( rasterizerDiscardEnable_ )
        , polygonMode( polygonMode_ )
        , cullMode( cullMode_ )
        , frontFace( frontFace_ )
        , depthBiasEnable( depthBiasEnable_ )
        , depthBiasConstantFactor( depthBiasConstantFactor_ )
        , depthBiasClamp( depthBiasClamp_ )
        , depthBiasSlopeFactor( depthBiasSlopeFactor_ )
        , lineWidth( lineWidth_ )
      {}

      PipelineRasterizationStateCreateInfo( VkPipelineRasterizationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationStateCreateInfo*>(this) = rhs;
      }

      PipelineRasterizationStateCreateInfo& operator=( VkPipelineRasterizationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineRasterizationStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineRasterizationStateCreateFlags flags;
      vk::Bool32 depthClampEnable;
      vk::Bool32 rasterizerDiscardEnable;
      vk::PolygonMode polygonMode;
      vk::CullModeFlags cullMode;
      vk::FrontFace frontFace;
      vk::Bool32 depthBiasEnable;
      float depthBiasConstantFactor;
      float depthBiasClamp;
      float depthBiasSlopeFactor;
      float lineWidth;
    };
    static_assert( sizeof( PipelineRasterizationStateCreateInfo ) == sizeof( VkPipelineRasterizationStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineRasterizationStateCreateInfo : public layout::PipelineRasterizationStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineRasterizationStateCreateInfo( vk::PipelineRasterizationStateCreateFlags flags_ = vk::PipelineRasterizationStateCreateFlags(),
                                                               vk::Bool32 depthClampEnable_ = 0,
                                                               vk::Bool32 rasterizerDiscardEnable_ = 0,
                                                               vk::PolygonMode polygonMode_ = vk::PolygonMode::eFill,
                                                               vk::CullModeFlags cullMode_ = vk::CullModeFlags(),
                                                               vk::FrontFace frontFace_ = vk::FrontFace::eCounterClockwise,
                                                               vk::Bool32 depthBiasEnable_ = 0,
                                                               float depthBiasConstantFactor_ = 0,
                                                               float depthBiasClamp_ = 0,
                                                               float depthBiasSlopeFactor_ = 0,
                                                               float lineWidth_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationStateCreateInfo( flags_, depthClampEnable_, rasterizerDiscardEnable_, polygonMode_, cullMode_, frontFace_, depthBiasEnable_, depthBiasConstantFactor_, depthBiasClamp_, depthBiasSlopeFactor_, lineWidth_ )
    {}

    PipelineRasterizationStateCreateInfo( VkPipelineRasterizationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationStateCreateInfo( rhs )
    {}

    PipelineRasterizationStateCreateInfo& operator=( VkPipelineRasterizationStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineRasterizationStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setFlags( vk::PipelineRasterizationStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setDepthClampEnable( vk::Bool32 depthClampEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      depthClampEnable = depthClampEnable_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setRasterizerDiscardEnable( vk::Bool32 rasterizerDiscardEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      rasterizerDiscardEnable = rasterizerDiscardEnable_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setPolygonMode( vk::PolygonMode polygonMode_ ) VULKAN_HPP_NOEXCEPT
    {
      polygonMode = polygonMode_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setCullMode( vk::CullModeFlags cullMode_ ) VULKAN_HPP_NOEXCEPT
    {
      cullMode = cullMode_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setFrontFace( vk::FrontFace frontFace_ ) VULKAN_HPP_NOEXCEPT
    {
      frontFace = frontFace_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setDepthBiasEnable( vk::Bool32 depthBiasEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      depthBiasEnable = depthBiasEnable_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setDepthBiasConstantFactor( float depthBiasConstantFactor_ ) VULKAN_HPP_NOEXCEPT
    {
      depthBiasConstantFactor = depthBiasConstantFactor_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setDepthBiasClamp( float depthBiasClamp_ ) VULKAN_HPP_NOEXCEPT
    {
      depthBiasClamp = depthBiasClamp_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setDepthBiasSlopeFactor( float depthBiasSlopeFactor_ ) VULKAN_HPP_NOEXCEPT
    {
      depthBiasSlopeFactor = depthBiasSlopeFactor_;
      return *this;
    }

    PipelineRasterizationStateCreateInfo & setLineWidth( float lineWidth_ ) VULKAN_HPP_NOEXCEPT
    {
      lineWidth = lineWidth_;
      return *this;
    }

    operator VkPipelineRasterizationStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineRasterizationStateCreateInfo*>( this );
    }

    operator VkPipelineRasterizationStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineRasterizationStateCreateInfo*>( this );
    }

    bool operator==( PipelineRasterizationStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( depthClampEnable == rhs.depthClampEnable )
          && ( rasterizerDiscardEnable == rhs.rasterizerDiscardEnable )
          && ( polygonMode == rhs.polygonMode )
          && ( cullMode == rhs.cullMode )
          && ( frontFace == rhs.frontFace )
          && ( depthBiasEnable == rhs.depthBiasEnable )
          && ( depthBiasConstantFactor == rhs.depthBiasConstantFactor )
          && ( depthBiasClamp == rhs.depthBiasClamp )
          && ( depthBiasSlopeFactor == rhs.depthBiasSlopeFactor )
          && ( lineWidth == rhs.lineWidth );
    }

    bool operator!=( PipelineRasterizationStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineRasterizationStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineRasterizationStateCreateInfo ) == sizeof( VkPipelineRasterizationStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineRasterizationStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineMultisampleStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineMultisampleStateCreateInfo( vk::PipelineMultisampleStateCreateFlags flags_ = vk::PipelineMultisampleStateCreateFlags(),
                                                               vk::SampleCountFlagBits rasterizationSamples_ = vk::SampleCountFlagBits::e1,
                                                               vk::Bool32 sampleShadingEnable_ = 0,
                                                               float minSampleShading_ = 0,
                                                               const vk::SampleMask* pSampleMask_ = nullptr,
                                                               vk::Bool32 alphaToCoverageEnable_ = 0,
                                                               vk::Bool32 alphaToOneEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , rasterizationSamples( rasterizationSamples_ )
        , sampleShadingEnable( sampleShadingEnable_ )
        , minSampleShading( minSampleShading_ )
        , pSampleMask( pSampleMask_ )
        , alphaToCoverageEnable( alphaToCoverageEnable_ )
        , alphaToOneEnable( alphaToOneEnable_ )
      {}

      PipelineMultisampleStateCreateInfo( VkPipelineMultisampleStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineMultisampleStateCreateInfo*>(this) = rhs;
      }

      PipelineMultisampleStateCreateInfo& operator=( VkPipelineMultisampleStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineMultisampleStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineMultisampleStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineMultisampleStateCreateFlags flags;
      vk::SampleCountFlagBits rasterizationSamples;
      vk::Bool32 sampleShadingEnable;
      float minSampleShading;
      const vk::SampleMask* pSampleMask;
      vk::Bool32 alphaToCoverageEnable;
      vk::Bool32 alphaToOneEnable;
    };
    static_assert( sizeof( PipelineMultisampleStateCreateInfo ) == sizeof( VkPipelineMultisampleStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineMultisampleStateCreateInfo : public layout::PipelineMultisampleStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineMultisampleStateCreateInfo( vk::PipelineMultisampleStateCreateFlags flags_ = vk::PipelineMultisampleStateCreateFlags(),
                                                             vk::SampleCountFlagBits rasterizationSamples_ = vk::SampleCountFlagBits::e1,
                                                             vk::Bool32 sampleShadingEnable_ = 0,
                                                             float minSampleShading_ = 0,
                                                             const vk::SampleMask* pSampleMask_ = nullptr,
                                                             vk::Bool32 alphaToCoverageEnable_ = 0,
                                                             vk::Bool32 alphaToOneEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineMultisampleStateCreateInfo( flags_, rasterizationSamples_, sampleShadingEnable_, minSampleShading_, pSampleMask_, alphaToCoverageEnable_, alphaToOneEnable_ )
    {}

    PipelineMultisampleStateCreateInfo( VkPipelineMultisampleStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineMultisampleStateCreateInfo( rhs )
    {}

    PipelineMultisampleStateCreateInfo& operator=( VkPipelineMultisampleStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineMultisampleStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setFlags( vk::PipelineMultisampleStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setRasterizationSamples( vk::SampleCountFlagBits rasterizationSamples_ ) VULKAN_HPP_NOEXCEPT
    {
      rasterizationSamples = rasterizationSamples_;
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setSampleShadingEnable( vk::Bool32 sampleShadingEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleShadingEnable = sampleShadingEnable_;
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setMinSampleShading( float minSampleShading_ ) VULKAN_HPP_NOEXCEPT
    {
      minSampleShading = minSampleShading_;
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setPSampleMask( const vk::SampleMask* pSampleMask_ ) VULKAN_HPP_NOEXCEPT
    {
      pSampleMask = pSampleMask_;
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setAlphaToCoverageEnable( vk::Bool32 alphaToCoverageEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      alphaToCoverageEnable = alphaToCoverageEnable_;
      return *this;
    }

    PipelineMultisampleStateCreateInfo & setAlphaToOneEnable( vk::Bool32 alphaToOneEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      alphaToOneEnable = alphaToOneEnable_;
      return *this;
    }

    operator VkPipelineMultisampleStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineMultisampleStateCreateInfo*>( this );
    }

    operator VkPipelineMultisampleStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineMultisampleStateCreateInfo*>( this );
    }

    bool operator==( PipelineMultisampleStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && vk::operator==( rasterizationSamples, rhs.rasterizationSamples )
          && ( sampleShadingEnable == rhs.sampleShadingEnable )
          && ( minSampleShading == rhs.minSampleShading )
          && ( pSampleMask == rhs.pSampleMask )
          && ( alphaToCoverageEnable == rhs.alphaToCoverageEnable )
          && ( alphaToOneEnable == rhs.alphaToOneEnable );
    }

    bool operator!=( PipelineMultisampleStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineMultisampleStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineMultisampleStateCreateInfo ) == sizeof( VkPipelineMultisampleStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineMultisampleStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct StencilOpState
  {
    VULKAN_HPP_CONSTEXPR StencilOpState( vk::StencilOp failOp_ = vk::StencilOp::eKeep,
                                         vk::StencilOp passOp_ = vk::StencilOp::eKeep,
                                         vk::StencilOp depthFailOp_ = vk::StencilOp::eKeep,
                                         vk::CompareOp compareOp_ = vk::CompareOp::eNever,
                                         uint32_t compareMask_ = 0,
                                         uint32_t writeMask_ = 0,
                                         uint32_t reference_ = 0 ) VULKAN_HPP_NOEXCEPT
      : failOp( failOp_ )
      , passOp( passOp_ )
      , depthFailOp( depthFailOp_ )
      , compareOp( compareOp_ )
      , compareMask( compareMask_ )
      , writeMask( writeMask_ )
      , reference( reference_ )
    {}

    StencilOpState( VkStencilOpState const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkStencilOpState*>(this) = rhs;
    }

    StencilOpState& operator=( VkStencilOpState const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkStencilOpState*>(this) = rhs;
      return *this;
    }

    StencilOpState & setFailOp( vk::StencilOp failOp_ ) VULKAN_HPP_NOEXCEPT
    {
      failOp = failOp_;
      return *this;
    }

    StencilOpState & setPassOp( vk::StencilOp passOp_ ) VULKAN_HPP_NOEXCEPT
    {
      passOp = passOp_;
      return *this;
    }

    StencilOpState & setDepthFailOp( vk::StencilOp depthFailOp_ ) VULKAN_HPP_NOEXCEPT
    {
      depthFailOp = depthFailOp_;
      return *this;
    }

    StencilOpState & setCompareOp( vk::CompareOp compareOp_ ) VULKAN_HPP_NOEXCEPT
    {
      compareOp = compareOp_;
      return *this;
    }

    StencilOpState & setCompareMask( uint32_t compareMask_ ) VULKAN_HPP_NOEXCEPT
    {
      compareMask = compareMask_;
      return *this;
    }

    StencilOpState & setWriteMask( uint32_t writeMask_ ) VULKAN_HPP_NOEXCEPT
    {
      writeMask = writeMask_;
      return *this;
    }

    StencilOpState & setReference( uint32_t reference_ ) VULKAN_HPP_NOEXCEPT
    {
      reference = reference_;
      return *this;
    }

    operator VkStencilOpState const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkStencilOpState*>( this );
    }

    operator VkStencilOpState &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkStencilOpState*>( this );
    }

    bool operator==( StencilOpState const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( failOp == rhs.failOp )
          && ( passOp == rhs.passOp )
          && ( depthFailOp == rhs.depthFailOp )
          && ( compareOp == rhs.compareOp )
          && ( compareMask == rhs.compareMask )
          && ( writeMask == rhs.writeMask )
          && ( reference == rhs.reference );
    }

    bool operator!=( StencilOpState const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::StencilOp failOp;
    vk::StencilOp passOp;
    vk::StencilOp depthFailOp;
    vk::CompareOp compareOp;
    uint32_t compareMask;
    uint32_t writeMask;
    uint32_t reference;
  };
  static_assert( sizeof( StencilOpState ) == sizeof( VkStencilOpState ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<StencilOpState>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineDepthStencilStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineDepthStencilStateCreateInfo( vk::PipelineDepthStencilStateCreateFlags flags_ = vk::PipelineDepthStencilStateCreateFlags(),
                                                                vk::Bool32 depthTestEnable_ = 0,
                                                                vk::Bool32 depthWriteEnable_ = 0,
                                                                vk::CompareOp depthCompareOp_ = vk::CompareOp::eNever,
                                                                vk::Bool32 depthBoundsTestEnable_ = 0,
                                                                vk::Bool32 stencilTestEnable_ = 0,
                                                                vk::StencilOpState front_ = vk::StencilOpState(),
                                                                vk::StencilOpState back_ = vk::StencilOpState(),
                                                                float minDepthBounds_ = 0,
                                                                float maxDepthBounds_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , depthTestEnable( depthTestEnable_ )
        , depthWriteEnable( depthWriteEnable_ )
        , depthCompareOp( depthCompareOp_ )
        , depthBoundsTestEnable( depthBoundsTestEnable_ )
        , stencilTestEnable( stencilTestEnable_ )
        , front( front_ )
        , back( back_ )
        , minDepthBounds( minDepthBounds_ )
        , maxDepthBounds( maxDepthBounds_ )
      {}

      PipelineDepthStencilStateCreateInfo( VkPipelineDepthStencilStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineDepthStencilStateCreateInfo*>(this) = rhs;
      }

      PipelineDepthStencilStateCreateInfo& operator=( VkPipelineDepthStencilStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineDepthStencilStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineDepthStencilStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineDepthStencilStateCreateFlags flags;
      vk::Bool32 depthTestEnable;
      vk::Bool32 depthWriteEnable;
      vk::CompareOp depthCompareOp;
      vk::Bool32 depthBoundsTestEnable;
      vk::Bool32 stencilTestEnable;
      vk::StencilOpState front;
      vk::StencilOpState back;
      float minDepthBounds;
      float maxDepthBounds;
    };
    static_assert( sizeof( PipelineDepthStencilStateCreateInfo ) == sizeof( VkPipelineDepthStencilStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineDepthStencilStateCreateInfo : public layout::PipelineDepthStencilStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineDepthStencilStateCreateInfo( vk::PipelineDepthStencilStateCreateFlags flags_ = vk::PipelineDepthStencilStateCreateFlags(),
                                                              vk::Bool32 depthTestEnable_ = 0,
                                                              vk::Bool32 depthWriteEnable_ = 0,
                                                              vk::CompareOp depthCompareOp_ = vk::CompareOp::eNever,
                                                              vk::Bool32 depthBoundsTestEnable_ = 0,
                                                              vk::Bool32 stencilTestEnable_ = 0,
                                                              vk::StencilOpState front_ = vk::StencilOpState(),
                                                              vk::StencilOpState back_ = vk::StencilOpState(),
                                                              float minDepthBounds_ = 0,
                                                              float maxDepthBounds_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineDepthStencilStateCreateInfo( flags_, depthTestEnable_, depthWriteEnable_, depthCompareOp_, depthBoundsTestEnable_, stencilTestEnable_, front_, back_, minDepthBounds_, maxDepthBounds_ )
    {}

    PipelineDepthStencilStateCreateInfo( VkPipelineDepthStencilStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineDepthStencilStateCreateInfo( rhs )
    {}

    PipelineDepthStencilStateCreateInfo& operator=( VkPipelineDepthStencilStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineDepthStencilStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setFlags( vk::PipelineDepthStencilStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setDepthTestEnable( vk::Bool32 depthTestEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      depthTestEnable = depthTestEnable_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setDepthWriteEnable( vk::Bool32 depthWriteEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      depthWriteEnable = depthWriteEnable_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setDepthCompareOp( vk::CompareOp depthCompareOp_ ) VULKAN_HPP_NOEXCEPT
    {
      depthCompareOp = depthCompareOp_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setDepthBoundsTestEnable( vk::Bool32 depthBoundsTestEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      depthBoundsTestEnable = depthBoundsTestEnable_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setStencilTestEnable( vk::Bool32 stencilTestEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      stencilTestEnable = stencilTestEnable_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setFront( vk::StencilOpState front_ ) VULKAN_HPP_NOEXCEPT
    {
      front = front_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setBack( vk::StencilOpState back_ ) VULKAN_HPP_NOEXCEPT
    {
      back = back_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setMinDepthBounds( float minDepthBounds_ ) VULKAN_HPP_NOEXCEPT
    {
      minDepthBounds = minDepthBounds_;
      return *this;
    }

    PipelineDepthStencilStateCreateInfo & setMaxDepthBounds( float maxDepthBounds_ ) VULKAN_HPP_NOEXCEPT
    {
      maxDepthBounds = maxDepthBounds_;
      return *this;
    }

    operator VkPipelineDepthStencilStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineDepthStencilStateCreateInfo*>( this );
    }

    operator VkPipelineDepthStencilStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineDepthStencilStateCreateInfo*>( this );
    }

    bool operator==( PipelineDepthStencilStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( depthTestEnable == rhs.depthTestEnable )
          && ( depthWriteEnable == rhs.depthWriteEnable )
          && ( depthCompareOp == rhs.depthCompareOp )
          && ( depthBoundsTestEnable == rhs.depthBoundsTestEnable )
          && ( stencilTestEnable == rhs.stencilTestEnable )
          && ( front == rhs.front )
          && ( back == rhs.back )
          && ( minDepthBounds == rhs.minDepthBounds )
          && ( maxDepthBounds == rhs.maxDepthBounds );
    }

    bool operator!=( PipelineDepthStencilStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineDepthStencilStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineDepthStencilStateCreateInfo ) == sizeof( VkPipelineDepthStencilStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineDepthStencilStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct PipelineColorBlendAttachmentState
  {
    VULKAN_HPP_CONSTEXPR PipelineColorBlendAttachmentState( vk::Bool32 blendEnable_ = 0,
                                                            vk::BlendFactor srcColorBlendFactor_ = vk::BlendFactor::eZero,
                                                            vk::BlendFactor dstColorBlendFactor_ = vk::BlendFactor::eZero,
                                                            vk::BlendOp colorBlendOp_ = vk::BlendOp::eAdd,
                                                            vk::BlendFactor srcAlphaBlendFactor_ = vk::BlendFactor::eZero,
                                                            vk::BlendFactor dstAlphaBlendFactor_ = vk::BlendFactor::eZero,
                                                            vk::BlendOp alphaBlendOp_ = vk::BlendOp::eAdd,
                                                            vk::ColorComponentFlags colorWriteMask_ = vk::ColorComponentFlags() ) VULKAN_HPP_NOEXCEPT
      : blendEnable( blendEnable_ )
      , srcColorBlendFactor( srcColorBlendFactor_ )
      , dstColorBlendFactor( dstColorBlendFactor_ )
      , colorBlendOp( colorBlendOp_ )
      , srcAlphaBlendFactor( srcAlphaBlendFactor_ )
      , dstAlphaBlendFactor( dstAlphaBlendFactor_ )
      , alphaBlendOp( alphaBlendOp_ )
      , colorWriteMask( colorWriteMask_ )
    {}

    PipelineColorBlendAttachmentState( VkPipelineColorBlendAttachmentState const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPipelineColorBlendAttachmentState*>(this) = rhs;
    }

    PipelineColorBlendAttachmentState& operator=( VkPipelineColorBlendAttachmentState const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPipelineColorBlendAttachmentState*>(this) = rhs;
      return *this;
    }

    PipelineColorBlendAttachmentState & setBlendEnable( vk::Bool32 blendEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      blendEnable = blendEnable_;
      return *this;
    }

    PipelineColorBlendAttachmentState & setSrcColorBlendFactor( vk::BlendFactor srcColorBlendFactor_ ) VULKAN_HPP_NOEXCEPT
    {
      srcColorBlendFactor = srcColorBlendFactor_;
      return *this;
    }

    PipelineColorBlendAttachmentState & setDstColorBlendFactor( vk::BlendFactor dstColorBlendFactor_ ) VULKAN_HPP_NOEXCEPT
    {
      dstColorBlendFactor = dstColorBlendFactor_;
      return *this;
    }

    PipelineColorBlendAttachmentState & setColorBlendOp( vk::BlendOp colorBlendOp_ ) VULKAN_HPP_NOEXCEPT
    {
      colorBlendOp = colorBlendOp_;
      return *this;
    }

    PipelineColorBlendAttachmentState & setSrcAlphaBlendFactor( vk::BlendFactor srcAlphaBlendFactor_ ) VULKAN_HPP_NOEXCEPT
    {
      srcAlphaBlendFactor = srcAlphaBlendFactor_;
      return *this;
    }

    PipelineColorBlendAttachmentState & setDstAlphaBlendFactor( vk::BlendFactor dstAlphaBlendFactor_ ) VULKAN_HPP_NOEXCEPT
    {
      dstAlphaBlendFactor = dstAlphaBlendFactor_;
      return *this;
    }

    PipelineColorBlendAttachmentState & setAlphaBlendOp( vk::BlendOp alphaBlendOp_ ) VULKAN_HPP_NOEXCEPT
    {
      alphaBlendOp = alphaBlendOp_;
      return *this;
    }

    PipelineColorBlendAttachmentState & setColorWriteMask( vk::ColorComponentFlags colorWriteMask_ ) VULKAN_HPP_NOEXCEPT
    {
      colorWriteMask = colorWriteMask_;
      return *this;
    }

    operator VkPipelineColorBlendAttachmentState const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineColorBlendAttachmentState*>( this );
    }

    operator VkPipelineColorBlendAttachmentState &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineColorBlendAttachmentState*>( this );
    }

    bool operator==( PipelineColorBlendAttachmentState const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( blendEnable == rhs.blendEnable )
          && ( srcColorBlendFactor == rhs.srcColorBlendFactor )
          && ( dstColorBlendFactor == rhs.dstColorBlendFactor )
          && ( colorBlendOp == rhs.colorBlendOp )
          && ( srcAlphaBlendFactor == rhs.srcAlphaBlendFactor )
          && ( dstAlphaBlendFactor == rhs.dstAlphaBlendFactor )
          && ( alphaBlendOp == rhs.alphaBlendOp )
          && ( colorWriteMask == rhs.colorWriteMask );
    }

    bool operator!=( PipelineColorBlendAttachmentState const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Bool32 blendEnable;
    vk::BlendFactor srcColorBlendFactor;
    vk::BlendFactor dstColorBlendFactor;
    vk::BlendOp colorBlendOp;
    vk::BlendFactor srcAlphaBlendFactor;
    vk::BlendFactor dstAlphaBlendFactor;
    vk::BlendOp alphaBlendOp;
    vk::ColorComponentFlags colorWriteMask;
  };
  static_assert( sizeof( PipelineColorBlendAttachmentState ) == sizeof( VkPipelineColorBlendAttachmentState ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineColorBlendAttachmentState>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineColorBlendStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR_14 PipelineColorBlendStateCreateInfo( vk::PipelineColorBlendStateCreateFlags flags_ = vk::PipelineColorBlendStateCreateFlags(),
                                                                 vk::Bool32 logicOpEnable_ = 0,
                                                                 vk::LogicOp logicOp_ = vk::LogicOp::eClear,
                                                                 uint32_t attachmentCount_ = 0,
                                                                 const vk::PipelineColorBlendAttachmentState* pAttachments_ = nullptr,
                                                                 std::array<float,4> const& blendConstants_ = { { 0 } } ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , logicOpEnable( logicOpEnable_ )
        , logicOp( logicOp_ )
        , attachmentCount( attachmentCount_ )
        , pAttachments( pAttachments_ )
        , blendConstants{}
      {
        vk::ConstExpressionArrayCopy<float,4,4>::copy( blendConstants, blendConstants_ );
      }

      PipelineColorBlendStateCreateInfo( VkPipelineColorBlendStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineColorBlendStateCreateInfo*>(this) = rhs;
      }

      PipelineColorBlendStateCreateInfo& operator=( VkPipelineColorBlendStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineColorBlendStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineColorBlendStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineColorBlendStateCreateFlags flags;
      vk::Bool32 logicOpEnable;
      vk::LogicOp logicOp;
      uint32_t attachmentCount;
      const vk::PipelineColorBlendAttachmentState* pAttachments;
      float blendConstants[4];
    };
    static_assert( sizeof( PipelineColorBlendStateCreateInfo ) == sizeof( VkPipelineColorBlendStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineColorBlendStateCreateInfo : public layout::PipelineColorBlendStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR_14 PipelineColorBlendStateCreateInfo( vk::PipelineColorBlendStateCreateFlags flags_ = vk::PipelineColorBlendStateCreateFlags(),
                                                               vk::Bool32 logicOpEnable_ = 0,
                                                               vk::LogicOp logicOp_ = vk::LogicOp::eClear,
                                                               uint32_t attachmentCount_ = 0,
                                                               const vk::PipelineColorBlendAttachmentState* pAttachments_ = nullptr,
                                                               std::array<float,4> const& blendConstants_ = { { 0 } } ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineColorBlendStateCreateInfo( flags_, logicOpEnable_, logicOp_, attachmentCount_, pAttachments_, blendConstants_ )
    {}

    PipelineColorBlendStateCreateInfo( VkPipelineColorBlendStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineColorBlendStateCreateInfo( rhs )
    {}

    PipelineColorBlendStateCreateInfo& operator=( VkPipelineColorBlendStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineColorBlendStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineColorBlendStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineColorBlendStateCreateInfo & setFlags( vk::PipelineColorBlendStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineColorBlendStateCreateInfo & setLogicOpEnable( vk::Bool32 logicOpEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      logicOpEnable = logicOpEnable_;
      return *this;
    }

    PipelineColorBlendStateCreateInfo & setLogicOp( vk::LogicOp logicOp_ ) VULKAN_HPP_NOEXCEPT
    {
      logicOp = logicOp_;
      return *this;
    }

    PipelineColorBlendStateCreateInfo & setAttachmentCount( uint32_t attachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentCount = attachmentCount_;
      return *this;
    }

    PipelineColorBlendStateCreateInfo & setPAttachments( const vk::PipelineColorBlendAttachmentState* pAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttachments = pAttachments_;
      return *this;
    }

    PipelineColorBlendStateCreateInfo & setBlendConstants( std::array<float,4> blendConstants_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( blendConstants, blendConstants_.data(), 4 * sizeof( float ) );
      return *this;
    }

    operator VkPipelineColorBlendStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineColorBlendStateCreateInfo*>( this );
    }

    operator VkPipelineColorBlendStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineColorBlendStateCreateInfo*>( this );
    }

    bool operator==( PipelineColorBlendStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( logicOpEnable == rhs.logicOpEnable )
          && ( logicOp == rhs.logicOp )
          && ( attachmentCount == rhs.attachmentCount )
          && ( pAttachments == rhs.pAttachments )
          && ( memcmp( blendConstants, rhs.blendConstants, 4 * sizeof( float ) ) == 0 );
    }

    bool operator!=( PipelineColorBlendStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineColorBlendStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineColorBlendStateCreateInfo ) == sizeof( VkPipelineColorBlendStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineColorBlendStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineDynamicStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineDynamicStateCreateInfo( vk::PipelineDynamicStateCreateFlags flags_ = vk::PipelineDynamicStateCreateFlags(),
                                                           uint32_t dynamicStateCount_ = 0,
                                                           const vk::DynamicState* pDynamicStates_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , dynamicStateCount( dynamicStateCount_ )
        , pDynamicStates( pDynamicStates_ )
      {}

      PipelineDynamicStateCreateInfo( VkPipelineDynamicStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineDynamicStateCreateInfo*>(this) = rhs;
      }

      PipelineDynamicStateCreateInfo& operator=( VkPipelineDynamicStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineDynamicStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineDynamicStateCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineDynamicStateCreateFlags flags;
      uint32_t dynamicStateCount;
      const vk::DynamicState* pDynamicStates;
    };
    static_assert( sizeof( PipelineDynamicStateCreateInfo ) == sizeof( VkPipelineDynamicStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineDynamicStateCreateInfo : public layout::PipelineDynamicStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineDynamicStateCreateInfo( vk::PipelineDynamicStateCreateFlags flags_ = vk::PipelineDynamicStateCreateFlags(),
                                                         uint32_t dynamicStateCount_ = 0,
                                                         const vk::DynamicState* pDynamicStates_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineDynamicStateCreateInfo( flags_, dynamicStateCount_, pDynamicStates_ )
    {}

    PipelineDynamicStateCreateInfo( VkPipelineDynamicStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineDynamicStateCreateInfo( rhs )
    {}

    PipelineDynamicStateCreateInfo& operator=( VkPipelineDynamicStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineDynamicStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineDynamicStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineDynamicStateCreateInfo & setFlags( vk::PipelineDynamicStateCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineDynamicStateCreateInfo & setDynamicStateCount( uint32_t dynamicStateCount_ ) VULKAN_HPP_NOEXCEPT
    {
      dynamicStateCount = dynamicStateCount_;
      return *this;
    }

    PipelineDynamicStateCreateInfo & setPDynamicStates( const vk::DynamicState* pDynamicStates_ ) VULKAN_HPP_NOEXCEPT
    {
      pDynamicStates = pDynamicStates_;
      return *this;
    }

    operator VkPipelineDynamicStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineDynamicStateCreateInfo*>( this );
    }

    operator VkPipelineDynamicStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineDynamicStateCreateInfo*>( this );
    }

    bool operator==( PipelineDynamicStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( dynamicStateCount == rhs.dynamicStateCount )
          && ( pDynamicStates == rhs.pDynamicStates );
    }

    bool operator!=( PipelineDynamicStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineDynamicStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineDynamicStateCreateInfo ) == sizeof( VkPipelineDynamicStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineDynamicStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct GraphicsPipelineCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR GraphicsPipelineCreateInfo( vk::PipelineCreateFlags flags_ = vk::PipelineCreateFlags(),
                                                       uint32_t stageCount_ = 0,
                                                       const vk::PipelineShaderStageCreateInfo* pStages_ = nullptr,
                                                       const vk::PipelineVertexInputStateCreateInfo* pVertexInputState_ = nullptr,
                                                       const vk::PipelineInputAssemblyStateCreateInfo* pInputAssemblyState_ = nullptr,
                                                       const vk::PipelineTessellationStateCreateInfo* pTessellationState_ = nullptr,
                                                       const vk::PipelineViewportStateCreateInfo* pViewportState_ = nullptr,
                                                       const vk::PipelineRasterizationStateCreateInfo* pRasterizationState_ = nullptr,
                                                       const vk::PipelineMultisampleStateCreateInfo* pMultisampleState_ = nullptr,
                                                       const vk::PipelineDepthStencilStateCreateInfo* pDepthStencilState_ = nullptr,
                                                       const vk::PipelineColorBlendStateCreateInfo* pColorBlendState_ = nullptr,
                                                       const vk::PipelineDynamicStateCreateInfo* pDynamicState_ = nullptr,
                                                       vk::PipelineLayout layout_ = vk::PipelineLayout(),
                                                       vk::RenderPass renderPass_ = vk::RenderPass(),
                                                       uint32_t subpass_ = 0,
                                                       vk::Pipeline basePipelineHandle_ = vk::Pipeline(),
                                                       int32_t basePipelineIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , stageCount( stageCount_ )
        , pStages( pStages_ )
        , pVertexInputState( pVertexInputState_ )
        , pInputAssemblyState( pInputAssemblyState_ )
        , pTessellationState( pTessellationState_ )
        , pViewportState( pViewportState_ )
        , pRasterizationState( pRasterizationState_ )
        , pMultisampleState( pMultisampleState_ )
        , pDepthStencilState( pDepthStencilState_ )
        , pColorBlendState( pColorBlendState_ )
        , pDynamicState( pDynamicState_ )
        , layout( layout_ )
        , renderPass( renderPass_ )
        , subpass( subpass_ )
        , basePipelineHandle( basePipelineHandle_ )
        , basePipelineIndex( basePipelineIndex_ )
      {}

      GraphicsPipelineCreateInfo( VkGraphicsPipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGraphicsPipelineCreateInfo*>(this) = rhs;
      }

      GraphicsPipelineCreateInfo& operator=( VkGraphicsPipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkGraphicsPipelineCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eGraphicsPipelineCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineCreateFlags flags;
      uint32_t stageCount;
      const vk::PipelineShaderStageCreateInfo* pStages;
      const vk::PipelineVertexInputStateCreateInfo* pVertexInputState;
      const vk::PipelineInputAssemblyStateCreateInfo* pInputAssemblyState;
      const vk::PipelineTessellationStateCreateInfo* pTessellationState;
      const vk::PipelineViewportStateCreateInfo* pViewportState;
      const vk::PipelineRasterizationStateCreateInfo* pRasterizationState;
      const vk::PipelineMultisampleStateCreateInfo* pMultisampleState;
      const vk::PipelineDepthStencilStateCreateInfo* pDepthStencilState;
      const vk::PipelineColorBlendStateCreateInfo* pColorBlendState;
      const vk::PipelineDynamicStateCreateInfo* pDynamicState;
      vk::PipelineLayout layout;
      vk::RenderPass renderPass;
      uint32_t subpass;
      vk::Pipeline basePipelineHandle;
      int32_t basePipelineIndex;
    };
    static_assert( sizeof( GraphicsPipelineCreateInfo ) == sizeof( VkGraphicsPipelineCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct GraphicsPipelineCreateInfo : public layout::GraphicsPipelineCreateInfo
  {
    VULKAN_HPP_CONSTEXPR GraphicsPipelineCreateInfo( vk::PipelineCreateFlags flags_ = vk::PipelineCreateFlags(),
                                                     uint32_t stageCount_ = 0,
                                                     const vk::PipelineShaderStageCreateInfo* pStages_ = nullptr,
                                                     const vk::PipelineVertexInputStateCreateInfo* pVertexInputState_ = nullptr,
                                                     const vk::PipelineInputAssemblyStateCreateInfo* pInputAssemblyState_ = nullptr,
                                                     const vk::PipelineTessellationStateCreateInfo* pTessellationState_ = nullptr,
                                                     const vk::PipelineViewportStateCreateInfo* pViewportState_ = nullptr,
                                                     const vk::PipelineRasterizationStateCreateInfo* pRasterizationState_ = nullptr,
                                                     const vk::PipelineMultisampleStateCreateInfo* pMultisampleState_ = nullptr,
                                                     const vk::PipelineDepthStencilStateCreateInfo* pDepthStencilState_ = nullptr,
                                                     const vk::PipelineColorBlendStateCreateInfo* pColorBlendState_ = nullptr,
                                                     const vk::PipelineDynamicStateCreateInfo* pDynamicState_ = nullptr,
                                                     vk::PipelineLayout layout_ = vk::PipelineLayout(),
                                                     vk::RenderPass renderPass_ = vk::RenderPass(),
                                                     uint32_t subpass_ = 0,
                                                     vk::Pipeline basePipelineHandle_ = vk::Pipeline(),
                                                     int32_t basePipelineIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::GraphicsPipelineCreateInfo( flags_, stageCount_, pStages_, pVertexInputState_, pInputAssemblyState_, pTessellationState_, pViewportState_, pRasterizationState_, pMultisampleState_, pDepthStencilState_, pColorBlendState_, pDynamicState_, layout_, renderPass_, subpass_, basePipelineHandle_, basePipelineIndex_ )
    {}

    GraphicsPipelineCreateInfo( VkGraphicsPipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::GraphicsPipelineCreateInfo( rhs )
    {}

    GraphicsPipelineCreateInfo& operator=( VkGraphicsPipelineCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::GraphicsPipelineCreateInfo::operator=(rhs);
      return *this;
    }

    GraphicsPipelineCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setFlags( vk::PipelineCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setStageCount( uint32_t stageCount_ ) VULKAN_HPP_NOEXCEPT
    {
      stageCount = stageCount_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPStages( const vk::PipelineShaderStageCreateInfo* pStages_ ) VULKAN_HPP_NOEXCEPT
    {
      pStages = pStages_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPVertexInputState( const vk::PipelineVertexInputStateCreateInfo* pVertexInputState_ ) VULKAN_HPP_NOEXCEPT
    {
      pVertexInputState = pVertexInputState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPInputAssemblyState( const vk::PipelineInputAssemblyStateCreateInfo* pInputAssemblyState_ ) VULKAN_HPP_NOEXCEPT
    {
      pInputAssemblyState = pInputAssemblyState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPTessellationState( const vk::PipelineTessellationStateCreateInfo* pTessellationState_ ) VULKAN_HPP_NOEXCEPT
    {
      pTessellationState = pTessellationState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPViewportState( const vk::PipelineViewportStateCreateInfo* pViewportState_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewportState = pViewportState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPRasterizationState( const vk::PipelineRasterizationStateCreateInfo* pRasterizationState_ ) VULKAN_HPP_NOEXCEPT
    {
      pRasterizationState = pRasterizationState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPMultisampleState( const vk::PipelineMultisampleStateCreateInfo* pMultisampleState_ ) VULKAN_HPP_NOEXCEPT
    {
      pMultisampleState = pMultisampleState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPDepthStencilState( const vk::PipelineDepthStencilStateCreateInfo* pDepthStencilState_ ) VULKAN_HPP_NOEXCEPT
    {
      pDepthStencilState = pDepthStencilState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPColorBlendState( const vk::PipelineColorBlendStateCreateInfo* pColorBlendState_ ) VULKAN_HPP_NOEXCEPT
    {
      pColorBlendState = pColorBlendState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setPDynamicState( const vk::PipelineDynamicStateCreateInfo* pDynamicState_ ) VULKAN_HPP_NOEXCEPT
    {
      pDynamicState = pDynamicState_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setLayout( vk::PipelineLayout layout_ ) VULKAN_HPP_NOEXCEPT
    {
      layout = layout_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setRenderPass( vk::RenderPass renderPass_ ) VULKAN_HPP_NOEXCEPT
    {
      renderPass = renderPass_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setSubpass( uint32_t subpass_ ) VULKAN_HPP_NOEXCEPT
    {
      subpass = subpass_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setBasePipelineHandle( vk::Pipeline basePipelineHandle_ ) VULKAN_HPP_NOEXCEPT
    {
      basePipelineHandle = basePipelineHandle_;
      return *this;
    }

    GraphicsPipelineCreateInfo & setBasePipelineIndex( int32_t basePipelineIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      basePipelineIndex = basePipelineIndex_;
      return *this;
    }

    operator VkGraphicsPipelineCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( this );
    }

    operator VkGraphicsPipelineCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkGraphicsPipelineCreateInfo*>( this );
    }

    bool operator==( GraphicsPipelineCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( stageCount == rhs.stageCount )
          && ( pStages == rhs.pStages )
          && ( pVertexInputState == rhs.pVertexInputState )
          && ( pInputAssemblyState == rhs.pInputAssemblyState )
          && ( pTessellationState == rhs.pTessellationState )
          && ( pViewportState == rhs.pViewportState )
          && ( pRasterizationState == rhs.pRasterizationState )
          && ( pMultisampleState == rhs.pMultisampleState )
          && ( pDepthStencilState == rhs.pDepthStencilState )
          && ( pColorBlendState == rhs.pColorBlendState )
          && ( pDynamicState == rhs.pDynamicState )
          && ( layout == rhs.layout )
          && ( renderPass == rhs.renderPass )
          && ( subpass == rhs.subpass )
          && ( basePipelineHandle == rhs.basePipelineHandle )
          && ( basePipelineIndex == rhs.basePipelineIndex );
    }

    bool operator!=( GraphicsPipelineCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::GraphicsPipelineCreateInfo::sType;
  };
  static_assert( sizeof( GraphicsPipelineCreateInfo ) == sizeof( VkGraphicsPipelineCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<GraphicsPipelineCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct XYColorEXT
  {
    VULKAN_HPP_CONSTEXPR XYColorEXT( float x_ = 0,
                                     float y_ = 0 ) VULKAN_HPP_NOEXCEPT
      : x( x_ )
      , y( y_ )
    {}

    XYColorEXT( VkXYColorEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkXYColorEXT*>(this) = rhs;
    }

    XYColorEXT& operator=( VkXYColorEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkXYColorEXT*>(this) = rhs;
      return *this;
    }

    XYColorEXT & setX( float x_ ) VULKAN_HPP_NOEXCEPT
    {
      x = x_;
      return *this;
    }

    XYColorEXT & setY( float y_ ) VULKAN_HPP_NOEXCEPT
    {
      y = y_;
      return *this;
    }

    operator VkXYColorEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkXYColorEXT*>( this );
    }

    operator VkXYColorEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkXYColorEXT*>( this );
    }

    bool operator==( XYColorEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( x == rhs.x )
          && ( y == rhs.y );
    }

    bool operator!=( XYColorEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    float x;
    float y;
  };
  static_assert( sizeof( XYColorEXT ) == sizeof( VkXYColorEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<XYColorEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct HdrMetadataEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR HdrMetadataEXT( vk::XYColorEXT displayPrimaryRed_ = vk::XYColorEXT(),
                                           vk::XYColorEXT displayPrimaryGreen_ = vk::XYColorEXT(),
                                           vk::XYColorEXT displayPrimaryBlue_ = vk::XYColorEXT(),
                                           vk::XYColorEXT whitePoint_ = vk::XYColorEXT(),
                                           float maxLuminance_ = 0,
                                           float minLuminance_ = 0,
                                           float maxContentLightLevel_ = 0,
                                           float maxFrameAverageLightLevel_ = 0 ) VULKAN_HPP_NOEXCEPT
        : displayPrimaryRed( displayPrimaryRed_ )
        , displayPrimaryGreen( displayPrimaryGreen_ )
        , displayPrimaryBlue( displayPrimaryBlue_ )
        , whitePoint( whitePoint_ )
        , maxLuminance( maxLuminance_ )
        , minLuminance( minLuminance_ )
        , maxContentLightLevel( maxContentLightLevel_ )
        , maxFrameAverageLightLevel( maxFrameAverageLightLevel_ )
      {}

      HdrMetadataEXT( VkHdrMetadataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkHdrMetadataEXT*>(this) = rhs;
      }

      HdrMetadataEXT& operator=( VkHdrMetadataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkHdrMetadataEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eHdrMetadataEXT;
      const void* pNext = nullptr;
      vk::XYColorEXT displayPrimaryRed;
      vk::XYColorEXT displayPrimaryGreen;
      vk::XYColorEXT displayPrimaryBlue;
      vk::XYColorEXT whitePoint;
      float maxLuminance;
      float minLuminance;
      float maxContentLightLevel;
      float maxFrameAverageLightLevel;
    };
    static_assert( sizeof( HdrMetadataEXT ) == sizeof( VkHdrMetadataEXT ), "layout struct and wrapper have different size!" );
  }

  struct HdrMetadataEXT : public layout::HdrMetadataEXT
  {
    VULKAN_HPP_CONSTEXPR HdrMetadataEXT( vk::XYColorEXT displayPrimaryRed_ = vk::XYColorEXT(),
                                         vk::XYColorEXT displayPrimaryGreen_ = vk::XYColorEXT(),
                                         vk::XYColorEXT displayPrimaryBlue_ = vk::XYColorEXT(),
                                         vk::XYColorEXT whitePoint_ = vk::XYColorEXT(),
                                         float maxLuminance_ = 0,
                                         float minLuminance_ = 0,
                                         float maxContentLightLevel_ = 0,
                                         float maxFrameAverageLightLevel_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::HdrMetadataEXT( displayPrimaryRed_, displayPrimaryGreen_, displayPrimaryBlue_, whitePoint_, maxLuminance_, minLuminance_, maxContentLightLevel_, maxFrameAverageLightLevel_ )
    {}

    HdrMetadataEXT( VkHdrMetadataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::HdrMetadataEXT( rhs )
    {}

    HdrMetadataEXT& operator=( VkHdrMetadataEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::HdrMetadataEXT::operator=(rhs);
      return *this;
    }

    HdrMetadataEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    HdrMetadataEXT & setDisplayPrimaryRed( vk::XYColorEXT displayPrimaryRed_ ) VULKAN_HPP_NOEXCEPT
    {
      displayPrimaryRed = displayPrimaryRed_;
      return *this;
    }

    HdrMetadataEXT & setDisplayPrimaryGreen( vk::XYColorEXT displayPrimaryGreen_ ) VULKAN_HPP_NOEXCEPT
    {
      displayPrimaryGreen = displayPrimaryGreen_;
      return *this;
    }

    HdrMetadataEXT & setDisplayPrimaryBlue( vk::XYColorEXT displayPrimaryBlue_ ) VULKAN_HPP_NOEXCEPT
    {
      displayPrimaryBlue = displayPrimaryBlue_;
      return *this;
    }

    HdrMetadataEXT & setWhitePoint( vk::XYColorEXT whitePoint_ ) VULKAN_HPP_NOEXCEPT
    {
      whitePoint = whitePoint_;
      return *this;
    }

    HdrMetadataEXT & setMaxLuminance( float maxLuminance_ ) VULKAN_HPP_NOEXCEPT
    {
      maxLuminance = maxLuminance_;
      return *this;
    }

    HdrMetadataEXT & setMinLuminance( float minLuminance_ ) VULKAN_HPP_NOEXCEPT
    {
      minLuminance = minLuminance_;
      return *this;
    }

    HdrMetadataEXT & setMaxContentLightLevel( float maxContentLightLevel_ ) VULKAN_HPP_NOEXCEPT
    {
      maxContentLightLevel = maxContentLightLevel_;
      return *this;
    }

    HdrMetadataEXT & setMaxFrameAverageLightLevel( float maxFrameAverageLightLevel_ ) VULKAN_HPP_NOEXCEPT
    {
      maxFrameAverageLightLevel = maxFrameAverageLightLevel_;
      return *this;
    }

    operator VkHdrMetadataEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkHdrMetadataEXT*>( this );
    }

    operator VkHdrMetadataEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkHdrMetadataEXT*>( this );
    }

    bool operator==( HdrMetadataEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( displayPrimaryRed == rhs.displayPrimaryRed )
          && ( displayPrimaryGreen == rhs.displayPrimaryGreen )
          && ( displayPrimaryBlue == rhs.displayPrimaryBlue )
          && ( whitePoint == rhs.whitePoint )
          && ( maxLuminance == rhs.maxLuminance )
          && ( minLuminance == rhs.minLuminance )
          && ( maxContentLightLevel == rhs.maxContentLightLevel )
          && ( maxFrameAverageLightLevel == rhs.maxFrameAverageLightLevel );
    }

    bool operator!=( HdrMetadataEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::HdrMetadataEXT::sType;
  };
  static_assert( sizeof( HdrMetadataEXT ) == sizeof( VkHdrMetadataEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<HdrMetadataEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct HeadlessSurfaceCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR HeadlessSurfaceCreateInfoEXT( vk::HeadlessSurfaceCreateFlagsEXT flags_ = vk::HeadlessSurfaceCreateFlagsEXT() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
      {}

      HeadlessSurfaceCreateInfoEXT( VkHeadlessSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkHeadlessSurfaceCreateInfoEXT*>(this) = rhs;
      }

      HeadlessSurfaceCreateInfoEXT& operator=( VkHeadlessSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkHeadlessSurfaceCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eHeadlessSurfaceCreateInfoEXT;
      const void* pNext = nullptr;
      vk::HeadlessSurfaceCreateFlagsEXT flags;
    };
    static_assert( sizeof( HeadlessSurfaceCreateInfoEXT ) == sizeof( VkHeadlessSurfaceCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct HeadlessSurfaceCreateInfoEXT : public layout::HeadlessSurfaceCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR HeadlessSurfaceCreateInfoEXT( vk::HeadlessSurfaceCreateFlagsEXT flags_ = vk::HeadlessSurfaceCreateFlagsEXT() ) VULKAN_HPP_NOEXCEPT
      : layout::HeadlessSurfaceCreateInfoEXT( flags_ )
    {}

    HeadlessSurfaceCreateInfoEXT( VkHeadlessSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::HeadlessSurfaceCreateInfoEXT( rhs )
    {}

    HeadlessSurfaceCreateInfoEXT& operator=( VkHeadlessSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::HeadlessSurfaceCreateInfoEXT::operator=(rhs);
      return *this;
    }

    HeadlessSurfaceCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    HeadlessSurfaceCreateInfoEXT & setFlags( vk::HeadlessSurfaceCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkHeadlessSurfaceCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkHeadlessSurfaceCreateInfoEXT*>( this );
    }

    operator VkHeadlessSurfaceCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkHeadlessSurfaceCreateInfoEXT*>( this );
    }

    bool operator==( HeadlessSurfaceCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags );
    }

    bool operator!=( HeadlessSurfaceCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::HeadlessSurfaceCreateInfoEXT::sType;
  };
  static_assert( sizeof( HeadlessSurfaceCreateInfoEXT ) == sizeof( VkHeadlessSurfaceCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<HeadlessSurfaceCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_IOS_MVK

  namespace layout
  {
    struct IOSSurfaceCreateInfoMVK
    {
    protected:
      VULKAN_HPP_CONSTEXPR IOSSurfaceCreateInfoMVK( vk::IOSSurfaceCreateFlagsMVK flags_ = vk::IOSSurfaceCreateFlagsMVK(),
                                                    const void* pView_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pView( pView_ )
      {}

      IOSSurfaceCreateInfoMVK( VkIOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkIOSSurfaceCreateInfoMVK*>(this) = rhs;
      }

      IOSSurfaceCreateInfoMVK& operator=( VkIOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkIOSSurfaceCreateInfoMVK*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eIosSurfaceCreateInfoMVK;
      const void* pNext = nullptr;
      vk::IOSSurfaceCreateFlagsMVK flags;
      const void* pView;
    };
    static_assert( sizeof( IOSSurfaceCreateInfoMVK ) == sizeof( VkIOSSurfaceCreateInfoMVK ), "layout struct and wrapper have different size!" );
  }

  struct IOSSurfaceCreateInfoMVK : public layout::IOSSurfaceCreateInfoMVK
  {
    VULKAN_HPP_CONSTEXPR IOSSurfaceCreateInfoMVK( vk::IOSSurfaceCreateFlagsMVK flags_ = vk::IOSSurfaceCreateFlagsMVK(),
                                                  const void* pView_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::IOSSurfaceCreateInfoMVK( flags_, pView_ )
    {}

    IOSSurfaceCreateInfoMVK( VkIOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::IOSSurfaceCreateInfoMVK( rhs )
    {}

    IOSSurfaceCreateInfoMVK& operator=( VkIOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::IOSSurfaceCreateInfoMVK::operator=(rhs);
      return *this;
    }

    IOSSurfaceCreateInfoMVK & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    IOSSurfaceCreateInfoMVK & setFlags( vk::IOSSurfaceCreateFlagsMVK flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    IOSSurfaceCreateInfoMVK & setPView( const void* pView_ ) VULKAN_HPP_NOEXCEPT
    {
      pView = pView_;
      return *this;
    }

    operator VkIOSSurfaceCreateInfoMVK const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkIOSSurfaceCreateInfoMVK*>( this );
    }

    operator VkIOSSurfaceCreateInfoMVK &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkIOSSurfaceCreateInfoMVK*>( this );
    }

    bool operator==( IOSSurfaceCreateInfoMVK const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pView == rhs.pView );
    }

    bool operator!=( IOSSurfaceCreateInfoMVK const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::IOSSurfaceCreateInfoMVK::sType;
  };
  static_assert( sizeof( IOSSurfaceCreateInfoMVK ) == sizeof( VkIOSSurfaceCreateInfoMVK ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<IOSSurfaceCreateInfoMVK>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_IOS_MVK*/

  struct ImageBlit
  {
    VULKAN_HPP_CONSTEXPR_14 ImageBlit( vk::ImageSubresourceLayers srcSubresource_ = vk::ImageSubresourceLayers(),
                                       std::array<vk::Offset3D,2> const& srcOffsets_ = { { vk::Offset3D() } },
                                       vk::ImageSubresourceLayers dstSubresource_ = vk::ImageSubresourceLayers(),
                                       std::array<vk::Offset3D,2> const& dstOffsets_ = { { vk::Offset3D() } } ) VULKAN_HPP_NOEXCEPT
      : srcSubresource( srcSubresource_ )
      , srcOffsets{}
      , dstSubresource( dstSubresource_ )
      , dstOffsets{}
    {
      vk::ConstExpressionArrayCopy<vk::Offset3D,2,2>::copy( srcOffsets, srcOffsets_ );
      vk::ConstExpressionArrayCopy<vk::Offset3D,2,2>::copy( dstOffsets, dstOffsets_ );
    }

    ImageBlit( VkImageBlit const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageBlit*>(this) = rhs;
    }

    ImageBlit& operator=( VkImageBlit const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageBlit*>(this) = rhs;
      return *this;
    }

    ImageBlit & setSrcSubresource( vk::ImageSubresourceLayers srcSubresource_ ) VULKAN_HPP_NOEXCEPT
    {
      srcSubresource = srcSubresource_;
      return *this;
    }

    ImageBlit & setSrcOffsets( std::array<vk::Offset3D,2> srcOffsets_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( srcOffsets, srcOffsets_.data(), 2 * sizeof( vk::Offset3D ) );
      return *this;
    }

    ImageBlit & setDstSubresource( vk::ImageSubresourceLayers dstSubresource_ ) VULKAN_HPP_NOEXCEPT
    {
      dstSubresource = dstSubresource_;
      return *this;
    }

    ImageBlit & setDstOffsets( std::array<vk::Offset3D,2> dstOffsets_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( dstOffsets, dstOffsets_.data(), 2 * sizeof( vk::Offset3D ) );
      return *this;
    }

    operator VkImageBlit const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageBlit*>( this );
    }

    operator VkImageBlit &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageBlit*>( this );
    }

    bool operator==( ImageBlit const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( srcSubresource == rhs.srcSubresource )
          && ( memcmp( srcOffsets, rhs.srcOffsets, 2 * sizeof( vk::Offset3D ) ) == 0 )
          && ( dstSubresource == rhs.dstSubresource )
          && ( memcmp( dstOffsets, rhs.dstOffsets, 2 * sizeof( vk::Offset3D ) ) == 0 );
    }

    bool operator!=( ImageBlit const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageSubresourceLayers srcSubresource;
    vk::Offset3D srcOffsets[2];
    vk::ImageSubresourceLayers dstSubresource;
    vk::Offset3D dstOffsets[2];
  };
  static_assert( sizeof( ImageBlit ) == sizeof( VkImageBlit ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageBlit>::value, "struct wrapper is not a standard layout!" );

  struct ImageCopy
  {
    VULKAN_HPP_CONSTEXPR ImageCopy( vk::ImageSubresourceLayers srcSubresource_ = vk::ImageSubresourceLayers(),
                                    vk::Offset3D srcOffset_ = vk::Offset3D(),
                                    vk::ImageSubresourceLayers dstSubresource_ = vk::ImageSubresourceLayers(),
                                    vk::Offset3D dstOffset_ = vk::Offset3D(),
                                    vk::Extent3D extent_ = vk::Extent3D() ) VULKAN_HPP_NOEXCEPT
      : srcSubresource( srcSubresource_ )
      , srcOffset( srcOffset_ )
      , dstSubresource( dstSubresource_ )
      , dstOffset( dstOffset_ )
      , extent( extent_ )
    {}

    ImageCopy( VkImageCopy const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageCopy*>(this) = rhs;
    }

    ImageCopy& operator=( VkImageCopy const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageCopy*>(this) = rhs;
      return *this;
    }

    ImageCopy & setSrcSubresource( vk::ImageSubresourceLayers srcSubresource_ ) VULKAN_HPP_NOEXCEPT
    {
      srcSubresource = srcSubresource_;
      return *this;
    }

    ImageCopy & setSrcOffset( vk::Offset3D srcOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      srcOffset = srcOffset_;
      return *this;
    }

    ImageCopy & setDstSubresource( vk::ImageSubresourceLayers dstSubresource_ ) VULKAN_HPP_NOEXCEPT
    {
      dstSubresource = dstSubresource_;
      return *this;
    }

    ImageCopy & setDstOffset( vk::Offset3D dstOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      dstOffset = dstOffset_;
      return *this;
    }

    ImageCopy & setExtent( vk::Extent3D extent_ ) VULKAN_HPP_NOEXCEPT
    {
      extent = extent_;
      return *this;
    }

    operator VkImageCopy const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageCopy*>( this );
    }

    operator VkImageCopy &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageCopy*>( this );
    }

    bool operator==( ImageCopy const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( srcSubresource == rhs.srcSubresource )
          && ( srcOffset == rhs.srcOffset )
          && ( dstSubresource == rhs.dstSubresource )
          && ( dstOffset == rhs.dstOffset )
          && ( extent == rhs.extent );
    }

    bool operator!=( ImageCopy const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageSubresourceLayers srcSubresource;
    vk::Offset3D srcOffset;
    vk::ImageSubresourceLayers dstSubresource;
    vk::Offset3D dstOffset;
    vk::Extent3D extent;
  };
  static_assert( sizeof( ImageCopy ) == sizeof( VkImageCopy ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageCopy>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageCreateInfo( vk::ImageCreateFlags flags_ = vk::ImageCreateFlags(),
                                            vk::ImageType imageType_ = vk::ImageType::e1D,
                                            vk::Format format_ = vk::Format::eUndefined,
                                            vk::Extent3D extent_ = vk::Extent3D(),
                                            uint32_t mipLevels_ = 0,
                                            uint32_t arrayLayers_ = 0,
                                            vk::SampleCountFlagBits samples_ = vk::SampleCountFlagBits::e1,
                                            vk::ImageTiling tiling_ = vk::ImageTiling::eOptimal,
                                            vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                            vk::SharingMode sharingMode_ = vk::SharingMode::eExclusive,
                                            uint32_t queueFamilyIndexCount_ = 0,
                                            const uint32_t* pQueueFamilyIndices_ = nullptr,
                                            vk::ImageLayout initialLayout_ = vk::ImageLayout::eUndefined ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , imageType( imageType_ )
        , format( format_ )
        , extent( extent_ )
        , mipLevels( mipLevels_ )
        , arrayLayers( arrayLayers_ )
        , samples( samples_ )
        , tiling( tiling_ )
        , usage( usage_ )
        , sharingMode( sharingMode_ )
        , queueFamilyIndexCount( queueFamilyIndexCount_ )
        , pQueueFamilyIndices( pQueueFamilyIndices_ )
        , initialLayout( initialLayout_ )
      {}

      ImageCreateInfo( VkImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageCreateInfo*>(this) = rhs;
      }

      ImageCreateInfo& operator=( VkImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageCreateInfo;
      const void* pNext = nullptr;
      vk::ImageCreateFlags flags;
      vk::ImageType imageType;
      vk::Format format;
      vk::Extent3D extent;
      uint32_t mipLevels;
      uint32_t arrayLayers;
      vk::SampleCountFlagBits samples;
      vk::ImageTiling tiling;
      vk::ImageUsageFlags usage;
      vk::SharingMode sharingMode;
      uint32_t queueFamilyIndexCount;
      const uint32_t* pQueueFamilyIndices;
      vk::ImageLayout initialLayout;
    };
    static_assert( sizeof( ImageCreateInfo ) == sizeof( VkImageCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ImageCreateInfo : public layout::ImageCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ImageCreateInfo( vk::ImageCreateFlags flags_ = vk::ImageCreateFlags(),
                                          vk::ImageType imageType_ = vk::ImageType::e1D,
                                          vk::Format format_ = vk::Format::eUndefined,
                                          vk::Extent3D extent_ = vk::Extent3D(),
                                          uint32_t mipLevels_ = 0,
                                          uint32_t arrayLayers_ = 0,
                                          vk::SampleCountFlagBits samples_ = vk::SampleCountFlagBits::e1,
                                          vk::ImageTiling tiling_ = vk::ImageTiling::eOptimal,
                                          vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                          vk::SharingMode sharingMode_ = vk::SharingMode::eExclusive,
                                          uint32_t queueFamilyIndexCount_ = 0,
                                          const uint32_t* pQueueFamilyIndices_ = nullptr,
                                          vk::ImageLayout initialLayout_ = vk::ImageLayout::eUndefined ) VULKAN_HPP_NOEXCEPT
      : layout::ImageCreateInfo( flags_, imageType_, format_, extent_, mipLevels_, arrayLayers_, samples_, tiling_, usage_, sharingMode_, queueFamilyIndexCount_, pQueueFamilyIndices_, initialLayout_ )
    {}

    ImageCreateInfo( VkImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageCreateInfo( rhs )
    {}

    ImageCreateInfo& operator=( VkImageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageCreateInfo::operator=(rhs);
      return *this;
    }

    ImageCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageCreateInfo & setFlags( vk::ImageCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ImageCreateInfo & setImageType( vk::ImageType imageType_ ) VULKAN_HPP_NOEXCEPT
    {
      imageType = imageType_;
      return *this;
    }

    ImageCreateInfo & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    ImageCreateInfo & setExtent( vk::Extent3D extent_ ) VULKAN_HPP_NOEXCEPT
    {
      extent = extent_;
      return *this;
    }

    ImageCreateInfo & setMipLevels( uint32_t mipLevels_ ) VULKAN_HPP_NOEXCEPT
    {
      mipLevels = mipLevels_;
      return *this;
    }

    ImageCreateInfo & setArrayLayers( uint32_t arrayLayers_ ) VULKAN_HPP_NOEXCEPT
    {
      arrayLayers = arrayLayers_;
      return *this;
    }

    ImageCreateInfo & setSamples( vk::SampleCountFlagBits samples_ ) VULKAN_HPP_NOEXCEPT
    {
      samples = samples_;
      return *this;
    }

    ImageCreateInfo & setTiling( vk::ImageTiling tiling_ ) VULKAN_HPP_NOEXCEPT
    {
      tiling = tiling_;
      return *this;
    }

    ImageCreateInfo & setUsage( vk::ImageUsageFlags usage_ ) VULKAN_HPP_NOEXCEPT
    {
      usage = usage_;
      return *this;
    }

    ImageCreateInfo & setSharingMode( vk::SharingMode sharingMode_ ) VULKAN_HPP_NOEXCEPT
    {
      sharingMode = sharingMode_;
      return *this;
    }

    ImageCreateInfo & setQueueFamilyIndexCount( uint32_t queueFamilyIndexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queueFamilyIndexCount = queueFamilyIndexCount_;
      return *this;
    }

    ImageCreateInfo & setPQueueFamilyIndices( const uint32_t* pQueueFamilyIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pQueueFamilyIndices = pQueueFamilyIndices_;
      return *this;
    }

    ImageCreateInfo & setInitialLayout( vk::ImageLayout initialLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      initialLayout = initialLayout_;
      return *this;
    }

    operator VkImageCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageCreateInfo*>( this );
    }

    operator VkImageCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageCreateInfo*>( this );
    }

    bool operator==( ImageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( imageType == rhs.imageType )
          && ( format == rhs.format )
          && ( extent == rhs.extent )
          && ( mipLevels == rhs.mipLevels )
          && ( arrayLayers == rhs.arrayLayers )
          && vk::operator==( samples, rhs.samples )
          && ( tiling == rhs.tiling )
          && ( usage == rhs.usage )
          && ( sharingMode == rhs.sharingMode )
          && ( queueFamilyIndexCount == rhs.queueFamilyIndexCount )
          && ( pQueueFamilyIndices == rhs.pQueueFamilyIndices )
          && ( initialLayout == rhs.initialLayout );
    }

    bool operator!=( ImageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageCreateInfo::sType;
  };
  static_assert( sizeof( ImageCreateInfo ) == sizeof( VkImageCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct SubresourceLayout
  {
    SubresourceLayout() VULKAN_HPP_NOEXCEPT
    {}

    SubresourceLayout( VkSubresourceLayout const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubresourceLayout*>(this) = rhs;
    }

    SubresourceLayout& operator=( VkSubresourceLayout const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubresourceLayout*>(this) = rhs;
      return *this;
    }

    operator VkSubresourceLayout const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubresourceLayout*>( this );
    }

    operator VkSubresourceLayout &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubresourceLayout*>( this );
    }

    bool operator==( SubresourceLayout const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( offset == rhs.offset )
          && ( size == rhs.size )
          && ( rowPitch == rhs.rowPitch )
          && ( arrayPitch == rhs.arrayPitch )
          && ( depthPitch == rhs.depthPitch );
    }

    bool operator!=( SubresourceLayout const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DeviceSize offset;
    vk::DeviceSize size;
    vk::DeviceSize rowPitch;
    vk::DeviceSize arrayPitch;
    vk::DeviceSize depthPitch;
  };
  static_assert( sizeof( SubresourceLayout ) == sizeof( VkSubresourceLayout ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubresourceLayout>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageDrmFormatModifierExplicitCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageDrmFormatModifierExplicitCreateInfoEXT( uint64_t drmFormatModifier_ = 0,
                                                                        uint32_t drmFormatModifierPlaneCount_ = 0,
                                                                        const vk::SubresourceLayout* pPlaneLayouts_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : drmFormatModifier( drmFormatModifier_ )
        , drmFormatModifierPlaneCount( drmFormatModifierPlaneCount_ )
        , pPlaneLayouts( pPlaneLayouts_ )
      {}

      ImageDrmFormatModifierExplicitCreateInfoEXT( VkImageDrmFormatModifierExplicitCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageDrmFormatModifierExplicitCreateInfoEXT*>(this) = rhs;
      }

      ImageDrmFormatModifierExplicitCreateInfoEXT& operator=( VkImageDrmFormatModifierExplicitCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageDrmFormatModifierExplicitCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageDrmFormatModifierExplicitCreateInfoEXT;
      const void* pNext = nullptr;
      uint64_t drmFormatModifier;
      uint32_t drmFormatModifierPlaneCount;
      const vk::SubresourceLayout* pPlaneLayouts;
    };
    static_assert( sizeof( ImageDrmFormatModifierExplicitCreateInfoEXT ) == sizeof( VkImageDrmFormatModifierExplicitCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct ImageDrmFormatModifierExplicitCreateInfoEXT : public layout::ImageDrmFormatModifierExplicitCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR ImageDrmFormatModifierExplicitCreateInfoEXT( uint64_t drmFormatModifier_ = 0,
                                                                      uint32_t drmFormatModifierPlaneCount_ = 0,
                                                                      const vk::SubresourceLayout* pPlaneLayouts_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImageDrmFormatModifierExplicitCreateInfoEXT( drmFormatModifier_, drmFormatModifierPlaneCount_, pPlaneLayouts_ )
    {}

    ImageDrmFormatModifierExplicitCreateInfoEXT( VkImageDrmFormatModifierExplicitCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageDrmFormatModifierExplicitCreateInfoEXT( rhs )
    {}

    ImageDrmFormatModifierExplicitCreateInfoEXT& operator=( VkImageDrmFormatModifierExplicitCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageDrmFormatModifierExplicitCreateInfoEXT::operator=(rhs);
      return *this;
    }

    ImageDrmFormatModifierExplicitCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageDrmFormatModifierExplicitCreateInfoEXT & setDrmFormatModifier( uint64_t drmFormatModifier_ ) VULKAN_HPP_NOEXCEPT
    {
      drmFormatModifier = drmFormatModifier_;
      return *this;
    }

    ImageDrmFormatModifierExplicitCreateInfoEXT & setDrmFormatModifierPlaneCount( uint32_t drmFormatModifierPlaneCount_ ) VULKAN_HPP_NOEXCEPT
    {
      drmFormatModifierPlaneCount = drmFormatModifierPlaneCount_;
      return *this;
    }

    ImageDrmFormatModifierExplicitCreateInfoEXT & setPPlaneLayouts( const vk::SubresourceLayout* pPlaneLayouts_ ) VULKAN_HPP_NOEXCEPT
    {
      pPlaneLayouts = pPlaneLayouts_;
      return *this;
    }

    operator VkImageDrmFormatModifierExplicitCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageDrmFormatModifierExplicitCreateInfoEXT*>( this );
    }

    operator VkImageDrmFormatModifierExplicitCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageDrmFormatModifierExplicitCreateInfoEXT*>( this );
    }

    bool operator==( ImageDrmFormatModifierExplicitCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( drmFormatModifier == rhs.drmFormatModifier )
          && ( drmFormatModifierPlaneCount == rhs.drmFormatModifierPlaneCount )
          && ( pPlaneLayouts == rhs.pPlaneLayouts );
    }

    bool operator!=( ImageDrmFormatModifierExplicitCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageDrmFormatModifierExplicitCreateInfoEXT::sType;
  };
  static_assert( sizeof( ImageDrmFormatModifierExplicitCreateInfoEXT ) == sizeof( VkImageDrmFormatModifierExplicitCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageDrmFormatModifierExplicitCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageDrmFormatModifierListCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageDrmFormatModifierListCreateInfoEXT( uint32_t drmFormatModifierCount_ = 0,
                                                                    const uint64_t* pDrmFormatModifiers_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : drmFormatModifierCount( drmFormatModifierCount_ )
        , pDrmFormatModifiers( pDrmFormatModifiers_ )
      {}

      ImageDrmFormatModifierListCreateInfoEXT( VkImageDrmFormatModifierListCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageDrmFormatModifierListCreateInfoEXT*>(this) = rhs;
      }

      ImageDrmFormatModifierListCreateInfoEXT& operator=( VkImageDrmFormatModifierListCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageDrmFormatModifierListCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageDrmFormatModifierListCreateInfoEXT;
      const void* pNext = nullptr;
      uint32_t drmFormatModifierCount;
      const uint64_t* pDrmFormatModifiers;
    };
    static_assert( sizeof( ImageDrmFormatModifierListCreateInfoEXT ) == sizeof( VkImageDrmFormatModifierListCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct ImageDrmFormatModifierListCreateInfoEXT : public layout::ImageDrmFormatModifierListCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR ImageDrmFormatModifierListCreateInfoEXT( uint32_t drmFormatModifierCount_ = 0,
                                                                  const uint64_t* pDrmFormatModifiers_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImageDrmFormatModifierListCreateInfoEXT( drmFormatModifierCount_, pDrmFormatModifiers_ )
    {}

    ImageDrmFormatModifierListCreateInfoEXT( VkImageDrmFormatModifierListCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageDrmFormatModifierListCreateInfoEXT( rhs )
    {}

    ImageDrmFormatModifierListCreateInfoEXT& operator=( VkImageDrmFormatModifierListCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageDrmFormatModifierListCreateInfoEXT::operator=(rhs);
      return *this;
    }

    ImageDrmFormatModifierListCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageDrmFormatModifierListCreateInfoEXT & setDrmFormatModifierCount( uint32_t drmFormatModifierCount_ ) VULKAN_HPP_NOEXCEPT
    {
      drmFormatModifierCount = drmFormatModifierCount_;
      return *this;
    }

    ImageDrmFormatModifierListCreateInfoEXT & setPDrmFormatModifiers( const uint64_t* pDrmFormatModifiers_ ) VULKAN_HPP_NOEXCEPT
    {
      pDrmFormatModifiers = pDrmFormatModifiers_;
      return *this;
    }

    operator VkImageDrmFormatModifierListCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageDrmFormatModifierListCreateInfoEXT*>( this );
    }

    operator VkImageDrmFormatModifierListCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageDrmFormatModifierListCreateInfoEXT*>( this );
    }

    bool operator==( ImageDrmFormatModifierListCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( drmFormatModifierCount == rhs.drmFormatModifierCount )
          && ( pDrmFormatModifiers == rhs.pDrmFormatModifiers );
    }

    bool operator!=( ImageDrmFormatModifierListCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageDrmFormatModifierListCreateInfoEXT::sType;
  };
  static_assert( sizeof( ImageDrmFormatModifierListCreateInfoEXT ) == sizeof( VkImageDrmFormatModifierListCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageDrmFormatModifierListCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageDrmFormatModifierPropertiesEXT
    {
    protected:
      ImageDrmFormatModifierPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      ImageDrmFormatModifierPropertiesEXT( VkImageDrmFormatModifierPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageDrmFormatModifierPropertiesEXT*>(this) = rhs;
      }

      ImageDrmFormatModifierPropertiesEXT& operator=( VkImageDrmFormatModifierPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageDrmFormatModifierPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageDrmFormatModifierPropertiesEXT;
      void* pNext = nullptr;
      uint64_t drmFormatModifier;
    };
    static_assert( sizeof( ImageDrmFormatModifierPropertiesEXT ) == sizeof( VkImageDrmFormatModifierPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct ImageDrmFormatModifierPropertiesEXT : public layout::ImageDrmFormatModifierPropertiesEXT
  {
    ImageDrmFormatModifierPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::ImageDrmFormatModifierPropertiesEXT()
    {}

    ImageDrmFormatModifierPropertiesEXT( VkImageDrmFormatModifierPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageDrmFormatModifierPropertiesEXT( rhs )
    {}

    ImageDrmFormatModifierPropertiesEXT& operator=( VkImageDrmFormatModifierPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageDrmFormatModifierPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkImageDrmFormatModifierPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageDrmFormatModifierPropertiesEXT*>( this );
    }

    operator VkImageDrmFormatModifierPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageDrmFormatModifierPropertiesEXT*>( this );
    }

    bool operator==( ImageDrmFormatModifierPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( drmFormatModifier == rhs.drmFormatModifier );
    }

    bool operator!=( ImageDrmFormatModifierPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageDrmFormatModifierPropertiesEXT::sType;
  };
  static_assert( sizeof( ImageDrmFormatModifierPropertiesEXT ) == sizeof( VkImageDrmFormatModifierPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageDrmFormatModifierPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageFormatListCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageFormatListCreateInfoKHR( uint32_t viewFormatCount_ = 0,
                                                         const vk::Format* pViewFormats_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : viewFormatCount( viewFormatCount_ )
        , pViewFormats( pViewFormats_ )
      {}

      ImageFormatListCreateInfoKHR( VkImageFormatListCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageFormatListCreateInfoKHR*>(this) = rhs;
      }

      ImageFormatListCreateInfoKHR& operator=( VkImageFormatListCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageFormatListCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageFormatListCreateInfoKHR;
      const void* pNext = nullptr;
      uint32_t viewFormatCount;
      const vk::Format* pViewFormats;
    };
    static_assert( sizeof( ImageFormatListCreateInfoKHR ) == sizeof( VkImageFormatListCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImageFormatListCreateInfoKHR : public layout::ImageFormatListCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImageFormatListCreateInfoKHR( uint32_t viewFormatCount_ = 0,
                                                       const vk::Format* pViewFormats_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImageFormatListCreateInfoKHR( viewFormatCount_, pViewFormats_ )
    {}

    ImageFormatListCreateInfoKHR( VkImageFormatListCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageFormatListCreateInfoKHR( rhs )
    {}

    ImageFormatListCreateInfoKHR& operator=( VkImageFormatListCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageFormatListCreateInfoKHR::operator=(rhs);
      return *this;
    }

    ImageFormatListCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageFormatListCreateInfoKHR & setViewFormatCount( uint32_t viewFormatCount_ ) VULKAN_HPP_NOEXCEPT
    {
      viewFormatCount = viewFormatCount_;
      return *this;
    }

    ImageFormatListCreateInfoKHR & setPViewFormats( const vk::Format* pViewFormats_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewFormats = pViewFormats_;
      return *this;
    }

    operator VkImageFormatListCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageFormatListCreateInfoKHR*>( this );
    }

    operator VkImageFormatListCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageFormatListCreateInfoKHR*>( this );
    }

    bool operator==( ImageFormatListCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( viewFormatCount == rhs.viewFormatCount )
          && ( pViewFormats == rhs.pViewFormats );
    }

    bool operator!=( ImageFormatListCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageFormatListCreateInfoKHR::sType;
  };
  static_assert( sizeof( ImageFormatListCreateInfoKHR ) == sizeof( VkImageFormatListCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageFormatListCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageFormatProperties2
    {
    protected:
      ImageFormatProperties2() VULKAN_HPP_NOEXCEPT
      {}

      ImageFormatProperties2( VkImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageFormatProperties2*>(this) = rhs;
      }

      ImageFormatProperties2& operator=( VkImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageFormatProperties2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageFormatProperties2;
      void* pNext = nullptr;
      vk::ImageFormatProperties imageFormatProperties;
    };
    static_assert( sizeof( ImageFormatProperties2 ) == sizeof( VkImageFormatProperties2 ), "layout struct and wrapper have different size!" );
  }

  struct ImageFormatProperties2 : public layout::ImageFormatProperties2
  {
    ImageFormatProperties2() VULKAN_HPP_NOEXCEPT
      : layout::ImageFormatProperties2()
    {}

    ImageFormatProperties2( VkImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageFormatProperties2( rhs )
    {}

    ImageFormatProperties2& operator=( VkImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageFormatProperties2::operator=(rhs);
      return *this;
    }

    operator VkImageFormatProperties2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageFormatProperties2*>( this );
    }

    operator VkImageFormatProperties2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageFormatProperties2*>( this );
    }

    bool operator==( ImageFormatProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( imageFormatProperties == rhs.imageFormatProperties );
    }

    bool operator!=( ImageFormatProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageFormatProperties2::sType;
  };
  static_assert( sizeof( ImageFormatProperties2 ) == sizeof( VkImageFormatProperties2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageFormatProperties2>::value, "struct wrapper is not a standard layout!" );

  struct ImageSubresourceRange
  {
    VULKAN_HPP_CONSTEXPR ImageSubresourceRange( vk::ImageAspectFlags aspectMask_ = vk::ImageAspectFlags(),
                                                uint32_t baseMipLevel_ = 0,
                                                uint32_t levelCount_ = 0,
                                                uint32_t baseArrayLayer_ = 0,
                                                uint32_t layerCount_ = 0 ) VULKAN_HPP_NOEXCEPT
      : aspectMask( aspectMask_ )
      , baseMipLevel( baseMipLevel_ )
      , levelCount( levelCount_ )
      , baseArrayLayer( baseArrayLayer_ )
      , layerCount( layerCount_ )
    {}

    ImageSubresourceRange( VkImageSubresourceRange const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageSubresourceRange*>(this) = rhs;
    }

    ImageSubresourceRange& operator=( VkImageSubresourceRange const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageSubresourceRange*>(this) = rhs;
      return *this;
    }

    ImageSubresourceRange & setAspectMask( vk::ImageAspectFlags aspectMask_ ) VULKAN_HPP_NOEXCEPT
    {
      aspectMask = aspectMask_;
      return *this;
    }

    ImageSubresourceRange & setBaseMipLevel( uint32_t baseMipLevel_ ) VULKAN_HPP_NOEXCEPT
    {
      baseMipLevel = baseMipLevel_;
      return *this;
    }

    ImageSubresourceRange & setLevelCount( uint32_t levelCount_ ) VULKAN_HPP_NOEXCEPT
    {
      levelCount = levelCount_;
      return *this;
    }

    ImageSubresourceRange & setBaseArrayLayer( uint32_t baseArrayLayer_ ) VULKAN_HPP_NOEXCEPT
    {
      baseArrayLayer = baseArrayLayer_;
      return *this;
    }

    ImageSubresourceRange & setLayerCount( uint32_t layerCount_ ) VULKAN_HPP_NOEXCEPT
    {
      layerCount = layerCount_;
      return *this;
    }

    operator VkImageSubresourceRange const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageSubresourceRange*>( this );
    }

    operator VkImageSubresourceRange &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageSubresourceRange*>( this );
    }

    bool operator==( ImageSubresourceRange const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( aspectMask == rhs.aspectMask )
          && ( baseMipLevel == rhs.baseMipLevel )
          && ( levelCount == rhs.levelCount )
          && ( baseArrayLayer == rhs.baseArrayLayer )
          && ( layerCount == rhs.layerCount );
    }

    bool operator!=( ImageSubresourceRange const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageAspectFlags aspectMask;
    uint32_t baseMipLevel;
    uint32_t levelCount;
    uint32_t baseArrayLayer;
    uint32_t layerCount;
  };
  static_assert( sizeof( ImageSubresourceRange ) == sizeof( VkImageSubresourceRange ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageSubresourceRange>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageMemoryBarrier
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageMemoryBarrier( vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                               vk::AccessFlags dstAccessMask_ = vk::AccessFlags(),
                                               vk::ImageLayout oldLayout_ = vk::ImageLayout::eUndefined,
                                               vk::ImageLayout newLayout_ = vk::ImageLayout::eUndefined,
                                               uint32_t srcQueueFamilyIndex_ = 0,
                                               uint32_t dstQueueFamilyIndex_ = 0,
                                               vk::Image image_ = vk::Image(),
                                               vk::ImageSubresourceRange subresourceRange_ = vk::ImageSubresourceRange() ) VULKAN_HPP_NOEXCEPT
        : srcAccessMask( srcAccessMask_ )
        , dstAccessMask( dstAccessMask_ )
        , oldLayout( oldLayout_ )
        , newLayout( newLayout_ )
        , srcQueueFamilyIndex( srcQueueFamilyIndex_ )
        , dstQueueFamilyIndex( dstQueueFamilyIndex_ )
        , image( image_ )
        , subresourceRange( subresourceRange_ )
      {}

      ImageMemoryBarrier( VkImageMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageMemoryBarrier*>(this) = rhs;
      }

      ImageMemoryBarrier& operator=( VkImageMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageMemoryBarrier*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageMemoryBarrier;
      const void* pNext = nullptr;
      vk::AccessFlags srcAccessMask;
      vk::AccessFlags dstAccessMask;
      vk::ImageLayout oldLayout;
      vk::ImageLayout newLayout;
      uint32_t srcQueueFamilyIndex;
      uint32_t dstQueueFamilyIndex;
      vk::Image image;
      vk::ImageSubresourceRange subresourceRange;
    };
    static_assert( sizeof( ImageMemoryBarrier ) == sizeof( VkImageMemoryBarrier ), "layout struct and wrapper have different size!" );
  }

  struct ImageMemoryBarrier : public layout::ImageMemoryBarrier
  {
    VULKAN_HPP_CONSTEXPR ImageMemoryBarrier( vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                             vk::AccessFlags dstAccessMask_ = vk::AccessFlags(),
                                             vk::ImageLayout oldLayout_ = vk::ImageLayout::eUndefined,
                                             vk::ImageLayout newLayout_ = vk::ImageLayout::eUndefined,
                                             uint32_t srcQueueFamilyIndex_ = 0,
                                             uint32_t dstQueueFamilyIndex_ = 0,
                                             vk::Image image_ = vk::Image(),
                                             vk::ImageSubresourceRange subresourceRange_ = vk::ImageSubresourceRange() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageMemoryBarrier( srcAccessMask_, dstAccessMask_, oldLayout_, newLayout_, srcQueueFamilyIndex_, dstQueueFamilyIndex_, image_, subresourceRange_ )
    {}

    ImageMemoryBarrier( VkImageMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageMemoryBarrier( rhs )
    {}

    ImageMemoryBarrier& operator=( VkImageMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageMemoryBarrier::operator=(rhs);
      return *this;
    }

    ImageMemoryBarrier & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageMemoryBarrier & setSrcAccessMask( vk::AccessFlags srcAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      srcAccessMask = srcAccessMask_;
      return *this;
    }

    ImageMemoryBarrier & setDstAccessMask( vk::AccessFlags dstAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      dstAccessMask = dstAccessMask_;
      return *this;
    }

    ImageMemoryBarrier & setOldLayout( vk::ImageLayout oldLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      oldLayout = oldLayout_;
      return *this;
    }

    ImageMemoryBarrier & setNewLayout( vk::ImageLayout newLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      newLayout = newLayout_;
      return *this;
    }

    ImageMemoryBarrier & setSrcQueueFamilyIndex( uint32_t srcQueueFamilyIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      srcQueueFamilyIndex = srcQueueFamilyIndex_;
      return *this;
    }

    ImageMemoryBarrier & setDstQueueFamilyIndex( uint32_t dstQueueFamilyIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      dstQueueFamilyIndex = dstQueueFamilyIndex_;
      return *this;
    }

    ImageMemoryBarrier & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    ImageMemoryBarrier & setSubresourceRange( vk::ImageSubresourceRange subresourceRange_ ) VULKAN_HPP_NOEXCEPT
    {
      subresourceRange = subresourceRange_;
      return *this;
    }

    operator VkImageMemoryBarrier const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageMemoryBarrier*>( this );
    }

    operator VkImageMemoryBarrier &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageMemoryBarrier*>( this );
    }

    bool operator==( ImageMemoryBarrier const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( srcAccessMask == rhs.srcAccessMask )
          && ( dstAccessMask == rhs.dstAccessMask )
          && ( oldLayout == rhs.oldLayout )
          && ( newLayout == rhs.newLayout )
          && ( srcQueueFamilyIndex == rhs.srcQueueFamilyIndex )
          && ( dstQueueFamilyIndex == rhs.dstQueueFamilyIndex )
          && ( image == rhs.image )
          && ( subresourceRange == rhs.subresourceRange );
    }

    bool operator!=( ImageMemoryBarrier const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageMemoryBarrier::sType;
  };
  static_assert( sizeof( ImageMemoryBarrier ) == sizeof( VkImageMemoryBarrier ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageMemoryBarrier>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageMemoryRequirementsInfo2
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageMemoryRequirementsInfo2( vk::Image image_ = vk::Image() ) VULKAN_HPP_NOEXCEPT
        : image( image_ )
      {}

      ImageMemoryRequirementsInfo2( VkImageMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageMemoryRequirementsInfo2*>(this) = rhs;
      }

      ImageMemoryRequirementsInfo2& operator=( VkImageMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageMemoryRequirementsInfo2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageMemoryRequirementsInfo2;
      const void* pNext = nullptr;
      vk::Image image;
    };
    static_assert( sizeof( ImageMemoryRequirementsInfo2 ) == sizeof( VkImageMemoryRequirementsInfo2 ), "layout struct and wrapper have different size!" );
  }

  struct ImageMemoryRequirementsInfo2 : public layout::ImageMemoryRequirementsInfo2
  {
    VULKAN_HPP_CONSTEXPR ImageMemoryRequirementsInfo2( vk::Image image_ = vk::Image() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageMemoryRequirementsInfo2( image_ )
    {}

    ImageMemoryRequirementsInfo2( VkImageMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageMemoryRequirementsInfo2( rhs )
    {}

    ImageMemoryRequirementsInfo2& operator=( VkImageMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageMemoryRequirementsInfo2::operator=(rhs);
      return *this;
    }

    ImageMemoryRequirementsInfo2 & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageMemoryRequirementsInfo2 & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    operator VkImageMemoryRequirementsInfo2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageMemoryRequirementsInfo2*>( this );
    }

    operator VkImageMemoryRequirementsInfo2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageMemoryRequirementsInfo2*>( this );
    }

    bool operator==( ImageMemoryRequirementsInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( image == rhs.image );
    }

    bool operator!=( ImageMemoryRequirementsInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageMemoryRequirementsInfo2::sType;
  };
  static_assert( sizeof( ImageMemoryRequirementsInfo2 ) == sizeof( VkImageMemoryRequirementsInfo2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageMemoryRequirementsInfo2>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_FUCHSIA

  namespace layout
  {
    struct ImagePipeSurfaceCreateInfoFUCHSIA
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImagePipeSurfaceCreateInfoFUCHSIA( vk::ImagePipeSurfaceCreateFlagsFUCHSIA flags_ = vk::ImagePipeSurfaceCreateFlagsFUCHSIA(),
                                                              zx_handle_t imagePipeHandle_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , imagePipeHandle( imagePipeHandle_ )
      {}

      ImagePipeSurfaceCreateInfoFUCHSIA( VkImagePipeSurfaceCreateInfoFUCHSIA const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImagePipeSurfaceCreateInfoFUCHSIA*>(this) = rhs;
      }

      ImagePipeSurfaceCreateInfoFUCHSIA& operator=( VkImagePipeSurfaceCreateInfoFUCHSIA const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImagePipeSurfaceCreateInfoFUCHSIA*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImagepipeSurfaceCreateInfoFUCHSIA;
      const void* pNext = nullptr;
      vk::ImagePipeSurfaceCreateFlagsFUCHSIA flags;
      zx_handle_t imagePipeHandle;
    };
    static_assert( sizeof( ImagePipeSurfaceCreateInfoFUCHSIA ) == sizeof( VkImagePipeSurfaceCreateInfoFUCHSIA ), "layout struct and wrapper have different size!" );
  }

  struct ImagePipeSurfaceCreateInfoFUCHSIA : public layout::ImagePipeSurfaceCreateInfoFUCHSIA
  {
    VULKAN_HPP_CONSTEXPR ImagePipeSurfaceCreateInfoFUCHSIA( vk::ImagePipeSurfaceCreateFlagsFUCHSIA flags_ = vk::ImagePipeSurfaceCreateFlagsFUCHSIA(),
                                                            zx_handle_t imagePipeHandle_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ImagePipeSurfaceCreateInfoFUCHSIA( flags_, imagePipeHandle_ )
    {}

    ImagePipeSurfaceCreateInfoFUCHSIA( VkImagePipeSurfaceCreateInfoFUCHSIA const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImagePipeSurfaceCreateInfoFUCHSIA( rhs )
    {}

    ImagePipeSurfaceCreateInfoFUCHSIA& operator=( VkImagePipeSurfaceCreateInfoFUCHSIA const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImagePipeSurfaceCreateInfoFUCHSIA::operator=(rhs);
      return *this;
    }

    ImagePipeSurfaceCreateInfoFUCHSIA & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImagePipeSurfaceCreateInfoFUCHSIA & setFlags( vk::ImagePipeSurfaceCreateFlagsFUCHSIA flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ImagePipeSurfaceCreateInfoFUCHSIA & setImagePipeHandle( zx_handle_t imagePipeHandle_ ) VULKAN_HPP_NOEXCEPT
    {
      imagePipeHandle = imagePipeHandle_;
      return *this;
    }

    operator VkImagePipeSurfaceCreateInfoFUCHSIA const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImagePipeSurfaceCreateInfoFUCHSIA*>( this );
    }

    operator VkImagePipeSurfaceCreateInfoFUCHSIA &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImagePipeSurfaceCreateInfoFUCHSIA*>( this );
    }

    bool operator==( ImagePipeSurfaceCreateInfoFUCHSIA const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( imagePipeHandle == rhs.imagePipeHandle );
    }

    bool operator!=( ImagePipeSurfaceCreateInfoFUCHSIA const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImagePipeSurfaceCreateInfoFUCHSIA::sType;
  };
  static_assert( sizeof( ImagePipeSurfaceCreateInfoFUCHSIA ) == sizeof( VkImagePipeSurfaceCreateInfoFUCHSIA ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImagePipeSurfaceCreateInfoFUCHSIA>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_FUCHSIA*/

  namespace layout
  {
    struct ImagePlaneMemoryRequirementsInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImagePlaneMemoryRequirementsInfo( vk::ImageAspectFlagBits planeAspect_ = vk::ImageAspectFlagBits::eColor ) VULKAN_HPP_NOEXCEPT
        : planeAspect( planeAspect_ )
      {}

      ImagePlaneMemoryRequirementsInfo( VkImagePlaneMemoryRequirementsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImagePlaneMemoryRequirementsInfo*>(this) = rhs;
      }

      ImagePlaneMemoryRequirementsInfo& operator=( VkImagePlaneMemoryRequirementsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImagePlaneMemoryRequirementsInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImagePlaneMemoryRequirementsInfo;
      const void* pNext = nullptr;
      vk::ImageAspectFlagBits planeAspect;
    };
    static_assert( sizeof( ImagePlaneMemoryRequirementsInfo ) == sizeof( VkImagePlaneMemoryRequirementsInfo ), "layout struct and wrapper have different size!" );
  }

  struct ImagePlaneMemoryRequirementsInfo : public layout::ImagePlaneMemoryRequirementsInfo
  {
    VULKAN_HPP_CONSTEXPR ImagePlaneMemoryRequirementsInfo( vk::ImageAspectFlagBits planeAspect_ = vk::ImageAspectFlagBits::eColor ) VULKAN_HPP_NOEXCEPT
      : layout::ImagePlaneMemoryRequirementsInfo( planeAspect_ )
    {}

    ImagePlaneMemoryRequirementsInfo( VkImagePlaneMemoryRequirementsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImagePlaneMemoryRequirementsInfo( rhs )
    {}

    ImagePlaneMemoryRequirementsInfo& operator=( VkImagePlaneMemoryRequirementsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImagePlaneMemoryRequirementsInfo::operator=(rhs);
      return *this;
    }

    ImagePlaneMemoryRequirementsInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImagePlaneMemoryRequirementsInfo & setPlaneAspect( vk::ImageAspectFlagBits planeAspect_ ) VULKAN_HPP_NOEXCEPT
    {
      planeAspect = planeAspect_;
      return *this;
    }

    operator VkImagePlaneMemoryRequirementsInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImagePlaneMemoryRequirementsInfo*>( this );
    }

    operator VkImagePlaneMemoryRequirementsInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImagePlaneMemoryRequirementsInfo*>( this );
    }

    bool operator==( ImagePlaneMemoryRequirementsInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( planeAspect, rhs.planeAspect );
    }

    bool operator!=( ImagePlaneMemoryRequirementsInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImagePlaneMemoryRequirementsInfo::sType;
  };
  static_assert( sizeof( ImagePlaneMemoryRequirementsInfo ) == sizeof( VkImagePlaneMemoryRequirementsInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImagePlaneMemoryRequirementsInfo>::value, "struct wrapper is not a standard layout!" );

  struct ImageResolve
  {
    VULKAN_HPP_CONSTEXPR ImageResolve( vk::ImageSubresourceLayers srcSubresource_ = vk::ImageSubresourceLayers(),
                                       vk::Offset3D srcOffset_ = vk::Offset3D(),
                                       vk::ImageSubresourceLayers dstSubresource_ = vk::ImageSubresourceLayers(),
                                       vk::Offset3D dstOffset_ = vk::Offset3D(),
                                       vk::Extent3D extent_ = vk::Extent3D() ) VULKAN_HPP_NOEXCEPT
      : srcSubresource( srcSubresource_ )
      , srcOffset( srcOffset_ )
      , dstSubresource( dstSubresource_ )
      , dstOffset( dstOffset_ )
      , extent( extent_ )
    {}

    ImageResolve( VkImageResolve const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageResolve*>(this) = rhs;
    }

    ImageResolve& operator=( VkImageResolve const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkImageResolve*>(this) = rhs;
      return *this;
    }

    ImageResolve & setSrcSubresource( vk::ImageSubresourceLayers srcSubresource_ ) VULKAN_HPP_NOEXCEPT
    {
      srcSubresource = srcSubresource_;
      return *this;
    }

    ImageResolve & setSrcOffset( vk::Offset3D srcOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      srcOffset = srcOffset_;
      return *this;
    }

    ImageResolve & setDstSubresource( vk::ImageSubresourceLayers dstSubresource_ ) VULKAN_HPP_NOEXCEPT
    {
      dstSubresource = dstSubresource_;
      return *this;
    }

    ImageResolve & setDstOffset( vk::Offset3D dstOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      dstOffset = dstOffset_;
      return *this;
    }

    ImageResolve & setExtent( vk::Extent3D extent_ ) VULKAN_HPP_NOEXCEPT
    {
      extent = extent_;
      return *this;
    }

    operator VkImageResolve const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageResolve*>( this );
    }

    operator VkImageResolve &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageResolve*>( this );
    }

    bool operator==( ImageResolve const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( srcSubresource == rhs.srcSubresource )
          && ( srcOffset == rhs.srcOffset )
          && ( dstSubresource == rhs.dstSubresource )
          && ( dstOffset == rhs.dstOffset )
          && ( extent == rhs.extent );
    }

    bool operator!=( ImageResolve const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageSubresourceLayers srcSubresource;
    vk::Offset3D srcOffset;
    vk::ImageSubresourceLayers dstSubresource;
    vk::Offset3D dstOffset;
    vk::Extent3D extent;
  };
  static_assert( sizeof( ImageResolve ) == sizeof( VkImageResolve ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageResolve>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageSparseMemoryRequirementsInfo2
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageSparseMemoryRequirementsInfo2( vk::Image image_ = vk::Image() ) VULKAN_HPP_NOEXCEPT
        : image( image_ )
      {}

      ImageSparseMemoryRequirementsInfo2( VkImageSparseMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageSparseMemoryRequirementsInfo2*>(this) = rhs;
      }

      ImageSparseMemoryRequirementsInfo2& operator=( VkImageSparseMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageSparseMemoryRequirementsInfo2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageSparseMemoryRequirementsInfo2;
      const void* pNext = nullptr;
      vk::Image image;
    };
    static_assert( sizeof( ImageSparseMemoryRequirementsInfo2 ) == sizeof( VkImageSparseMemoryRequirementsInfo2 ), "layout struct and wrapper have different size!" );
  }

  struct ImageSparseMemoryRequirementsInfo2 : public layout::ImageSparseMemoryRequirementsInfo2
  {
    VULKAN_HPP_CONSTEXPR ImageSparseMemoryRequirementsInfo2( vk::Image image_ = vk::Image() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageSparseMemoryRequirementsInfo2( image_ )
    {}

    ImageSparseMemoryRequirementsInfo2( VkImageSparseMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageSparseMemoryRequirementsInfo2( rhs )
    {}

    ImageSparseMemoryRequirementsInfo2& operator=( VkImageSparseMemoryRequirementsInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageSparseMemoryRequirementsInfo2::operator=(rhs);
      return *this;
    }

    ImageSparseMemoryRequirementsInfo2 & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageSparseMemoryRequirementsInfo2 & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    operator VkImageSparseMemoryRequirementsInfo2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( this );
    }

    operator VkImageSparseMemoryRequirementsInfo2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageSparseMemoryRequirementsInfo2*>( this );
    }

    bool operator==( ImageSparseMemoryRequirementsInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( image == rhs.image );
    }

    bool operator!=( ImageSparseMemoryRequirementsInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageSparseMemoryRequirementsInfo2::sType;
  };
  static_assert( sizeof( ImageSparseMemoryRequirementsInfo2 ) == sizeof( VkImageSparseMemoryRequirementsInfo2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageSparseMemoryRequirementsInfo2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageStencilUsageCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageStencilUsageCreateInfoEXT( vk::ImageUsageFlags stencilUsage_ = vk::ImageUsageFlags() ) VULKAN_HPP_NOEXCEPT
        : stencilUsage( stencilUsage_ )
      {}

      ImageStencilUsageCreateInfoEXT( VkImageStencilUsageCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageStencilUsageCreateInfoEXT*>(this) = rhs;
      }

      ImageStencilUsageCreateInfoEXT& operator=( VkImageStencilUsageCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageStencilUsageCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageStencilUsageCreateInfoEXT;
      const void* pNext = nullptr;
      vk::ImageUsageFlags stencilUsage;
    };
    static_assert( sizeof( ImageStencilUsageCreateInfoEXT ) == sizeof( VkImageStencilUsageCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct ImageStencilUsageCreateInfoEXT : public layout::ImageStencilUsageCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR ImageStencilUsageCreateInfoEXT( vk::ImageUsageFlags stencilUsage_ = vk::ImageUsageFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageStencilUsageCreateInfoEXT( stencilUsage_ )
    {}

    ImageStencilUsageCreateInfoEXT( VkImageStencilUsageCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageStencilUsageCreateInfoEXT( rhs )
    {}

    ImageStencilUsageCreateInfoEXT& operator=( VkImageStencilUsageCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageStencilUsageCreateInfoEXT::operator=(rhs);
      return *this;
    }

    ImageStencilUsageCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageStencilUsageCreateInfoEXT & setStencilUsage( vk::ImageUsageFlags stencilUsage_ ) VULKAN_HPP_NOEXCEPT
    {
      stencilUsage = stencilUsage_;
      return *this;
    }

    operator VkImageStencilUsageCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageStencilUsageCreateInfoEXT*>( this );
    }

    operator VkImageStencilUsageCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageStencilUsageCreateInfoEXT*>( this );
    }

    bool operator==( ImageStencilUsageCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( stencilUsage == rhs.stencilUsage );
    }

    bool operator!=( ImageStencilUsageCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageStencilUsageCreateInfoEXT::sType;
  };
  static_assert( sizeof( ImageStencilUsageCreateInfoEXT ) == sizeof( VkImageStencilUsageCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageStencilUsageCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageSwapchainCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageSwapchainCreateInfoKHR( vk::SwapchainKHR swapchain_ = vk::SwapchainKHR() ) VULKAN_HPP_NOEXCEPT
        : swapchain( swapchain_ )
      {}

      ImageSwapchainCreateInfoKHR( VkImageSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageSwapchainCreateInfoKHR*>(this) = rhs;
      }

      ImageSwapchainCreateInfoKHR& operator=( VkImageSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageSwapchainCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageSwapchainCreateInfoKHR;
      const void* pNext = nullptr;
      vk::SwapchainKHR swapchain;
    };
    static_assert( sizeof( ImageSwapchainCreateInfoKHR ) == sizeof( VkImageSwapchainCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImageSwapchainCreateInfoKHR : public layout::ImageSwapchainCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImageSwapchainCreateInfoKHR( vk::SwapchainKHR swapchain_ = vk::SwapchainKHR() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageSwapchainCreateInfoKHR( swapchain_ )
    {}

    ImageSwapchainCreateInfoKHR( VkImageSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageSwapchainCreateInfoKHR( rhs )
    {}

    ImageSwapchainCreateInfoKHR& operator=( VkImageSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageSwapchainCreateInfoKHR::operator=(rhs);
      return *this;
    }

    ImageSwapchainCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageSwapchainCreateInfoKHR & setSwapchain( vk::SwapchainKHR swapchain_ ) VULKAN_HPP_NOEXCEPT
    {
      swapchain = swapchain_;
      return *this;
    }

    operator VkImageSwapchainCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageSwapchainCreateInfoKHR*>( this );
    }

    operator VkImageSwapchainCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageSwapchainCreateInfoKHR*>( this );
    }

    bool operator==( ImageSwapchainCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( swapchain == rhs.swapchain );
    }

    bool operator!=( ImageSwapchainCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageSwapchainCreateInfoKHR::sType;
  };
  static_assert( sizeof( ImageSwapchainCreateInfoKHR ) == sizeof( VkImageSwapchainCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageSwapchainCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageViewASTCDecodeModeEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageViewASTCDecodeModeEXT( vk::Format decodeMode_ = vk::Format::eUndefined ) VULKAN_HPP_NOEXCEPT
        : decodeMode( decodeMode_ )
      {}

      ImageViewASTCDecodeModeEXT( VkImageViewASTCDecodeModeEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewASTCDecodeModeEXT*>(this) = rhs;
      }

      ImageViewASTCDecodeModeEXT& operator=( VkImageViewASTCDecodeModeEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewASTCDecodeModeEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageViewAstcDecodeModeEXT;
      const void* pNext = nullptr;
      vk::Format decodeMode;
    };
    static_assert( sizeof( ImageViewASTCDecodeModeEXT ) == sizeof( VkImageViewASTCDecodeModeEXT ), "layout struct and wrapper have different size!" );
  }

  struct ImageViewASTCDecodeModeEXT : public layout::ImageViewASTCDecodeModeEXT
  {
    VULKAN_HPP_CONSTEXPR ImageViewASTCDecodeModeEXT( vk::Format decodeMode_ = vk::Format::eUndefined ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewASTCDecodeModeEXT( decodeMode_ )
    {}

    ImageViewASTCDecodeModeEXT( VkImageViewASTCDecodeModeEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewASTCDecodeModeEXT( rhs )
    {}

    ImageViewASTCDecodeModeEXT& operator=( VkImageViewASTCDecodeModeEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageViewASTCDecodeModeEXT::operator=(rhs);
      return *this;
    }

    ImageViewASTCDecodeModeEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageViewASTCDecodeModeEXT & setDecodeMode( vk::Format decodeMode_ ) VULKAN_HPP_NOEXCEPT
    {
      decodeMode = decodeMode_;
      return *this;
    }

    operator VkImageViewASTCDecodeModeEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageViewASTCDecodeModeEXT*>( this );
    }

    operator VkImageViewASTCDecodeModeEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageViewASTCDecodeModeEXT*>( this );
    }

    bool operator==( ImageViewASTCDecodeModeEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( decodeMode == rhs.decodeMode );
    }

    bool operator!=( ImageViewASTCDecodeModeEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageViewASTCDecodeModeEXT::sType;
  };
  static_assert( sizeof( ImageViewASTCDecodeModeEXT ) == sizeof( VkImageViewASTCDecodeModeEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageViewASTCDecodeModeEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageViewCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageViewCreateInfo( vk::ImageViewCreateFlags flags_ = vk::ImageViewCreateFlags(),
                                                vk::Image image_ = vk::Image(),
                                                vk::ImageViewType viewType_ = vk::ImageViewType::e1D,
                                                vk::Format format_ = vk::Format::eUndefined,
                                                vk::ComponentMapping components_ = vk::ComponentMapping(),
                                                vk::ImageSubresourceRange subresourceRange_ = vk::ImageSubresourceRange() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , image( image_ )
        , viewType( viewType_ )
        , format( format_ )
        , components( components_ )
        , subresourceRange( subresourceRange_ )
      {}

      ImageViewCreateInfo( VkImageViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewCreateInfo*>(this) = rhs;
      }

      ImageViewCreateInfo& operator=( VkImageViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageViewCreateInfo;
      const void* pNext = nullptr;
      vk::ImageViewCreateFlags flags;
      vk::Image image;
      vk::ImageViewType viewType;
      vk::Format format;
      vk::ComponentMapping components;
      vk::ImageSubresourceRange subresourceRange;
    };
    static_assert( sizeof( ImageViewCreateInfo ) == sizeof( VkImageViewCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ImageViewCreateInfo : public layout::ImageViewCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ImageViewCreateInfo( vk::ImageViewCreateFlags flags_ = vk::ImageViewCreateFlags(),
                                              vk::Image image_ = vk::Image(),
                                              vk::ImageViewType viewType_ = vk::ImageViewType::e1D,
                                              vk::Format format_ = vk::Format::eUndefined,
                                              vk::ComponentMapping components_ = vk::ComponentMapping(),
                                              vk::ImageSubresourceRange subresourceRange_ = vk::ImageSubresourceRange() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewCreateInfo( flags_, image_, viewType_, format_, components_, subresourceRange_ )
    {}

    ImageViewCreateInfo( VkImageViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewCreateInfo( rhs )
    {}

    ImageViewCreateInfo& operator=( VkImageViewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageViewCreateInfo::operator=(rhs);
      return *this;
    }

    ImageViewCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageViewCreateInfo & setFlags( vk::ImageViewCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ImageViewCreateInfo & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    ImageViewCreateInfo & setViewType( vk::ImageViewType viewType_ ) VULKAN_HPP_NOEXCEPT
    {
      viewType = viewType_;
      return *this;
    }

    ImageViewCreateInfo & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    ImageViewCreateInfo & setComponents( vk::ComponentMapping components_ ) VULKAN_HPP_NOEXCEPT
    {
      components = components_;
      return *this;
    }

    ImageViewCreateInfo & setSubresourceRange( vk::ImageSubresourceRange subresourceRange_ ) VULKAN_HPP_NOEXCEPT
    {
      subresourceRange = subresourceRange_;
      return *this;
    }

    operator VkImageViewCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageViewCreateInfo*>( this );
    }

    operator VkImageViewCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageViewCreateInfo*>( this );
    }

    bool operator==( ImageViewCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( image == rhs.image )
          && ( viewType == rhs.viewType )
          && ( format == rhs.format )
          && ( components == rhs.components )
          && ( subresourceRange == rhs.subresourceRange );
    }

    bool operator!=( ImageViewCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageViewCreateInfo::sType;
  };
  static_assert( sizeof( ImageViewCreateInfo ) == sizeof( VkImageViewCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageViewCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageViewHandleInfoNVX
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageViewHandleInfoNVX( vk::ImageView imageView_ = vk::ImageView(),
                                                   vk::DescriptorType descriptorType_ = vk::DescriptorType::eSampler,
                                                   vk::Sampler sampler_ = vk::Sampler() ) VULKAN_HPP_NOEXCEPT
        : imageView( imageView_ )
        , descriptorType( descriptorType_ )
        , sampler( sampler_ )
      {}

      ImageViewHandleInfoNVX( VkImageViewHandleInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewHandleInfoNVX*>(this) = rhs;
      }

      ImageViewHandleInfoNVX& operator=( VkImageViewHandleInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewHandleInfoNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageViewHandleInfoNVX;
      const void* pNext = nullptr;
      vk::ImageView imageView;
      vk::DescriptorType descriptorType;
      vk::Sampler sampler;
    };
    static_assert( sizeof( ImageViewHandleInfoNVX ) == sizeof( VkImageViewHandleInfoNVX ), "layout struct and wrapper have different size!" );
  }

  struct ImageViewHandleInfoNVX : public layout::ImageViewHandleInfoNVX
  {
    VULKAN_HPP_CONSTEXPR ImageViewHandleInfoNVX( vk::ImageView imageView_ = vk::ImageView(),
                                                 vk::DescriptorType descriptorType_ = vk::DescriptorType::eSampler,
                                                 vk::Sampler sampler_ = vk::Sampler() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewHandleInfoNVX( imageView_, descriptorType_, sampler_ )
    {}

    ImageViewHandleInfoNVX( VkImageViewHandleInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewHandleInfoNVX( rhs )
    {}

    ImageViewHandleInfoNVX& operator=( VkImageViewHandleInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageViewHandleInfoNVX::operator=(rhs);
      return *this;
    }

    ImageViewHandleInfoNVX & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageViewHandleInfoNVX & setImageView( vk::ImageView imageView_ ) VULKAN_HPP_NOEXCEPT
    {
      imageView = imageView_;
      return *this;
    }

    ImageViewHandleInfoNVX & setDescriptorType( vk::DescriptorType descriptorType_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorType = descriptorType_;
      return *this;
    }

    ImageViewHandleInfoNVX & setSampler( vk::Sampler sampler_ ) VULKAN_HPP_NOEXCEPT
    {
      sampler = sampler_;
      return *this;
    }

    operator VkImageViewHandleInfoNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageViewHandleInfoNVX*>( this );
    }

    operator VkImageViewHandleInfoNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageViewHandleInfoNVX*>( this );
    }

    bool operator==( ImageViewHandleInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( imageView == rhs.imageView )
          && ( descriptorType == rhs.descriptorType )
          && ( sampler == rhs.sampler );
    }

    bool operator!=( ImageViewHandleInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageViewHandleInfoNVX::sType;
  };
  static_assert( sizeof( ImageViewHandleInfoNVX ) == sizeof( VkImageViewHandleInfoNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageViewHandleInfoNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImageViewUsageCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImageViewUsageCreateInfo( vk::ImageUsageFlags usage_ = vk::ImageUsageFlags() ) VULKAN_HPP_NOEXCEPT
        : usage( usage_ )
      {}

      ImageViewUsageCreateInfo( VkImageViewUsageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewUsageCreateInfo*>(this) = rhs;
      }

      ImageViewUsageCreateInfo& operator=( VkImageViewUsageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImageViewUsageCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImageViewUsageCreateInfo;
      const void* pNext = nullptr;
      vk::ImageUsageFlags usage;
    };
    static_assert( sizeof( ImageViewUsageCreateInfo ) == sizeof( VkImageViewUsageCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ImageViewUsageCreateInfo : public layout::ImageViewUsageCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ImageViewUsageCreateInfo( vk::ImageUsageFlags usage_ = vk::ImageUsageFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewUsageCreateInfo( usage_ )
    {}

    ImageViewUsageCreateInfo( VkImageViewUsageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImageViewUsageCreateInfo( rhs )
    {}

    ImageViewUsageCreateInfo& operator=( VkImageViewUsageCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImageViewUsageCreateInfo::operator=(rhs);
      return *this;
    }

    ImageViewUsageCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImageViewUsageCreateInfo & setUsage( vk::ImageUsageFlags usage_ ) VULKAN_HPP_NOEXCEPT
    {
      usage = usage_;
      return *this;
    }

    operator VkImageViewUsageCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImageViewUsageCreateInfo*>( this );
    }

    operator VkImageViewUsageCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImageViewUsageCreateInfo*>( this );
    }

    bool operator==( ImageViewUsageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( usage == rhs.usage );
    }

    bool operator!=( ImageViewUsageCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImageViewUsageCreateInfo::sType;
  };
  static_assert( sizeof( ImageViewUsageCreateInfo ) == sizeof( VkImageViewUsageCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImageViewUsageCreateInfo>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_ANDROID_KHR

  namespace layout
  {
    struct ImportAndroidHardwareBufferInfoANDROID
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportAndroidHardwareBufferInfoANDROID( struct AHardwareBuffer* buffer_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : buffer( buffer_ )
      {}

      ImportAndroidHardwareBufferInfoANDROID( VkImportAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportAndroidHardwareBufferInfoANDROID*>(this) = rhs;
      }

      ImportAndroidHardwareBufferInfoANDROID& operator=( VkImportAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportAndroidHardwareBufferInfoANDROID*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportAndroidHardwareBufferInfoANDROID;
      const void* pNext = nullptr;
      struct AHardwareBuffer* buffer;
    };
    static_assert( sizeof( ImportAndroidHardwareBufferInfoANDROID ) == sizeof( VkImportAndroidHardwareBufferInfoANDROID ), "layout struct and wrapper have different size!" );
  }

  struct ImportAndroidHardwareBufferInfoANDROID : public layout::ImportAndroidHardwareBufferInfoANDROID
  {
    VULKAN_HPP_CONSTEXPR ImportAndroidHardwareBufferInfoANDROID( struct AHardwareBuffer* buffer_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImportAndroidHardwareBufferInfoANDROID( buffer_ )
    {}

    ImportAndroidHardwareBufferInfoANDROID( VkImportAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportAndroidHardwareBufferInfoANDROID( rhs )
    {}

    ImportAndroidHardwareBufferInfoANDROID& operator=( VkImportAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportAndroidHardwareBufferInfoANDROID::operator=(rhs);
      return *this;
    }

    ImportAndroidHardwareBufferInfoANDROID & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportAndroidHardwareBufferInfoANDROID & setBuffer( struct AHardwareBuffer* buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    operator VkImportAndroidHardwareBufferInfoANDROID const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportAndroidHardwareBufferInfoANDROID*>( this );
    }

    operator VkImportAndroidHardwareBufferInfoANDROID &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportAndroidHardwareBufferInfoANDROID*>( this );
    }

    bool operator==( ImportAndroidHardwareBufferInfoANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( buffer == rhs.buffer );
    }

    bool operator!=( ImportAndroidHardwareBufferInfoANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportAndroidHardwareBufferInfoANDROID::sType;
  };
  static_assert( sizeof( ImportAndroidHardwareBufferInfoANDROID ) == sizeof( VkImportAndroidHardwareBufferInfoANDROID ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportAndroidHardwareBufferInfoANDROID>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  namespace layout
  {
    struct ImportFenceFdInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportFenceFdInfoKHR( vk::Fence fence_ = vk::Fence(),
                                                 vk::FenceImportFlags flags_ = vk::FenceImportFlags(),
                                                 vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd,
                                                 int fd_ = 0 ) VULKAN_HPP_NOEXCEPT
        : fence( fence_ )
        , flags( flags_ )
        , handleType( handleType_ )
        , fd( fd_ )
      {}

      ImportFenceFdInfoKHR( VkImportFenceFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportFenceFdInfoKHR*>(this) = rhs;
      }

      ImportFenceFdInfoKHR& operator=( VkImportFenceFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportFenceFdInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportFenceFdInfoKHR;
      const void* pNext = nullptr;
      vk::Fence fence;
      vk::FenceImportFlags flags;
      vk::ExternalFenceHandleTypeFlagBits handleType;
      int fd;
    };
    static_assert( sizeof( ImportFenceFdInfoKHR ) == sizeof( VkImportFenceFdInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImportFenceFdInfoKHR : public layout::ImportFenceFdInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImportFenceFdInfoKHR( vk::Fence fence_ = vk::Fence(),
                                               vk::FenceImportFlags flags_ = vk::FenceImportFlags(),
                                               vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd,
                                               int fd_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ImportFenceFdInfoKHR( fence_, flags_, handleType_, fd_ )
    {}

    ImportFenceFdInfoKHR( VkImportFenceFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportFenceFdInfoKHR( rhs )
    {}

    ImportFenceFdInfoKHR& operator=( VkImportFenceFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportFenceFdInfoKHR::operator=(rhs);
      return *this;
    }

    ImportFenceFdInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportFenceFdInfoKHR & setFence( vk::Fence fence_ ) VULKAN_HPP_NOEXCEPT
    {
      fence = fence_;
      return *this;
    }

    ImportFenceFdInfoKHR & setFlags( vk::FenceImportFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ImportFenceFdInfoKHR & setHandleType( vk::ExternalFenceHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportFenceFdInfoKHR & setFd( int fd_ ) VULKAN_HPP_NOEXCEPT
    {
      fd = fd_;
      return *this;
    }

    operator VkImportFenceFdInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportFenceFdInfoKHR*>( this );
    }

    operator VkImportFenceFdInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportFenceFdInfoKHR*>( this );
    }

    bool operator==( ImportFenceFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fence == rhs.fence )
          && ( flags == rhs.flags )
          && vk::operator==( handleType, rhs.handleType )
          && ( fd == rhs.fd );
    }

    bool operator!=( ImportFenceFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportFenceFdInfoKHR::sType;
  };
  static_assert( sizeof( ImportFenceFdInfoKHR ) == sizeof( VkImportFenceFdInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportFenceFdInfoKHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ImportFenceWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportFenceWin32HandleInfoKHR( vk::Fence fence_ = vk::Fence(),
                                                          vk::FenceImportFlags flags_ = vk::FenceImportFlags(),
                                                          vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd,
                                                          HANDLE handle_ = 0,
                                                          LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : fence( fence_ )
        , flags( flags_ )
        , handleType( handleType_ )
        , handle( handle_ )
        , name( name_ )
      {}

      ImportFenceWin32HandleInfoKHR( VkImportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportFenceWin32HandleInfoKHR*>(this) = rhs;
      }

      ImportFenceWin32HandleInfoKHR& operator=( VkImportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportFenceWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportFenceWin32HandleInfoKHR;
      const void* pNext = nullptr;
      vk::Fence fence;
      vk::FenceImportFlags flags;
      vk::ExternalFenceHandleTypeFlagBits handleType;
      HANDLE handle;
      LPCWSTR name;
    };
    static_assert( sizeof( ImportFenceWin32HandleInfoKHR ) == sizeof( VkImportFenceWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImportFenceWin32HandleInfoKHR : public layout::ImportFenceWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImportFenceWin32HandleInfoKHR( vk::Fence fence_ = vk::Fence(),
                                                        vk::FenceImportFlags flags_ = vk::FenceImportFlags(),
                                                        vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd,
                                                        HANDLE handle_ = 0,
                                                        LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImportFenceWin32HandleInfoKHR( fence_, flags_, handleType_, handle_, name_ )
    {}

    ImportFenceWin32HandleInfoKHR( VkImportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportFenceWin32HandleInfoKHR( rhs )
    {}

    ImportFenceWin32HandleInfoKHR& operator=( VkImportFenceWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportFenceWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    ImportFenceWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportFenceWin32HandleInfoKHR & setFence( vk::Fence fence_ ) VULKAN_HPP_NOEXCEPT
    {
      fence = fence_;
      return *this;
    }

    ImportFenceWin32HandleInfoKHR & setFlags( vk::FenceImportFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ImportFenceWin32HandleInfoKHR & setHandleType( vk::ExternalFenceHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportFenceWin32HandleInfoKHR & setHandle( HANDLE handle_ ) VULKAN_HPP_NOEXCEPT
    {
      handle = handle_;
      return *this;
    }

    ImportFenceWin32HandleInfoKHR & setName( LPCWSTR name_ ) VULKAN_HPP_NOEXCEPT
    {
      name = name_;
      return *this;
    }

    operator VkImportFenceWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportFenceWin32HandleInfoKHR*>( this );
    }

    operator VkImportFenceWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportFenceWin32HandleInfoKHR*>( this );
    }

    bool operator==( ImportFenceWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fence == rhs.fence )
          && ( flags == rhs.flags )
          && vk::operator==( handleType, rhs.handleType )
          && ( handle == rhs.handle )
          && ( name == rhs.name );
    }

    bool operator!=( ImportFenceWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportFenceWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( ImportFenceWin32HandleInfoKHR ) == sizeof( VkImportFenceWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportFenceWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct ImportMemoryFdInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportMemoryFdInfoKHR( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd,
                                                  int fd_ = 0 ) VULKAN_HPP_NOEXCEPT
        : handleType( handleType_ )
        , fd( fd_ )
      {}

      ImportMemoryFdInfoKHR( VkImportMemoryFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryFdInfoKHR*>(this) = rhs;
      }

      ImportMemoryFdInfoKHR& operator=( VkImportMemoryFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryFdInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportMemoryFdInfoKHR;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlagBits handleType;
      int fd;
    };
    static_assert( sizeof( ImportMemoryFdInfoKHR ) == sizeof( VkImportMemoryFdInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImportMemoryFdInfoKHR : public layout::ImportMemoryFdInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImportMemoryFdInfoKHR( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd,
                                                int fd_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryFdInfoKHR( handleType_, fd_ )
    {}

    ImportMemoryFdInfoKHR( VkImportMemoryFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryFdInfoKHR( rhs )
    {}

    ImportMemoryFdInfoKHR& operator=( VkImportMemoryFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportMemoryFdInfoKHR::operator=(rhs);
      return *this;
    }

    ImportMemoryFdInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportMemoryFdInfoKHR & setHandleType( vk::ExternalMemoryHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportMemoryFdInfoKHR & setFd( int fd_ ) VULKAN_HPP_NOEXCEPT
    {
      fd = fd_;
      return *this;
    }

    operator VkImportMemoryFdInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportMemoryFdInfoKHR*>( this );
    }

    operator VkImportMemoryFdInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportMemoryFdInfoKHR*>( this );
    }

    bool operator==( ImportMemoryFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( handleType, rhs.handleType )
          && ( fd == rhs.fd );
    }

    bool operator!=( ImportMemoryFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportMemoryFdInfoKHR::sType;
  };
  static_assert( sizeof( ImportMemoryFdInfoKHR ) == sizeof( VkImportMemoryFdInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportMemoryFdInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ImportMemoryHostPointerInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportMemoryHostPointerInfoEXT( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd,
                                                           void* pHostPointer_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : handleType( handleType_ )
        , pHostPointer( pHostPointer_ )
      {}

      ImportMemoryHostPointerInfoEXT( VkImportMemoryHostPointerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryHostPointerInfoEXT*>(this) = rhs;
      }

      ImportMemoryHostPointerInfoEXT& operator=( VkImportMemoryHostPointerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryHostPointerInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportMemoryHostPointerInfoEXT;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlagBits handleType;
      void* pHostPointer;
    };
    static_assert( sizeof( ImportMemoryHostPointerInfoEXT ) == sizeof( VkImportMemoryHostPointerInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct ImportMemoryHostPointerInfoEXT : public layout::ImportMemoryHostPointerInfoEXT
  {
    VULKAN_HPP_CONSTEXPR ImportMemoryHostPointerInfoEXT( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd,
                                                         void* pHostPointer_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryHostPointerInfoEXT( handleType_, pHostPointer_ )
    {}

    ImportMemoryHostPointerInfoEXT( VkImportMemoryHostPointerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryHostPointerInfoEXT( rhs )
    {}

    ImportMemoryHostPointerInfoEXT& operator=( VkImportMemoryHostPointerInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportMemoryHostPointerInfoEXT::operator=(rhs);
      return *this;
    }

    ImportMemoryHostPointerInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportMemoryHostPointerInfoEXT & setHandleType( vk::ExternalMemoryHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportMemoryHostPointerInfoEXT & setPHostPointer( void* pHostPointer_ ) VULKAN_HPP_NOEXCEPT
    {
      pHostPointer = pHostPointer_;
      return *this;
    }

    operator VkImportMemoryHostPointerInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportMemoryHostPointerInfoEXT*>( this );
    }

    operator VkImportMemoryHostPointerInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportMemoryHostPointerInfoEXT*>( this );
    }

    bool operator==( ImportMemoryHostPointerInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( handleType, rhs.handleType )
          && ( pHostPointer == rhs.pHostPointer );
    }

    bool operator!=( ImportMemoryHostPointerInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportMemoryHostPointerInfoEXT::sType;
  };
  static_assert( sizeof( ImportMemoryHostPointerInfoEXT ) == sizeof( VkImportMemoryHostPointerInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportMemoryHostPointerInfoEXT>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ImportMemoryWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportMemoryWin32HandleInfoKHR( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd,
                                                           HANDLE handle_ = 0,
                                                           LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : handleType( handleType_ )
        , handle( handle_ )
        , name( name_ )
      {}

      ImportMemoryWin32HandleInfoKHR( VkImportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryWin32HandleInfoKHR*>(this) = rhs;
      }

      ImportMemoryWin32HandleInfoKHR& operator=( VkImportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportMemoryWin32HandleInfoKHR;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlagBits handleType;
      HANDLE handle;
      LPCWSTR name;
    };
    static_assert( sizeof( ImportMemoryWin32HandleInfoKHR ) == sizeof( VkImportMemoryWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImportMemoryWin32HandleInfoKHR : public layout::ImportMemoryWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImportMemoryWin32HandleInfoKHR( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd,
                                                         HANDLE handle_ = 0,
                                                         LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryWin32HandleInfoKHR( handleType_, handle_, name_ )
    {}

    ImportMemoryWin32HandleInfoKHR( VkImportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryWin32HandleInfoKHR( rhs )
    {}

    ImportMemoryWin32HandleInfoKHR& operator=( VkImportMemoryWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportMemoryWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    ImportMemoryWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportMemoryWin32HandleInfoKHR & setHandleType( vk::ExternalMemoryHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportMemoryWin32HandleInfoKHR & setHandle( HANDLE handle_ ) VULKAN_HPP_NOEXCEPT
    {
      handle = handle_;
      return *this;
    }

    ImportMemoryWin32HandleInfoKHR & setName( LPCWSTR name_ ) VULKAN_HPP_NOEXCEPT
    {
      name = name_;
      return *this;
    }

    operator VkImportMemoryWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportMemoryWin32HandleInfoKHR*>( this );
    }

    operator VkImportMemoryWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportMemoryWin32HandleInfoKHR*>( this );
    }

    bool operator==( ImportMemoryWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( handleType, rhs.handleType )
          && ( handle == rhs.handle )
          && ( name == rhs.name );
    }

    bool operator!=( ImportMemoryWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportMemoryWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( ImportMemoryWin32HandleInfoKHR ) == sizeof( VkImportMemoryWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportMemoryWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ImportMemoryWin32HandleInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportMemoryWin32HandleInfoNV( vk::ExternalMemoryHandleTypeFlagsNV handleType_ = vk::ExternalMemoryHandleTypeFlagsNV(),
                                                          HANDLE handle_ = 0 ) VULKAN_HPP_NOEXCEPT
        : handleType( handleType_ )
        , handle( handle_ )
      {}

      ImportMemoryWin32HandleInfoNV( VkImportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryWin32HandleInfoNV*>(this) = rhs;
      }

      ImportMemoryWin32HandleInfoNV& operator=( VkImportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportMemoryWin32HandleInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportMemoryWin32HandleInfoNV;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlagsNV handleType;
      HANDLE handle;
    };
    static_assert( sizeof( ImportMemoryWin32HandleInfoNV ) == sizeof( VkImportMemoryWin32HandleInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct ImportMemoryWin32HandleInfoNV : public layout::ImportMemoryWin32HandleInfoNV
  {
    VULKAN_HPP_CONSTEXPR ImportMemoryWin32HandleInfoNV( vk::ExternalMemoryHandleTypeFlagsNV handleType_ = vk::ExternalMemoryHandleTypeFlagsNV(),
                                                        HANDLE handle_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryWin32HandleInfoNV( handleType_, handle_ )
    {}

    ImportMemoryWin32HandleInfoNV( VkImportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportMemoryWin32HandleInfoNV( rhs )
    {}

    ImportMemoryWin32HandleInfoNV& operator=( VkImportMemoryWin32HandleInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportMemoryWin32HandleInfoNV::operator=(rhs);
      return *this;
    }

    ImportMemoryWin32HandleInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportMemoryWin32HandleInfoNV & setHandleType( vk::ExternalMemoryHandleTypeFlagsNV handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportMemoryWin32HandleInfoNV & setHandle( HANDLE handle_ ) VULKAN_HPP_NOEXCEPT
    {
      handle = handle_;
      return *this;
    }

    operator VkImportMemoryWin32HandleInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportMemoryWin32HandleInfoNV*>( this );
    }

    operator VkImportMemoryWin32HandleInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportMemoryWin32HandleInfoNV*>( this );
    }

    bool operator==( ImportMemoryWin32HandleInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( handleType == rhs.handleType )
          && ( handle == rhs.handle );
    }

    bool operator!=( ImportMemoryWin32HandleInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportMemoryWin32HandleInfoNV::sType;
  };
  static_assert( sizeof( ImportMemoryWin32HandleInfoNV ) == sizeof( VkImportMemoryWin32HandleInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportMemoryWin32HandleInfoNV>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct ImportSemaphoreFdInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportSemaphoreFdInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                     vk::SemaphoreImportFlags flags_ = vk::SemaphoreImportFlags(),
                                                     vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd,
                                                     int fd_ = 0 ) VULKAN_HPP_NOEXCEPT
        : semaphore( semaphore_ )
        , flags( flags_ )
        , handleType( handleType_ )
        , fd( fd_ )
      {}

      ImportSemaphoreFdInfoKHR( VkImportSemaphoreFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportSemaphoreFdInfoKHR*>(this) = rhs;
      }

      ImportSemaphoreFdInfoKHR& operator=( VkImportSemaphoreFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportSemaphoreFdInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportSemaphoreFdInfoKHR;
      const void* pNext = nullptr;
      vk::Semaphore semaphore;
      vk::SemaphoreImportFlags flags;
      vk::ExternalSemaphoreHandleTypeFlagBits handleType;
      int fd;
    };
    static_assert( sizeof( ImportSemaphoreFdInfoKHR ) == sizeof( VkImportSemaphoreFdInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImportSemaphoreFdInfoKHR : public layout::ImportSemaphoreFdInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImportSemaphoreFdInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                   vk::SemaphoreImportFlags flags_ = vk::SemaphoreImportFlags(),
                                                   vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd,
                                                   int fd_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ImportSemaphoreFdInfoKHR( semaphore_, flags_, handleType_, fd_ )
    {}

    ImportSemaphoreFdInfoKHR( VkImportSemaphoreFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportSemaphoreFdInfoKHR( rhs )
    {}

    ImportSemaphoreFdInfoKHR& operator=( VkImportSemaphoreFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportSemaphoreFdInfoKHR::operator=(rhs);
      return *this;
    }

    ImportSemaphoreFdInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportSemaphoreFdInfoKHR & setSemaphore( vk::Semaphore semaphore_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphore = semaphore_;
      return *this;
    }

    ImportSemaphoreFdInfoKHR & setFlags( vk::SemaphoreImportFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ImportSemaphoreFdInfoKHR & setHandleType( vk::ExternalSemaphoreHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportSemaphoreFdInfoKHR & setFd( int fd_ ) VULKAN_HPP_NOEXCEPT
    {
      fd = fd_;
      return *this;
    }

    operator VkImportSemaphoreFdInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportSemaphoreFdInfoKHR*>( this );
    }

    operator VkImportSemaphoreFdInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportSemaphoreFdInfoKHR*>( this );
    }

    bool operator==( ImportSemaphoreFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( semaphore == rhs.semaphore )
          && ( flags == rhs.flags )
          && vk::operator==( handleType, rhs.handleType )
          && ( fd == rhs.fd );
    }

    bool operator!=( ImportSemaphoreFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportSemaphoreFdInfoKHR::sType;
  };
  static_assert( sizeof( ImportSemaphoreFdInfoKHR ) == sizeof( VkImportSemaphoreFdInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportSemaphoreFdInfoKHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct ImportSemaphoreWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR ImportSemaphoreWin32HandleInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                              vk::SemaphoreImportFlags flags_ = vk::SemaphoreImportFlags(),
                                                              vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd,
                                                              HANDLE handle_ = 0,
                                                              LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : semaphore( semaphore_ )
        , flags( flags_ )
        , handleType( handleType_ )
        , handle( handle_ )
        , name( name_ )
      {}

      ImportSemaphoreWin32HandleInfoKHR( VkImportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportSemaphoreWin32HandleInfoKHR*>(this) = rhs;
      }

      ImportSemaphoreWin32HandleInfoKHR& operator=( VkImportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkImportSemaphoreWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eImportSemaphoreWin32HandleInfoKHR;
      const void* pNext = nullptr;
      vk::Semaphore semaphore;
      vk::SemaphoreImportFlags flags;
      vk::ExternalSemaphoreHandleTypeFlagBits handleType;
      HANDLE handle;
      LPCWSTR name;
    };
    static_assert( sizeof( ImportSemaphoreWin32HandleInfoKHR ) == sizeof( VkImportSemaphoreWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct ImportSemaphoreWin32HandleInfoKHR : public layout::ImportSemaphoreWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR ImportSemaphoreWin32HandleInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                            vk::SemaphoreImportFlags flags_ = vk::SemaphoreImportFlags(),
                                                            vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd,
                                                            HANDLE handle_ = 0,
                                                            LPCWSTR name_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ImportSemaphoreWin32HandleInfoKHR( semaphore_, flags_, handleType_, handle_, name_ )
    {}

    ImportSemaphoreWin32HandleInfoKHR( VkImportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ImportSemaphoreWin32HandleInfoKHR( rhs )
    {}

    ImportSemaphoreWin32HandleInfoKHR& operator=( VkImportSemaphoreWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ImportSemaphoreWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    ImportSemaphoreWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ImportSemaphoreWin32HandleInfoKHR & setSemaphore( vk::Semaphore semaphore_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphore = semaphore_;
      return *this;
    }

    ImportSemaphoreWin32HandleInfoKHR & setFlags( vk::SemaphoreImportFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ImportSemaphoreWin32HandleInfoKHR & setHandleType( vk::ExternalSemaphoreHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    ImportSemaphoreWin32HandleInfoKHR & setHandle( HANDLE handle_ ) VULKAN_HPP_NOEXCEPT
    {
      handle = handle_;
      return *this;
    }

    ImportSemaphoreWin32HandleInfoKHR & setName( LPCWSTR name_ ) VULKAN_HPP_NOEXCEPT
    {
      name = name_;
      return *this;
    }

    operator VkImportSemaphoreWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkImportSemaphoreWin32HandleInfoKHR*>( this );
    }

    operator VkImportSemaphoreWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkImportSemaphoreWin32HandleInfoKHR*>( this );
    }

    bool operator==( ImportSemaphoreWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( semaphore == rhs.semaphore )
          && ( flags == rhs.flags )
          && vk::operator==( handleType, rhs.handleType )
          && ( handle == rhs.handle )
          && ( name == rhs.name );
    }

    bool operator!=( ImportSemaphoreWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ImportSemaphoreWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( ImportSemaphoreWin32HandleInfoKHR ) == sizeof( VkImportSemaphoreWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ImportSemaphoreWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  struct IndirectCommandsLayoutTokenNVX
  {
    VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutTokenNVX( vk::IndirectCommandsTokenTypeNVX tokenType_ = vk::IndirectCommandsTokenTypeNVX::ePipeline,
                                                         uint32_t bindingUnit_ = 0,
                                                         uint32_t dynamicCount_ = 0,
                                                         uint32_t divisor_ = 0 ) VULKAN_HPP_NOEXCEPT
      : tokenType( tokenType_ )
      , bindingUnit( bindingUnit_ )
      , dynamicCount( dynamicCount_ )
      , divisor( divisor_ )
    {}

    IndirectCommandsLayoutTokenNVX( VkIndirectCommandsLayoutTokenNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkIndirectCommandsLayoutTokenNVX*>(this) = rhs;
    }

    IndirectCommandsLayoutTokenNVX& operator=( VkIndirectCommandsLayoutTokenNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkIndirectCommandsLayoutTokenNVX*>(this) = rhs;
      return *this;
    }

    IndirectCommandsLayoutTokenNVX & setTokenType( vk::IndirectCommandsTokenTypeNVX tokenType_ ) VULKAN_HPP_NOEXCEPT
    {
      tokenType = tokenType_;
      return *this;
    }

    IndirectCommandsLayoutTokenNVX & setBindingUnit( uint32_t bindingUnit_ ) VULKAN_HPP_NOEXCEPT
    {
      bindingUnit = bindingUnit_;
      return *this;
    }

    IndirectCommandsLayoutTokenNVX & setDynamicCount( uint32_t dynamicCount_ ) VULKAN_HPP_NOEXCEPT
    {
      dynamicCount = dynamicCount_;
      return *this;
    }

    IndirectCommandsLayoutTokenNVX & setDivisor( uint32_t divisor_ ) VULKAN_HPP_NOEXCEPT
    {
      divisor = divisor_;
      return *this;
    }

    operator VkIndirectCommandsLayoutTokenNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkIndirectCommandsLayoutTokenNVX*>( this );
    }

    operator VkIndirectCommandsLayoutTokenNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkIndirectCommandsLayoutTokenNVX*>( this );
    }

    bool operator==( IndirectCommandsLayoutTokenNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( tokenType == rhs.tokenType )
          && ( bindingUnit == rhs.bindingUnit )
          && ( dynamicCount == rhs.dynamicCount )
          && ( divisor == rhs.divisor );
    }

    bool operator!=( IndirectCommandsLayoutTokenNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::IndirectCommandsTokenTypeNVX tokenType;
    uint32_t bindingUnit;
    uint32_t dynamicCount;
    uint32_t divisor;
  };
  static_assert( sizeof( IndirectCommandsLayoutTokenNVX ) == sizeof( VkIndirectCommandsLayoutTokenNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<IndirectCommandsLayoutTokenNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct IndirectCommandsLayoutCreateInfoNVX
    {
    protected:
      VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutCreateInfoNVX( vk::PipelineBindPoint pipelineBindPoint_ = vk::PipelineBindPoint::eGraphics,
                                                                vk::IndirectCommandsLayoutUsageFlagsNVX flags_ = vk::IndirectCommandsLayoutUsageFlagsNVX(),
                                                                uint32_t tokenCount_ = 0,
                                                                const vk::IndirectCommandsLayoutTokenNVX* pTokens_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : pipelineBindPoint( pipelineBindPoint_ )
        , flags( flags_ )
        , tokenCount( tokenCount_ )
        , pTokens( pTokens_ )
      {}

      IndirectCommandsLayoutCreateInfoNVX( VkIndirectCommandsLayoutCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkIndirectCommandsLayoutCreateInfoNVX*>(this) = rhs;
      }

      IndirectCommandsLayoutCreateInfoNVX& operator=( VkIndirectCommandsLayoutCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkIndirectCommandsLayoutCreateInfoNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eIndirectCommandsLayoutCreateInfoNVX;
      const void* pNext = nullptr;
      vk::PipelineBindPoint pipelineBindPoint;
      vk::IndirectCommandsLayoutUsageFlagsNVX flags;
      uint32_t tokenCount;
      const vk::IndirectCommandsLayoutTokenNVX* pTokens;
    };
    static_assert( sizeof( IndirectCommandsLayoutCreateInfoNVX ) == sizeof( VkIndirectCommandsLayoutCreateInfoNVX ), "layout struct and wrapper have different size!" );
  }

  struct IndirectCommandsLayoutCreateInfoNVX : public layout::IndirectCommandsLayoutCreateInfoNVX
  {
    VULKAN_HPP_CONSTEXPR IndirectCommandsLayoutCreateInfoNVX( vk::PipelineBindPoint pipelineBindPoint_ = vk::PipelineBindPoint::eGraphics,
                                                              vk::IndirectCommandsLayoutUsageFlagsNVX flags_ = vk::IndirectCommandsLayoutUsageFlagsNVX(),
                                                              uint32_t tokenCount_ = 0,
                                                              const vk::IndirectCommandsLayoutTokenNVX* pTokens_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::IndirectCommandsLayoutCreateInfoNVX( pipelineBindPoint_, flags_, tokenCount_, pTokens_ )
    {}

    IndirectCommandsLayoutCreateInfoNVX( VkIndirectCommandsLayoutCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::IndirectCommandsLayoutCreateInfoNVX( rhs )
    {}

    IndirectCommandsLayoutCreateInfoNVX& operator=( VkIndirectCommandsLayoutCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::IndirectCommandsLayoutCreateInfoNVX::operator=(rhs);
      return *this;
    }

    IndirectCommandsLayoutCreateInfoNVX & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    IndirectCommandsLayoutCreateInfoNVX & setPipelineBindPoint( vk::PipelineBindPoint pipelineBindPoint_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineBindPoint = pipelineBindPoint_;
      return *this;
    }

    IndirectCommandsLayoutCreateInfoNVX & setFlags( vk::IndirectCommandsLayoutUsageFlagsNVX flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    IndirectCommandsLayoutCreateInfoNVX & setTokenCount( uint32_t tokenCount_ ) VULKAN_HPP_NOEXCEPT
    {
      tokenCount = tokenCount_;
      return *this;
    }

    IndirectCommandsLayoutCreateInfoNVX & setPTokens( const vk::IndirectCommandsLayoutTokenNVX* pTokens_ ) VULKAN_HPP_NOEXCEPT
    {
      pTokens = pTokens_;
      return *this;
    }

    operator VkIndirectCommandsLayoutCreateInfoNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkIndirectCommandsLayoutCreateInfoNVX*>( this );
    }

    operator VkIndirectCommandsLayoutCreateInfoNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkIndirectCommandsLayoutCreateInfoNVX*>( this );
    }

    bool operator==( IndirectCommandsLayoutCreateInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pipelineBindPoint == rhs.pipelineBindPoint )
          && ( flags == rhs.flags )
          && ( tokenCount == rhs.tokenCount )
          && ( pTokens == rhs.pTokens );
    }

    bool operator!=( IndirectCommandsLayoutCreateInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::IndirectCommandsLayoutCreateInfoNVX::sType;
  };
  static_assert( sizeof( IndirectCommandsLayoutCreateInfoNVX ) == sizeof( VkIndirectCommandsLayoutCreateInfoNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<IndirectCommandsLayoutCreateInfoNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct InitializePerformanceApiInfoINTEL
    {
    protected:
      VULKAN_HPP_CONSTEXPR InitializePerformanceApiInfoINTEL( void* pUserData_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : pUserData( pUserData_ )
      {}

      InitializePerformanceApiInfoINTEL( VkInitializePerformanceApiInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkInitializePerformanceApiInfoINTEL*>(this) = rhs;
      }

      InitializePerformanceApiInfoINTEL& operator=( VkInitializePerformanceApiInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkInitializePerformanceApiInfoINTEL*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eInitializePerformanceApiInfoINTEL;
      const void* pNext = nullptr;
      void* pUserData;
    };
    static_assert( sizeof( InitializePerformanceApiInfoINTEL ) == sizeof( VkInitializePerformanceApiInfoINTEL ), "layout struct and wrapper have different size!" );
  }

  struct InitializePerformanceApiInfoINTEL : public layout::InitializePerformanceApiInfoINTEL
  {
    VULKAN_HPP_CONSTEXPR InitializePerformanceApiInfoINTEL( void* pUserData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::InitializePerformanceApiInfoINTEL( pUserData_ )
    {}

    InitializePerformanceApiInfoINTEL( VkInitializePerformanceApiInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::InitializePerformanceApiInfoINTEL( rhs )
    {}

    InitializePerformanceApiInfoINTEL& operator=( VkInitializePerformanceApiInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::InitializePerformanceApiInfoINTEL::operator=(rhs);
      return *this;
    }

    InitializePerformanceApiInfoINTEL & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    InitializePerformanceApiInfoINTEL & setPUserData( void* pUserData_ ) VULKAN_HPP_NOEXCEPT
    {
      pUserData = pUserData_;
      return *this;
    }

    operator VkInitializePerformanceApiInfoINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkInitializePerformanceApiInfoINTEL*>( this );
    }

    operator VkInitializePerformanceApiInfoINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkInitializePerformanceApiInfoINTEL*>( this );
    }

    bool operator==( InitializePerformanceApiInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pUserData == rhs.pUserData );
    }

    bool operator!=( InitializePerformanceApiInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::InitializePerformanceApiInfoINTEL::sType;
  };
  static_assert( sizeof( InitializePerformanceApiInfoINTEL ) == sizeof( VkInitializePerformanceApiInfoINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<InitializePerformanceApiInfoINTEL>::value, "struct wrapper is not a standard layout!" );

  struct InputAttachmentAspectReference
  {
    VULKAN_HPP_CONSTEXPR InputAttachmentAspectReference( uint32_t subpass_ = 0,
                                                         uint32_t inputAttachmentIndex_ = 0,
                                                         vk::ImageAspectFlags aspectMask_ = vk::ImageAspectFlags() ) VULKAN_HPP_NOEXCEPT
      : subpass( subpass_ )
      , inputAttachmentIndex( inputAttachmentIndex_ )
      , aspectMask( aspectMask_ )
    {}

    InputAttachmentAspectReference( VkInputAttachmentAspectReference const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkInputAttachmentAspectReference*>(this) = rhs;
    }

    InputAttachmentAspectReference& operator=( VkInputAttachmentAspectReference const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkInputAttachmentAspectReference*>(this) = rhs;
      return *this;
    }

    InputAttachmentAspectReference & setSubpass( uint32_t subpass_ ) VULKAN_HPP_NOEXCEPT
    {
      subpass = subpass_;
      return *this;
    }

    InputAttachmentAspectReference & setInputAttachmentIndex( uint32_t inputAttachmentIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      inputAttachmentIndex = inputAttachmentIndex_;
      return *this;
    }

    InputAttachmentAspectReference & setAspectMask( vk::ImageAspectFlags aspectMask_ ) VULKAN_HPP_NOEXCEPT
    {
      aspectMask = aspectMask_;
      return *this;
    }

    operator VkInputAttachmentAspectReference const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkInputAttachmentAspectReference*>( this );
    }

    operator VkInputAttachmentAspectReference &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkInputAttachmentAspectReference*>( this );
    }

    bool operator==( InputAttachmentAspectReference const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( subpass == rhs.subpass )
          && ( inputAttachmentIndex == rhs.inputAttachmentIndex )
          && ( aspectMask == rhs.aspectMask );
    }

    bool operator!=( InputAttachmentAspectReference const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t subpass;
    uint32_t inputAttachmentIndex;
    vk::ImageAspectFlags aspectMask;
  };
  static_assert( sizeof( InputAttachmentAspectReference ) == sizeof( VkInputAttachmentAspectReference ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<InputAttachmentAspectReference>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct InstanceCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR InstanceCreateInfo( vk::InstanceCreateFlags flags_ = vk::InstanceCreateFlags(),
                                               const vk::ApplicationInfo* pApplicationInfo_ = nullptr,
                                               uint32_t enabledLayerCount_ = 0,
                                               const char* const* ppEnabledLayerNames_ = nullptr,
                                               uint32_t enabledExtensionCount_ = 0,
                                               const char* const* ppEnabledExtensionNames_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pApplicationInfo( pApplicationInfo_ )
        , enabledLayerCount( enabledLayerCount_ )
        , ppEnabledLayerNames( ppEnabledLayerNames_ )
        , enabledExtensionCount( enabledExtensionCount_ )
        , ppEnabledExtensionNames( ppEnabledExtensionNames_ )
      {}

      InstanceCreateInfo( VkInstanceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkInstanceCreateInfo*>(this) = rhs;
      }

      InstanceCreateInfo& operator=( VkInstanceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkInstanceCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eInstanceCreateInfo;
      const void* pNext = nullptr;
      vk::InstanceCreateFlags flags;
      const vk::ApplicationInfo* pApplicationInfo;
      uint32_t enabledLayerCount;
      const char* const* ppEnabledLayerNames;
      uint32_t enabledExtensionCount;
      const char* const* ppEnabledExtensionNames;
    };
    static_assert( sizeof( InstanceCreateInfo ) == sizeof( VkInstanceCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct InstanceCreateInfo : public layout::InstanceCreateInfo
  {
    VULKAN_HPP_CONSTEXPR InstanceCreateInfo( vk::InstanceCreateFlags flags_ = vk::InstanceCreateFlags(),
                                             const vk::ApplicationInfo* pApplicationInfo_ = nullptr,
                                             uint32_t enabledLayerCount_ = 0,
                                             const char* const* ppEnabledLayerNames_ = nullptr,
                                             uint32_t enabledExtensionCount_ = 0,
                                             const char* const* ppEnabledExtensionNames_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::InstanceCreateInfo( flags_, pApplicationInfo_, enabledLayerCount_, ppEnabledLayerNames_, enabledExtensionCount_, ppEnabledExtensionNames_ )
    {}

    InstanceCreateInfo( VkInstanceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::InstanceCreateInfo( rhs )
    {}

    InstanceCreateInfo& operator=( VkInstanceCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::InstanceCreateInfo::operator=(rhs);
      return *this;
    }

    InstanceCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    InstanceCreateInfo & setFlags( vk::InstanceCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    InstanceCreateInfo & setPApplicationInfo( const vk::ApplicationInfo* pApplicationInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      pApplicationInfo = pApplicationInfo_;
      return *this;
    }

    InstanceCreateInfo & setEnabledLayerCount( uint32_t enabledLayerCount_ ) VULKAN_HPP_NOEXCEPT
    {
      enabledLayerCount = enabledLayerCount_;
      return *this;
    }

    InstanceCreateInfo & setPpEnabledLayerNames( const char* const* ppEnabledLayerNames_ ) VULKAN_HPP_NOEXCEPT
    {
      ppEnabledLayerNames = ppEnabledLayerNames_;
      return *this;
    }

    InstanceCreateInfo & setEnabledExtensionCount( uint32_t enabledExtensionCount_ ) VULKAN_HPP_NOEXCEPT
    {
      enabledExtensionCount = enabledExtensionCount_;
      return *this;
    }

    InstanceCreateInfo & setPpEnabledExtensionNames( const char* const* ppEnabledExtensionNames_ ) VULKAN_HPP_NOEXCEPT
    {
      ppEnabledExtensionNames = ppEnabledExtensionNames_;
      return *this;
    }

    operator VkInstanceCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkInstanceCreateInfo*>( this );
    }

    operator VkInstanceCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkInstanceCreateInfo*>( this );
    }

    bool operator==( InstanceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pApplicationInfo == rhs.pApplicationInfo )
          && ( enabledLayerCount == rhs.enabledLayerCount )
          && ( ppEnabledLayerNames == rhs.ppEnabledLayerNames )
          && ( enabledExtensionCount == rhs.enabledExtensionCount )
          && ( ppEnabledExtensionNames == rhs.ppEnabledExtensionNames );
    }

    bool operator!=( InstanceCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::InstanceCreateInfo::sType;
  };
  static_assert( sizeof( InstanceCreateInfo ) == sizeof( VkInstanceCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<InstanceCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct LayerProperties
  {
    LayerProperties() VULKAN_HPP_NOEXCEPT
    {}

    LayerProperties( VkLayerProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkLayerProperties*>(this) = rhs;
    }

    LayerProperties& operator=( VkLayerProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkLayerProperties*>(this) = rhs;
      return *this;
    }

    operator VkLayerProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkLayerProperties*>( this );
    }

    operator VkLayerProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkLayerProperties*>( this );
    }

    bool operator==( LayerProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( memcmp( layerName, rhs.layerName, VK_MAX_EXTENSION_NAME_SIZE * sizeof( char ) ) == 0 )
          && ( specVersion == rhs.specVersion )
          && ( implementationVersion == rhs.implementationVersion )
          && ( memcmp( description, rhs.description, VK_MAX_DESCRIPTION_SIZE * sizeof( char ) ) == 0 );
    }

    bool operator!=( LayerProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    char layerName[VK_MAX_EXTENSION_NAME_SIZE];
    uint32_t specVersion;
    uint32_t implementationVersion;
    char description[VK_MAX_DESCRIPTION_SIZE];
  };
  static_assert( sizeof( LayerProperties ) == sizeof( VkLayerProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<LayerProperties>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_MACOS_MVK

  namespace layout
  {
    struct MacOSSurfaceCreateInfoMVK
    {
    protected:
      VULKAN_HPP_CONSTEXPR MacOSSurfaceCreateInfoMVK( vk::MacOSSurfaceCreateFlagsMVK flags_ = vk::MacOSSurfaceCreateFlagsMVK(),
                                                      const void* pView_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pView( pView_ )
      {}

      MacOSSurfaceCreateInfoMVK( VkMacOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMacOSSurfaceCreateInfoMVK*>(this) = rhs;
      }

      MacOSSurfaceCreateInfoMVK& operator=( VkMacOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMacOSSurfaceCreateInfoMVK*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMacosSurfaceCreateInfoMVK;
      const void* pNext = nullptr;
      vk::MacOSSurfaceCreateFlagsMVK flags;
      const void* pView;
    };
    static_assert( sizeof( MacOSSurfaceCreateInfoMVK ) == sizeof( VkMacOSSurfaceCreateInfoMVK ), "layout struct and wrapper have different size!" );
  }

  struct MacOSSurfaceCreateInfoMVK : public layout::MacOSSurfaceCreateInfoMVK
  {
    VULKAN_HPP_CONSTEXPR MacOSSurfaceCreateInfoMVK( vk::MacOSSurfaceCreateFlagsMVK flags_ = vk::MacOSSurfaceCreateFlagsMVK(),
                                                    const void* pView_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::MacOSSurfaceCreateInfoMVK( flags_, pView_ )
    {}

    MacOSSurfaceCreateInfoMVK( VkMacOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MacOSSurfaceCreateInfoMVK( rhs )
    {}

    MacOSSurfaceCreateInfoMVK& operator=( VkMacOSSurfaceCreateInfoMVK const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MacOSSurfaceCreateInfoMVK::operator=(rhs);
      return *this;
    }

    MacOSSurfaceCreateInfoMVK & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MacOSSurfaceCreateInfoMVK & setFlags( vk::MacOSSurfaceCreateFlagsMVK flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    MacOSSurfaceCreateInfoMVK & setPView( const void* pView_ ) VULKAN_HPP_NOEXCEPT
    {
      pView = pView_;
      return *this;
    }

    operator VkMacOSSurfaceCreateInfoMVK const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMacOSSurfaceCreateInfoMVK*>( this );
    }

    operator VkMacOSSurfaceCreateInfoMVK &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMacOSSurfaceCreateInfoMVK*>( this );
    }

    bool operator==( MacOSSurfaceCreateInfoMVK const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pView == rhs.pView );
    }

    bool operator!=( MacOSSurfaceCreateInfoMVK const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MacOSSurfaceCreateInfoMVK::sType;
  };
  static_assert( sizeof( MacOSSurfaceCreateInfoMVK ) == sizeof( VkMacOSSurfaceCreateInfoMVK ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MacOSSurfaceCreateInfoMVK>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_MACOS_MVK*/

  namespace layout
  {
    struct MappedMemoryRange
    {
    protected:
      VULKAN_HPP_CONSTEXPR MappedMemoryRange( vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                              vk::DeviceSize offset_ = 0,
                                              vk::DeviceSize size_ = 0 ) VULKAN_HPP_NOEXCEPT
        : memory( memory_ )
        , offset( offset_ )
        , size( size_ )
      {}

      MappedMemoryRange( VkMappedMemoryRange const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMappedMemoryRange*>(this) = rhs;
      }

      MappedMemoryRange& operator=( VkMappedMemoryRange const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMappedMemoryRange*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMappedMemoryRange;
      const void* pNext = nullptr;
      vk::DeviceMemory memory;
      vk::DeviceSize offset;
      vk::DeviceSize size;
    };
    static_assert( sizeof( MappedMemoryRange ) == sizeof( VkMappedMemoryRange ), "layout struct and wrapper have different size!" );
  }

  struct MappedMemoryRange : public layout::MappedMemoryRange
  {
    VULKAN_HPP_CONSTEXPR MappedMemoryRange( vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                            vk::DeviceSize offset_ = 0,
                                            vk::DeviceSize size_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::MappedMemoryRange( memory_, offset_, size_ )
    {}

    MappedMemoryRange( VkMappedMemoryRange const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MappedMemoryRange( rhs )
    {}

    MappedMemoryRange& operator=( VkMappedMemoryRange const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MappedMemoryRange::operator=(rhs);
      return *this;
    }

    MappedMemoryRange & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MappedMemoryRange & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    MappedMemoryRange & setOffset( vk::DeviceSize offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    MappedMemoryRange & setSize( vk::DeviceSize size_ ) VULKAN_HPP_NOEXCEPT
    {
      size = size_;
      return *this;
    }

    operator VkMappedMemoryRange const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMappedMemoryRange*>( this );
    }

    operator VkMappedMemoryRange &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMappedMemoryRange*>( this );
    }

    bool operator==( MappedMemoryRange const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memory == rhs.memory )
          && ( offset == rhs.offset )
          && ( size == rhs.size );
    }

    bool operator!=( MappedMemoryRange const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MappedMemoryRange::sType;
  };
  static_assert( sizeof( MappedMemoryRange ) == sizeof( VkMappedMemoryRange ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MappedMemoryRange>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryAllocateFlagsInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryAllocateFlagsInfo( vk::MemoryAllocateFlags flags_ = vk::MemoryAllocateFlags(),
                                                    uint32_t deviceMask_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , deviceMask( deviceMask_ )
      {}

      MemoryAllocateFlagsInfo( VkMemoryAllocateFlagsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryAllocateFlagsInfo*>(this) = rhs;
      }

      MemoryAllocateFlagsInfo& operator=( VkMemoryAllocateFlagsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryAllocateFlagsInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryAllocateFlagsInfo;
      const void* pNext = nullptr;
      vk::MemoryAllocateFlags flags;
      uint32_t deviceMask;
    };
    static_assert( sizeof( MemoryAllocateFlagsInfo ) == sizeof( VkMemoryAllocateFlagsInfo ), "layout struct and wrapper have different size!" );
  }

  struct MemoryAllocateFlagsInfo : public layout::MemoryAllocateFlagsInfo
  {
    VULKAN_HPP_CONSTEXPR MemoryAllocateFlagsInfo( vk::MemoryAllocateFlags flags_ = vk::MemoryAllocateFlags(),
                                                  uint32_t deviceMask_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryAllocateFlagsInfo( flags_, deviceMask_ )
    {}

    MemoryAllocateFlagsInfo( VkMemoryAllocateFlagsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryAllocateFlagsInfo( rhs )
    {}

    MemoryAllocateFlagsInfo& operator=( VkMemoryAllocateFlagsInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryAllocateFlagsInfo::operator=(rhs);
      return *this;
    }

    MemoryAllocateFlagsInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryAllocateFlagsInfo & setFlags( vk::MemoryAllocateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    MemoryAllocateFlagsInfo & setDeviceMask( uint32_t deviceMask_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceMask = deviceMask_;
      return *this;
    }

    operator VkMemoryAllocateFlagsInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryAllocateFlagsInfo*>( this );
    }

    operator VkMemoryAllocateFlagsInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryAllocateFlagsInfo*>( this );
    }

    bool operator==( MemoryAllocateFlagsInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( deviceMask == rhs.deviceMask );
    }

    bool operator!=( MemoryAllocateFlagsInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryAllocateFlagsInfo::sType;
  };
  static_assert( sizeof( MemoryAllocateFlagsInfo ) == sizeof( VkMemoryAllocateFlagsInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryAllocateFlagsInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryAllocateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryAllocateInfo( vk::DeviceSize allocationSize_ = 0,
                                               uint32_t memoryTypeIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : allocationSize( allocationSize_ )
        , memoryTypeIndex( memoryTypeIndex_ )
      {}

      MemoryAllocateInfo( VkMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryAllocateInfo*>(this) = rhs;
      }

      MemoryAllocateInfo& operator=( VkMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryAllocateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryAllocateInfo;
      const void* pNext = nullptr;
      vk::DeviceSize allocationSize;
      uint32_t memoryTypeIndex;
    };
    static_assert( sizeof( MemoryAllocateInfo ) == sizeof( VkMemoryAllocateInfo ), "layout struct and wrapper have different size!" );
  }

  struct MemoryAllocateInfo : public layout::MemoryAllocateInfo
  {
    VULKAN_HPP_CONSTEXPR MemoryAllocateInfo( vk::DeviceSize allocationSize_ = 0,
                                             uint32_t memoryTypeIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryAllocateInfo( allocationSize_, memoryTypeIndex_ )
    {}

    MemoryAllocateInfo( VkMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryAllocateInfo( rhs )
    {}

    MemoryAllocateInfo& operator=( VkMemoryAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryAllocateInfo::operator=(rhs);
      return *this;
    }

    MemoryAllocateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryAllocateInfo & setAllocationSize( vk::DeviceSize allocationSize_ ) VULKAN_HPP_NOEXCEPT
    {
      allocationSize = allocationSize_;
      return *this;
    }

    MemoryAllocateInfo & setMemoryTypeIndex( uint32_t memoryTypeIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryTypeIndex = memoryTypeIndex_;
      return *this;
    }

    operator VkMemoryAllocateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryAllocateInfo*>( this );
    }

    operator VkMemoryAllocateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryAllocateInfo*>( this );
    }

    bool operator==( MemoryAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( allocationSize == rhs.allocationSize )
          && ( memoryTypeIndex == rhs.memoryTypeIndex );
    }

    bool operator!=( MemoryAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryAllocateInfo::sType;
  };
  static_assert( sizeof( MemoryAllocateInfo ) == sizeof( VkMemoryAllocateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryAllocateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryBarrier
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryBarrier( vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                          vk::AccessFlags dstAccessMask_ = vk::AccessFlags() ) VULKAN_HPP_NOEXCEPT
        : srcAccessMask( srcAccessMask_ )
        , dstAccessMask( dstAccessMask_ )
      {}

      MemoryBarrier( VkMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryBarrier*>(this) = rhs;
      }

      MemoryBarrier& operator=( VkMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryBarrier*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryBarrier;
      const void* pNext = nullptr;
      vk::AccessFlags srcAccessMask;
      vk::AccessFlags dstAccessMask;
    };
    static_assert( sizeof( MemoryBarrier ) == sizeof( VkMemoryBarrier ), "layout struct and wrapper have different size!" );
  }

  struct MemoryBarrier : public layout::MemoryBarrier
  {
    VULKAN_HPP_CONSTEXPR MemoryBarrier( vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                        vk::AccessFlags dstAccessMask_ = vk::AccessFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryBarrier( srcAccessMask_, dstAccessMask_ )
    {}

    MemoryBarrier( VkMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryBarrier( rhs )
    {}

    MemoryBarrier& operator=( VkMemoryBarrier const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryBarrier::operator=(rhs);
      return *this;
    }

    MemoryBarrier & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryBarrier & setSrcAccessMask( vk::AccessFlags srcAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      srcAccessMask = srcAccessMask_;
      return *this;
    }

    MemoryBarrier & setDstAccessMask( vk::AccessFlags dstAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      dstAccessMask = dstAccessMask_;
      return *this;
    }

    operator VkMemoryBarrier const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryBarrier*>( this );
    }

    operator VkMemoryBarrier &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryBarrier*>( this );
    }

    bool operator==( MemoryBarrier const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( srcAccessMask == rhs.srcAccessMask )
          && ( dstAccessMask == rhs.dstAccessMask );
    }

    bool operator!=( MemoryBarrier const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryBarrier::sType;
  };
  static_assert( sizeof( MemoryBarrier ) == sizeof( VkMemoryBarrier ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryBarrier>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryDedicatedAllocateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryDedicatedAllocateInfo( vk::Image image_ = vk::Image(),
                                                        vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
        : image( image_ )
        , buffer( buffer_ )
      {}

      MemoryDedicatedAllocateInfo( VkMemoryDedicatedAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryDedicatedAllocateInfo*>(this) = rhs;
      }

      MemoryDedicatedAllocateInfo& operator=( VkMemoryDedicatedAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryDedicatedAllocateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryDedicatedAllocateInfo;
      const void* pNext = nullptr;
      vk::Image image;
      vk::Buffer buffer;
    };
    static_assert( sizeof( MemoryDedicatedAllocateInfo ) == sizeof( VkMemoryDedicatedAllocateInfo ), "layout struct and wrapper have different size!" );
  }

  struct MemoryDedicatedAllocateInfo : public layout::MemoryDedicatedAllocateInfo
  {
    VULKAN_HPP_CONSTEXPR MemoryDedicatedAllocateInfo( vk::Image image_ = vk::Image(),
                                                      vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryDedicatedAllocateInfo( image_, buffer_ )
    {}

    MemoryDedicatedAllocateInfo( VkMemoryDedicatedAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryDedicatedAllocateInfo( rhs )
    {}

    MemoryDedicatedAllocateInfo& operator=( VkMemoryDedicatedAllocateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryDedicatedAllocateInfo::operator=(rhs);
      return *this;
    }

    MemoryDedicatedAllocateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryDedicatedAllocateInfo & setImage( vk::Image image_ ) VULKAN_HPP_NOEXCEPT
    {
      image = image_;
      return *this;
    }

    MemoryDedicatedAllocateInfo & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    operator VkMemoryDedicatedAllocateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryDedicatedAllocateInfo*>( this );
    }

    operator VkMemoryDedicatedAllocateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryDedicatedAllocateInfo*>( this );
    }

    bool operator==( MemoryDedicatedAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( image == rhs.image )
          && ( buffer == rhs.buffer );
    }

    bool operator!=( MemoryDedicatedAllocateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryDedicatedAllocateInfo::sType;
  };
  static_assert( sizeof( MemoryDedicatedAllocateInfo ) == sizeof( VkMemoryDedicatedAllocateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryDedicatedAllocateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryDedicatedRequirements
    {
    protected:
      MemoryDedicatedRequirements() VULKAN_HPP_NOEXCEPT
      {}

      MemoryDedicatedRequirements( VkMemoryDedicatedRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryDedicatedRequirements*>(this) = rhs;
      }

      MemoryDedicatedRequirements& operator=( VkMemoryDedicatedRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryDedicatedRequirements*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryDedicatedRequirements;
      void* pNext = nullptr;
      vk::Bool32 prefersDedicatedAllocation;
      vk::Bool32 requiresDedicatedAllocation;
    };
    static_assert( sizeof( MemoryDedicatedRequirements ) == sizeof( VkMemoryDedicatedRequirements ), "layout struct and wrapper have different size!" );
  }

  struct MemoryDedicatedRequirements : public layout::MemoryDedicatedRequirements
  {
    MemoryDedicatedRequirements() VULKAN_HPP_NOEXCEPT
      : layout::MemoryDedicatedRequirements()
    {}

    MemoryDedicatedRequirements( VkMemoryDedicatedRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryDedicatedRequirements( rhs )
    {}

    MemoryDedicatedRequirements& operator=( VkMemoryDedicatedRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryDedicatedRequirements::operator=(rhs);
      return *this;
    }

    operator VkMemoryDedicatedRequirements const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryDedicatedRequirements*>( this );
    }

    operator VkMemoryDedicatedRequirements &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryDedicatedRequirements*>( this );
    }

    bool operator==( MemoryDedicatedRequirements const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( prefersDedicatedAllocation == rhs.prefersDedicatedAllocation )
          && ( requiresDedicatedAllocation == rhs.requiresDedicatedAllocation );
    }

    bool operator!=( MemoryDedicatedRequirements const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryDedicatedRequirements::sType;
  };
  static_assert( sizeof( MemoryDedicatedRequirements ) == sizeof( VkMemoryDedicatedRequirements ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryDedicatedRequirements>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryFdPropertiesKHR
    {
    protected:
      MemoryFdPropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      MemoryFdPropertiesKHR( VkMemoryFdPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryFdPropertiesKHR*>(this) = rhs;
      }

      MemoryFdPropertiesKHR& operator=( VkMemoryFdPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryFdPropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryFdPropertiesKHR;
      void* pNext = nullptr;
      uint32_t memoryTypeBits;
    };
    static_assert( sizeof( MemoryFdPropertiesKHR ) == sizeof( VkMemoryFdPropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct MemoryFdPropertiesKHR : public layout::MemoryFdPropertiesKHR
  {
    MemoryFdPropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::MemoryFdPropertiesKHR()
    {}

    MemoryFdPropertiesKHR( VkMemoryFdPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryFdPropertiesKHR( rhs )
    {}

    MemoryFdPropertiesKHR& operator=( VkMemoryFdPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryFdPropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkMemoryFdPropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryFdPropertiesKHR*>( this );
    }

    operator VkMemoryFdPropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryFdPropertiesKHR*>( this );
    }

    bool operator==( MemoryFdPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memoryTypeBits == rhs.memoryTypeBits );
    }

    bool operator!=( MemoryFdPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryFdPropertiesKHR::sType;
  };
  static_assert( sizeof( MemoryFdPropertiesKHR ) == sizeof( VkMemoryFdPropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryFdPropertiesKHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_ANDROID_KHR

  namespace layout
  {
    struct MemoryGetAndroidHardwareBufferInfoANDROID
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryGetAndroidHardwareBufferInfoANDROID( vk::DeviceMemory memory_ = vk::DeviceMemory() ) VULKAN_HPP_NOEXCEPT
        : memory( memory_ )
      {}

      MemoryGetAndroidHardwareBufferInfoANDROID( VkMemoryGetAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryGetAndroidHardwareBufferInfoANDROID*>(this) = rhs;
      }

      MemoryGetAndroidHardwareBufferInfoANDROID& operator=( VkMemoryGetAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryGetAndroidHardwareBufferInfoANDROID*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryGetAndroidHardwareBufferInfoANDROID;
      const void* pNext = nullptr;
      vk::DeviceMemory memory;
    };
    static_assert( sizeof( MemoryGetAndroidHardwareBufferInfoANDROID ) == sizeof( VkMemoryGetAndroidHardwareBufferInfoANDROID ), "layout struct and wrapper have different size!" );
  }

  struct MemoryGetAndroidHardwareBufferInfoANDROID : public layout::MemoryGetAndroidHardwareBufferInfoANDROID
  {
    VULKAN_HPP_CONSTEXPR MemoryGetAndroidHardwareBufferInfoANDROID( vk::DeviceMemory memory_ = vk::DeviceMemory() ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryGetAndroidHardwareBufferInfoANDROID( memory_ )
    {}

    MemoryGetAndroidHardwareBufferInfoANDROID( VkMemoryGetAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryGetAndroidHardwareBufferInfoANDROID( rhs )
    {}

    MemoryGetAndroidHardwareBufferInfoANDROID& operator=( VkMemoryGetAndroidHardwareBufferInfoANDROID const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryGetAndroidHardwareBufferInfoANDROID::operator=(rhs);
      return *this;
    }

    MemoryGetAndroidHardwareBufferInfoANDROID & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryGetAndroidHardwareBufferInfoANDROID & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    operator VkMemoryGetAndroidHardwareBufferInfoANDROID const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryGetAndroidHardwareBufferInfoANDROID*>( this );
    }

    operator VkMemoryGetAndroidHardwareBufferInfoANDROID &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryGetAndroidHardwareBufferInfoANDROID*>( this );
    }

    bool operator==( MemoryGetAndroidHardwareBufferInfoANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memory == rhs.memory );
    }

    bool operator!=( MemoryGetAndroidHardwareBufferInfoANDROID const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryGetAndroidHardwareBufferInfoANDROID::sType;
  };
  static_assert( sizeof( MemoryGetAndroidHardwareBufferInfoANDROID ) == sizeof( VkMemoryGetAndroidHardwareBufferInfoANDROID ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryGetAndroidHardwareBufferInfoANDROID>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  namespace layout
  {
    struct MemoryGetFdInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryGetFdInfoKHR( vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                               vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : memory( memory_ )
        , handleType( handleType_ )
      {}

      MemoryGetFdInfoKHR( VkMemoryGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryGetFdInfoKHR*>(this) = rhs;
      }

      MemoryGetFdInfoKHR& operator=( VkMemoryGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryGetFdInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryGetFdInfoKHR;
      const void* pNext = nullptr;
      vk::DeviceMemory memory;
      vk::ExternalMemoryHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( MemoryGetFdInfoKHR ) == sizeof( VkMemoryGetFdInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct MemoryGetFdInfoKHR : public layout::MemoryGetFdInfoKHR
  {
    VULKAN_HPP_CONSTEXPR MemoryGetFdInfoKHR( vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                             vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryGetFdInfoKHR( memory_, handleType_ )
    {}

    MemoryGetFdInfoKHR( VkMemoryGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryGetFdInfoKHR( rhs )
    {}

    MemoryGetFdInfoKHR& operator=( VkMemoryGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryGetFdInfoKHR::operator=(rhs);
      return *this;
    }

    MemoryGetFdInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryGetFdInfoKHR & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    MemoryGetFdInfoKHR & setHandleType( vk::ExternalMemoryHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkMemoryGetFdInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryGetFdInfoKHR*>( this );
    }

    operator VkMemoryGetFdInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryGetFdInfoKHR*>( this );
    }

    bool operator==( MemoryGetFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memory == rhs.memory )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( MemoryGetFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryGetFdInfoKHR::sType;
  };
  static_assert( sizeof( MemoryGetFdInfoKHR ) == sizeof( VkMemoryGetFdInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryGetFdInfoKHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct MemoryGetWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryGetWin32HandleInfoKHR( vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                                        vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : memory( memory_ )
        , handleType( handleType_ )
      {}

      MemoryGetWin32HandleInfoKHR( VkMemoryGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryGetWin32HandleInfoKHR*>(this) = rhs;
      }

      MemoryGetWin32HandleInfoKHR& operator=( VkMemoryGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryGetWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryGetWin32HandleInfoKHR;
      const void* pNext = nullptr;
      vk::DeviceMemory memory;
      vk::ExternalMemoryHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( MemoryGetWin32HandleInfoKHR ) == sizeof( VkMemoryGetWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct MemoryGetWin32HandleInfoKHR : public layout::MemoryGetWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR MemoryGetWin32HandleInfoKHR( vk::DeviceMemory memory_ = vk::DeviceMemory(),
                                                      vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryGetWin32HandleInfoKHR( memory_, handleType_ )
    {}

    MemoryGetWin32HandleInfoKHR( VkMemoryGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryGetWin32HandleInfoKHR( rhs )
    {}

    MemoryGetWin32HandleInfoKHR& operator=( VkMemoryGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryGetWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    MemoryGetWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryGetWin32HandleInfoKHR & setMemory( vk::DeviceMemory memory_ ) VULKAN_HPP_NOEXCEPT
    {
      memory = memory_;
      return *this;
    }

    MemoryGetWin32HandleInfoKHR & setHandleType( vk::ExternalMemoryHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkMemoryGetWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryGetWin32HandleInfoKHR*>( this );
    }

    operator VkMemoryGetWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryGetWin32HandleInfoKHR*>( this );
    }

    bool operator==( MemoryGetWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memory == rhs.memory )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( MemoryGetWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryGetWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( MemoryGetWin32HandleInfoKHR ) == sizeof( VkMemoryGetWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryGetWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  struct MemoryHeap
  {
    MemoryHeap() VULKAN_HPP_NOEXCEPT
    {}

    MemoryHeap( VkMemoryHeap const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkMemoryHeap*>(this) = rhs;
    }

    MemoryHeap& operator=( VkMemoryHeap const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkMemoryHeap*>(this) = rhs;
      return *this;
    }

    operator VkMemoryHeap const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryHeap*>( this );
    }

    operator VkMemoryHeap &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryHeap*>( this );
    }

    bool operator==( MemoryHeap const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( size == rhs.size )
          && ( flags == rhs.flags );
    }

    bool operator!=( MemoryHeap const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DeviceSize size;
    vk::MemoryHeapFlags flags;
  };
  static_assert( sizeof( MemoryHeap ) == sizeof( VkMemoryHeap ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryHeap>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryHostPointerPropertiesEXT
    {
    protected:
      MemoryHostPointerPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      MemoryHostPointerPropertiesEXT( VkMemoryHostPointerPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryHostPointerPropertiesEXT*>(this) = rhs;
      }

      MemoryHostPointerPropertiesEXT& operator=( VkMemoryHostPointerPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryHostPointerPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryHostPointerPropertiesEXT;
      void* pNext = nullptr;
      uint32_t memoryTypeBits;
    };
    static_assert( sizeof( MemoryHostPointerPropertiesEXT ) == sizeof( VkMemoryHostPointerPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct MemoryHostPointerPropertiesEXT : public layout::MemoryHostPointerPropertiesEXT
  {
    MemoryHostPointerPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::MemoryHostPointerPropertiesEXT()
    {}

    MemoryHostPointerPropertiesEXT( VkMemoryHostPointerPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryHostPointerPropertiesEXT( rhs )
    {}

    MemoryHostPointerPropertiesEXT& operator=( VkMemoryHostPointerPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryHostPointerPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkMemoryHostPointerPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryHostPointerPropertiesEXT*>( this );
    }

    operator VkMemoryHostPointerPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryHostPointerPropertiesEXT*>( this );
    }

    bool operator==( MemoryHostPointerPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memoryTypeBits == rhs.memoryTypeBits );
    }

    bool operator!=( MemoryHostPointerPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryHostPointerPropertiesEXT::sType;
  };
  static_assert( sizeof( MemoryHostPointerPropertiesEXT ) == sizeof( VkMemoryHostPointerPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryHostPointerPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryPriorityAllocateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR MemoryPriorityAllocateInfoEXT( float priority_ = 0 ) VULKAN_HPP_NOEXCEPT
        : priority( priority_ )
      {}

      MemoryPriorityAllocateInfoEXT( VkMemoryPriorityAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryPriorityAllocateInfoEXT*>(this) = rhs;
      }

      MemoryPriorityAllocateInfoEXT& operator=( VkMemoryPriorityAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryPriorityAllocateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryPriorityAllocateInfoEXT;
      const void* pNext = nullptr;
      float priority;
    };
    static_assert( sizeof( MemoryPriorityAllocateInfoEXT ) == sizeof( VkMemoryPriorityAllocateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct MemoryPriorityAllocateInfoEXT : public layout::MemoryPriorityAllocateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR MemoryPriorityAllocateInfoEXT( float priority_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryPriorityAllocateInfoEXT( priority_ )
    {}

    MemoryPriorityAllocateInfoEXT( VkMemoryPriorityAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryPriorityAllocateInfoEXT( rhs )
    {}

    MemoryPriorityAllocateInfoEXT& operator=( VkMemoryPriorityAllocateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryPriorityAllocateInfoEXT::operator=(rhs);
      return *this;
    }

    MemoryPriorityAllocateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MemoryPriorityAllocateInfoEXT & setPriority( float priority_ ) VULKAN_HPP_NOEXCEPT
    {
      priority = priority_;
      return *this;
    }

    operator VkMemoryPriorityAllocateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryPriorityAllocateInfoEXT*>( this );
    }

    operator VkMemoryPriorityAllocateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryPriorityAllocateInfoEXT*>( this );
    }

    bool operator==( MemoryPriorityAllocateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( priority == rhs.priority );
    }

    bool operator!=( MemoryPriorityAllocateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryPriorityAllocateInfoEXT::sType;
  };
  static_assert( sizeof( MemoryPriorityAllocateInfoEXT ) == sizeof( VkMemoryPriorityAllocateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryPriorityAllocateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  struct MemoryRequirements
  {
    MemoryRequirements() VULKAN_HPP_NOEXCEPT
    {}

    MemoryRequirements( VkMemoryRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkMemoryRequirements*>(this) = rhs;
    }

    MemoryRequirements& operator=( VkMemoryRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkMemoryRequirements*>(this) = rhs;
      return *this;
    }

    operator VkMemoryRequirements const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryRequirements*>( this );
    }

    operator VkMemoryRequirements &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryRequirements*>( this );
    }

    bool operator==( MemoryRequirements const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( size == rhs.size )
          && ( alignment == rhs.alignment )
          && ( memoryTypeBits == rhs.memoryTypeBits );
    }

    bool operator!=( MemoryRequirements const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::DeviceSize size;
    vk::DeviceSize alignment;
    uint32_t memoryTypeBits;
  };
  static_assert( sizeof( MemoryRequirements ) == sizeof( VkMemoryRequirements ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryRequirements>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct MemoryRequirements2
    {
    protected:
      MemoryRequirements2() VULKAN_HPP_NOEXCEPT
      {}

      MemoryRequirements2( VkMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryRequirements2*>(this) = rhs;
      }

      MemoryRequirements2& operator=( VkMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryRequirements2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryRequirements2;
      void* pNext = nullptr;
      vk::MemoryRequirements memoryRequirements;
    };
    static_assert( sizeof( MemoryRequirements2 ) == sizeof( VkMemoryRequirements2 ), "layout struct and wrapper have different size!" );
  }

  struct MemoryRequirements2 : public layout::MemoryRequirements2
  {
    MemoryRequirements2() VULKAN_HPP_NOEXCEPT
      : layout::MemoryRequirements2()
    {}

    MemoryRequirements2( VkMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryRequirements2( rhs )
    {}

    MemoryRequirements2& operator=( VkMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryRequirements2::operator=(rhs);
      return *this;
    }

    operator VkMemoryRequirements2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryRequirements2*>( this );
    }

    operator VkMemoryRequirements2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryRequirements2*>( this );
    }

    bool operator==( MemoryRequirements2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memoryRequirements == rhs.memoryRequirements );
    }

    bool operator!=( MemoryRequirements2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryRequirements2::sType;
  };
  static_assert( sizeof( MemoryRequirements2 ) == sizeof( VkMemoryRequirements2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryRequirements2>::value, "struct wrapper is not a standard layout!" );

  struct MemoryType
  {
    MemoryType() VULKAN_HPP_NOEXCEPT
    {}

    MemoryType( VkMemoryType const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkMemoryType*>(this) = rhs;
    }

    MemoryType& operator=( VkMemoryType const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkMemoryType*>(this) = rhs;
      return *this;
    }

    operator VkMemoryType const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryType*>( this );
    }

    operator VkMemoryType &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryType*>( this );
    }

    bool operator==( MemoryType const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( propertyFlags == rhs.propertyFlags )
          && ( heapIndex == rhs.heapIndex );
    }

    bool operator!=( MemoryType const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::MemoryPropertyFlags propertyFlags;
    uint32_t heapIndex;
  };
  static_assert( sizeof( MemoryType ) == sizeof( VkMemoryType ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryType>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct MemoryWin32HandlePropertiesKHR
    {
    protected:
      MemoryWin32HandlePropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      MemoryWin32HandlePropertiesKHR( VkMemoryWin32HandlePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryWin32HandlePropertiesKHR*>(this) = rhs;
      }

      MemoryWin32HandlePropertiesKHR& operator=( VkMemoryWin32HandlePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMemoryWin32HandlePropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMemoryWin32HandlePropertiesKHR;
      void* pNext = nullptr;
      uint32_t memoryTypeBits;
    };
    static_assert( sizeof( MemoryWin32HandlePropertiesKHR ) == sizeof( VkMemoryWin32HandlePropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct MemoryWin32HandlePropertiesKHR : public layout::MemoryWin32HandlePropertiesKHR
  {
    MemoryWin32HandlePropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::MemoryWin32HandlePropertiesKHR()
    {}

    MemoryWin32HandlePropertiesKHR( VkMemoryWin32HandlePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MemoryWin32HandlePropertiesKHR( rhs )
    {}

    MemoryWin32HandlePropertiesKHR& operator=( VkMemoryWin32HandlePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MemoryWin32HandlePropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkMemoryWin32HandlePropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMemoryWin32HandlePropertiesKHR*>( this );
    }

    operator VkMemoryWin32HandlePropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMemoryWin32HandlePropertiesKHR*>( this );
    }

    bool operator==( MemoryWin32HandlePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memoryTypeBits == rhs.memoryTypeBits );
    }

    bool operator!=( MemoryWin32HandlePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MemoryWin32HandlePropertiesKHR::sType;
  };
  static_assert( sizeof( MemoryWin32HandlePropertiesKHR ) == sizeof( VkMemoryWin32HandlePropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MemoryWin32HandlePropertiesKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_METAL_EXT

  namespace layout
  {
    struct MetalSurfaceCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR MetalSurfaceCreateInfoEXT( vk::MetalSurfaceCreateFlagsEXT flags_ = vk::MetalSurfaceCreateFlagsEXT(),
                                                      const CAMetalLayer* pLayer_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pLayer( pLayer_ )
      {}

      MetalSurfaceCreateInfoEXT( VkMetalSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMetalSurfaceCreateInfoEXT*>(this) = rhs;
      }

      MetalSurfaceCreateInfoEXT& operator=( VkMetalSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMetalSurfaceCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMetalSurfaceCreateInfoEXT;
      const void* pNext = nullptr;
      vk::MetalSurfaceCreateFlagsEXT flags;
      const CAMetalLayer* pLayer;
    };
    static_assert( sizeof( MetalSurfaceCreateInfoEXT ) == sizeof( VkMetalSurfaceCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct MetalSurfaceCreateInfoEXT : public layout::MetalSurfaceCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR MetalSurfaceCreateInfoEXT( vk::MetalSurfaceCreateFlagsEXT flags_ = vk::MetalSurfaceCreateFlagsEXT(),
                                                    const CAMetalLayer* pLayer_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::MetalSurfaceCreateInfoEXT( flags_, pLayer_ )
    {}

    MetalSurfaceCreateInfoEXT( VkMetalSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MetalSurfaceCreateInfoEXT( rhs )
    {}

    MetalSurfaceCreateInfoEXT& operator=( VkMetalSurfaceCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MetalSurfaceCreateInfoEXT::operator=(rhs);
      return *this;
    }

    MetalSurfaceCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    MetalSurfaceCreateInfoEXT & setFlags( vk::MetalSurfaceCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    MetalSurfaceCreateInfoEXT & setPLayer( const CAMetalLayer* pLayer_ ) VULKAN_HPP_NOEXCEPT
    {
      pLayer = pLayer_;
      return *this;
    }

    operator VkMetalSurfaceCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMetalSurfaceCreateInfoEXT*>( this );
    }

    operator VkMetalSurfaceCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMetalSurfaceCreateInfoEXT*>( this );
    }

    bool operator==( MetalSurfaceCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pLayer == rhs.pLayer );
    }

    bool operator!=( MetalSurfaceCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MetalSurfaceCreateInfoEXT::sType;
  };
  static_assert( sizeof( MetalSurfaceCreateInfoEXT ) == sizeof( VkMetalSurfaceCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MetalSurfaceCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_METAL_EXT*/

  namespace layout
  {
    struct MultisamplePropertiesEXT
    {
    protected:
      MultisamplePropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      MultisamplePropertiesEXT( VkMultisamplePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMultisamplePropertiesEXT*>(this) = rhs;
      }

      MultisamplePropertiesEXT& operator=( VkMultisamplePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkMultisamplePropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eMultisamplePropertiesEXT;
      void* pNext = nullptr;
      vk::Extent2D maxSampleLocationGridSize;
    };
    static_assert( sizeof( MultisamplePropertiesEXT ) == sizeof( VkMultisamplePropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct MultisamplePropertiesEXT : public layout::MultisamplePropertiesEXT
  {
    MultisamplePropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::MultisamplePropertiesEXT()
    {}

    MultisamplePropertiesEXT( VkMultisamplePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::MultisamplePropertiesEXT( rhs )
    {}

    MultisamplePropertiesEXT& operator=( VkMultisamplePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::MultisamplePropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkMultisamplePropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkMultisamplePropertiesEXT*>( this );
    }

    operator VkMultisamplePropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkMultisamplePropertiesEXT*>( this );
    }

    bool operator==( MultisamplePropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxSampleLocationGridSize == rhs.maxSampleLocationGridSize );
    }

    bool operator!=( MultisamplePropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::MultisamplePropertiesEXT::sType;
  };
  static_assert( sizeof( MultisamplePropertiesEXT ) == sizeof( VkMultisamplePropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<MultisamplePropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ObjectTableCreateInfoNVX
    {
    protected:
      VULKAN_HPP_CONSTEXPR ObjectTableCreateInfoNVX( uint32_t objectCount_ = 0,
                                                     const vk::ObjectEntryTypeNVX* pObjectEntryTypes_ = nullptr,
                                                     const uint32_t* pObjectEntryCounts_ = nullptr,
                                                     const vk::ObjectEntryUsageFlagsNVX* pObjectEntryUsageFlags_ = nullptr,
                                                     uint32_t maxUniformBuffersPerDescriptor_ = 0,
                                                     uint32_t maxStorageBuffersPerDescriptor_ = 0,
                                                     uint32_t maxStorageImagesPerDescriptor_ = 0,
                                                     uint32_t maxSampledImagesPerDescriptor_ = 0,
                                                     uint32_t maxPipelineLayouts_ = 0 ) VULKAN_HPP_NOEXCEPT
        : objectCount( objectCount_ )
        , pObjectEntryTypes( pObjectEntryTypes_ )
        , pObjectEntryCounts( pObjectEntryCounts_ )
        , pObjectEntryUsageFlags( pObjectEntryUsageFlags_ )
        , maxUniformBuffersPerDescriptor( maxUniformBuffersPerDescriptor_ )
        , maxStorageBuffersPerDescriptor( maxStorageBuffersPerDescriptor_ )
        , maxStorageImagesPerDescriptor( maxStorageImagesPerDescriptor_ )
        , maxSampledImagesPerDescriptor( maxSampledImagesPerDescriptor_ )
        , maxPipelineLayouts( maxPipelineLayouts_ )
      {}

      ObjectTableCreateInfoNVX( VkObjectTableCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkObjectTableCreateInfoNVX*>(this) = rhs;
      }

      ObjectTableCreateInfoNVX& operator=( VkObjectTableCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkObjectTableCreateInfoNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eObjectTableCreateInfoNVX;
      const void* pNext = nullptr;
      uint32_t objectCount;
      const vk::ObjectEntryTypeNVX* pObjectEntryTypes;
      const uint32_t* pObjectEntryCounts;
      const vk::ObjectEntryUsageFlagsNVX* pObjectEntryUsageFlags;
      uint32_t maxUniformBuffersPerDescriptor;
      uint32_t maxStorageBuffersPerDescriptor;
      uint32_t maxStorageImagesPerDescriptor;
      uint32_t maxSampledImagesPerDescriptor;
      uint32_t maxPipelineLayouts;
    };
    static_assert( sizeof( ObjectTableCreateInfoNVX ) == sizeof( VkObjectTableCreateInfoNVX ), "layout struct and wrapper have different size!" );
  }

  struct ObjectTableCreateInfoNVX : public layout::ObjectTableCreateInfoNVX
  {
    VULKAN_HPP_CONSTEXPR ObjectTableCreateInfoNVX( uint32_t objectCount_ = 0,
                                                   const vk::ObjectEntryTypeNVX* pObjectEntryTypes_ = nullptr,
                                                   const uint32_t* pObjectEntryCounts_ = nullptr,
                                                   const vk::ObjectEntryUsageFlagsNVX* pObjectEntryUsageFlags_ = nullptr,
                                                   uint32_t maxUniformBuffersPerDescriptor_ = 0,
                                                   uint32_t maxStorageBuffersPerDescriptor_ = 0,
                                                   uint32_t maxStorageImagesPerDescriptor_ = 0,
                                                   uint32_t maxSampledImagesPerDescriptor_ = 0,
                                                   uint32_t maxPipelineLayouts_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ObjectTableCreateInfoNVX( objectCount_, pObjectEntryTypes_, pObjectEntryCounts_, pObjectEntryUsageFlags_, maxUniformBuffersPerDescriptor_, maxStorageBuffersPerDescriptor_, maxStorageImagesPerDescriptor_, maxSampledImagesPerDescriptor_, maxPipelineLayouts_ )
    {}

    ObjectTableCreateInfoNVX( VkObjectTableCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ObjectTableCreateInfoNVX( rhs )
    {}

    ObjectTableCreateInfoNVX& operator=( VkObjectTableCreateInfoNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ObjectTableCreateInfoNVX::operator=(rhs);
      return *this;
    }

    ObjectTableCreateInfoNVX & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setObjectCount( uint32_t objectCount_ ) VULKAN_HPP_NOEXCEPT
    {
      objectCount = objectCount_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setPObjectEntryTypes( const vk::ObjectEntryTypeNVX* pObjectEntryTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      pObjectEntryTypes = pObjectEntryTypes_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setPObjectEntryCounts( const uint32_t* pObjectEntryCounts_ ) VULKAN_HPP_NOEXCEPT
    {
      pObjectEntryCounts = pObjectEntryCounts_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setPObjectEntryUsageFlags( const vk::ObjectEntryUsageFlagsNVX* pObjectEntryUsageFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      pObjectEntryUsageFlags = pObjectEntryUsageFlags_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setMaxUniformBuffersPerDescriptor( uint32_t maxUniformBuffersPerDescriptor_ ) VULKAN_HPP_NOEXCEPT
    {
      maxUniformBuffersPerDescriptor = maxUniformBuffersPerDescriptor_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setMaxStorageBuffersPerDescriptor( uint32_t maxStorageBuffersPerDescriptor_ ) VULKAN_HPP_NOEXCEPT
    {
      maxStorageBuffersPerDescriptor = maxStorageBuffersPerDescriptor_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setMaxStorageImagesPerDescriptor( uint32_t maxStorageImagesPerDescriptor_ ) VULKAN_HPP_NOEXCEPT
    {
      maxStorageImagesPerDescriptor = maxStorageImagesPerDescriptor_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setMaxSampledImagesPerDescriptor( uint32_t maxSampledImagesPerDescriptor_ ) VULKAN_HPP_NOEXCEPT
    {
      maxSampledImagesPerDescriptor = maxSampledImagesPerDescriptor_;
      return *this;
    }

    ObjectTableCreateInfoNVX & setMaxPipelineLayouts( uint32_t maxPipelineLayouts_ ) VULKAN_HPP_NOEXCEPT
    {
      maxPipelineLayouts = maxPipelineLayouts_;
      return *this;
    }

    operator VkObjectTableCreateInfoNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkObjectTableCreateInfoNVX*>( this );
    }

    operator VkObjectTableCreateInfoNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkObjectTableCreateInfoNVX*>( this );
    }

    bool operator==( ObjectTableCreateInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( objectCount == rhs.objectCount )
          && ( pObjectEntryTypes == rhs.pObjectEntryTypes )
          && ( pObjectEntryCounts == rhs.pObjectEntryCounts )
          && ( pObjectEntryUsageFlags == rhs.pObjectEntryUsageFlags )
          && ( maxUniformBuffersPerDescriptor == rhs.maxUniformBuffersPerDescriptor )
          && ( maxStorageBuffersPerDescriptor == rhs.maxStorageBuffersPerDescriptor )
          && ( maxStorageImagesPerDescriptor == rhs.maxStorageImagesPerDescriptor )
          && ( maxSampledImagesPerDescriptor == rhs.maxSampledImagesPerDescriptor )
          && ( maxPipelineLayouts == rhs.maxPipelineLayouts );
    }

    bool operator!=( ObjectTableCreateInfoNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ObjectTableCreateInfoNVX::sType;
  };
  static_assert( sizeof( ObjectTableCreateInfoNVX ) == sizeof( VkObjectTableCreateInfoNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ObjectTableCreateInfoNVX>::value, "struct wrapper is not a standard layout!" );

  struct ObjectTableEntryNVX
  {
    VULKAN_HPP_CONSTEXPR ObjectTableEntryNVX( vk::ObjectEntryTypeNVX type_ = vk::ObjectEntryTypeNVX::eDescriptorSet,
                                              vk::ObjectEntryUsageFlagsNVX flags_ = vk::ObjectEntryUsageFlagsNVX() ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , flags( flags_ )
    {}

    ObjectTableEntryNVX( VkObjectTableEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableEntryNVX*>(this) = rhs;
    }

    ObjectTableEntryNVX& operator=( VkObjectTableEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableEntryNVX*>(this) = rhs;
      return *this;
    }

    ObjectTableEntryNVX & setType( vk::ObjectEntryTypeNVX type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    ObjectTableEntryNVX & setFlags( vk::ObjectEntryUsageFlagsNVX flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkObjectTableEntryNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkObjectTableEntryNVX*>( this );
    }

    operator VkObjectTableEntryNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkObjectTableEntryNVX*>( this );
    }

    bool operator==( ObjectTableEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( type == rhs.type )
          && ( flags == rhs.flags );
    }

    bool operator!=( ObjectTableEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ObjectEntryTypeNVX type;
    vk::ObjectEntryUsageFlagsNVX flags;
  };
  static_assert( sizeof( ObjectTableEntryNVX ) == sizeof( VkObjectTableEntryNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ObjectTableEntryNVX>::value, "struct wrapper is not a standard layout!" );

  struct ObjectTableDescriptorSetEntryNVX
  {
    VULKAN_HPP_CONSTEXPR ObjectTableDescriptorSetEntryNVX( vk::ObjectEntryTypeNVX type_ = vk::ObjectEntryTypeNVX::eDescriptorSet,
                                                           vk::ObjectEntryUsageFlagsNVX flags_ = vk::ObjectEntryUsageFlagsNVX(),
                                                           vk::PipelineLayout pipelineLayout_ = vk::PipelineLayout(),
                                                           vk::DescriptorSet descriptorSet_ = vk::DescriptorSet() ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , flags( flags_ )
      , pipelineLayout( pipelineLayout_ )
      , descriptorSet( descriptorSet_ )
    {}

    explicit ObjectTableDescriptorSetEntryNVX( ObjectTableEntryNVX const& objectTableEntryNVX,
                                               vk::PipelineLayout pipelineLayout_ = vk::PipelineLayout(),
                                               vk::DescriptorSet descriptorSet_ = vk::DescriptorSet() )
      : type( objectTableEntryNVX.type )
      , flags( objectTableEntryNVX.flags )
      , pipelineLayout( pipelineLayout_ )
      , descriptorSet( descriptorSet_ )
    {}

    ObjectTableDescriptorSetEntryNVX( VkObjectTableDescriptorSetEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableDescriptorSetEntryNVX*>(this) = rhs;
    }

    ObjectTableDescriptorSetEntryNVX& operator=( VkObjectTableDescriptorSetEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableDescriptorSetEntryNVX*>(this) = rhs;
      return *this;
    }

    ObjectTableDescriptorSetEntryNVX & setType( vk::ObjectEntryTypeNVX type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    ObjectTableDescriptorSetEntryNVX & setFlags( vk::ObjectEntryUsageFlagsNVX flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ObjectTableDescriptorSetEntryNVX & setPipelineLayout( vk::PipelineLayout pipelineLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineLayout = pipelineLayout_;
      return *this;
    }

    ObjectTableDescriptorSetEntryNVX & setDescriptorSet( vk::DescriptorSet descriptorSet_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorSet = descriptorSet_;
      return *this;
    }

    operator VkObjectTableDescriptorSetEntryNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkObjectTableDescriptorSetEntryNVX*>( this );
    }

    operator VkObjectTableDescriptorSetEntryNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkObjectTableDescriptorSetEntryNVX*>( this );
    }

    bool operator==( ObjectTableDescriptorSetEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( type == rhs.type )
          && ( flags == rhs.flags )
          && ( pipelineLayout == rhs.pipelineLayout )
          && ( descriptorSet == rhs.descriptorSet );
    }

    bool operator!=( ObjectTableDescriptorSetEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ObjectEntryTypeNVX type;
    vk::ObjectEntryUsageFlagsNVX flags;
    vk::PipelineLayout pipelineLayout;
    vk::DescriptorSet descriptorSet;
  };
  static_assert( sizeof( ObjectTableDescriptorSetEntryNVX ) == sizeof( VkObjectTableDescriptorSetEntryNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ObjectTableDescriptorSetEntryNVX>::value, "struct wrapper is not a standard layout!" );

  struct ObjectTableIndexBufferEntryNVX
  {
    VULKAN_HPP_CONSTEXPR ObjectTableIndexBufferEntryNVX( vk::ObjectEntryTypeNVX type_ = vk::ObjectEntryTypeNVX::eDescriptorSet,
                                                         vk::ObjectEntryUsageFlagsNVX flags_ = vk::ObjectEntryUsageFlagsNVX(),
                                                         vk::Buffer buffer_ = vk::Buffer(),
                                                         vk::IndexType indexType_ = vk::IndexType::eUint16 ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , flags( flags_ )
      , buffer( buffer_ )
      , indexType( indexType_ )
    {}

    explicit ObjectTableIndexBufferEntryNVX( ObjectTableEntryNVX const& objectTableEntryNVX,
                                             vk::Buffer buffer_ = vk::Buffer(),
                                             vk::IndexType indexType_ = vk::IndexType::eUint16 )
      : type( objectTableEntryNVX.type )
      , flags( objectTableEntryNVX.flags )
      , buffer( buffer_ )
      , indexType( indexType_ )
    {}

    ObjectTableIndexBufferEntryNVX( VkObjectTableIndexBufferEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableIndexBufferEntryNVX*>(this) = rhs;
    }

    ObjectTableIndexBufferEntryNVX& operator=( VkObjectTableIndexBufferEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableIndexBufferEntryNVX*>(this) = rhs;
      return *this;
    }

    ObjectTableIndexBufferEntryNVX & setType( vk::ObjectEntryTypeNVX type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    ObjectTableIndexBufferEntryNVX & setFlags( vk::ObjectEntryUsageFlagsNVX flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ObjectTableIndexBufferEntryNVX & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    ObjectTableIndexBufferEntryNVX & setIndexType( vk::IndexType indexType_ ) VULKAN_HPP_NOEXCEPT
    {
      indexType = indexType_;
      return *this;
    }

    operator VkObjectTableIndexBufferEntryNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkObjectTableIndexBufferEntryNVX*>( this );
    }

    operator VkObjectTableIndexBufferEntryNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkObjectTableIndexBufferEntryNVX*>( this );
    }

    bool operator==( ObjectTableIndexBufferEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( type == rhs.type )
          && ( flags == rhs.flags )
          && ( buffer == rhs.buffer )
          && ( indexType == rhs.indexType );
    }

    bool operator!=( ObjectTableIndexBufferEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ObjectEntryTypeNVX type;
    vk::ObjectEntryUsageFlagsNVX flags;
    vk::Buffer buffer;
    vk::IndexType indexType;
  };
  static_assert( sizeof( ObjectTableIndexBufferEntryNVX ) == sizeof( VkObjectTableIndexBufferEntryNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ObjectTableIndexBufferEntryNVX>::value, "struct wrapper is not a standard layout!" );

  struct ObjectTablePipelineEntryNVX
  {
    VULKAN_HPP_CONSTEXPR ObjectTablePipelineEntryNVX( vk::ObjectEntryTypeNVX type_ = vk::ObjectEntryTypeNVX::eDescriptorSet,
                                                      vk::ObjectEntryUsageFlagsNVX flags_ = vk::ObjectEntryUsageFlagsNVX(),
                                                      vk::Pipeline pipeline_ = vk::Pipeline() ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , flags( flags_ )
      , pipeline( pipeline_ )
    {}

    explicit ObjectTablePipelineEntryNVX( ObjectTableEntryNVX const& objectTableEntryNVX,
                                          vk::Pipeline pipeline_ = vk::Pipeline() )
      : type( objectTableEntryNVX.type )
      , flags( objectTableEntryNVX.flags )
      , pipeline( pipeline_ )
    {}

    ObjectTablePipelineEntryNVX( VkObjectTablePipelineEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTablePipelineEntryNVX*>(this) = rhs;
    }

    ObjectTablePipelineEntryNVX& operator=( VkObjectTablePipelineEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTablePipelineEntryNVX*>(this) = rhs;
      return *this;
    }

    ObjectTablePipelineEntryNVX & setType( vk::ObjectEntryTypeNVX type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    ObjectTablePipelineEntryNVX & setFlags( vk::ObjectEntryUsageFlagsNVX flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ObjectTablePipelineEntryNVX & setPipeline( vk::Pipeline pipeline_ ) VULKAN_HPP_NOEXCEPT
    {
      pipeline = pipeline_;
      return *this;
    }

    operator VkObjectTablePipelineEntryNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkObjectTablePipelineEntryNVX*>( this );
    }

    operator VkObjectTablePipelineEntryNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkObjectTablePipelineEntryNVX*>( this );
    }

    bool operator==( ObjectTablePipelineEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( type == rhs.type )
          && ( flags == rhs.flags )
          && ( pipeline == rhs.pipeline );
    }

    bool operator!=( ObjectTablePipelineEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ObjectEntryTypeNVX type;
    vk::ObjectEntryUsageFlagsNVX flags;
    vk::Pipeline pipeline;
  };
  static_assert( sizeof( ObjectTablePipelineEntryNVX ) == sizeof( VkObjectTablePipelineEntryNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ObjectTablePipelineEntryNVX>::value, "struct wrapper is not a standard layout!" );

  struct ObjectTablePushConstantEntryNVX
  {
    VULKAN_HPP_CONSTEXPR ObjectTablePushConstantEntryNVX( vk::ObjectEntryTypeNVX type_ = vk::ObjectEntryTypeNVX::eDescriptorSet,
                                                          vk::ObjectEntryUsageFlagsNVX flags_ = vk::ObjectEntryUsageFlagsNVX(),
                                                          vk::PipelineLayout pipelineLayout_ = vk::PipelineLayout(),
                                                          vk::ShaderStageFlags stageFlags_ = vk::ShaderStageFlags() ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , flags( flags_ )
      , pipelineLayout( pipelineLayout_ )
      , stageFlags( stageFlags_ )
    {}

    explicit ObjectTablePushConstantEntryNVX( ObjectTableEntryNVX const& objectTableEntryNVX,
                                              vk::PipelineLayout pipelineLayout_ = vk::PipelineLayout(),
                                              vk::ShaderStageFlags stageFlags_ = vk::ShaderStageFlags() )
      : type( objectTableEntryNVX.type )
      , flags( objectTableEntryNVX.flags )
      , pipelineLayout( pipelineLayout_ )
      , stageFlags( stageFlags_ )
    {}

    ObjectTablePushConstantEntryNVX( VkObjectTablePushConstantEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTablePushConstantEntryNVX*>(this) = rhs;
    }

    ObjectTablePushConstantEntryNVX& operator=( VkObjectTablePushConstantEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTablePushConstantEntryNVX*>(this) = rhs;
      return *this;
    }

    ObjectTablePushConstantEntryNVX & setType( vk::ObjectEntryTypeNVX type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    ObjectTablePushConstantEntryNVX & setFlags( vk::ObjectEntryUsageFlagsNVX flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ObjectTablePushConstantEntryNVX & setPipelineLayout( vk::PipelineLayout pipelineLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineLayout = pipelineLayout_;
      return *this;
    }

    ObjectTablePushConstantEntryNVX & setStageFlags( vk::ShaderStageFlags stageFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      stageFlags = stageFlags_;
      return *this;
    }

    operator VkObjectTablePushConstantEntryNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkObjectTablePushConstantEntryNVX*>( this );
    }

    operator VkObjectTablePushConstantEntryNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkObjectTablePushConstantEntryNVX*>( this );
    }

    bool operator==( ObjectTablePushConstantEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( type == rhs.type )
          && ( flags == rhs.flags )
          && ( pipelineLayout == rhs.pipelineLayout )
          && ( stageFlags == rhs.stageFlags );
    }

    bool operator!=( ObjectTablePushConstantEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ObjectEntryTypeNVX type;
    vk::ObjectEntryUsageFlagsNVX flags;
    vk::PipelineLayout pipelineLayout;
    vk::ShaderStageFlags stageFlags;
  };
  static_assert( sizeof( ObjectTablePushConstantEntryNVX ) == sizeof( VkObjectTablePushConstantEntryNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ObjectTablePushConstantEntryNVX>::value, "struct wrapper is not a standard layout!" );

  struct ObjectTableVertexBufferEntryNVX
  {
    VULKAN_HPP_CONSTEXPR ObjectTableVertexBufferEntryNVX( vk::ObjectEntryTypeNVX type_ = vk::ObjectEntryTypeNVX::eDescriptorSet,
                                                          vk::ObjectEntryUsageFlagsNVX flags_ = vk::ObjectEntryUsageFlagsNVX(),
                                                          vk::Buffer buffer_ = vk::Buffer() ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , flags( flags_ )
      , buffer( buffer_ )
    {}

    explicit ObjectTableVertexBufferEntryNVX( ObjectTableEntryNVX const& objectTableEntryNVX,
                                              vk::Buffer buffer_ = vk::Buffer() )
      : type( objectTableEntryNVX.type )
      , flags( objectTableEntryNVX.flags )
      , buffer( buffer_ )
    {}

    ObjectTableVertexBufferEntryNVX( VkObjectTableVertexBufferEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableVertexBufferEntryNVX*>(this) = rhs;
    }

    ObjectTableVertexBufferEntryNVX& operator=( VkObjectTableVertexBufferEntryNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkObjectTableVertexBufferEntryNVX*>(this) = rhs;
      return *this;
    }

    ObjectTableVertexBufferEntryNVX & setType( vk::ObjectEntryTypeNVX type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    ObjectTableVertexBufferEntryNVX & setFlags( vk::ObjectEntryUsageFlagsNVX flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ObjectTableVertexBufferEntryNVX & setBuffer( vk::Buffer buffer_ ) VULKAN_HPP_NOEXCEPT
    {
      buffer = buffer_;
      return *this;
    }

    operator VkObjectTableVertexBufferEntryNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkObjectTableVertexBufferEntryNVX*>( this );
    }

    operator VkObjectTableVertexBufferEntryNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkObjectTableVertexBufferEntryNVX*>( this );
    }

    bool operator==( ObjectTableVertexBufferEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( type == rhs.type )
          && ( flags == rhs.flags )
          && ( buffer == rhs.buffer );
    }

    bool operator!=( ObjectTableVertexBufferEntryNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ObjectEntryTypeNVX type;
    vk::ObjectEntryUsageFlagsNVX flags;
    vk::Buffer buffer;
  };
  static_assert( sizeof( ObjectTableVertexBufferEntryNVX ) == sizeof( VkObjectTableVertexBufferEntryNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ObjectTableVertexBufferEntryNVX>::value, "struct wrapper is not a standard layout!" );

  struct PastPresentationTimingGOOGLE
  {
    PastPresentationTimingGOOGLE() VULKAN_HPP_NOEXCEPT
    {}

    PastPresentationTimingGOOGLE( VkPastPresentationTimingGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPastPresentationTimingGOOGLE*>(this) = rhs;
    }

    PastPresentationTimingGOOGLE& operator=( VkPastPresentationTimingGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPastPresentationTimingGOOGLE*>(this) = rhs;
      return *this;
    }

    operator VkPastPresentationTimingGOOGLE const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPastPresentationTimingGOOGLE*>( this );
    }

    operator VkPastPresentationTimingGOOGLE &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPastPresentationTimingGOOGLE*>( this );
    }

    bool operator==( PastPresentationTimingGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( presentID == rhs.presentID )
          && ( desiredPresentTime == rhs.desiredPresentTime )
          && ( actualPresentTime == rhs.actualPresentTime )
          && ( earliestPresentTime == rhs.earliestPresentTime )
          && ( presentMargin == rhs.presentMargin );
    }

    bool operator!=( PastPresentationTimingGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t presentID;
    uint64_t desiredPresentTime;
    uint64_t actualPresentTime;
    uint64_t earliestPresentTime;
    uint64_t presentMargin;
  };
  static_assert( sizeof( PastPresentationTimingGOOGLE ) == sizeof( VkPastPresentationTimingGOOGLE ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PastPresentationTimingGOOGLE>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PerformanceConfigurationAcquireInfoINTEL
    {
    protected:
      VULKAN_HPP_CONSTEXPR PerformanceConfigurationAcquireInfoINTEL( vk::PerformanceConfigurationTypeINTEL type_ = vk::PerformanceConfigurationTypeINTEL::eCommandQueueMetricsDiscoveryActivated ) VULKAN_HPP_NOEXCEPT
        : type( type_ )
      {}

      PerformanceConfigurationAcquireInfoINTEL( VkPerformanceConfigurationAcquireInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceConfigurationAcquireInfoINTEL*>(this) = rhs;
      }

      PerformanceConfigurationAcquireInfoINTEL& operator=( VkPerformanceConfigurationAcquireInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceConfigurationAcquireInfoINTEL*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePerformanceConfigurationAcquireInfoINTEL;
      const void* pNext = nullptr;
      vk::PerformanceConfigurationTypeINTEL type;
    };
    static_assert( sizeof( PerformanceConfigurationAcquireInfoINTEL ) == sizeof( VkPerformanceConfigurationAcquireInfoINTEL ), "layout struct and wrapper have different size!" );
  }

  struct PerformanceConfigurationAcquireInfoINTEL : public layout::PerformanceConfigurationAcquireInfoINTEL
  {
    VULKAN_HPP_CONSTEXPR PerformanceConfigurationAcquireInfoINTEL( vk::PerformanceConfigurationTypeINTEL type_ = vk::PerformanceConfigurationTypeINTEL::eCommandQueueMetricsDiscoveryActivated ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceConfigurationAcquireInfoINTEL( type_ )
    {}

    PerformanceConfigurationAcquireInfoINTEL( VkPerformanceConfigurationAcquireInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceConfigurationAcquireInfoINTEL( rhs )
    {}

    PerformanceConfigurationAcquireInfoINTEL& operator=( VkPerformanceConfigurationAcquireInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PerformanceConfigurationAcquireInfoINTEL::operator=(rhs);
      return *this;
    }

    PerformanceConfigurationAcquireInfoINTEL & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PerformanceConfigurationAcquireInfoINTEL & setType( vk::PerformanceConfigurationTypeINTEL type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    operator VkPerformanceConfigurationAcquireInfoINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPerformanceConfigurationAcquireInfoINTEL*>( this );
    }

    operator VkPerformanceConfigurationAcquireInfoINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPerformanceConfigurationAcquireInfoINTEL*>( this );
    }

    bool operator==( PerformanceConfigurationAcquireInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( type == rhs.type );
    }

    bool operator!=( PerformanceConfigurationAcquireInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PerformanceConfigurationAcquireInfoINTEL::sType;
  };
  static_assert( sizeof( PerformanceConfigurationAcquireInfoINTEL ) == sizeof( VkPerformanceConfigurationAcquireInfoINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PerformanceConfigurationAcquireInfoINTEL>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PerformanceMarkerInfoINTEL
    {
    protected:
      VULKAN_HPP_CONSTEXPR PerformanceMarkerInfoINTEL( uint64_t marker_ = 0 ) VULKAN_HPP_NOEXCEPT
        : marker( marker_ )
      {}

      PerformanceMarkerInfoINTEL( VkPerformanceMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceMarkerInfoINTEL*>(this) = rhs;
      }

      PerformanceMarkerInfoINTEL& operator=( VkPerformanceMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceMarkerInfoINTEL*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePerformanceMarkerInfoINTEL;
      const void* pNext = nullptr;
      uint64_t marker;
    };
    static_assert( sizeof( PerformanceMarkerInfoINTEL ) == sizeof( VkPerformanceMarkerInfoINTEL ), "layout struct and wrapper have different size!" );
  }

  struct PerformanceMarkerInfoINTEL : public layout::PerformanceMarkerInfoINTEL
  {
    VULKAN_HPP_CONSTEXPR PerformanceMarkerInfoINTEL( uint64_t marker_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceMarkerInfoINTEL( marker_ )
    {}

    PerformanceMarkerInfoINTEL( VkPerformanceMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceMarkerInfoINTEL( rhs )
    {}

    PerformanceMarkerInfoINTEL& operator=( VkPerformanceMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PerformanceMarkerInfoINTEL::operator=(rhs);
      return *this;
    }

    PerformanceMarkerInfoINTEL & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PerformanceMarkerInfoINTEL & setMarker( uint64_t marker_ ) VULKAN_HPP_NOEXCEPT
    {
      marker = marker_;
      return *this;
    }

    operator VkPerformanceMarkerInfoINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPerformanceMarkerInfoINTEL*>( this );
    }

    operator VkPerformanceMarkerInfoINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPerformanceMarkerInfoINTEL*>( this );
    }

    bool operator==( PerformanceMarkerInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( marker == rhs.marker );
    }

    bool operator!=( PerformanceMarkerInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PerformanceMarkerInfoINTEL::sType;
  };
  static_assert( sizeof( PerformanceMarkerInfoINTEL ) == sizeof( VkPerformanceMarkerInfoINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PerformanceMarkerInfoINTEL>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PerformanceOverrideInfoINTEL
    {
    protected:
      VULKAN_HPP_CONSTEXPR PerformanceOverrideInfoINTEL( vk::PerformanceOverrideTypeINTEL type_ = vk::PerformanceOverrideTypeINTEL::eNullHardware,
                                                         vk::Bool32 enable_ = 0,
                                                         uint64_t parameter_ = 0 ) VULKAN_HPP_NOEXCEPT
        : type( type_ )
        , enable( enable_ )
        , parameter( parameter_ )
      {}

      PerformanceOverrideInfoINTEL( VkPerformanceOverrideInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceOverrideInfoINTEL*>(this) = rhs;
      }

      PerformanceOverrideInfoINTEL& operator=( VkPerformanceOverrideInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceOverrideInfoINTEL*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePerformanceOverrideInfoINTEL;
      const void* pNext = nullptr;
      vk::PerformanceOverrideTypeINTEL type;
      vk::Bool32 enable;
      uint64_t parameter;
    };
    static_assert( sizeof( PerformanceOverrideInfoINTEL ) == sizeof( VkPerformanceOverrideInfoINTEL ), "layout struct and wrapper have different size!" );
  }

  struct PerformanceOverrideInfoINTEL : public layout::PerformanceOverrideInfoINTEL
  {
    VULKAN_HPP_CONSTEXPR PerformanceOverrideInfoINTEL( vk::PerformanceOverrideTypeINTEL type_ = vk::PerformanceOverrideTypeINTEL::eNullHardware,
                                                       vk::Bool32 enable_ = 0,
                                                       uint64_t parameter_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceOverrideInfoINTEL( type_, enable_, parameter_ )
    {}

    PerformanceOverrideInfoINTEL( VkPerformanceOverrideInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceOverrideInfoINTEL( rhs )
    {}

    PerformanceOverrideInfoINTEL& operator=( VkPerformanceOverrideInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PerformanceOverrideInfoINTEL::operator=(rhs);
      return *this;
    }

    PerformanceOverrideInfoINTEL & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PerformanceOverrideInfoINTEL & setType( vk::PerformanceOverrideTypeINTEL type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    PerformanceOverrideInfoINTEL & setEnable( vk::Bool32 enable_ ) VULKAN_HPP_NOEXCEPT
    {
      enable = enable_;
      return *this;
    }

    PerformanceOverrideInfoINTEL & setParameter( uint64_t parameter_ ) VULKAN_HPP_NOEXCEPT
    {
      parameter = parameter_;
      return *this;
    }

    operator VkPerformanceOverrideInfoINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPerformanceOverrideInfoINTEL*>( this );
    }

    operator VkPerformanceOverrideInfoINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPerformanceOverrideInfoINTEL*>( this );
    }

    bool operator==( PerformanceOverrideInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( type == rhs.type )
          && ( enable == rhs.enable )
          && ( parameter == rhs.parameter );
    }

    bool operator!=( PerformanceOverrideInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PerformanceOverrideInfoINTEL::sType;
  };
  static_assert( sizeof( PerformanceOverrideInfoINTEL ) == sizeof( VkPerformanceOverrideInfoINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PerformanceOverrideInfoINTEL>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PerformanceStreamMarkerInfoINTEL
    {
    protected:
      VULKAN_HPP_CONSTEXPR PerformanceStreamMarkerInfoINTEL( uint32_t marker_ = 0 ) VULKAN_HPP_NOEXCEPT
        : marker( marker_ )
      {}

      PerformanceStreamMarkerInfoINTEL( VkPerformanceStreamMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceStreamMarkerInfoINTEL*>(this) = rhs;
      }

      PerformanceStreamMarkerInfoINTEL& operator=( VkPerformanceStreamMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPerformanceStreamMarkerInfoINTEL*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePerformanceStreamMarkerInfoINTEL;
      const void* pNext = nullptr;
      uint32_t marker;
    };
    static_assert( sizeof( PerformanceStreamMarkerInfoINTEL ) == sizeof( VkPerformanceStreamMarkerInfoINTEL ), "layout struct and wrapper have different size!" );
  }

  struct PerformanceStreamMarkerInfoINTEL : public layout::PerformanceStreamMarkerInfoINTEL
  {
    VULKAN_HPP_CONSTEXPR PerformanceStreamMarkerInfoINTEL( uint32_t marker_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceStreamMarkerInfoINTEL( marker_ )
    {}

    PerformanceStreamMarkerInfoINTEL( VkPerformanceStreamMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PerformanceStreamMarkerInfoINTEL( rhs )
    {}

    PerformanceStreamMarkerInfoINTEL& operator=( VkPerformanceStreamMarkerInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PerformanceStreamMarkerInfoINTEL::operator=(rhs);
      return *this;
    }

    PerformanceStreamMarkerInfoINTEL & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PerformanceStreamMarkerInfoINTEL & setMarker( uint32_t marker_ ) VULKAN_HPP_NOEXCEPT
    {
      marker = marker_;
      return *this;
    }

    operator VkPerformanceStreamMarkerInfoINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPerformanceStreamMarkerInfoINTEL*>( this );
    }

    operator VkPerformanceStreamMarkerInfoINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPerformanceStreamMarkerInfoINTEL*>( this );
    }

    bool operator==( PerformanceStreamMarkerInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( marker == rhs.marker );
    }

    bool operator!=( PerformanceStreamMarkerInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PerformanceStreamMarkerInfoINTEL::sType;
  };
  static_assert( sizeof( PerformanceStreamMarkerInfoINTEL ) == sizeof( VkPerformanceStreamMarkerInfoINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PerformanceStreamMarkerInfoINTEL>::value, "struct wrapper is not a standard layout!" );

  union PerformanceValueDataINTEL
  {
    PerformanceValueDataINTEL( uint32_t value32_ = 0 )
    {
      value32 = value32_;
    }

    PerformanceValueDataINTEL( uint64_t value64_ )
    {
      value64 = value64_;
    }

    PerformanceValueDataINTEL( float valueFloat_ )
    {
      valueFloat = valueFloat_;
    }

    PerformanceValueDataINTEL( const char* valueString_ )
    {
      valueString = valueString_;
    }

    PerformanceValueDataINTEL & setValue32( uint32_t value32_ ) VULKAN_HPP_NOEXCEPT
    {
      value32 = value32_;
      return *this;
    }

    PerformanceValueDataINTEL & setValue64( uint64_t value64_ ) VULKAN_HPP_NOEXCEPT
    {
      value64 = value64_;
      return *this;
    }

    PerformanceValueDataINTEL & setValueFloat( float valueFloat_ ) VULKAN_HPP_NOEXCEPT
    {
      valueFloat = valueFloat_;
      return *this;
    }

    PerformanceValueDataINTEL & setValueBool( vk::Bool32 valueBool_ ) VULKAN_HPP_NOEXCEPT
    {
      valueBool = valueBool_;
      return *this;
    }

    PerformanceValueDataINTEL & setValueString( const char* valueString_ ) VULKAN_HPP_NOEXCEPT
    {
      valueString = valueString_;
      return *this;
    }
    operator VkPerformanceValueDataINTEL const&() const
    {
      return *reinterpret_cast<const VkPerformanceValueDataINTEL*>(this);
    }

    operator VkPerformanceValueDataINTEL &()
    {
      return *reinterpret_cast<VkPerformanceValueDataINTEL*>(this);
    }

#ifdef VULKAN_HPP_HAS_UNRESTRICTED_UNIONS
    uint32_t value32;
    uint64_t value64;
    float valueFloat;
    vk::Bool32 valueBool;
    const char* valueString;
#else
    uint32_t value32;
    uint64_t value64;
    float valueFloat;
    VkBool32 valueBool;
    const char* valueString;
#endif  /*VULKAN_HPP_HAS_UNRESTRICTED_UNIONS*/
  };

  struct PerformanceValueINTEL
  {
    PerformanceValueINTEL( vk::PerformanceValueTypeINTEL type_ = vk::PerformanceValueTypeINTEL::eUint32,
                           vk::PerformanceValueDataINTEL data_ = vk::PerformanceValueDataINTEL() ) VULKAN_HPP_NOEXCEPT
      : type( type_ )
      , data( data_ )
    {}

    PerformanceValueINTEL( VkPerformanceValueINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPerformanceValueINTEL*>(this) = rhs;
    }

    PerformanceValueINTEL& operator=( VkPerformanceValueINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPerformanceValueINTEL*>(this) = rhs;
      return *this;
    }

    PerformanceValueINTEL & setType( vk::PerformanceValueTypeINTEL type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    PerformanceValueINTEL & setData( vk::PerformanceValueDataINTEL data_ ) VULKAN_HPP_NOEXCEPT
    {
      data = data_;
      return *this;
    }

    operator VkPerformanceValueINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPerformanceValueINTEL*>( this );
    }

    operator VkPerformanceValueINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPerformanceValueINTEL*>( this );
    }

  public:
    vk::PerformanceValueTypeINTEL type;
    vk::PerformanceValueDataINTEL data;
  };
  static_assert( sizeof( PerformanceValueINTEL ) == sizeof( VkPerformanceValueINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PerformanceValueINTEL>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDevice16BitStorageFeatures
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDevice16BitStorageFeatures( vk::Bool32 storageBuffer16BitAccess_ = 0,
                                                               vk::Bool32 uniformAndStorageBuffer16BitAccess_ = 0,
                                                               vk::Bool32 storagePushConstant16_ = 0,
                                                               vk::Bool32 storageInputOutput16_ = 0 ) VULKAN_HPP_NOEXCEPT
        : storageBuffer16BitAccess( storageBuffer16BitAccess_ )
        , uniformAndStorageBuffer16BitAccess( uniformAndStorageBuffer16BitAccess_ )
        , storagePushConstant16( storagePushConstant16_ )
        , storageInputOutput16( storageInputOutput16_ )
      {}

      PhysicalDevice16BitStorageFeatures( VkPhysicalDevice16BitStorageFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevice16BitStorageFeatures*>(this) = rhs;
      }

      PhysicalDevice16BitStorageFeatures& operator=( VkPhysicalDevice16BitStorageFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevice16BitStorageFeatures*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDevice16BitStorageFeatures;
      void* pNext = nullptr;
      vk::Bool32 storageBuffer16BitAccess;
      vk::Bool32 uniformAndStorageBuffer16BitAccess;
      vk::Bool32 storagePushConstant16;
      vk::Bool32 storageInputOutput16;
    };
    static_assert( sizeof( PhysicalDevice16BitStorageFeatures ) == sizeof( VkPhysicalDevice16BitStorageFeatures ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDevice16BitStorageFeatures : public layout::PhysicalDevice16BitStorageFeatures
  {
    VULKAN_HPP_CONSTEXPR PhysicalDevice16BitStorageFeatures( vk::Bool32 storageBuffer16BitAccess_ = 0,
                                                             vk::Bool32 uniformAndStorageBuffer16BitAccess_ = 0,
                                                             vk::Bool32 storagePushConstant16_ = 0,
                                                             vk::Bool32 storageInputOutput16_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevice16BitStorageFeatures( storageBuffer16BitAccess_, uniformAndStorageBuffer16BitAccess_, storagePushConstant16_, storageInputOutput16_ )
    {}

    PhysicalDevice16BitStorageFeatures( VkPhysicalDevice16BitStorageFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevice16BitStorageFeatures( rhs )
    {}

    PhysicalDevice16BitStorageFeatures& operator=( VkPhysicalDevice16BitStorageFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDevice16BitStorageFeatures::operator=(rhs);
      return *this;
    }

    PhysicalDevice16BitStorageFeatures & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDevice16BitStorageFeatures & setStorageBuffer16BitAccess( vk::Bool32 storageBuffer16BitAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      storageBuffer16BitAccess = storageBuffer16BitAccess_;
      return *this;
    }

    PhysicalDevice16BitStorageFeatures & setUniformAndStorageBuffer16BitAccess( vk::Bool32 uniformAndStorageBuffer16BitAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      uniformAndStorageBuffer16BitAccess = uniformAndStorageBuffer16BitAccess_;
      return *this;
    }

    PhysicalDevice16BitStorageFeatures & setStoragePushConstant16( vk::Bool32 storagePushConstant16_ ) VULKAN_HPP_NOEXCEPT
    {
      storagePushConstant16 = storagePushConstant16_;
      return *this;
    }

    PhysicalDevice16BitStorageFeatures & setStorageInputOutput16( vk::Bool32 storageInputOutput16_ ) VULKAN_HPP_NOEXCEPT
    {
      storageInputOutput16 = storageInputOutput16_;
      return *this;
    }

    operator VkPhysicalDevice16BitStorageFeatures const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDevice16BitStorageFeatures*>( this );
    }

    operator VkPhysicalDevice16BitStorageFeatures &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDevice16BitStorageFeatures*>( this );
    }

    bool operator==( PhysicalDevice16BitStorageFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( storageBuffer16BitAccess == rhs.storageBuffer16BitAccess )
          && ( uniformAndStorageBuffer16BitAccess == rhs.uniformAndStorageBuffer16BitAccess )
          && ( storagePushConstant16 == rhs.storagePushConstant16 )
          && ( storageInputOutput16 == rhs.storageInputOutput16 );
    }

    bool operator!=( PhysicalDevice16BitStorageFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDevice16BitStorageFeatures::sType;
  };
  static_assert( sizeof( PhysicalDevice16BitStorageFeatures ) == sizeof( VkPhysicalDevice16BitStorageFeatures ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDevice16BitStorageFeatures>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDevice8BitStorageFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDevice8BitStorageFeaturesKHR( vk::Bool32 storageBuffer8BitAccess_ = 0,
                                                                 vk::Bool32 uniformAndStorageBuffer8BitAccess_ = 0,
                                                                 vk::Bool32 storagePushConstant8_ = 0 ) VULKAN_HPP_NOEXCEPT
        : storageBuffer8BitAccess( storageBuffer8BitAccess_ )
        , uniformAndStorageBuffer8BitAccess( uniformAndStorageBuffer8BitAccess_ )
        , storagePushConstant8( storagePushConstant8_ )
      {}

      PhysicalDevice8BitStorageFeaturesKHR( VkPhysicalDevice8BitStorageFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevice8BitStorageFeaturesKHR*>(this) = rhs;
      }

      PhysicalDevice8BitStorageFeaturesKHR& operator=( VkPhysicalDevice8BitStorageFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevice8BitStorageFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDevice8BitStorageFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 storageBuffer8BitAccess;
      vk::Bool32 uniformAndStorageBuffer8BitAccess;
      vk::Bool32 storagePushConstant8;
    };
    static_assert( sizeof( PhysicalDevice8BitStorageFeaturesKHR ) == sizeof( VkPhysicalDevice8BitStorageFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDevice8BitStorageFeaturesKHR : public layout::PhysicalDevice8BitStorageFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDevice8BitStorageFeaturesKHR( vk::Bool32 storageBuffer8BitAccess_ = 0,
                                                               vk::Bool32 uniformAndStorageBuffer8BitAccess_ = 0,
                                                               vk::Bool32 storagePushConstant8_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevice8BitStorageFeaturesKHR( storageBuffer8BitAccess_, uniformAndStorageBuffer8BitAccess_, storagePushConstant8_ )
    {}

    PhysicalDevice8BitStorageFeaturesKHR( VkPhysicalDevice8BitStorageFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevice8BitStorageFeaturesKHR( rhs )
    {}

    PhysicalDevice8BitStorageFeaturesKHR& operator=( VkPhysicalDevice8BitStorageFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDevice8BitStorageFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDevice8BitStorageFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDevice8BitStorageFeaturesKHR & setStorageBuffer8BitAccess( vk::Bool32 storageBuffer8BitAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      storageBuffer8BitAccess = storageBuffer8BitAccess_;
      return *this;
    }

    PhysicalDevice8BitStorageFeaturesKHR & setUniformAndStorageBuffer8BitAccess( vk::Bool32 uniformAndStorageBuffer8BitAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      uniformAndStorageBuffer8BitAccess = uniformAndStorageBuffer8BitAccess_;
      return *this;
    }

    PhysicalDevice8BitStorageFeaturesKHR & setStoragePushConstant8( vk::Bool32 storagePushConstant8_ ) VULKAN_HPP_NOEXCEPT
    {
      storagePushConstant8 = storagePushConstant8_;
      return *this;
    }

    operator VkPhysicalDevice8BitStorageFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDevice8BitStorageFeaturesKHR*>( this );
    }

    operator VkPhysicalDevice8BitStorageFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDevice8BitStorageFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDevice8BitStorageFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( storageBuffer8BitAccess == rhs.storageBuffer8BitAccess )
          && ( uniformAndStorageBuffer8BitAccess == rhs.uniformAndStorageBuffer8BitAccess )
          && ( storagePushConstant8 == rhs.storagePushConstant8 );
    }

    bool operator!=( PhysicalDevice8BitStorageFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDevice8BitStorageFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDevice8BitStorageFeaturesKHR ) == sizeof( VkPhysicalDevice8BitStorageFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDevice8BitStorageFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceASTCDecodeFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceASTCDecodeFeaturesEXT( vk::Bool32 decodeModeSharedExponent_ = 0 ) VULKAN_HPP_NOEXCEPT
        : decodeModeSharedExponent( decodeModeSharedExponent_ )
      {}

      PhysicalDeviceASTCDecodeFeaturesEXT( VkPhysicalDeviceASTCDecodeFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceASTCDecodeFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceASTCDecodeFeaturesEXT& operator=( VkPhysicalDeviceASTCDecodeFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceASTCDecodeFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceAstcDecodeFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 decodeModeSharedExponent;
    };
    static_assert( sizeof( PhysicalDeviceASTCDecodeFeaturesEXT ) == sizeof( VkPhysicalDeviceASTCDecodeFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceASTCDecodeFeaturesEXT : public layout::PhysicalDeviceASTCDecodeFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceASTCDecodeFeaturesEXT( vk::Bool32 decodeModeSharedExponent_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceASTCDecodeFeaturesEXT( decodeModeSharedExponent_ )
    {}

    PhysicalDeviceASTCDecodeFeaturesEXT( VkPhysicalDeviceASTCDecodeFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceASTCDecodeFeaturesEXT( rhs )
    {}

    PhysicalDeviceASTCDecodeFeaturesEXT& operator=( VkPhysicalDeviceASTCDecodeFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceASTCDecodeFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceASTCDecodeFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceASTCDecodeFeaturesEXT & setDecodeModeSharedExponent( vk::Bool32 decodeModeSharedExponent_ ) VULKAN_HPP_NOEXCEPT
    {
      decodeModeSharedExponent = decodeModeSharedExponent_;
      return *this;
    }

    operator VkPhysicalDeviceASTCDecodeFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceASTCDecodeFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceASTCDecodeFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceASTCDecodeFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceASTCDecodeFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( decodeModeSharedExponent == rhs.decodeModeSharedExponent );
    }

    bool operator!=( PhysicalDeviceASTCDecodeFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceASTCDecodeFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceASTCDecodeFeaturesEXT ) == sizeof( VkPhysicalDeviceASTCDecodeFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceASTCDecodeFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceBlendOperationAdvancedFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceBlendOperationAdvancedFeaturesEXT( vk::Bool32 advancedBlendCoherentOperations_ = 0 ) VULKAN_HPP_NOEXCEPT
        : advancedBlendCoherentOperations( advancedBlendCoherentOperations_ )
      {}

      PhysicalDeviceBlendOperationAdvancedFeaturesEXT( VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceBlendOperationAdvancedFeaturesEXT& operator=( VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceBlendOperationAdvancedFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 advancedBlendCoherentOperations;
    };
    static_assert( sizeof( PhysicalDeviceBlendOperationAdvancedFeaturesEXT ) == sizeof( VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceBlendOperationAdvancedFeaturesEXT : public layout::PhysicalDeviceBlendOperationAdvancedFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceBlendOperationAdvancedFeaturesEXT( vk::Bool32 advancedBlendCoherentOperations_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceBlendOperationAdvancedFeaturesEXT( advancedBlendCoherentOperations_ )
    {}

    PhysicalDeviceBlendOperationAdvancedFeaturesEXT( VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceBlendOperationAdvancedFeaturesEXT( rhs )
    {}

    PhysicalDeviceBlendOperationAdvancedFeaturesEXT& operator=( VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceBlendOperationAdvancedFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceBlendOperationAdvancedFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceBlendOperationAdvancedFeaturesEXT & setAdvancedBlendCoherentOperations( vk::Bool32 advancedBlendCoherentOperations_ ) VULKAN_HPP_NOEXCEPT
    {
      advancedBlendCoherentOperations = advancedBlendCoherentOperations_;
      return *this;
    }

    operator VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceBlendOperationAdvancedFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( advancedBlendCoherentOperations == rhs.advancedBlendCoherentOperations );
    }

    bool operator!=( PhysicalDeviceBlendOperationAdvancedFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceBlendOperationAdvancedFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceBlendOperationAdvancedFeaturesEXT ) == sizeof( VkPhysicalDeviceBlendOperationAdvancedFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceBlendOperationAdvancedFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceBlendOperationAdvancedPropertiesEXT
    {
    protected:
      PhysicalDeviceBlendOperationAdvancedPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceBlendOperationAdvancedPropertiesEXT( VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceBlendOperationAdvancedPropertiesEXT& operator=( VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceBlendOperationAdvancedPropertiesEXT;
      void* pNext = nullptr;
      uint32_t advancedBlendMaxColorAttachments;
      vk::Bool32 advancedBlendIndependentBlend;
      vk::Bool32 advancedBlendNonPremultipliedSrcColor;
      vk::Bool32 advancedBlendNonPremultipliedDstColor;
      vk::Bool32 advancedBlendCorrelatedOverlap;
      vk::Bool32 advancedBlendAllOperations;
    };
    static_assert( sizeof( PhysicalDeviceBlendOperationAdvancedPropertiesEXT ) == sizeof( VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceBlendOperationAdvancedPropertiesEXT : public layout::PhysicalDeviceBlendOperationAdvancedPropertiesEXT
  {
    PhysicalDeviceBlendOperationAdvancedPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceBlendOperationAdvancedPropertiesEXT()
    {}

    PhysicalDeviceBlendOperationAdvancedPropertiesEXT( VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceBlendOperationAdvancedPropertiesEXT( rhs )
    {}

    PhysicalDeviceBlendOperationAdvancedPropertiesEXT& operator=( VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceBlendOperationAdvancedPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceBlendOperationAdvancedPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( advancedBlendMaxColorAttachments == rhs.advancedBlendMaxColorAttachments )
          && ( advancedBlendIndependentBlend == rhs.advancedBlendIndependentBlend )
          && ( advancedBlendNonPremultipliedSrcColor == rhs.advancedBlendNonPremultipliedSrcColor )
          && ( advancedBlendNonPremultipliedDstColor == rhs.advancedBlendNonPremultipliedDstColor )
          && ( advancedBlendCorrelatedOverlap == rhs.advancedBlendCorrelatedOverlap )
          && ( advancedBlendAllOperations == rhs.advancedBlendAllOperations );
    }

    bool operator!=( PhysicalDeviceBlendOperationAdvancedPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceBlendOperationAdvancedPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceBlendOperationAdvancedPropertiesEXT ) == sizeof( VkPhysicalDeviceBlendOperationAdvancedPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceBlendOperationAdvancedPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceBufferDeviceAddressFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceBufferDeviceAddressFeaturesEXT( vk::Bool32 bufferDeviceAddress_ = 0,
                                                                         vk::Bool32 bufferDeviceAddressCaptureReplay_ = 0,
                                                                         vk::Bool32 bufferDeviceAddressMultiDevice_ = 0 ) VULKAN_HPP_NOEXCEPT
        : bufferDeviceAddress( bufferDeviceAddress_ )
        , bufferDeviceAddressCaptureReplay( bufferDeviceAddressCaptureReplay_ )
        , bufferDeviceAddressMultiDevice( bufferDeviceAddressMultiDevice_ )
      {}

      PhysicalDeviceBufferDeviceAddressFeaturesEXT( VkPhysicalDeviceBufferDeviceAddressFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceBufferDeviceAddressFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceBufferDeviceAddressFeaturesEXT& operator=( VkPhysicalDeviceBufferDeviceAddressFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceBufferDeviceAddressFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceBufferDeviceAddressFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 bufferDeviceAddress;
      vk::Bool32 bufferDeviceAddressCaptureReplay;
      vk::Bool32 bufferDeviceAddressMultiDevice;
    };
    static_assert( sizeof( PhysicalDeviceBufferDeviceAddressFeaturesEXT ) == sizeof( VkPhysicalDeviceBufferDeviceAddressFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceBufferDeviceAddressFeaturesEXT : public layout::PhysicalDeviceBufferDeviceAddressFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceBufferDeviceAddressFeaturesEXT( vk::Bool32 bufferDeviceAddress_ = 0,
                                                                       vk::Bool32 bufferDeviceAddressCaptureReplay_ = 0,
                                                                       vk::Bool32 bufferDeviceAddressMultiDevice_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceBufferDeviceAddressFeaturesEXT( bufferDeviceAddress_, bufferDeviceAddressCaptureReplay_, bufferDeviceAddressMultiDevice_ )
    {}

    PhysicalDeviceBufferDeviceAddressFeaturesEXT( VkPhysicalDeviceBufferDeviceAddressFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceBufferDeviceAddressFeaturesEXT( rhs )
    {}

    PhysicalDeviceBufferDeviceAddressFeaturesEXT& operator=( VkPhysicalDeviceBufferDeviceAddressFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceBufferDeviceAddressFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceBufferDeviceAddressFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceBufferDeviceAddressFeaturesEXT & setBufferDeviceAddress( vk::Bool32 bufferDeviceAddress_ ) VULKAN_HPP_NOEXCEPT
    {
      bufferDeviceAddress = bufferDeviceAddress_;
      return *this;
    }

    PhysicalDeviceBufferDeviceAddressFeaturesEXT & setBufferDeviceAddressCaptureReplay( vk::Bool32 bufferDeviceAddressCaptureReplay_ ) VULKAN_HPP_NOEXCEPT
    {
      bufferDeviceAddressCaptureReplay = bufferDeviceAddressCaptureReplay_;
      return *this;
    }

    PhysicalDeviceBufferDeviceAddressFeaturesEXT & setBufferDeviceAddressMultiDevice( vk::Bool32 bufferDeviceAddressMultiDevice_ ) VULKAN_HPP_NOEXCEPT
    {
      bufferDeviceAddressMultiDevice = bufferDeviceAddressMultiDevice_;
      return *this;
    }

    operator VkPhysicalDeviceBufferDeviceAddressFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceBufferDeviceAddressFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceBufferDeviceAddressFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceBufferDeviceAddressFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceBufferDeviceAddressFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( bufferDeviceAddress == rhs.bufferDeviceAddress )
          && ( bufferDeviceAddressCaptureReplay == rhs.bufferDeviceAddressCaptureReplay )
          && ( bufferDeviceAddressMultiDevice == rhs.bufferDeviceAddressMultiDevice );
    }

    bool operator!=( PhysicalDeviceBufferDeviceAddressFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceBufferDeviceAddressFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceBufferDeviceAddressFeaturesEXT ) == sizeof( VkPhysicalDeviceBufferDeviceAddressFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceBufferDeviceAddressFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceCoherentMemoryFeaturesAMD
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceCoherentMemoryFeaturesAMD( vk::Bool32 deviceCoherentMemory_ = 0 ) VULKAN_HPP_NOEXCEPT
        : deviceCoherentMemory( deviceCoherentMemory_ )
      {}

      PhysicalDeviceCoherentMemoryFeaturesAMD( VkPhysicalDeviceCoherentMemoryFeaturesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCoherentMemoryFeaturesAMD*>(this) = rhs;
      }

      PhysicalDeviceCoherentMemoryFeaturesAMD& operator=( VkPhysicalDeviceCoherentMemoryFeaturesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCoherentMemoryFeaturesAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceCoherentMemoryFeaturesAMD;
      void* pNext = nullptr;
      vk::Bool32 deviceCoherentMemory;
    };
    static_assert( sizeof( PhysicalDeviceCoherentMemoryFeaturesAMD ) == sizeof( VkPhysicalDeviceCoherentMemoryFeaturesAMD ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceCoherentMemoryFeaturesAMD : public layout::PhysicalDeviceCoherentMemoryFeaturesAMD
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceCoherentMemoryFeaturesAMD( vk::Bool32 deviceCoherentMemory_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCoherentMemoryFeaturesAMD( deviceCoherentMemory_ )
    {}

    PhysicalDeviceCoherentMemoryFeaturesAMD( VkPhysicalDeviceCoherentMemoryFeaturesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCoherentMemoryFeaturesAMD( rhs )
    {}

    PhysicalDeviceCoherentMemoryFeaturesAMD& operator=( VkPhysicalDeviceCoherentMemoryFeaturesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceCoherentMemoryFeaturesAMD::operator=(rhs);
      return *this;
    }

    PhysicalDeviceCoherentMemoryFeaturesAMD & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceCoherentMemoryFeaturesAMD & setDeviceCoherentMemory( vk::Bool32 deviceCoherentMemory_ ) VULKAN_HPP_NOEXCEPT
    {
      deviceCoherentMemory = deviceCoherentMemory_;
      return *this;
    }

    operator VkPhysicalDeviceCoherentMemoryFeaturesAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceCoherentMemoryFeaturesAMD*>( this );
    }

    operator VkPhysicalDeviceCoherentMemoryFeaturesAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceCoherentMemoryFeaturesAMD*>( this );
    }

    bool operator==( PhysicalDeviceCoherentMemoryFeaturesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( deviceCoherentMemory == rhs.deviceCoherentMemory );
    }

    bool operator!=( PhysicalDeviceCoherentMemoryFeaturesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceCoherentMemoryFeaturesAMD::sType;
  };
  static_assert( sizeof( PhysicalDeviceCoherentMemoryFeaturesAMD ) == sizeof( VkPhysicalDeviceCoherentMemoryFeaturesAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceCoherentMemoryFeaturesAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceComputeShaderDerivativesFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceComputeShaderDerivativesFeaturesNV( vk::Bool32 computeDerivativeGroupQuads_ = 0,
                                                                             vk::Bool32 computeDerivativeGroupLinear_ = 0 ) VULKAN_HPP_NOEXCEPT
        : computeDerivativeGroupQuads( computeDerivativeGroupQuads_ )
        , computeDerivativeGroupLinear( computeDerivativeGroupLinear_ )
      {}

      PhysicalDeviceComputeShaderDerivativesFeaturesNV( VkPhysicalDeviceComputeShaderDerivativesFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceComputeShaderDerivativesFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceComputeShaderDerivativesFeaturesNV& operator=( VkPhysicalDeviceComputeShaderDerivativesFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceComputeShaderDerivativesFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceComputeShaderDerivativesFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 computeDerivativeGroupQuads;
      vk::Bool32 computeDerivativeGroupLinear;
    };
    static_assert( sizeof( PhysicalDeviceComputeShaderDerivativesFeaturesNV ) == sizeof( VkPhysicalDeviceComputeShaderDerivativesFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceComputeShaderDerivativesFeaturesNV : public layout::PhysicalDeviceComputeShaderDerivativesFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceComputeShaderDerivativesFeaturesNV( vk::Bool32 computeDerivativeGroupQuads_ = 0,
                                                                           vk::Bool32 computeDerivativeGroupLinear_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceComputeShaderDerivativesFeaturesNV( computeDerivativeGroupQuads_, computeDerivativeGroupLinear_ )
    {}

    PhysicalDeviceComputeShaderDerivativesFeaturesNV( VkPhysicalDeviceComputeShaderDerivativesFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceComputeShaderDerivativesFeaturesNV( rhs )
    {}

    PhysicalDeviceComputeShaderDerivativesFeaturesNV& operator=( VkPhysicalDeviceComputeShaderDerivativesFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceComputeShaderDerivativesFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceComputeShaderDerivativesFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceComputeShaderDerivativesFeaturesNV & setComputeDerivativeGroupQuads( vk::Bool32 computeDerivativeGroupQuads_ ) VULKAN_HPP_NOEXCEPT
    {
      computeDerivativeGroupQuads = computeDerivativeGroupQuads_;
      return *this;
    }

    PhysicalDeviceComputeShaderDerivativesFeaturesNV & setComputeDerivativeGroupLinear( vk::Bool32 computeDerivativeGroupLinear_ ) VULKAN_HPP_NOEXCEPT
    {
      computeDerivativeGroupLinear = computeDerivativeGroupLinear_;
      return *this;
    }

    operator VkPhysicalDeviceComputeShaderDerivativesFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceComputeShaderDerivativesFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceComputeShaderDerivativesFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceComputeShaderDerivativesFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceComputeShaderDerivativesFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( computeDerivativeGroupQuads == rhs.computeDerivativeGroupQuads )
          && ( computeDerivativeGroupLinear == rhs.computeDerivativeGroupLinear );
    }

    bool operator!=( PhysicalDeviceComputeShaderDerivativesFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceComputeShaderDerivativesFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceComputeShaderDerivativesFeaturesNV ) == sizeof( VkPhysicalDeviceComputeShaderDerivativesFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceComputeShaderDerivativesFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceConditionalRenderingFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceConditionalRenderingFeaturesEXT( vk::Bool32 conditionalRendering_ = 0,
                                                                          vk::Bool32 inheritedConditionalRendering_ = 0 ) VULKAN_HPP_NOEXCEPT
        : conditionalRendering( conditionalRendering_ )
        , inheritedConditionalRendering( inheritedConditionalRendering_ )
      {}

      PhysicalDeviceConditionalRenderingFeaturesEXT( VkPhysicalDeviceConditionalRenderingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceConditionalRenderingFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceConditionalRenderingFeaturesEXT& operator=( VkPhysicalDeviceConditionalRenderingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceConditionalRenderingFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceConditionalRenderingFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 conditionalRendering;
      vk::Bool32 inheritedConditionalRendering;
    };
    static_assert( sizeof( PhysicalDeviceConditionalRenderingFeaturesEXT ) == sizeof( VkPhysicalDeviceConditionalRenderingFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceConditionalRenderingFeaturesEXT : public layout::PhysicalDeviceConditionalRenderingFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceConditionalRenderingFeaturesEXT( vk::Bool32 conditionalRendering_ = 0,
                                                                        vk::Bool32 inheritedConditionalRendering_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceConditionalRenderingFeaturesEXT( conditionalRendering_, inheritedConditionalRendering_ )
    {}

    PhysicalDeviceConditionalRenderingFeaturesEXT( VkPhysicalDeviceConditionalRenderingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceConditionalRenderingFeaturesEXT( rhs )
    {}

    PhysicalDeviceConditionalRenderingFeaturesEXT& operator=( VkPhysicalDeviceConditionalRenderingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceConditionalRenderingFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceConditionalRenderingFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceConditionalRenderingFeaturesEXT & setConditionalRendering( vk::Bool32 conditionalRendering_ ) VULKAN_HPP_NOEXCEPT
    {
      conditionalRendering = conditionalRendering_;
      return *this;
    }

    PhysicalDeviceConditionalRenderingFeaturesEXT & setInheritedConditionalRendering( vk::Bool32 inheritedConditionalRendering_ ) VULKAN_HPP_NOEXCEPT
    {
      inheritedConditionalRendering = inheritedConditionalRendering_;
      return *this;
    }

    operator VkPhysicalDeviceConditionalRenderingFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceConditionalRenderingFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceConditionalRenderingFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceConditionalRenderingFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceConditionalRenderingFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( conditionalRendering == rhs.conditionalRendering )
          && ( inheritedConditionalRendering == rhs.inheritedConditionalRendering );
    }

    bool operator!=( PhysicalDeviceConditionalRenderingFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceConditionalRenderingFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceConditionalRenderingFeaturesEXT ) == sizeof( VkPhysicalDeviceConditionalRenderingFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceConditionalRenderingFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceConservativeRasterizationPropertiesEXT
    {
    protected:
      PhysicalDeviceConservativeRasterizationPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceConservativeRasterizationPropertiesEXT( VkPhysicalDeviceConservativeRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceConservativeRasterizationPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceConservativeRasterizationPropertiesEXT& operator=( VkPhysicalDeviceConservativeRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceConservativeRasterizationPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceConservativeRasterizationPropertiesEXT;
      void* pNext = nullptr;
      float primitiveOverestimationSize;
      float maxExtraPrimitiveOverestimationSize;
      float extraPrimitiveOverestimationSizeGranularity;
      vk::Bool32 primitiveUnderestimation;
      vk::Bool32 conservativePointAndLineRasterization;
      vk::Bool32 degenerateTrianglesRasterized;
      vk::Bool32 degenerateLinesRasterized;
      vk::Bool32 fullyCoveredFragmentShaderInputVariable;
      vk::Bool32 conservativeRasterizationPostDepthCoverage;
    };
    static_assert( sizeof( PhysicalDeviceConservativeRasterizationPropertiesEXT ) == sizeof( VkPhysicalDeviceConservativeRasterizationPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceConservativeRasterizationPropertiesEXT : public layout::PhysicalDeviceConservativeRasterizationPropertiesEXT
  {
    PhysicalDeviceConservativeRasterizationPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceConservativeRasterizationPropertiesEXT()
    {}

    PhysicalDeviceConservativeRasterizationPropertiesEXT( VkPhysicalDeviceConservativeRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceConservativeRasterizationPropertiesEXT( rhs )
    {}

    PhysicalDeviceConservativeRasterizationPropertiesEXT& operator=( VkPhysicalDeviceConservativeRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceConservativeRasterizationPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceConservativeRasterizationPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceConservativeRasterizationPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceConservativeRasterizationPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceConservativeRasterizationPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceConservativeRasterizationPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( primitiveOverestimationSize == rhs.primitiveOverestimationSize )
          && ( maxExtraPrimitiveOverestimationSize == rhs.maxExtraPrimitiveOverestimationSize )
          && ( extraPrimitiveOverestimationSizeGranularity == rhs.extraPrimitiveOverestimationSizeGranularity )
          && ( primitiveUnderestimation == rhs.primitiveUnderestimation )
          && ( conservativePointAndLineRasterization == rhs.conservativePointAndLineRasterization )
          && ( degenerateTrianglesRasterized == rhs.degenerateTrianglesRasterized )
          && ( degenerateLinesRasterized == rhs.degenerateLinesRasterized )
          && ( fullyCoveredFragmentShaderInputVariable == rhs.fullyCoveredFragmentShaderInputVariable )
          && ( conservativeRasterizationPostDepthCoverage == rhs.conservativeRasterizationPostDepthCoverage );
    }

    bool operator!=( PhysicalDeviceConservativeRasterizationPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceConservativeRasterizationPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceConservativeRasterizationPropertiesEXT ) == sizeof( VkPhysicalDeviceConservativeRasterizationPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceConservativeRasterizationPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceCooperativeMatrixFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceCooperativeMatrixFeaturesNV( vk::Bool32 cooperativeMatrix_ = 0,
                                                                      vk::Bool32 cooperativeMatrixRobustBufferAccess_ = 0 ) VULKAN_HPP_NOEXCEPT
        : cooperativeMatrix( cooperativeMatrix_ )
        , cooperativeMatrixRobustBufferAccess( cooperativeMatrixRobustBufferAccess_ )
      {}

      PhysicalDeviceCooperativeMatrixFeaturesNV( VkPhysicalDeviceCooperativeMatrixFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCooperativeMatrixFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceCooperativeMatrixFeaturesNV& operator=( VkPhysicalDeviceCooperativeMatrixFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCooperativeMatrixFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceCooperativeMatrixFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 cooperativeMatrix;
      vk::Bool32 cooperativeMatrixRobustBufferAccess;
    };
    static_assert( sizeof( PhysicalDeviceCooperativeMatrixFeaturesNV ) == sizeof( VkPhysicalDeviceCooperativeMatrixFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceCooperativeMatrixFeaturesNV : public layout::PhysicalDeviceCooperativeMatrixFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceCooperativeMatrixFeaturesNV( vk::Bool32 cooperativeMatrix_ = 0,
                                                                    vk::Bool32 cooperativeMatrixRobustBufferAccess_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCooperativeMatrixFeaturesNV( cooperativeMatrix_, cooperativeMatrixRobustBufferAccess_ )
    {}

    PhysicalDeviceCooperativeMatrixFeaturesNV( VkPhysicalDeviceCooperativeMatrixFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCooperativeMatrixFeaturesNV( rhs )
    {}

    PhysicalDeviceCooperativeMatrixFeaturesNV& operator=( VkPhysicalDeviceCooperativeMatrixFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceCooperativeMatrixFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceCooperativeMatrixFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceCooperativeMatrixFeaturesNV & setCooperativeMatrix( vk::Bool32 cooperativeMatrix_ ) VULKAN_HPP_NOEXCEPT
    {
      cooperativeMatrix = cooperativeMatrix_;
      return *this;
    }

    PhysicalDeviceCooperativeMatrixFeaturesNV & setCooperativeMatrixRobustBufferAccess( vk::Bool32 cooperativeMatrixRobustBufferAccess_ ) VULKAN_HPP_NOEXCEPT
    {
      cooperativeMatrixRobustBufferAccess = cooperativeMatrixRobustBufferAccess_;
      return *this;
    }

    operator VkPhysicalDeviceCooperativeMatrixFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceCooperativeMatrixFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceCooperativeMatrixFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceCooperativeMatrixFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceCooperativeMatrixFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( cooperativeMatrix == rhs.cooperativeMatrix )
          && ( cooperativeMatrixRobustBufferAccess == rhs.cooperativeMatrixRobustBufferAccess );
    }

    bool operator!=( PhysicalDeviceCooperativeMatrixFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceCooperativeMatrixFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceCooperativeMatrixFeaturesNV ) == sizeof( VkPhysicalDeviceCooperativeMatrixFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceCooperativeMatrixFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceCooperativeMatrixPropertiesNV
    {
    protected:
      PhysicalDeviceCooperativeMatrixPropertiesNV() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceCooperativeMatrixPropertiesNV( VkPhysicalDeviceCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCooperativeMatrixPropertiesNV*>(this) = rhs;
      }

      PhysicalDeviceCooperativeMatrixPropertiesNV& operator=( VkPhysicalDeviceCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCooperativeMatrixPropertiesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceCooperativeMatrixPropertiesNV;
      void* pNext = nullptr;
      vk::ShaderStageFlags cooperativeMatrixSupportedStages;
    };
    static_assert( sizeof( PhysicalDeviceCooperativeMatrixPropertiesNV ) == sizeof( VkPhysicalDeviceCooperativeMatrixPropertiesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceCooperativeMatrixPropertiesNV : public layout::PhysicalDeviceCooperativeMatrixPropertiesNV
  {
    PhysicalDeviceCooperativeMatrixPropertiesNV() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCooperativeMatrixPropertiesNV()
    {}

    PhysicalDeviceCooperativeMatrixPropertiesNV( VkPhysicalDeviceCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCooperativeMatrixPropertiesNV( rhs )
    {}

    PhysicalDeviceCooperativeMatrixPropertiesNV& operator=( VkPhysicalDeviceCooperativeMatrixPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceCooperativeMatrixPropertiesNV::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceCooperativeMatrixPropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceCooperativeMatrixPropertiesNV*>( this );
    }

    operator VkPhysicalDeviceCooperativeMatrixPropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceCooperativeMatrixPropertiesNV*>( this );
    }

    bool operator==( PhysicalDeviceCooperativeMatrixPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( cooperativeMatrixSupportedStages == rhs.cooperativeMatrixSupportedStages );
    }

    bool operator!=( PhysicalDeviceCooperativeMatrixPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceCooperativeMatrixPropertiesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceCooperativeMatrixPropertiesNV ) == sizeof( VkPhysicalDeviceCooperativeMatrixPropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceCooperativeMatrixPropertiesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceCornerSampledImageFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceCornerSampledImageFeaturesNV( vk::Bool32 cornerSampledImage_ = 0 ) VULKAN_HPP_NOEXCEPT
        : cornerSampledImage( cornerSampledImage_ )
      {}

      PhysicalDeviceCornerSampledImageFeaturesNV( VkPhysicalDeviceCornerSampledImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCornerSampledImageFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceCornerSampledImageFeaturesNV& operator=( VkPhysicalDeviceCornerSampledImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCornerSampledImageFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceCornerSampledImageFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 cornerSampledImage;
    };
    static_assert( sizeof( PhysicalDeviceCornerSampledImageFeaturesNV ) == sizeof( VkPhysicalDeviceCornerSampledImageFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceCornerSampledImageFeaturesNV : public layout::PhysicalDeviceCornerSampledImageFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceCornerSampledImageFeaturesNV( vk::Bool32 cornerSampledImage_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCornerSampledImageFeaturesNV( cornerSampledImage_ )
    {}

    PhysicalDeviceCornerSampledImageFeaturesNV( VkPhysicalDeviceCornerSampledImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCornerSampledImageFeaturesNV( rhs )
    {}

    PhysicalDeviceCornerSampledImageFeaturesNV& operator=( VkPhysicalDeviceCornerSampledImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceCornerSampledImageFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceCornerSampledImageFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceCornerSampledImageFeaturesNV & setCornerSampledImage( vk::Bool32 cornerSampledImage_ ) VULKAN_HPP_NOEXCEPT
    {
      cornerSampledImage = cornerSampledImage_;
      return *this;
    }

    operator VkPhysicalDeviceCornerSampledImageFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceCornerSampledImageFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceCornerSampledImageFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceCornerSampledImageFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceCornerSampledImageFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( cornerSampledImage == rhs.cornerSampledImage );
    }

    bool operator!=( PhysicalDeviceCornerSampledImageFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceCornerSampledImageFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceCornerSampledImageFeaturesNV ) == sizeof( VkPhysicalDeviceCornerSampledImageFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceCornerSampledImageFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceCoverageReductionModeFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceCoverageReductionModeFeaturesNV( vk::Bool32 coverageReductionMode_ = 0 ) VULKAN_HPP_NOEXCEPT
        : coverageReductionMode( coverageReductionMode_ )
      {}

      PhysicalDeviceCoverageReductionModeFeaturesNV( VkPhysicalDeviceCoverageReductionModeFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCoverageReductionModeFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceCoverageReductionModeFeaturesNV& operator=( VkPhysicalDeviceCoverageReductionModeFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceCoverageReductionModeFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceCoverageReductionModeFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 coverageReductionMode;
    };
    static_assert( sizeof( PhysicalDeviceCoverageReductionModeFeaturesNV ) == sizeof( VkPhysicalDeviceCoverageReductionModeFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceCoverageReductionModeFeaturesNV : public layout::PhysicalDeviceCoverageReductionModeFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceCoverageReductionModeFeaturesNV( vk::Bool32 coverageReductionMode_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCoverageReductionModeFeaturesNV( coverageReductionMode_ )
    {}

    PhysicalDeviceCoverageReductionModeFeaturesNV( VkPhysicalDeviceCoverageReductionModeFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceCoverageReductionModeFeaturesNV( rhs )
    {}

    PhysicalDeviceCoverageReductionModeFeaturesNV& operator=( VkPhysicalDeviceCoverageReductionModeFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceCoverageReductionModeFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceCoverageReductionModeFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceCoverageReductionModeFeaturesNV & setCoverageReductionMode( vk::Bool32 coverageReductionMode_ ) VULKAN_HPP_NOEXCEPT
    {
      coverageReductionMode = coverageReductionMode_;
      return *this;
    }

    operator VkPhysicalDeviceCoverageReductionModeFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceCoverageReductionModeFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceCoverageReductionModeFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceCoverageReductionModeFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceCoverageReductionModeFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( coverageReductionMode == rhs.coverageReductionMode );
    }

    bool operator!=( PhysicalDeviceCoverageReductionModeFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceCoverageReductionModeFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceCoverageReductionModeFeaturesNV ) == sizeof( VkPhysicalDeviceCoverageReductionModeFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceCoverageReductionModeFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV( vk::Bool32 dedicatedAllocationImageAliasing_ = 0 ) VULKAN_HPP_NOEXCEPT
        : dedicatedAllocationImageAliasing( dedicatedAllocationImageAliasing_ )
      {}

      PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV( VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV& operator=( VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 dedicatedAllocationImageAliasing;
    };
    static_assert( sizeof( PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV ) == sizeof( VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV : public layout::PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV( vk::Bool32 dedicatedAllocationImageAliasing_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV( dedicatedAllocationImageAliasing_ )
    {}

    PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV( VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV( rhs )
    {}

    PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV& operator=( VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV & setDedicatedAllocationImageAliasing( vk::Bool32 dedicatedAllocationImageAliasing_ ) VULKAN_HPP_NOEXCEPT
    {
      dedicatedAllocationImageAliasing = dedicatedAllocationImageAliasing_;
      return *this;
    }

    operator VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( dedicatedAllocationImageAliasing == rhs.dedicatedAllocationImageAliasing );
    }

    bool operator!=( PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV ) == sizeof( VkPhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceDepthClipEnableFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceDepthClipEnableFeaturesEXT( vk::Bool32 depthClipEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
        : depthClipEnable( depthClipEnable_ )
      {}

      PhysicalDeviceDepthClipEnableFeaturesEXT( VkPhysicalDeviceDepthClipEnableFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDepthClipEnableFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceDepthClipEnableFeaturesEXT& operator=( VkPhysicalDeviceDepthClipEnableFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDepthClipEnableFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceDepthClipEnableFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 depthClipEnable;
    };
    static_assert( sizeof( PhysicalDeviceDepthClipEnableFeaturesEXT ) == sizeof( VkPhysicalDeviceDepthClipEnableFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceDepthClipEnableFeaturesEXT : public layout::PhysicalDeviceDepthClipEnableFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceDepthClipEnableFeaturesEXT( vk::Bool32 depthClipEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDepthClipEnableFeaturesEXT( depthClipEnable_ )
    {}

    PhysicalDeviceDepthClipEnableFeaturesEXT( VkPhysicalDeviceDepthClipEnableFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDepthClipEnableFeaturesEXT( rhs )
    {}

    PhysicalDeviceDepthClipEnableFeaturesEXT& operator=( VkPhysicalDeviceDepthClipEnableFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceDepthClipEnableFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceDepthClipEnableFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceDepthClipEnableFeaturesEXT & setDepthClipEnable( vk::Bool32 depthClipEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      depthClipEnable = depthClipEnable_;
      return *this;
    }

    operator VkPhysicalDeviceDepthClipEnableFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceDepthClipEnableFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceDepthClipEnableFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceDepthClipEnableFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceDepthClipEnableFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( depthClipEnable == rhs.depthClipEnable );
    }

    bool operator!=( PhysicalDeviceDepthClipEnableFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceDepthClipEnableFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceDepthClipEnableFeaturesEXT ) == sizeof( VkPhysicalDeviceDepthClipEnableFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceDepthClipEnableFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceDepthStencilResolvePropertiesKHR
    {
    protected:
      PhysicalDeviceDepthStencilResolvePropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceDepthStencilResolvePropertiesKHR( VkPhysicalDeviceDepthStencilResolvePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDepthStencilResolvePropertiesKHR*>(this) = rhs;
      }

      PhysicalDeviceDepthStencilResolvePropertiesKHR& operator=( VkPhysicalDeviceDepthStencilResolvePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDepthStencilResolvePropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceDepthStencilResolvePropertiesKHR;
      void* pNext = nullptr;
      vk::ResolveModeFlagsKHR supportedDepthResolveModes;
      vk::ResolveModeFlagsKHR supportedStencilResolveModes;
      vk::Bool32 independentResolveNone;
      vk::Bool32 independentResolve;
    };
    static_assert( sizeof( PhysicalDeviceDepthStencilResolvePropertiesKHR ) == sizeof( VkPhysicalDeviceDepthStencilResolvePropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceDepthStencilResolvePropertiesKHR : public layout::PhysicalDeviceDepthStencilResolvePropertiesKHR
  {
    PhysicalDeviceDepthStencilResolvePropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDepthStencilResolvePropertiesKHR()
    {}

    PhysicalDeviceDepthStencilResolvePropertiesKHR( VkPhysicalDeviceDepthStencilResolvePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDepthStencilResolvePropertiesKHR( rhs )
    {}

    PhysicalDeviceDepthStencilResolvePropertiesKHR& operator=( VkPhysicalDeviceDepthStencilResolvePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceDepthStencilResolvePropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceDepthStencilResolvePropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceDepthStencilResolvePropertiesKHR*>( this );
    }

    operator VkPhysicalDeviceDepthStencilResolvePropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceDepthStencilResolvePropertiesKHR*>( this );
    }

    bool operator==( PhysicalDeviceDepthStencilResolvePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( supportedDepthResolveModes == rhs.supportedDepthResolveModes )
          && ( supportedStencilResolveModes == rhs.supportedStencilResolveModes )
          && ( independentResolveNone == rhs.independentResolveNone )
          && ( independentResolve == rhs.independentResolve );
    }

    bool operator!=( PhysicalDeviceDepthStencilResolvePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceDepthStencilResolvePropertiesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceDepthStencilResolvePropertiesKHR ) == sizeof( VkPhysicalDeviceDepthStencilResolvePropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceDepthStencilResolvePropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceDescriptorIndexingFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceDescriptorIndexingFeaturesEXT( vk::Bool32 shaderInputAttachmentArrayDynamicIndexing_ = 0,
                                                                        vk::Bool32 shaderUniformTexelBufferArrayDynamicIndexing_ = 0,
                                                                        vk::Bool32 shaderStorageTexelBufferArrayDynamicIndexing_ = 0,
                                                                        vk::Bool32 shaderUniformBufferArrayNonUniformIndexing_ = 0,
                                                                        vk::Bool32 shaderSampledImageArrayNonUniformIndexing_ = 0,
                                                                        vk::Bool32 shaderStorageBufferArrayNonUniformIndexing_ = 0,
                                                                        vk::Bool32 shaderStorageImageArrayNonUniformIndexing_ = 0,
                                                                        vk::Bool32 shaderInputAttachmentArrayNonUniformIndexing_ = 0,
                                                                        vk::Bool32 shaderUniformTexelBufferArrayNonUniformIndexing_ = 0,
                                                                        vk::Bool32 shaderStorageTexelBufferArrayNonUniformIndexing_ = 0,
                                                                        vk::Bool32 descriptorBindingUniformBufferUpdateAfterBind_ = 0,
                                                                        vk::Bool32 descriptorBindingSampledImageUpdateAfterBind_ = 0,
                                                                        vk::Bool32 descriptorBindingStorageImageUpdateAfterBind_ = 0,
                                                                        vk::Bool32 descriptorBindingStorageBufferUpdateAfterBind_ = 0,
                                                                        vk::Bool32 descriptorBindingUniformTexelBufferUpdateAfterBind_ = 0,
                                                                        vk::Bool32 descriptorBindingStorageTexelBufferUpdateAfterBind_ = 0,
                                                                        vk::Bool32 descriptorBindingUpdateUnusedWhilePending_ = 0,
                                                                        vk::Bool32 descriptorBindingPartiallyBound_ = 0,
                                                                        vk::Bool32 descriptorBindingVariableDescriptorCount_ = 0,
                                                                        vk::Bool32 runtimeDescriptorArray_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderInputAttachmentArrayDynamicIndexing( shaderInputAttachmentArrayDynamicIndexing_ )
        , shaderUniformTexelBufferArrayDynamicIndexing( shaderUniformTexelBufferArrayDynamicIndexing_ )
        , shaderStorageTexelBufferArrayDynamicIndexing( shaderStorageTexelBufferArrayDynamicIndexing_ )
        , shaderUniformBufferArrayNonUniformIndexing( shaderUniformBufferArrayNonUniformIndexing_ )
        , shaderSampledImageArrayNonUniformIndexing( shaderSampledImageArrayNonUniformIndexing_ )
        , shaderStorageBufferArrayNonUniformIndexing( shaderStorageBufferArrayNonUniformIndexing_ )
        , shaderStorageImageArrayNonUniformIndexing( shaderStorageImageArrayNonUniformIndexing_ )
        , shaderInputAttachmentArrayNonUniformIndexing( shaderInputAttachmentArrayNonUniformIndexing_ )
        , shaderUniformTexelBufferArrayNonUniformIndexing( shaderUniformTexelBufferArrayNonUniformIndexing_ )
        , shaderStorageTexelBufferArrayNonUniformIndexing( shaderStorageTexelBufferArrayNonUniformIndexing_ )
        , descriptorBindingUniformBufferUpdateAfterBind( descriptorBindingUniformBufferUpdateAfterBind_ )
        , descriptorBindingSampledImageUpdateAfterBind( descriptorBindingSampledImageUpdateAfterBind_ )
        , descriptorBindingStorageImageUpdateAfterBind( descriptorBindingStorageImageUpdateAfterBind_ )
        , descriptorBindingStorageBufferUpdateAfterBind( descriptorBindingStorageBufferUpdateAfterBind_ )
        , descriptorBindingUniformTexelBufferUpdateAfterBind( descriptorBindingUniformTexelBufferUpdateAfterBind_ )
        , descriptorBindingStorageTexelBufferUpdateAfterBind( descriptorBindingStorageTexelBufferUpdateAfterBind_ )
        , descriptorBindingUpdateUnusedWhilePending( descriptorBindingUpdateUnusedWhilePending_ )
        , descriptorBindingPartiallyBound( descriptorBindingPartiallyBound_ )
        , descriptorBindingVariableDescriptorCount( descriptorBindingVariableDescriptorCount_ )
        , runtimeDescriptorArray( runtimeDescriptorArray_ )
      {}

      PhysicalDeviceDescriptorIndexingFeaturesEXT( VkPhysicalDeviceDescriptorIndexingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDescriptorIndexingFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceDescriptorIndexingFeaturesEXT& operator=( VkPhysicalDeviceDescriptorIndexingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDescriptorIndexingFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceDescriptorIndexingFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 shaderInputAttachmentArrayDynamicIndexing;
      vk::Bool32 shaderUniformTexelBufferArrayDynamicIndexing;
      vk::Bool32 shaderStorageTexelBufferArrayDynamicIndexing;
      vk::Bool32 shaderUniformBufferArrayNonUniformIndexing;
      vk::Bool32 shaderSampledImageArrayNonUniformIndexing;
      vk::Bool32 shaderStorageBufferArrayNonUniformIndexing;
      vk::Bool32 shaderStorageImageArrayNonUniformIndexing;
      vk::Bool32 shaderInputAttachmentArrayNonUniformIndexing;
      vk::Bool32 shaderUniformTexelBufferArrayNonUniformIndexing;
      vk::Bool32 shaderStorageTexelBufferArrayNonUniformIndexing;
      vk::Bool32 descriptorBindingUniformBufferUpdateAfterBind;
      vk::Bool32 descriptorBindingSampledImageUpdateAfterBind;
      vk::Bool32 descriptorBindingStorageImageUpdateAfterBind;
      vk::Bool32 descriptorBindingStorageBufferUpdateAfterBind;
      vk::Bool32 descriptorBindingUniformTexelBufferUpdateAfterBind;
      vk::Bool32 descriptorBindingStorageTexelBufferUpdateAfterBind;
      vk::Bool32 descriptorBindingUpdateUnusedWhilePending;
      vk::Bool32 descriptorBindingPartiallyBound;
      vk::Bool32 descriptorBindingVariableDescriptorCount;
      vk::Bool32 runtimeDescriptorArray;
    };
    static_assert( sizeof( PhysicalDeviceDescriptorIndexingFeaturesEXT ) == sizeof( VkPhysicalDeviceDescriptorIndexingFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceDescriptorIndexingFeaturesEXT : public layout::PhysicalDeviceDescriptorIndexingFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceDescriptorIndexingFeaturesEXT( vk::Bool32 shaderInputAttachmentArrayDynamicIndexing_ = 0,
                                                                      vk::Bool32 shaderUniformTexelBufferArrayDynamicIndexing_ = 0,
                                                                      vk::Bool32 shaderStorageTexelBufferArrayDynamicIndexing_ = 0,
                                                                      vk::Bool32 shaderUniformBufferArrayNonUniformIndexing_ = 0,
                                                                      vk::Bool32 shaderSampledImageArrayNonUniformIndexing_ = 0,
                                                                      vk::Bool32 shaderStorageBufferArrayNonUniformIndexing_ = 0,
                                                                      vk::Bool32 shaderStorageImageArrayNonUniformIndexing_ = 0,
                                                                      vk::Bool32 shaderInputAttachmentArrayNonUniformIndexing_ = 0,
                                                                      vk::Bool32 shaderUniformTexelBufferArrayNonUniformIndexing_ = 0,
                                                                      vk::Bool32 shaderStorageTexelBufferArrayNonUniformIndexing_ = 0,
                                                                      vk::Bool32 descriptorBindingUniformBufferUpdateAfterBind_ = 0,
                                                                      vk::Bool32 descriptorBindingSampledImageUpdateAfterBind_ = 0,
                                                                      vk::Bool32 descriptorBindingStorageImageUpdateAfterBind_ = 0,
                                                                      vk::Bool32 descriptorBindingStorageBufferUpdateAfterBind_ = 0,
                                                                      vk::Bool32 descriptorBindingUniformTexelBufferUpdateAfterBind_ = 0,
                                                                      vk::Bool32 descriptorBindingStorageTexelBufferUpdateAfterBind_ = 0,
                                                                      vk::Bool32 descriptorBindingUpdateUnusedWhilePending_ = 0,
                                                                      vk::Bool32 descriptorBindingPartiallyBound_ = 0,
                                                                      vk::Bool32 descriptorBindingVariableDescriptorCount_ = 0,
                                                                      vk::Bool32 runtimeDescriptorArray_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDescriptorIndexingFeaturesEXT( shaderInputAttachmentArrayDynamicIndexing_, shaderUniformTexelBufferArrayDynamicIndexing_, shaderStorageTexelBufferArrayDynamicIndexing_, shaderUniformBufferArrayNonUniformIndexing_, shaderSampledImageArrayNonUniformIndexing_, shaderStorageBufferArrayNonUniformIndexing_, shaderStorageImageArrayNonUniformIndexing_, shaderInputAttachmentArrayNonUniformIndexing_, shaderUniformTexelBufferArrayNonUniformIndexing_, shaderStorageTexelBufferArrayNonUniformIndexing_, descriptorBindingUniformBufferUpdateAfterBind_, descriptorBindingSampledImageUpdateAfterBind_, descriptorBindingStorageImageUpdateAfterBind_, descriptorBindingStorageBufferUpdateAfterBind_, descriptorBindingUniformTexelBufferUpdateAfterBind_, descriptorBindingStorageTexelBufferUpdateAfterBind_, descriptorBindingUpdateUnusedWhilePending_, descriptorBindingPartiallyBound_, descriptorBindingVariableDescriptorCount_, runtimeDescriptorArray_ )
    {}

    PhysicalDeviceDescriptorIndexingFeaturesEXT( VkPhysicalDeviceDescriptorIndexingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDescriptorIndexingFeaturesEXT( rhs )
    {}

    PhysicalDeviceDescriptorIndexingFeaturesEXT& operator=( VkPhysicalDeviceDescriptorIndexingFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceDescriptorIndexingFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderInputAttachmentArrayDynamicIndexing( vk::Bool32 shaderInputAttachmentArrayDynamicIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderInputAttachmentArrayDynamicIndexing = shaderInputAttachmentArrayDynamicIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderUniformTexelBufferArrayDynamicIndexing( vk::Bool32 shaderUniformTexelBufferArrayDynamicIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderUniformTexelBufferArrayDynamicIndexing = shaderUniformTexelBufferArrayDynamicIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderStorageTexelBufferArrayDynamicIndexing( vk::Bool32 shaderStorageTexelBufferArrayDynamicIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageTexelBufferArrayDynamicIndexing = shaderStorageTexelBufferArrayDynamicIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderUniformBufferArrayNonUniformIndexing( vk::Bool32 shaderUniformBufferArrayNonUniformIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderUniformBufferArrayNonUniformIndexing = shaderUniformBufferArrayNonUniformIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderSampledImageArrayNonUniformIndexing( vk::Bool32 shaderSampledImageArrayNonUniformIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderSampledImageArrayNonUniformIndexing = shaderSampledImageArrayNonUniformIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderStorageBufferArrayNonUniformIndexing( vk::Bool32 shaderStorageBufferArrayNonUniformIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageBufferArrayNonUniformIndexing = shaderStorageBufferArrayNonUniformIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderStorageImageArrayNonUniformIndexing( vk::Bool32 shaderStorageImageArrayNonUniformIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageImageArrayNonUniformIndexing = shaderStorageImageArrayNonUniformIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderInputAttachmentArrayNonUniformIndexing( vk::Bool32 shaderInputAttachmentArrayNonUniformIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderInputAttachmentArrayNonUniformIndexing = shaderInputAttachmentArrayNonUniformIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderUniformTexelBufferArrayNonUniformIndexing( vk::Bool32 shaderUniformTexelBufferArrayNonUniformIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderUniformTexelBufferArrayNonUniformIndexing = shaderUniformTexelBufferArrayNonUniformIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setShaderStorageTexelBufferArrayNonUniformIndexing( vk::Bool32 shaderStorageTexelBufferArrayNonUniformIndexing_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderStorageTexelBufferArrayNonUniformIndexing = shaderStorageTexelBufferArrayNonUniformIndexing_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingUniformBufferUpdateAfterBind( vk::Bool32 descriptorBindingUniformBufferUpdateAfterBind_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingUniformBufferUpdateAfterBind = descriptorBindingUniformBufferUpdateAfterBind_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingSampledImageUpdateAfterBind( vk::Bool32 descriptorBindingSampledImageUpdateAfterBind_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingSampledImageUpdateAfterBind = descriptorBindingSampledImageUpdateAfterBind_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingStorageImageUpdateAfterBind( vk::Bool32 descriptorBindingStorageImageUpdateAfterBind_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingStorageImageUpdateAfterBind = descriptorBindingStorageImageUpdateAfterBind_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingStorageBufferUpdateAfterBind( vk::Bool32 descriptorBindingStorageBufferUpdateAfterBind_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingStorageBufferUpdateAfterBind = descriptorBindingStorageBufferUpdateAfterBind_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingUniformTexelBufferUpdateAfterBind( vk::Bool32 descriptorBindingUniformTexelBufferUpdateAfterBind_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingUniformTexelBufferUpdateAfterBind = descriptorBindingUniformTexelBufferUpdateAfterBind_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingStorageTexelBufferUpdateAfterBind( vk::Bool32 descriptorBindingStorageTexelBufferUpdateAfterBind_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingStorageTexelBufferUpdateAfterBind = descriptorBindingStorageTexelBufferUpdateAfterBind_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingUpdateUnusedWhilePending( vk::Bool32 descriptorBindingUpdateUnusedWhilePending_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingUpdateUnusedWhilePending = descriptorBindingUpdateUnusedWhilePending_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingPartiallyBound( vk::Bool32 descriptorBindingPartiallyBound_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingPartiallyBound = descriptorBindingPartiallyBound_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setDescriptorBindingVariableDescriptorCount( vk::Bool32 descriptorBindingVariableDescriptorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingVariableDescriptorCount = descriptorBindingVariableDescriptorCount_;
      return *this;
    }

    PhysicalDeviceDescriptorIndexingFeaturesEXT & setRuntimeDescriptorArray( vk::Bool32 runtimeDescriptorArray_ ) VULKAN_HPP_NOEXCEPT
    {
      runtimeDescriptorArray = runtimeDescriptorArray_;
      return *this;
    }

    operator VkPhysicalDeviceDescriptorIndexingFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceDescriptorIndexingFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceDescriptorIndexingFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceDescriptorIndexingFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceDescriptorIndexingFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderInputAttachmentArrayDynamicIndexing == rhs.shaderInputAttachmentArrayDynamicIndexing )
          && ( shaderUniformTexelBufferArrayDynamicIndexing == rhs.shaderUniformTexelBufferArrayDynamicIndexing )
          && ( shaderStorageTexelBufferArrayDynamicIndexing == rhs.shaderStorageTexelBufferArrayDynamicIndexing )
          && ( shaderUniformBufferArrayNonUniformIndexing == rhs.shaderUniformBufferArrayNonUniformIndexing )
          && ( shaderSampledImageArrayNonUniformIndexing == rhs.shaderSampledImageArrayNonUniformIndexing )
          && ( shaderStorageBufferArrayNonUniformIndexing == rhs.shaderStorageBufferArrayNonUniformIndexing )
          && ( shaderStorageImageArrayNonUniformIndexing == rhs.shaderStorageImageArrayNonUniformIndexing )
          && ( shaderInputAttachmentArrayNonUniformIndexing == rhs.shaderInputAttachmentArrayNonUniformIndexing )
          && ( shaderUniformTexelBufferArrayNonUniformIndexing == rhs.shaderUniformTexelBufferArrayNonUniformIndexing )
          && ( shaderStorageTexelBufferArrayNonUniformIndexing == rhs.shaderStorageTexelBufferArrayNonUniformIndexing )
          && ( descriptorBindingUniformBufferUpdateAfterBind == rhs.descriptorBindingUniformBufferUpdateAfterBind )
          && ( descriptorBindingSampledImageUpdateAfterBind == rhs.descriptorBindingSampledImageUpdateAfterBind )
          && ( descriptorBindingStorageImageUpdateAfterBind == rhs.descriptorBindingStorageImageUpdateAfterBind )
          && ( descriptorBindingStorageBufferUpdateAfterBind == rhs.descriptorBindingStorageBufferUpdateAfterBind )
          && ( descriptorBindingUniformTexelBufferUpdateAfterBind == rhs.descriptorBindingUniformTexelBufferUpdateAfterBind )
          && ( descriptorBindingStorageTexelBufferUpdateAfterBind == rhs.descriptorBindingStorageTexelBufferUpdateAfterBind )
          && ( descriptorBindingUpdateUnusedWhilePending == rhs.descriptorBindingUpdateUnusedWhilePending )
          && ( descriptorBindingPartiallyBound == rhs.descriptorBindingPartiallyBound )
          && ( descriptorBindingVariableDescriptorCount == rhs.descriptorBindingVariableDescriptorCount )
          && ( runtimeDescriptorArray == rhs.runtimeDescriptorArray );
    }

    bool operator!=( PhysicalDeviceDescriptorIndexingFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceDescriptorIndexingFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceDescriptorIndexingFeaturesEXT ) == sizeof( VkPhysicalDeviceDescriptorIndexingFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceDescriptorIndexingFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceDescriptorIndexingPropertiesEXT
    {
    protected:
      PhysicalDeviceDescriptorIndexingPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceDescriptorIndexingPropertiesEXT( VkPhysicalDeviceDescriptorIndexingPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDescriptorIndexingPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceDescriptorIndexingPropertiesEXT& operator=( VkPhysicalDeviceDescriptorIndexingPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDescriptorIndexingPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceDescriptorIndexingPropertiesEXT;
      void* pNext = nullptr;
      uint32_t maxUpdateAfterBindDescriptorsInAllPools;
      vk::Bool32 shaderUniformBufferArrayNonUniformIndexingNative;
      vk::Bool32 shaderSampledImageArrayNonUniformIndexingNative;
      vk::Bool32 shaderStorageBufferArrayNonUniformIndexingNative;
      vk::Bool32 shaderStorageImageArrayNonUniformIndexingNative;
      vk::Bool32 shaderInputAttachmentArrayNonUniformIndexingNative;
      vk::Bool32 robustBufferAccessUpdateAfterBind;
      vk::Bool32 quadDivergentImplicitLod;
      uint32_t maxPerStageDescriptorUpdateAfterBindSamplers;
      uint32_t maxPerStageDescriptorUpdateAfterBindUniformBuffers;
      uint32_t maxPerStageDescriptorUpdateAfterBindStorageBuffers;
      uint32_t maxPerStageDescriptorUpdateAfterBindSampledImages;
      uint32_t maxPerStageDescriptorUpdateAfterBindStorageImages;
      uint32_t maxPerStageDescriptorUpdateAfterBindInputAttachments;
      uint32_t maxPerStageUpdateAfterBindResources;
      uint32_t maxDescriptorSetUpdateAfterBindSamplers;
      uint32_t maxDescriptorSetUpdateAfterBindUniformBuffers;
      uint32_t maxDescriptorSetUpdateAfterBindUniformBuffersDynamic;
      uint32_t maxDescriptorSetUpdateAfterBindStorageBuffers;
      uint32_t maxDescriptorSetUpdateAfterBindStorageBuffersDynamic;
      uint32_t maxDescriptorSetUpdateAfterBindSampledImages;
      uint32_t maxDescriptorSetUpdateAfterBindStorageImages;
      uint32_t maxDescriptorSetUpdateAfterBindInputAttachments;
    };
    static_assert( sizeof( PhysicalDeviceDescriptorIndexingPropertiesEXT ) == sizeof( VkPhysicalDeviceDescriptorIndexingPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceDescriptorIndexingPropertiesEXT : public layout::PhysicalDeviceDescriptorIndexingPropertiesEXT
  {
    PhysicalDeviceDescriptorIndexingPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDescriptorIndexingPropertiesEXT()
    {}

    PhysicalDeviceDescriptorIndexingPropertiesEXT( VkPhysicalDeviceDescriptorIndexingPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDescriptorIndexingPropertiesEXT( rhs )
    {}

    PhysicalDeviceDescriptorIndexingPropertiesEXT& operator=( VkPhysicalDeviceDescriptorIndexingPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceDescriptorIndexingPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceDescriptorIndexingPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceDescriptorIndexingPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceDescriptorIndexingPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceDescriptorIndexingPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceDescriptorIndexingPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxUpdateAfterBindDescriptorsInAllPools == rhs.maxUpdateAfterBindDescriptorsInAllPools )
          && ( shaderUniformBufferArrayNonUniformIndexingNative == rhs.shaderUniformBufferArrayNonUniformIndexingNative )
          && ( shaderSampledImageArrayNonUniformIndexingNative == rhs.shaderSampledImageArrayNonUniformIndexingNative )
          && ( shaderStorageBufferArrayNonUniformIndexingNative == rhs.shaderStorageBufferArrayNonUniformIndexingNative )
          && ( shaderStorageImageArrayNonUniformIndexingNative == rhs.shaderStorageImageArrayNonUniformIndexingNative )
          && ( shaderInputAttachmentArrayNonUniformIndexingNative == rhs.shaderInputAttachmentArrayNonUniformIndexingNative )
          && ( robustBufferAccessUpdateAfterBind == rhs.robustBufferAccessUpdateAfterBind )
          && ( quadDivergentImplicitLod == rhs.quadDivergentImplicitLod )
          && ( maxPerStageDescriptorUpdateAfterBindSamplers == rhs.maxPerStageDescriptorUpdateAfterBindSamplers )
          && ( maxPerStageDescriptorUpdateAfterBindUniformBuffers == rhs.maxPerStageDescriptorUpdateAfterBindUniformBuffers )
          && ( maxPerStageDescriptorUpdateAfterBindStorageBuffers == rhs.maxPerStageDescriptorUpdateAfterBindStorageBuffers )
          && ( maxPerStageDescriptorUpdateAfterBindSampledImages == rhs.maxPerStageDescriptorUpdateAfterBindSampledImages )
          && ( maxPerStageDescriptorUpdateAfterBindStorageImages == rhs.maxPerStageDescriptorUpdateAfterBindStorageImages )
          && ( maxPerStageDescriptorUpdateAfterBindInputAttachments == rhs.maxPerStageDescriptorUpdateAfterBindInputAttachments )
          && ( maxPerStageUpdateAfterBindResources == rhs.maxPerStageUpdateAfterBindResources )
          && ( maxDescriptorSetUpdateAfterBindSamplers == rhs.maxDescriptorSetUpdateAfterBindSamplers )
          && ( maxDescriptorSetUpdateAfterBindUniformBuffers == rhs.maxDescriptorSetUpdateAfterBindUniformBuffers )
          && ( maxDescriptorSetUpdateAfterBindUniformBuffersDynamic == rhs.maxDescriptorSetUpdateAfterBindUniformBuffersDynamic )
          && ( maxDescriptorSetUpdateAfterBindStorageBuffers == rhs.maxDescriptorSetUpdateAfterBindStorageBuffers )
          && ( maxDescriptorSetUpdateAfterBindStorageBuffersDynamic == rhs.maxDescriptorSetUpdateAfterBindStorageBuffersDynamic )
          && ( maxDescriptorSetUpdateAfterBindSampledImages == rhs.maxDescriptorSetUpdateAfterBindSampledImages )
          && ( maxDescriptorSetUpdateAfterBindStorageImages == rhs.maxDescriptorSetUpdateAfterBindStorageImages )
          && ( maxDescriptorSetUpdateAfterBindInputAttachments == rhs.maxDescriptorSetUpdateAfterBindInputAttachments );
    }

    bool operator!=( PhysicalDeviceDescriptorIndexingPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceDescriptorIndexingPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceDescriptorIndexingPropertiesEXT ) == sizeof( VkPhysicalDeviceDescriptorIndexingPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceDescriptorIndexingPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceDiscardRectanglePropertiesEXT
    {
    protected:
      PhysicalDeviceDiscardRectanglePropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceDiscardRectanglePropertiesEXT( VkPhysicalDeviceDiscardRectanglePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDiscardRectanglePropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceDiscardRectanglePropertiesEXT& operator=( VkPhysicalDeviceDiscardRectanglePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDiscardRectanglePropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceDiscardRectanglePropertiesEXT;
      void* pNext = nullptr;
      uint32_t maxDiscardRectangles;
    };
    static_assert( sizeof( PhysicalDeviceDiscardRectanglePropertiesEXT ) == sizeof( VkPhysicalDeviceDiscardRectanglePropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceDiscardRectanglePropertiesEXT : public layout::PhysicalDeviceDiscardRectanglePropertiesEXT
  {
    PhysicalDeviceDiscardRectanglePropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDiscardRectanglePropertiesEXT()
    {}

    PhysicalDeviceDiscardRectanglePropertiesEXT( VkPhysicalDeviceDiscardRectanglePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDiscardRectanglePropertiesEXT( rhs )
    {}

    PhysicalDeviceDiscardRectanglePropertiesEXT& operator=( VkPhysicalDeviceDiscardRectanglePropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceDiscardRectanglePropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceDiscardRectanglePropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceDiscardRectanglePropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceDiscardRectanglePropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceDiscardRectanglePropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceDiscardRectanglePropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxDiscardRectangles == rhs.maxDiscardRectangles );
    }

    bool operator!=( PhysicalDeviceDiscardRectanglePropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceDiscardRectanglePropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceDiscardRectanglePropertiesEXT ) == sizeof( VkPhysicalDeviceDiscardRectanglePropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceDiscardRectanglePropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceDriverPropertiesKHR
    {
    protected:
      PhysicalDeviceDriverPropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceDriverPropertiesKHR( VkPhysicalDeviceDriverPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDriverPropertiesKHR*>(this) = rhs;
      }

      PhysicalDeviceDriverPropertiesKHR& operator=( VkPhysicalDeviceDriverPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceDriverPropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceDriverPropertiesKHR;
      void* pNext = nullptr;
      vk::DriverIdKHR driverID;
      char driverName[VK_MAX_DRIVER_NAME_SIZE_KHR];
      char driverInfo[VK_MAX_DRIVER_INFO_SIZE_KHR];
      vk::ConformanceVersionKHR conformanceVersion;
    };
    static_assert( sizeof( PhysicalDeviceDriverPropertiesKHR ) == sizeof( VkPhysicalDeviceDriverPropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceDriverPropertiesKHR : public layout::PhysicalDeviceDriverPropertiesKHR
  {
    PhysicalDeviceDriverPropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDriverPropertiesKHR()
    {}

    PhysicalDeviceDriverPropertiesKHR( VkPhysicalDeviceDriverPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceDriverPropertiesKHR( rhs )
    {}

    PhysicalDeviceDriverPropertiesKHR& operator=( VkPhysicalDeviceDriverPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceDriverPropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceDriverPropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceDriverPropertiesKHR*>( this );
    }

    operator VkPhysicalDeviceDriverPropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceDriverPropertiesKHR*>( this );
    }

    bool operator==( PhysicalDeviceDriverPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( driverID == rhs.driverID )
          && ( memcmp( driverName, rhs.driverName, VK_MAX_DRIVER_NAME_SIZE_KHR * sizeof( char ) ) == 0 )
          && ( memcmp( driverInfo, rhs.driverInfo, VK_MAX_DRIVER_INFO_SIZE_KHR * sizeof( char ) ) == 0 )
          && ( conformanceVersion == rhs.conformanceVersion );
    }

    bool operator!=( PhysicalDeviceDriverPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceDriverPropertiesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceDriverPropertiesKHR ) == sizeof( VkPhysicalDeviceDriverPropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceDriverPropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceExclusiveScissorFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceExclusiveScissorFeaturesNV( vk::Bool32 exclusiveScissor_ = 0 ) VULKAN_HPP_NOEXCEPT
        : exclusiveScissor( exclusiveScissor_ )
      {}

      PhysicalDeviceExclusiveScissorFeaturesNV( VkPhysicalDeviceExclusiveScissorFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExclusiveScissorFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceExclusiveScissorFeaturesNV& operator=( VkPhysicalDeviceExclusiveScissorFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExclusiveScissorFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceExclusiveScissorFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 exclusiveScissor;
    };
    static_assert( sizeof( PhysicalDeviceExclusiveScissorFeaturesNV ) == sizeof( VkPhysicalDeviceExclusiveScissorFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceExclusiveScissorFeaturesNV : public layout::PhysicalDeviceExclusiveScissorFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceExclusiveScissorFeaturesNV( vk::Bool32 exclusiveScissor_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExclusiveScissorFeaturesNV( exclusiveScissor_ )
    {}

    PhysicalDeviceExclusiveScissorFeaturesNV( VkPhysicalDeviceExclusiveScissorFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExclusiveScissorFeaturesNV( rhs )
    {}

    PhysicalDeviceExclusiveScissorFeaturesNV& operator=( VkPhysicalDeviceExclusiveScissorFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceExclusiveScissorFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceExclusiveScissorFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceExclusiveScissorFeaturesNV & setExclusiveScissor( vk::Bool32 exclusiveScissor_ ) VULKAN_HPP_NOEXCEPT
    {
      exclusiveScissor = exclusiveScissor_;
      return *this;
    }

    operator VkPhysicalDeviceExclusiveScissorFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceExclusiveScissorFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceExclusiveScissorFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceExclusiveScissorFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceExclusiveScissorFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( exclusiveScissor == rhs.exclusiveScissor );
    }

    bool operator!=( PhysicalDeviceExclusiveScissorFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceExclusiveScissorFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceExclusiveScissorFeaturesNV ) == sizeof( VkPhysicalDeviceExclusiveScissorFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceExclusiveScissorFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceExternalBufferInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalBufferInfo( vk::BufferCreateFlags flags_ = vk::BufferCreateFlags(),
                                                             vk::BufferUsageFlags usage_ = vk::BufferUsageFlags(),
                                                             vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , usage( usage_ )
        , handleType( handleType_ )
      {}

      PhysicalDeviceExternalBufferInfo( VkPhysicalDeviceExternalBufferInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalBufferInfo*>(this) = rhs;
      }

      PhysicalDeviceExternalBufferInfo& operator=( VkPhysicalDeviceExternalBufferInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalBufferInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceExternalBufferInfo;
      const void* pNext = nullptr;
      vk::BufferCreateFlags flags;
      vk::BufferUsageFlags usage;
      vk::ExternalMemoryHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( PhysicalDeviceExternalBufferInfo ) == sizeof( VkPhysicalDeviceExternalBufferInfo ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceExternalBufferInfo : public layout::PhysicalDeviceExternalBufferInfo
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalBufferInfo( vk::BufferCreateFlags flags_ = vk::BufferCreateFlags(),
                                                           vk::BufferUsageFlags usage_ = vk::BufferUsageFlags(),
                                                           vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalBufferInfo( flags_, usage_, handleType_ )
    {}

    PhysicalDeviceExternalBufferInfo( VkPhysicalDeviceExternalBufferInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalBufferInfo( rhs )
    {}

    PhysicalDeviceExternalBufferInfo& operator=( VkPhysicalDeviceExternalBufferInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceExternalBufferInfo::operator=(rhs);
      return *this;
    }

    PhysicalDeviceExternalBufferInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceExternalBufferInfo & setFlags( vk::BufferCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PhysicalDeviceExternalBufferInfo & setUsage( vk::BufferUsageFlags usage_ ) VULKAN_HPP_NOEXCEPT
    {
      usage = usage_;
      return *this;
    }

    PhysicalDeviceExternalBufferInfo & setHandleType( vk::ExternalMemoryHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkPhysicalDeviceExternalBufferInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceExternalBufferInfo*>( this );
    }

    operator VkPhysicalDeviceExternalBufferInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceExternalBufferInfo*>( this );
    }

    bool operator==( PhysicalDeviceExternalBufferInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( usage == rhs.usage )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( PhysicalDeviceExternalBufferInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceExternalBufferInfo::sType;
  };
  static_assert( sizeof( PhysicalDeviceExternalBufferInfo ) == sizeof( VkPhysicalDeviceExternalBufferInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceExternalBufferInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceExternalFenceInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalFenceInfo( vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : handleType( handleType_ )
      {}

      PhysicalDeviceExternalFenceInfo( VkPhysicalDeviceExternalFenceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalFenceInfo*>(this) = rhs;
      }

      PhysicalDeviceExternalFenceInfo& operator=( VkPhysicalDeviceExternalFenceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalFenceInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceExternalFenceInfo;
      const void* pNext = nullptr;
      vk::ExternalFenceHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( PhysicalDeviceExternalFenceInfo ) == sizeof( VkPhysicalDeviceExternalFenceInfo ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceExternalFenceInfo : public layout::PhysicalDeviceExternalFenceInfo
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalFenceInfo( vk::ExternalFenceHandleTypeFlagBits handleType_ = vk::ExternalFenceHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalFenceInfo( handleType_ )
    {}

    PhysicalDeviceExternalFenceInfo( VkPhysicalDeviceExternalFenceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalFenceInfo( rhs )
    {}

    PhysicalDeviceExternalFenceInfo& operator=( VkPhysicalDeviceExternalFenceInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceExternalFenceInfo::operator=(rhs);
      return *this;
    }

    PhysicalDeviceExternalFenceInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceExternalFenceInfo & setHandleType( vk::ExternalFenceHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkPhysicalDeviceExternalFenceInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceExternalFenceInfo*>( this );
    }

    operator VkPhysicalDeviceExternalFenceInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceExternalFenceInfo*>( this );
    }

    bool operator==( PhysicalDeviceExternalFenceInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( PhysicalDeviceExternalFenceInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceExternalFenceInfo::sType;
  };
  static_assert( sizeof( PhysicalDeviceExternalFenceInfo ) == sizeof( VkPhysicalDeviceExternalFenceInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceExternalFenceInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceExternalImageFormatInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalImageFormatInfo( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : handleType( handleType_ )
      {}

      PhysicalDeviceExternalImageFormatInfo( VkPhysicalDeviceExternalImageFormatInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalImageFormatInfo*>(this) = rhs;
      }

      PhysicalDeviceExternalImageFormatInfo& operator=( VkPhysicalDeviceExternalImageFormatInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalImageFormatInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceExternalImageFormatInfo;
      const void* pNext = nullptr;
      vk::ExternalMemoryHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( PhysicalDeviceExternalImageFormatInfo ) == sizeof( VkPhysicalDeviceExternalImageFormatInfo ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceExternalImageFormatInfo : public layout::PhysicalDeviceExternalImageFormatInfo
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalImageFormatInfo( vk::ExternalMemoryHandleTypeFlagBits handleType_ = vk::ExternalMemoryHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalImageFormatInfo( handleType_ )
    {}

    PhysicalDeviceExternalImageFormatInfo( VkPhysicalDeviceExternalImageFormatInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalImageFormatInfo( rhs )
    {}

    PhysicalDeviceExternalImageFormatInfo& operator=( VkPhysicalDeviceExternalImageFormatInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceExternalImageFormatInfo::operator=(rhs);
      return *this;
    }

    PhysicalDeviceExternalImageFormatInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceExternalImageFormatInfo & setHandleType( vk::ExternalMemoryHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkPhysicalDeviceExternalImageFormatInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceExternalImageFormatInfo*>( this );
    }

    operator VkPhysicalDeviceExternalImageFormatInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceExternalImageFormatInfo*>( this );
    }

    bool operator==( PhysicalDeviceExternalImageFormatInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( PhysicalDeviceExternalImageFormatInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceExternalImageFormatInfo::sType;
  };
  static_assert( sizeof( PhysicalDeviceExternalImageFormatInfo ) == sizeof( VkPhysicalDeviceExternalImageFormatInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceExternalImageFormatInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceExternalMemoryHostPropertiesEXT
    {
    protected:
      PhysicalDeviceExternalMemoryHostPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceExternalMemoryHostPropertiesEXT( VkPhysicalDeviceExternalMemoryHostPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalMemoryHostPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceExternalMemoryHostPropertiesEXT& operator=( VkPhysicalDeviceExternalMemoryHostPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalMemoryHostPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceExternalMemoryHostPropertiesEXT;
      void* pNext = nullptr;
      vk::DeviceSize minImportedHostPointerAlignment;
    };
    static_assert( sizeof( PhysicalDeviceExternalMemoryHostPropertiesEXT ) == sizeof( VkPhysicalDeviceExternalMemoryHostPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceExternalMemoryHostPropertiesEXT : public layout::PhysicalDeviceExternalMemoryHostPropertiesEXT
  {
    PhysicalDeviceExternalMemoryHostPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalMemoryHostPropertiesEXT()
    {}

    PhysicalDeviceExternalMemoryHostPropertiesEXT( VkPhysicalDeviceExternalMemoryHostPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalMemoryHostPropertiesEXT( rhs )
    {}

    PhysicalDeviceExternalMemoryHostPropertiesEXT& operator=( VkPhysicalDeviceExternalMemoryHostPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceExternalMemoryHostPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceExternalMemoryHostPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceExternalMemoryHostPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceExternalMemoryHostPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceExternalMemoryHostPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceExternalMemoryHostPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( minImportedHostPointerAlignment == rhs.minImportedHostPointerAlignment );
    }

    bool operator!=( PhysicalDeviceExternalMemoryHostPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceExternalMemoryHostPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceExternalMemoryHostPropertiesEXT ) == sizeof( VkPhysicalDeviceExternalMemoryHostPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceExternalMemoryHostPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceExternalSemaphoreInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalSemaphoreInfo( vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : handleType( handleType_ )
      {}

      PhysicalDeviceExternalSemaphoreInfo( VkPhysicalDeviceExternalSemaphoreInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalSemaphoreInfo*>(this) = rhs;
      }

      PhysicalDeviceExternalSemaphoreInfo& operator=( VkPhysicalDeviceExternalSemaphoreInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceExternalSemaphoreInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceExternalSemaphoreInfo;
      const void* pNext = nullptr;
      vk::ExternalSemaphoreHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( PhysicalDeviceExternalSemaphoreInfo ) == sizeof( VkPhysicalDeviceExternalSemaphoreInfo ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceExternalSemaphoreInfo : public layout::PhysicalDeviceExternalSemaphoreInfo
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceExternalSemaphoreInfo( vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalSemaphoreInfo( handleType_ )
    {}

    PhysicalDeviceExternalSemaphoreInfo( VkPhysicalDeviceExternalSemaphoreInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceExternalSemaphoreInfo( rhs )
    {}

    PhysicalDeviceExternalSemaphoreInfo& operator=( VkPhysicalDeviceExternalSemaphoreInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceExternalSemaphoreInfo::operator=(rhs);
      return *this;
    }

    PhysicalDeviceExternalSemaphoreInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceExternalSemaphoreInfo & setHandleType( vk::ExternalSemaphoreHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkPhysicalDeviceExternalSemaphoreInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceExternalSemaphoreInfo*>( this );
    }

    operator VkPhysicalDeviceExternalSemaphoreInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceExternalSemaphoreInfo*>( this );
    }

    bool operator==( PhysicalDeviceExternalSemaphoreInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( PhysicalDeviceExternalSemaphoreInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceExternalSemaphoreInfo::sType;
  };
  static_assert( sizeof( PhysicalDeviceExternalSemaphoreInfo ) == sizeof( VkPhysicalDeviceExternalSemaphoreInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceExternalSemaphoreInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceFeatures2
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceFeatures2( vk::PhysicalDeviceFeatures features_ = vk::PhysicalDeviceFeatures() ) VULKAN_HPP_NOEXCEPT
        : features( features_ )
      {}

      PhysicalDeviceFeatures2( VkPhysicalDeviceFeatures2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFeatures2*>(this) = rhs;
      }

      PhysicalDeviceFeatures2& operator=( VkPhysicalDeviceFeatures2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFeatures2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceFeatures2;
      void* pNext = nullptr;
      vk::PhysicalDeviceFeatures features;
    };
    static_assert( sizeof( PhysicalDeviceFeatures2 ) == sizeof( VkPhysicalDeviceFeatures2 ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceFeatures2 : public layout::PhysicalDeviceFeatures2
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceFeatures2( vk::PhysicalDeviceFeatures features_ = vk::PhysicalDeviceFeatures() ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFeatures2( features_ )
    {}

    PhysicalDeviceFeatures2( VkPhysicalDeviceFeatures2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFeatures2( rhs )
    {}

    PhysicalDeviceFeatures2& operator=( VkPhysicalDeviceFeatures2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceFeatures2::operator=(rhs);
      return *this;
    }

    PhysicalDeviceFeatures2 & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceFeatures2 & setFeatures( vk::PhysicalDeviceFeatures features_ ) VULKAN_HPP_NOEXCEPT
    {
      features = features_;
      return *this;
    }

    operator VkPhysicalDeviceFeatures2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceFeatures2*>( this );
    }

    operator VkPhysicalDeviceFeatures2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceFeatures2*>( this );
    }

    bool operator==( PhysicalDeviceFeatures2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( features == rhs.features );
    }

    bool operator!=( PhysicalDeviceFeatures2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceFeatures2::sType;
  };
  static_assert( sizeof( PhysicalDeviceFeatures2 ) == sizeof( VkPhysicalDeviceFeatures2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceFeatures2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceFloatControlsPropertiesKHR
    {
    protected:
      PhysicalDeviceFloatControlsPropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceFloatControlsPropertiesKHR( VkPhysicalDeviceFloatControlsPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFloatControlsPropertiesKHR*>(this) = rhs;
      }

      PhysicalDeviceFloatControlsPropertiesKHR& operator=( VkPhysicalDeviceFloatControlsPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFloatControlsPropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceFloatControlsPropertiesKHR;
      void* pNext = nullptr;
      vk::ShaderFloatControlsIndependenceKHR denormBehaviorIndependence;
      vk::ShaderFloatControlsIndependenceKHR roundingModeIndependence;
      vk::Bool32 shaderSignedZeroInfNanPreserveFloat16;
      vk::Bool32 shaderSignedZeroInfNanPreserveFloat32;
      vk::Bool32 shaderSignedZeroInfNanPreserveFloat64;
      vk::Bool32 shaderDenormPreserveFloat16;
      vk::Bool32 shaderDenormPreserveFloat32;
      vk::Bool32 shaderDenormPreserveFloat64;
      vk::Bool32 shaderDenormFlushToZeroFloat16;
      vk::Bool32 shaderDenormFlushToZeroFloat32;
      vk::Bool32 shaderDenormFlushToZeroFloat64;
      vk::Bool32 shaderRoundingModeRTEFloat16;
      vk::Bool32 shaderRoundingModeRTEFloat32;
      vk::Bool32 shaderRoundingModeRTEFloat64;
      vk::Bool32 shaderRoundingModeRTZFloat16;
      vk::Bool32 shaderRoundingModeRTZFloat32;
      vk::Bool32 shaderRoundingModeRTZFloat64;
    };
    static_assert( sizeof( PhysicalDeviceFloatControlsPropertiesKHR ) == sizeof( VkPhysicalDeviceFloatControlsPropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceFloatControlsPropertiesKHR : public layout::PhysicalDeviceFloatControlsPropertiesKHR
  {
    PhysicalDeviceFloatControlsPropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFloatControlsPropertiesKHR()
    {}

    PhysicalDeviceFloatControlsPropertiesKHR( VkPhysicalDeviceFloatControlsPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFloatControlsPropertiesKHR( rhs )
    {}

    PhysicalDeviceFloatControlsPropertiesKHR& operator=( VkPhysicalDeviceFloatControlsPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceFloatControlsPropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceFloatControlsPropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceFloatControlsPropertiesKHR*>( this );
    }

    operator VkPhysicalDeviceFloatControlsPropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceFloatControlsPropertiesKHR*>( this );
    }

    bool operator==( PhysicalDeviceFloatControlsPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( denormBehaviorIndependence == rhs.denormBehaviorIndependence )
          && ( roundingModeIndependence == rhs.roundingModeIndependence )
          && ( shaderSignedZeroInfNanPreserveFloat16 == rhs.shaderSignedZeroInfNanPreserveFloat16 )
          && ( shaderSignedZeroInfNanPreserveFloat32 == rhs.shaderSignedZeroInfNanPreserveFloat32 )
          && ( shaderSignedZeroInfNanPreserveFloat64 == rhs.shaderSignedZeroInfNanPreserveFloat64 )
          && ( shaderDenormPreserveFloat16 == rhs.shaderDenormPreserveFloat16 )
          && ( shaderDenormPreserveFloat32 == rhs.shaderDenormPreserveFloat32 )
          && ( shaderDenormPreserveFloat64 == rhs.shaderDenormPreserveFloat64 )
          && ( shaderDenormFlushToZeroFloat16 == rhs.shaderDenormFlushToZeroFloat16 )
          && ( shaderDenormFlushToZeroFloat32 == rhs.shaderDenormFlushToZeroFloat32 )
          && ( shaderDenormFlushToZeroFloat64 == rhs.shaderDenormFlushToZeroFloat64 )
          && ( shaderRoundingModeRTEFloat16 == rhs.shaderRoundingModeRTEFloat16 )
          && ( shaderRoundingModeRTEFloat32 == rhs.shaderRoundingModeRTEFloat32 )
          && ( shaderRoundingModeRTEFloat64 == rhs.shaderRoundingModeRTEFloat64 )
          && ( shaderRoundingModeRTZFloat16 == rhs.shaderRoundingModeRTZFloat16 )
          && ( shaderRoundingModeRTZFloat32 == rhs.shaderRoundingModeRTZFloat32 )
          && ( shaderRoundingModeRTZFloat64 == rhs.shaderRoundingModeRTZFloat64 );
    }

    bool operator!=( PhysicalDeviceFloatControlsPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceFloatControlsPropertiesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceFloatControlsPropertiesKHR ) == sizeof( VkPhysicalDeviceFloatControlsPropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceFloatControlsPropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceFragmentDensityMapFeaturesEXT
    {
    protected:
      PhysicalDeviceFragmentDensityMapFeaturesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceFragmentDensityMapFeaturesEXT( VkPhysicalDeviceFragmentDensityMapFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentDensityMapFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceFragmentDensityMapFeaturesEXT& operator=( VkPhysicalDeviceFragmentDensityMapFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentDensityMapFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceFragmentDensityMapFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 fragmentDensityMap;
      vk::Bool32 fragmentDensityMapDynamic;
      vk::Bool32 fragmentDensityMapNonSubsampledImages;
    };
    static_assert( sizeof( PhysicalDeviceFragmentDensityMapFeaturesEXT ) == sizeof( VkPhysicalDeviceFragmentDensityMapFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceFragmentDensityMapFeaturesEXT : public layout::PhysicalDeviceFragmentDensityMapFeaturesEXT
  {
    PhysicalDeviceFragmentDensityMapFeaturesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentDensityMapFeaturesEXT()
    {}

    PhysicalDeviceFragmentDensityMapFeaturesEXT( VkPhysicalDeviceFragmentDensityMapFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentDensityMapFeaturesEXT( rhs )
    {}

    PhysicalDeviceFragmentDensityMapFeaturesEXT& operator=( VkPhysicalDeviceFragmentDensityMapFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceFragmentDensityMapFeaturesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceFragmentDensityMapFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceFragmentDensityMapFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceFragmentDensityMapFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceFragmentDensityMapFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceFragmentDensityMapFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fragmentDensityMap == rhs.fragmentDensityMap )
          && ( fragmentDensityMapDynamic == rhs.fragmentDensityMapDynamic )
          && ( fragmentDensityMapNonSubsampledImages == rhs.fragmentDensityMapNonSubsampledImages );
    }

    bool operator!=( PhysicalDeviceFragmentDensityMapFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceFragmentDensityMapFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceFragmentDensityMapFeaturesEXT ) == sizeof( VkPhysicalDeviceFragmentDensityMapFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceFragmentDensityMapFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceFragmentDensityMapPropertiesEXT
    {
    protected:
      PhysicalDeviceFragmentDensityMapPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceFragmentDensityMapPropertiesEXT( VkPhysicalDeviceFragmentDensityMapPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentDensityMapPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceFragmentDensityMapPropertiesEXT& operator=( VkPhysicalDeviceFragmentDensityMapPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentDensityMapPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceFragmentDensityMapPropertiesEXT;
      void* pNext = nullptr;
      vk::Extent2D minFragmentDensityTexelSize;
      vk::Extent2D maxFragmentDensityTexelSize;
      vk::Bool32 fragmentDensityInvocations;
    };
    static_assert( sizeof( PhysicalDeviceFragmentDensityMapPropertiesEXT ) == sizeof( VkPhysicalDeviceFragmentDensityMapPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceFragmentDensityMapPropertiesEXT : public layout::PhysicalDeviceFragmentDensityMapPropertiesEXT
  {
    PhysicalDeviceFragmentDensityMapPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentDensityMapPropertiesEXT()
    {}

    PhysicalDeviceFragmentDensityMapPropertiesEXT( VkPhysicalDeviceFragmentDensityMapPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentDensityMapPropertiesEXT( rhs )
    {}

    PhysicalDeviceFragmentDensityMapPropertiesEXT& operator=( VkPhysicalDeviceFragmentDensityMapPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceFragmentDensityMapPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceFragmentDensityMapPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceFragmentDensityMapPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceFragmentDensityMapPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceFragmentDensityMapPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceFragmentDensityMapPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( minFragmentDensityTexelSize == rhs.minFragmentDensityTexelSize )
          && ( maxFragmentDensityTexelSize == rhs.maxFragmentDensityTexelSize )
          && ( fragmentDensityInvocations == rhs.fragmentDensityInvocations );
    }

    bool operator!=( PhysicalDeviceFragmentDensityMapPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceFragmentDensityMapPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceFragmentDensityMapPropertiesEXT ) == sizeof( VkPhysicalDeviceFragmentDensityMapPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceFragmentDensityMapPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceFragmentShaderBarycentricFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceFragmentShaderBarycentricFeaturesNV( vk::Bool32 fragmentShaderBarycentric_ = 0 ) VULKAN_HPP_NOEXCEPT
        : fragmentShaderBarycentric( fragmentShaderBarycentric_ )
      {}

      PhysicalDeviceFragmentShaderBarycentricFeaturesNV( VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceFragmentShaderBarycentricFeaturesNV& operator=( VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceFragmentShaderBarycentricFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 fragmentShaderBarycentric;
    };
    static_assert( sizeof( PhysicalDeviceFragmentShaderBarycentricFeaturesNV ) == sizeof( VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceFragmentShaderBarycentricFeaturesNV : public layout::PhysicalDeviceFragmentShaderBarycentricFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceFragmentShaderBarycentricFeaturesNV( vk::Bool32 fragmentShaderBarycentric_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentShaderBarycentricFeaturesNV( fragmentShaderBarycentric_ )
    {}

    PhysicalDeviceFragmentShaderBarycentricFeaturesNV( VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentShaderBarycentricFeaturesNV( rhs )
    {}

    PhysicalDeviceFragmentShaderBarycentricFeaturesNV& operator=( VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceFragmentShaderBarycentricFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceFragmentShaderBarycentricFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceFragmentShaderBarycentricFeaturesNV & setFragmentShaderBarycentric( vk::Bool32 fragmentShaderBarycentric_ ) VULKAN_HPP_NOEXCEPT
    {
      fragmentShaderBarycentric = fragmentShaderBarycentric_;
      return *this;
    }

    operator VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceFragmentShaderBarycentricFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fragmentShaderBarycentric == rhs.fragmentShaderBarycentric );
    }

    bool operator!=( PhysicalDeviceFragmentShaderBarycentricFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceFragmentShaderBarycentricFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceFragmentShaderBarycentricFeaturesNV ) == sizeof( VkPhysicalDeviceFragmentShaderBarycentricFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceFragmentShaderBarycentricFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceFragmentShaderInterlockFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceFragmentShaderInterlockFeaturesEXT( vk::Bool32 fragmentShaderSampleInterlock_ = 0,
                                                                             vk::Bool32 fragmentShaderPixelInterlock_ = 0,
                                                                             vk::Bool32 fragmentShaderShadingRateInterlock_ = 0 ) VULKAN_HPP_NOEXCEPT
        : fragmentShaderSampleInterlock( fragmentShaderSampleInterlock_ )
        , fragmentShaderPixelInterlock( fragmentShaderPixelInterlock_ )
        , fragmentShaderShadingRateInterlock( fragmentShaderShadingRateInterlock_ )
      {}

      PhysicalDeviceFragmentShaderInterlockFeaturesEXT( VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceFragmentShaderInterlockFeaturesEXT& operator=( VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceFragmentShaderInterlockFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 fragmentShaderSampleInterlock;
      vk::Bool32 fragmentShaderPixelInterlock;
      vk::Bool32 fragmentShaderShadingRateInterlock;
    };
    static_assert( sizeof( PhysicalDeviceFragmentShaderInterlockFeaturesEXT ) == sizeof( VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceFragmentShaderInterlockFeaturesEXT : public layout::PhysicalDeviceFragmentShaderInterlockFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceFragmentShaderInterlockFeaturesEXT( vk::Bool32 fragmentShaderSampleInterlock_ = 0,
                                                                           vk::Bool32 fragmentShaderPixelInterlock_ = 0,
                                                                           vk::Bool32 fragmentShaderShadingRateInterlock_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentShaderInterlockFeaturesEXT( fragmentShaderSampleInterlock_, fragmentShaderPixelInterlock_, fragmentShaderShadingRateInterlock_ )
    {}

    PhysicalDeviceFragmentShaderInterlockFeaturesEXT( VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceFragmentShaderInterlockFeaturesEXT( rhs )
    {}

    PhysicalDeviceFragmentShaderInterlockFeaturesEXT& operator=( VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceFragmentShaderInterlockFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceFragmentShaderInterlockFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceFragmentShaderInterlockFeaturesEXT & setFragmentShaderSampleInterlock( vk::Bool32 fragmentShaderSampleInterlock_ ) VULKAN_HPP_NOEXCEPT
    {
      fragmentShaderSampleInterlock = fragmentShaderSampleInterlock_;
      return *this;
    }

    PhysicalDeviceFragmentShaderInterlockFeaturesEXT & setFragmentShaderPixelInterlock( vk::Bool32 fragmentShaderPixelInterlock_ ) VULKAN_HPP_NOEXCEPT
    {
      fragmentShaderPixelInterlock = fragmentShaderPixelInterlock_;
      return *this;
    }

    PhysicalDeviceFragmentShaderInterlockFeaturesEXT & setFragmentShaderShadingRateInterlock( vk::Bool32 fragmentShaderShadingRateInterlock_ ) VULKAN_HPP_NOEXCEPT
    {
      fragmentShaderShadingRateInterlock = fragmentShaderShadingRateInterlock_;
      return *this;
    }

    operator VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceFragmentShaderInterlockFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fragmentShaderSampleInterlock == rhs.fragmentShaderSampleInterlock )
          && ( fragmentShaderPixelInterlock == rhs.fragmentShaderPixelInterlock )
          && ( fragmentShaderShadingRateInterlock == rhs.fragmentShaderShadingRateInterlock );
    }

    bool operator!=( PhysicalDeviceFragmentShaderInterlockFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceFragmentShaderInterlockFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceFragmentShaderInterlockFeaturesEXT ) == sizeof( VkPhysicalDeviceFragmentShaderInterlockFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceFragmentShaderInterlockFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceGroupProperties
    {
    protected:
      PhysicalDeviceGroupProperties() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceGroupProperties( VkPhysicalDeviceGroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceGroupProperties*>(this) = rhs;
      }

      PhysicalDeviceGroupProperties& operator=( VkPhysicalDeviceGroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceGroupProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceGroupProperties;
      void* pNext = nullptr;
      uint32_t physicalDeviceCount;
      vk::PhysicalDevice physicalDevices[VK_MAX_DEVICE_GROUP_SIZE];
      vk::Bool32 subsetAllocation;
    };
    static_assert( sizeof( PhysicalDeviceGroupProperties ) == sizeof( VkPhysicalDeviceGroupProperties ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceGroupProperties : public layout::PhysicalDeviceGroupProperties
  {
    PhysicalDeviceGroupProperties() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceGroupProperties()
    {}

    PhysicalDeviceGroupProperties( VkPhysicalDeviceGroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceGroupProperties( rhs )
    {}

    PhysicalDeviceGroupProperties& operator=( VkPhysicalDeviceGroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceGroupProperties::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceGroupProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceGroupProperties*>( this );
    }

    operator VkPhysicalDeviceGroupProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceGroupProperties*>( this );
    }

    bool operator==( PhysicalDeviceGroupProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( physicalDeviceCount == rhs.physicalDeviceCount )
          && ( memcmp( physicalDevices, rhs.physicalDevices, VK_MAX_DEVICE_GROUP_SIZE * sizeof( vk::PhysicalDevice ) ) == 0 )
          && ( subsetAllocation == rhs.subsetAllocation );
    }

    bool operator!=( PhysicalDeviceGroupProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceGroupProperties::sType;
  };
  static_assert( sizeof( PhysicalDeviceGroupProperties ) == sizeof( VkPhysicalDeviceGroupProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceGroupProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceHostQueryResetFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceHostQueryResetFeaturesEXT( vk::Bool32 hostQueryReset_ = 0 ) VULKAN_HPP_NOEXCEPT
        : hostQueryReset( hostQueryReset_ )
      {}

      PhysicalDeviceHostQueryResetFeaturesEXT( VkPhysicalDeviceHostQueryResetFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceHostQueryResetFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceHostQueryResetFeaturesEXT& operator=( VkPhysicalDeviceHostQueryResetFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceHostQueryResetFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceHostQueryResetFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 hostQueryReset;
    };
    static_assert( sizeof( PhysicalDeviceHostQueryResetFeaturesEXT ) == sizeof( VkPhysicalDeviceHostQueryResetFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceHostQueryResetFeaturesEXT : public layout::PhysicalDeviceHostQueryResetFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceHostQueryResetFeaturesEXT( vk::Bool32 hostQueryReset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceHostQueryResetFeaturesEXT( hostQueryReset_ )
    {}

    PhysicalDeviceHostQueryResetFeaturesEXT( VkPhysicalDeviceHostQueryResetFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceHostQueryResetFeaturesEXT( rhs )
    {}

    PhysicalDeviceHostQueryResetFeaturesEXT& operator=( VkPhysicalDeviceHostQueryResetFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceHostQueryResetFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceHostQueryResetFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceHostQueryResetFeaturesEXT & setHostQueryReset( vk::Bool32 hostQueryReset_ ) VULKAN_HPP_NOEXCEPT
    {
      hostQueryReset = hostQueryReset_;
      return *this;
    }

    operator VkPhysicalDeviceHostQueryResetFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceHostQueryResetFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceHostQueryResetFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceHostQueryResetFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceHostQueryResetFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( hostQueryReset == rhs.hostQueryReset );
    }

    bool operator!=( PhysicalDeviceHostQueryResetFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceHostQueryResetFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceHostQueryResetFeaturesEXT ) == sizeof( VkPhysicalDeviceHostQueryResetFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceHostQueryResetFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceIDProperties
    {
    protected:
      PhysicalDeviceIDProperties() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceIDProperties( VkPhysicalDeviceIDProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceIDProperties*>(this) = rhs;
      }

      PhysicalDeviceIDProperties& operator=( VkPhysicalDeviceIDProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceIDProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceIdProperties;
      void* pNext = nullptr;
      uint8_t deviceUUID[VK_UUID_SIZE];
      uint8_t driverUUID[VK_UUID_SIZE];
      uint8_t deviceLUID[VK_LUID_SIZE];
      uint32_t deviceNodeMask;
      vk::Bool32 deviceLUIDValid;
    };
    static_assert( sizeof( PhysicalDeviceIDProperties ) == sizeof( VkPhysicalDeviceIDProperties ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceIDProperties : public layout::PhysicalDeviceIDProperties
  {
    PhysicalDeviceIDProperties() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceIDProperties()
    {}

    PhysicalDeviceIDProperties( VkPhysicalDeviceIDProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceIDProperties( rhs )
    {}

    PhysicalDeviceIDProperties& operator=( VkPhysicalDeviceIDProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceIDProperties::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceIDProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceIDProperties*>( this );
    }

    operator VkPhysicalDeviceIDProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceIDProperties*>( this );
    }

    bool operator==( PhysicalDeviceIDProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memcmp( deviceUUID, rhs.deviceUUID, VK_UUID_SIZE * sizeof( uint8_t ) ) == 0 )
          && ( memcmp( driverUUID, rhs.driverUUID, VK_UUID_SIZE * sizeof( uint8_t ) ) == 0 )
          && ( memcmp( deviceLUID, rhs.deviceLUID, VK_LUID_SIZE * sizeof( uint8_t ) ) == 0 )
          && ( deviceNodeMask == rhs.deviceNodeMask )
          && ( deviceLUIDValid == rhs.deviceLUIDValid );
    }

    bool operator!=( PhysicalDeviceIDProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceIDProperties::sType;
  };
  static_assert( sizeof( PhysicalDeviceIDProperties ) == sizeof( VkPhysicalDeviceIDProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceIDProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceImageDrmFormatModifierInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceImageDrmFormatModifierInfoEXT( uint64_t drmFormatModifier_ = 0,
                                                                        vk::SharingMode sharingMode_ = vk::SharingMode::eExclusive,
                                                                        uint32_t queueFamilyIndexCount_ = 0,
                                                                        const uint32_t* pQueueFamilyIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : drmFormatModifier( drmFormatModifier_ )
        , sharingMode( sharingMode_ )
        , queueFamilyIndexCount( queueFamilyIndexCount_ )
        , pQueueFamilyIndices( pQueueFamilyIndices_ )
      {}

      PhysicalDeviceImageDrmFormatModifierInfoEXT( VkPhysicalDeviceImageDrmFormatModifierInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImageDrmFormatModifierInfoEXT*>(this) = rhs;
      }

      PhysicalDeviceImageDrmFormatModifierInfoEXT& operator=( VkPhysicalDeviceImageDrmFormatModifierInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImageDrmFormatModifierInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceImageDrmFormatModifierInfoEXT;
      const void* pNext = nullptr;
      uint64_t drmFormatModifier;
      vk::SharingMode sharingMode;
      uint32_t queueFamilyIndexCount;
      const uint32_t* pQueueFamilyIndices;
    };
    static_assert( sizeof( PhysicalDeviceImageDrmFormatModifierInfoEXT ) == sizeof( VkPhysicalDeviceImageDrmFormatModifierInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceImageDrmFormatModifierInfoEXT : public layout::PhysicalDeviceImageDrmFormatModifierInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceImageDrmFormatModifierInfoEXT( uint64_t drmFormatModifier_ = 0,
                                                                      vk::SharingMode sharingMode_ = vk::SharingMode::eExclusive,
                                                                      uint32_t queueFamilyIndexCount_ = 0,
                                                                      const uint32_t* pQueueFamilyIndices_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImageDrmFormatModifierInfoEXT( drmFormatModifier_, sharingMode_, queueFamilyIndexCount_, pQueueFamilyIndices_ )
    {}

    PhysicalDeviceImageDrmFormatModifierInfoEXT( VkPhysicalDeviceImageDrmFormatModifierInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImageDrmFormatModifierInfoEXT( rhs )
    {}

    PhysicalDeviceImageDrmFormatModifierInfoEXT& operator=( VkPhysicalDeviceImageDrmFormatModifierInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceImageDrmFormatModifierInfoEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceImageDrmFormatModifierInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceImageDrmFormatModifierInfoEXT & setDrmFormatModifier( uint64_t drmFormatModifier_ ) VULKAN_HPP_NOEXCEPT
    {
      drmFormatModifier = drmFormatModifier_;
      return *this;
    }

    PhysicalDeviceImageDrmFormatModifierInfoEXT & setSharingMode( vk::SharingMode sharingMode_ ) VULKAN_HPP_NOEXCEPT
    {
      sharingMode = sharingMode_;
      return *this;
    }

    PhysicalDeviceImageDrmFormatModifierInfoEXT & setQueueFamilyIndexCount( uint32_t queueFamilyIndexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queueFamilyIndexCount = queueFamilyIndexCount_;
      return *this;
    }

    PhysicalDeviceImageDrmFormatModifierInfoEXT & setPQueueFamilyIndices( const uint32_t* pQueueFamilyIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pQueueFamilyIndices = pQueueFamilyIndices_;
      return *this;
    }

    operator VkPhysicalDeviceImageDrmFormatModifierInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceImageDrmFormatModifierInfoEXT*>( this );
    }

    operator VkPhysicalDeviceImageDrmFormatModifierInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceImageDrmFormatModifierInfoEXT*>( this );
    }

    bool operator==( PhysicalDeviceImageDrmFormatModifierInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( drmFormatModifier == rhs.drmFormatModifier )
          && ( sharingMode == rhs.sharingMode )
          && ( queueFamilyIndexCount == rhs.queueFamilyIndexCount )
          && ( pQueueFamilyIndices == rhs.pQueueFamilyIndices );
    }

    bool operator!=( PhysicalDeviceImageDrmFormatModifierInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceImageDrmFormatModifierInfoEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceImageDrmFormatModifierInfoEXT ) == sizeof( VkPhysicalDeviceImageDrmFormatModifierInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceImageDrmFormatModifierInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceImageFormatInfo2
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceImageFormatInfo2( vk::Format format_ = vk::Format::eUndefined,
                                                           vk::ImageType type_ = vk::ImageType::e1D,
                                                           vk::ImageTiling tiling_ = vk::ImageTiling::eOptimal,
                                                           vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                                           vk::ImageCreateFlags flags_ = vk::ImageCreateFlags() ) VULKAN_HPP_NOEXCEPT
        : format( format_ )
        , type( type_ )
        , tiling( tiling_ )
        , usage( usage_ )
        , flags( flags_ )
      {}

      PhysicalDeviceImageFormatInfo2( VkPhysicalDeviceImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImageFormatInfo2*>(this) = rhs;
      }

      PhysicalDeviceImageFormatInfo2& operator=( VkPhysicalDeviceImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImageFormatInfo2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceImageFormatInfo2;
      const void* pNext = nullptr;
      vk::Format format;
      vk::ImageType type;
      vk::ImageTiling tiling;
      vk::ImageUsageFlags usage;
      vk::ImageCreateFlags flags;
    };
    static_assert( sizeof( PhysicalDeviceImageFormatInfo2 ) == sizeof( VkPhysicalDeviceImageFormatInfo2 ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceImageFormatInfo2 : public layout::PhysicalDeviceImageFormatInfo2
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceImageFormatInfo2( vk::Format format_ = vk::Format::eUndefined,
                                                         vk::ImageType type_ = vk::ImageType::e1D,
                                                         vk::ImageTiling tiling_ = vk::ImageTiling::eOptimal,
                                                         vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                                         vk::ImageCreateFlags flags_ = vk::ImageCreateFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImageFormatInfo2( format_, type_, tiling_, usage_, flags_ )
    {}

    PhysicalDeviceImageFormatInfo2( VkPhysicalDeviceImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImageFormatInfo2( rhs )
    {}

    PhysicalDeviceImageFormatInfo2& operator=( VkPhysicalDeviceImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceImageFormatInfo2::operator=(rhs);
      return *this;
    }

    PhysicalDeviceImageFormatInfo2 & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceImageFormatInfo2 & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    PhysicalDeviceImageFormatInfo2 & setType( vk::ImageType type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    PhysicalDeviceImageFormatInfo2 & setTiling( vk::ImageTiling tiling_ ) VULKAN_HPP_NOEXCEPT
    {
      tiling = tiling_;
      return *this;
    }

    PhysicalDeviceImageFormatInfo2 & setUsage( vk::ImageUsageFlags usage_ ) VULKAN_HPP_NOEXCEPT
    {
      usage = usage_;
      return *this;
    }

    PhysicalDeviceImageFormatInfo2 & setFlags( vk::ImageCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkPhysicalDeviceImageFormatInfo2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>( this );
    }

    operator VkPhysicalDeviceImageFormatInfo2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceImageFormatInfo2*>( this );
    }

    bool operator==( PhysicalDeviceImageFormatInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( format == rhs.format )
          && ( type == rhs.type )
          && ( tiling == rhs.tiling )
          && ( usage == rhs.usage )
          && ( flags == rhs.flags );
    }

    bool operator!=( PhysicalDeviceImageFormatInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceImageFormatInfo2::sType;
  };
  static_assert( sizeof( PhysicalDeviceImageFormatInfo2 ) == sizeof( VkPhysicalDeviceImageFormatInfo2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceImageFormatInfo2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceImageViewImageFormatInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceImageViewImageFormatInfoEXT( vk::ImageViewType imageViewType_ = vk::ImageViewType::e1D ) VULKAN_HPP_NOEXCEPT
        : imageViewType( imageViewType_ )
      {}

      PhysicalDeviceImageViewImageFormatInfoEXT( VkPhysicalDeviceImageViewImageFormatInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImageViewImageFormatInfoEXT*>(this) = rhs;
      }

      PhysicalDeviceImageViewImageFormatInfoEXT& operator=( VkPhysicalDeviceImageViewImageFormatInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImageViewImageFormatInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceImageViewImageFormatInfoEXT;
      void* pNext = nullptr;
      vk::ImageViewType imageViewType;
    };
    static_assert( sizeof( PhysicalDeviceImageViewImageFormatInfoEXT ) == sizeof( VkPhysicalDeviceImageViewImageFormatInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceImageViewImageFormatInfoEXT : public layout::PhysicalDeviceImageViewImageFormatInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceImageViewImageFormatInfoEXT( vk::ImageViewType imageViewType_ = vk::ImageViewType::e1D ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImageViewImageFormatInfoEXT( imageViewType_ )
    {}

    PhysicalDeviceImageViewImageFormatInfoEXT( VkPhysicalDeviceImageViewImageFormatInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImageViewImageFormatInfoEXT( rhs )
    {}

    PhysicalDeviceImageViewImageFormatInfoEXT& operator=( VkPhysicalDeviceImageViewImageFormatInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceImageViewImageFormatInfoEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceImageViewImageFormatInfoEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceImageViewImageFormatInfoEXT & setImageViewType( vk::ImageViewType imageViewType_ ) VULKAN_HPP_NOEXCEPT
    {
      imageViewType = imageViewType_;
      return *this;
    }

    operator VkPhysicalDeviceImageViewImageFormatInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceImageViewImageFormatInfoEXT*>( this );
    }

    operator VkPhysicalDeviceImageViewImageFormatInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceImageViewImageFormatInfoEXT*>( this );
    }

    bool operator==( PhysicalDeviceImageViewImageFormatInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( imageViewType == rhs.imageViewType );
    }

    bool operator!=( PhysicalDeviceImageViewImageFormatInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceImageViewImageFormatInfoEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceImageViewImageFormatInfoEXT ) == sizeof( VkPhysicalDeviceImageViewImageFormatInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceImageViewImageFormatInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceImagelessFramebufferFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceImagelessFramebufferFeaturesKHR( vk::Bool32 imagelessFramebuffer_ = 0 ) VULKAN_HPP_NOEXCEPT
        : imagelessFramebuffer( imagelessFramebuffer_ )
      {}

      PhysicalDeviceImagelessFramebufferFeaturesKHR( VkPhysicalDeviceImagelessFramebufferFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImagelessFramebufferFeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceImagelessFramebufferFeaturesKHR& operator=( VkPhysicalDeviceImagelessFramebufferFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceImagelessFramebufferFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceImagelessFramebufferFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 imagelessFramebuffer;
    };
    static_assert( sizeof( PhysicalDeviceImagelessFramebufferFeaturesKHR ) == sizeof( VkPhysicalDeviceImagelessFramebufferFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceImagelessFramebufferFeaturesKHR : public layout::PhysicalDeviceImagelessFramebufferFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceImagelessFramebufferFeaturesKHR( vk::Bool32 imagelessFramebuffer_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImagelessFramebufferFeaturesKHR( imagelessFramebuffer_ )
    {}

    PhysicalDeviceImagelessFramebufferFeaturesKHR( VkPhysicalDeviceImagelessFramebufferFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceImagelessFramebufferFeaturesKHR( rhs )
    {}

    PhysicalDeviceImagelessFramebufferFeaturesKHR& operator=( VkPhysicalDeviceImagelessFramebufferFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceImagelessFramebufferFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceImagelessFramebufferFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceImagelessFramebufferFeaturesKHR & setImagelessFramebuffer( vk::Bool32 imagelessFramebuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      imagelessFramebuffer = imagelessFramebuffer_;
      return *this;
    }

    operator VkPhysicalDeviceImagelessFramebufferFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceImagelessFramebufferFeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceImagelessFramebufferFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceImagelessFramebufferFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceImagelessFramebufferFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( imagelessFramebuffer == rhs.imagelessFramebuffer );
    }

    bool operator!=( PhysicalDeviceImagelessFramebufferFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceImagelessFramebufferFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceImagelessFramebufferFeaturesKHR ) == sizeof( VkPhysicalDeviceImagelessFramebufferFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceImagelessFramebufferFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceIndexTypeUint8FeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceIndexTypeUint8FeaturesEXT( vk::Bool32 indexTypeUint8_ = 0 ) VULKAN_HPP_NOEXCEPT
        : indexTypeUint8( indexTypeUint8_ )
      {}

      PhysicalDeviceIndexTypeUint8FeaturesEXT( VkPhysicalDeviceIndexTypeUint8FeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceIndexTypeUint8FeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceIndexTypeUint8FeaturesEXT& operator=( VkPhysicalDeviceIndexTypeUint8FeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceIndexTypeUint8FeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceIndexTypeUint8FeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 indexTypeUint8;
    };
    static_assert( sizeof( PhysicalDeviceIndexTypeUint8FeaturesEXT ) == sizeof( VkPhysicalDeviceIndexTypeUint8FeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceIndexTypeUint8FeaturesEXT : public layout::PhysicalDeviceIndexTypeUint8FeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceIndexTypeUint8FeaturesEXT( vk::Bool32 indexTypeUint8_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceIndexTypeUint8FeaturesEXT( indexTypeUint8_ )
    {}

    PhysicalDeviceIndexTypeUint8FeaturesEXT( VkPhysicalDeviceIndexTypeUint8FeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceIndexTypeUint8FeaturesEXT( rhs )
    {}

    PhysicalDeviceIndexTypeUint8FeaturesEXT& operator=( VkPhysicalDeviceIndexTypeUint8FeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceIndexTypeUint8FeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceIndexTypeUint8FeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceIndexTypeUint8FeaturesEXT & setIndexTypeUint8( vk::Bool32 indexTypeUint8_ ) VULKAN_HPP_NOEXCEPT
    {
      indexTypeUint8 = indexTypeUint8_;
      return *this;
    }

    operator VkPhysicalDeviceIndexTypeUint8FeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceIndexTypeUint8FeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceIndexTypeUint8FeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceIndexTypeUint8FeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceIndexTypeUint8FeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( indexTypeUint8 == rhs.indexTypeUint8 );
    }

    bool operator!=( PhysicalDeviceIndexTypeUint8FeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceIndexTypeUint8FeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceIndexTypeUint8FeaturesEXT ) == sizeof( VkPhysicalDeviceIndexTypeUint8FeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceIndexTypeUint8FeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceInlineUniformBlockFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceInlineUniformBlockFeaturesEXT( vk::Bool32 inlineUniformBlock_ = 0,
                                                                        vk::Bool32 descriptorBindingInlineUniformBlockUpdateAfterBind_ = 0 ) VULKAN_HPP_NOEXCEPT
        : inlineUniformBlock( inlineUniformBlock_ )
        , descriptorBindingInlineUniformBlockUpdateAfterBind( descriptorBindingInlineUniformBlockUpdateAfterBind_ )
      {}

      PhysicalDeviceInlineUniformBlockFeaturesEXT( VkPhysicalDeviceInlineUniformBlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceInlineUniformBlockFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceInlineUniformBlockFeaturesEXT& operator=( VkPhysicalDeviceInlineUniformBlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceInlineUniformBlockFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceInlineUniformBlockFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 inlineUniformBlock;
      vk::Bool32 descriptorBindingInlineUniformBlockUpdateAfterBind;
    };
    static_assert( sizeof( PhysicalDeviceInlineUniformBlockFeaturesEXT ) == sizeof( VkPhysicalDeviceInlineUniformBlockFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceInlineUniformBlockFeaturesEXT : public layout::PhysicalDeviceInlineUniformBlockFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceInlineUniformBlockFeaturesEXT( vk::Bool32 inlineUniformBlock_ = 0,
                                                                      vk::Bool32 descriptorBindingInlineUniformBlockUpdateAfterBind_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceInlineUniformBlockFeaturesEXT( inlineUniformBlock_, descriptorBindingInlineUniformBlockUpdateAfterBind_ )
    {}

    PhysicalDeviceInlineUniformBlockFeaturesEXT( VkPhysicalDeviceInlineUniformBlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceInlineUniformBlockFeaturesEXT( rhs )
    {}

    PhysicalDeviceInlineUniformBlockFeaturesEXT& operator=( VkPhysicalDeviceInlineUniformBlockFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceInlineUniformBlockFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceInlineUniformBlockFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceInlineUniformBlockFeaturesEXT & setInlineUniformBlock( vk::Bool32 inlineUniformBlock_ ) VULKAN_HPP_NOEXCEPT
    {
      inlineUniformBlock = inlineUniformBlock_;
      return *this;
    }

    PhysicalDeviceInlineUniformBlockFeaturesEXT & setDescriptorBindingInlineUniformBlockUpdateAfterBind( vk::Bool32 descriptorBindingInlineUniformBlockUpdateAfterBind_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorBindingInlineUniformBlockUpdateAfterBind = descriptorBindingInlineUniformBlockUpdateAfterBind_;
      return *this;
    }

    operator VkPhysicalDeviceInlineUniformBlockFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceInlineUniformBlockFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceInlineUniformBlockFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceInlineUniformBlockFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceInlineUniformBlockFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( inlineUniformBlock == rhs.inlineUniformBlock )
          && ( descriptorBindingInlineUniformBlockUpdateAfterBind == rhs.descriptorBindingInlineUniformBlockUpdateAfterBind );
    }

    bool operator!=( PhysicalDeviceInlineUniformBlockFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceInlineUniformBlockFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceInlineUniformBlockFeaturesEXT ) == sizeof( VkPhysicalDeviceInlineUniformBlockFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceInlineUniformBlockFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceInlineUniformBlockPropertiesEXT
    {
    protected:
      PhysicalDeviceInlineUniformBlockPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceInlineUniformBlockPropertiesEXT( VkPhysicalDeviceInlineUniformBlockPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceInlineUniformBlockPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceInlineUniformBlockPropertiesEXT& operator=( VkPhysicalDeviceInlineUniformBlockPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceInlineUniformBlockPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceInlineUniformBlockPropertiesEXT;
      void* pNext = nullptr;
      uint32_t maxInlineUniformBlockSize;
      uint32_t maxPerStageDescriptorInlineUniformBlocks;
      uint32_t maxPerStageDescriptorUpdateAfterBindInlineUniformBlocks;
      uint32_t maxDescriptorSetInlineUniformBlocks;
      uint32_t maxDescriptorSetUpdateAfterBindInlineUniformBlocks;
    };
    static_assert( sizeof( PhysicalDeviceInlineUniformBlockPropertiesEXT ) == sizeof( VkPhysicalDeviceInlineUniformBlockPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceInlineUniformBlockPropertiesEXT : public layout::PhysicalDeviceInlineUniformBlockPropertiesEXT
  {
    PhysicalDeviceInlineUniformBlockPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceInlineUniformBlockPropertiesEXT()
    {}

    PhysicalDeviceInlineUniformBlockPropertiesEXT( VkPhysicalDeviceInlineUniformBlockPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceInlineUniformBlockPropertiesEXT( rhs )
    {}

    PhysicalDeviceInlineUniformBlockPropertiesEXT& operator=( VkPhysicalDeviceInlineUniformBlockPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceInlineUniformBlockPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceInlineUniformBlockPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceInlineUniformBlockPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceInlineUniformBlockPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceInlineUniformBlockPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceInlineUniformBlockPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxInlineUniformBlockSize == rhs.maxInlineUniformBlockSize )
          && ( maxPerStageDescriptorInlineUniformBlocks == rhs.maxPerStageDescriptorInlineUniformBlocks )
          && ( maxPerStageDescriptorUpdateAfterBindInlineUniformBlocks == rhs.maxPerStageDescriptorUpdateAfterBindInlineUniformBlocks )
          && ( maxDescriptorSetInlineUniformBlocks == rhs.maxDescriptorSetInlineUniformBlocks )
          && ( maxDescriptorSetUpdateAfterBindInlineUniformBlocks == rhs.maxDescriptorSetUpdateAfterBindInlineUniformBlocks );
    }

    bool operator!=( PhysicalDeviceInlineUniformBlockPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceInlineUniformBlockPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceInlineUniformBlockPropertiesEXT ) == sizeof( VkPhysicalDeviceInlineUniformBlockPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceInlineUniformBlockPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  struct PhysicalDeviceLimits
  {
    PhysicalDeviceLimits() VULKAN_HPP_NOEXCEPT
    {}

    PhysicalDeviceLimits( VkPhysicalDeviceLimits const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceLimits*>(this) = rhs;
    }

    PhysicalDeviceLimits& operator=( VkPhysicalDeviceLimits const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceLimits*>(this) = rhs;
      return *this;
    }

    operator VkPhysicalDeviceLimits const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceLimits*>( this );
    }

    operator VkPhysicalDeviceLimits &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceLimits*>( this );
    }

    bool operator==( PhysicalDeviceLimits const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( maxImageDimension1D == rhs.maxImageDimension1D )
          && ( maxImageDimension2D == rhs.maxImageDimension2D )
          && ( maxImageDimension3D == rhs.maxImageDimension3D )
          && ( maxImageDimensionCube == rhs.maxImageDimensionCube )
          && ( maxImageArrayLayers == rhs.maxImageArrayLayers )
          && ( maxTexelBufferElements == rhs.maxTexelBufferElements )
          && ( maxUniformBufferRange == rhs.maxUniformBufferRange )
          && ( maxStorageBufferRange == rhs.maxStorageBufferRange )
          && ( maxPushConstantsSize == rhs.maxPushConstantsSize )
          && ( maxMemoryAllocationCount == rhs.maxMemoryAllocationCount )
          && ( maxSamplerAllocationCount == rhs.maxSamplerAllocationCount )
          && ( bufferImageGranularity == rhs.bufferImageGranularity )
          && ( sparseAddressSpaceSize == rhs.sparseAddressSpaceSize )
          && ( maxBoundDescriptorSets == rhs.maxBoundDescriptorSets )
          && ( maxPerStageDescriptorSamplers == rhs.maxPerStageDescriptorSamplers )
          && ( maxPerStageDescriptorUniformBuffers == rhs.maxPerStageDescriptorUniformBuffers )
          && ( maxPerStageDescriptorStorageBuffers == rhs.maxPerStageDescriptorStorageBuffers )
          && ( maxPerStageDescriptorSampledImages == rhs.maxPerStageDescriptorSampledImages )
          && ( maxPerStageDescriptorStorageImages == rhs.maxPerStageDescriptorStorageImages )
          && ( maxPerStageDescriptorInputAttachments == rhs.maxPerStageDescriptorInputAttachments )
          && ( maxPerStageResources == rhs.maxPerStageResources )
          && ( maxDescriptorSetSamplers == rhs.maxDescriptorSetSamplers )
          && ( maxDescriptorSetUniformBuffers == rhs.maxDescriptorSetUniformBuffers )
          && ( maxDescriptorSetUniformBuffersDynamic == rhs.maxDescriptorSetUniformBuffersDynamic )
          && ( maxDescriptorSetStorageBuffers == rhs.maxDescriptorSetStorageBuffers )
          && ( maxDescriptorSetStorageBuffersDynamic == rhs.maxDescriptorSetStorageBuffersDynamic )
          && ( maxDescriptorSetSampledImages == rhs.maxDescriptorSetSampledImages )
          && ( maxDescriptorSetStorageImages == rhs.maxDescriptorSetStorageImages )
          && ( maxDescriptorSetInputAttachments == rhs.maxDescriptorSetInputAttachments )
          && ( maxVertexInputAttributes == rhs.maxVertexInputAttributes )
          && ( maxVertexInputBindings == rhs.maxVertexInputBindings )
          && ( maxVertexInputAttributeOffset == rhs.maxVertexInputAttributeOffset )
          && ( maxVertexInputBindingStride == rhs.maxVertexInputBindingStride )
          && ( maxVertexOutputComponents == rhs.maxVertexOutputComponents )
          && ( maxTessellationGenerationLevel == rhs.maxTessellationGenerationLevel )
          && ( maxTessellationPatchSize == rhs.maxTessellationPatchSize )
          && ( maxTessellationControlPerVertexInputComponents == rhs.maxTessellationControlPerVertexInputComponents )
          && ( maxTessellationControlPerVertexOutputComponents == rhs.maxTessellationControlPerVertexOutputComponents )
          && ( maxTessellationControlPerPatchOutputComponents == rhs.maxTessellationControlPerPatchOutputComponents )
          && ( maxTessellationControlTotalOutputComponents == rhs.maxTessellationControlTotalOutputComponents )
          && ( maxTessellationEvaluationInputComponents == rhs.maxTessellationEvaluationInputComponents )
          && ( maxTessellationEvaluationOutputComponents == rhs.maxTessellationEvaluationOutputComponents )
          && ( maxGeometryShaderInvocations == rhs.maxGeometryShaderInvocations )
          && ( maxGeometryInputComponents == rhs.maxGeometryInputComponents )
          && ( maxGeometryOutputComponents == rhs.maxGeometryOutputComponents )
          && ( maxGeometryOutputVertices == rhs.maxGeometryOutputVertices )
          && ( maxGeometryTotalOutputComponents == rhs.maxGeometryTotalOutputComponents )
          && ( maxFragmentInputComponents == rhs.maxFragmentInputComponents )
          && ( maxFragmentOutputAttachments == rhs.maxFragmentOutputAttachments )
          && ( maxFragmentDualSrcAttachments == rhs.maxFragmentDualSrcAttachments )
          && ( maxFragmentCombinedOutputResources == rhs.maxFragmentCombinedOutputResources )
          && ( maxComputeSharedMemorySize == rhs.maxComputeSharedMemorySize )
          && ( memcmp( maxComputeWorkGroupCount, rhs.maxComputeWorkGroupCount, 3 * sizeof( uint32_t ) ) == 0 )
          && ( maxComputeWorkGroupInvocations == rhs.maxComputeWorkGroupInvocations )
          && ( memcmp( maxComputeWorkGroupSize, rhs.maxComputeWorkGroupSize, 3 * sizeof( uint32_t ) ) == 0 )
          && ( subPixelPrecisionBits == rhs.subPixelPrecisionBits )
          && ( subTexelPrecisionBits == rhs.subTexelPrecisionBits )
          && ( mipmapPrecisionBits == rhs.mipmapPrecisionBits )
          && ( maxDrawIndexedIndexValue == rhs.maxDrawIndexedIndexValue )
          && ( maxDrawIndirectCount == rhs.maxDrawIndirectCount )
          && ( maxSamplerLodBias == rhs.maxSamplerLodBias )
          && ( maxSamplerAnisotropy == rhs.maxSamplerAnisotropy )
          && ( maxViewports == rhs.maxViewports )
          && ( memcmp( maxViewportDimensions, rhs.maxViewportDimensions, 2 * sizeof( uint32_t ) ) == 0 )
          && ( memcmp( viewportBoundsRange, rhs.viewportBoundsRange, 2 * sizeof( float ) ) == 0 )
          && ( viewportSubPixelBits == rhs.viewportSubPixelBits )
          && ( minMemoryMapAlignment == rhs.minMemoryMapAlignment )
          && ( minTexelBufferOffsetAlignment == rhs.minTexelBufferOffsetAlignment )
          && ( minUniformBufferOffsetAlignment == rhs.minUniformBufferOffsetAlignment )
          && ( minStorageBufferOffsetAlignment == rhs.minStorageBufferOffsetAlignment )
          && ( minTexelOffset == rhs.minTexelOffset )
          && ( maxTexelOffset == rhs.maxTexelOffset )
          && ( minTexelGatherOffset == rhs.minTexelGatherOffset )
          && ( maxTexelGatherOffset == rhs.maxTexelGatherOffset )
          && ( minInterpolationOffset == rhs.minInterpolationOffset )
          && ( maxInterpolationOffset == rhs.maxInterpolationOffset )
          && ( subPixelInterpolationOffsetBits == rhs.subPixelInterpolationOffsetBits )
          && ( maxFramebufferWidth == rhs.maxFramebufferWidth )
          && ( maxFramebufferHeight == rhs.maxFramebufferHeight )
          && ( maxFramebufferLayers == rhs.maxFramebufferLayers )
          && ( framebufferColorSampleCounts == rhs.framebufferColorSampleCounts )
          && ( framebufferDepthSampleCounts == rhs.framebufferDepthSampleCounts )
          && ( framebufferStencilSampleCounts == rhs.framebufferStencilSampleCounts )
          && ( framebufferNoAttachmentsSampleCounts == rhs.framebufferNoAttachmentsSampleCounts )
          && ( maxColorAttachments == rhs.maxColorAttachments )
          && ( sampledImageColorSampleCounts == rhs.sampledImageColorSampleCounts )
          && ( sampledImageIntegerSampleCounts == rhs.sampledImageIntegerSampleCounts )
          && ( sampledImageDepthSampleCounts == rhs.sampledImageDepthSampleCounts )
          && ( sampledImageStencilSampleCounts == rhs.sampledImageStencilSampleCounts )
          && ( storageImageSampleCounts == rhs.storageImageSampleCounts )
          && ( maxSampleMaskWords == rhs.maxSampleMaskWords )
          && ( timestampComputeAndGraphics == rhs.timestampComputeAndGraphics )
          && ( timestampPeriod == rhs.timestampPeriod )
          && ( maxClipDistances == rhs.maxClipDistances )
          && ( maxCullDistances == rhs.maxCullDistances )
          && ( maxCombinedClipAndCullDistances == rhs.maxCombinedClipAndCullDistances )
          && ( discreteQueuePriorities == rhs.discreteQueuePriorities )
          && ( memcmp( pointSizeRange, rhs.pointSizeRange, 2 * sizeof( float ) ) == 0 )
          && ( memcmp( lineWidthRange, rhs.lineWidthRange, 2 * sizeof( float ) ) == 0 )
          && ( pointSizeGranularity == rhs.pointSizeGranularity )
          && ( lineWidthGranularity == rhs.lineWidthGranularity )
          && ( strictLines == rhs.strictLines )
          && ( standardSampleLocations == rhs.standardSampleLocations )
          && ( optimalBufferCopyOffsetAlignment == rhs.optimalBufferCopyOffsetAlignment )
          && ( optimalBufferCopyRowPitchAlignment == rhs.optimalBufferCopyRowPitchAlignment )
          && ( nonCoherentAtomSize == rhs.nonCoherentAtomSize );
    }

    bool operator!=( PhysicalDeviceLimits const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t maxImageDimension1D;
    uint32_t maxImageDimension2D;
    uint32_t maxImageDimension3D;
    uint32_t maxImageDimensionCube;
    uint32_t maxImageArrayLayers;
    uint32_t maxTexelBufferElements;
    uint32_t maxUniformBufferRange;
    uint32_t maxStorageBufferRange;
    uint32_t maxPushConstantsSize;
    uint32_t maxMemoryAllocationCount;
    uint32_t maxSamplerAllocationCount;
    vk::DeviceSize bufferImageGranularity;
    vk::DeviceSize sparseAddressSpaceSize;
    uint32_t maxBoundDescriptorSets;
    uint32_t maxPerStageDescriptorSamplers;
    uint32_t maxPerStageDescriptorUniformBuffers;
    uint32_t maxPerStageDescriptorStorageBuffers;
    uint32_t maxPerStageDescriptorSampledImages;
    uint32_t maxPerStageDescriptorStorageImages;
    uint32_t maxPerStageDescriptorInputAttachments;
    uint32_t maxPerStageResources;
    uint32_t maxDescriptorSetSamplers;
    uint32_t maxDescriptorSetUniformBuffers;
    uint32_t maxDescriptorSetUniformBuffersDynamic;
    uint32_t maxDescriptorSetStorageBuffers;
    uint32_t maxDescriptorSetStorageBuffersDynamic;
    uint32_t maxDescriptorSetSampledImages;
    uint32_t maxDescriptorSetStorageImages;
    uint32_t maxDescriptorSetInputAttachments;
    uint32_t maxVertexInputAttributes;
    uint32_t maxVertexInputBindings;
    uint32_t maxVertexInputAttributeOffset;
    uint32_t maxVertexInputBindingStride;
    uint32_t maxVertexOutputComponents;
    uint32_t maxTessellationGenerationLevel;
    uint32_t maxTessellationPatchSize;
    uint32_t maxTessellationControlPerVertexInputComponents;
    uint32_t maxTessellationControlPerVertexOutputComponents;
    uint32_t maxTessellationControlPerPatchOutputComponents;
    uint32_t maxTessellationControlTotalOutputComponents;
    uint32_t maxTessellationEvaluationInputComponents;
    uint32_t maxTessellationEvaluationOutputComponents;
    uint32_t maxGeometryShaderInvocations;
    uint32_t maxGeometryInputComponents;
    uint32_t maxGeometryOutputComponents;
    uint32_t maxGeometryOutputVertices;
    uint32_t maxGeometryTotalOutputComponents;
    uint32_t maxFragmentInputComponents;
    uint32_t maxFragmentOutputAttachments;
    uint32_t maxFragmentDualSrcAttachments;
    uint32_t maxFragmentCombinedOutputResources;
    uint32_t maxComputeSharedMemorySize;
    uint32_t maxComputeWorkGroupCount[3];
    uint32_t maxComputeWorkGroupInvocations;
    uint32_t maxComputeWorkGroupSize[3];
    uint32_t subPixelPrecisionBits;
    uint32_t subTexelPrecisionBits;
    uint32_t mipmapPrecisionBits;
    uint32_t maxDrawIndexedIndexValue;
    uint32_t maxDrawIndirectCount;
    float maxSamplerLodBias;
    float maxSamplerAnisotropy;
    uint32_t maxViewports;
    uint32_t maxViewportDimensions[2];
    float viewportBoundsRange[2];
    uint32_t viewportSubPixelBits;
    size_t minMemoryMapAlignment;
    vk::DeviceSize minTexelBufferOffsetAlignment;
    vk::DeviceSize minUniformBufferOffsetAlignment;
    vk::DeviceSize minStorageBufferOffsetAlignment;
    int32_t minTexelOffset;
    uint32_t maxTexelOffset;
    int32_t minTexelGatherOffset;
    uint32_t maxTexelGatherOffset;
    float minInterpolationOffset;
    float maxInterpolationOffset;
    uint32_t subPixelInterpolationOffsetBits;
    uint32_t maxFramebufferWidth;
    uint32_t maxFramebufferHeight;
    uint32_t maxFramebufferLayers;
    vk::SampleCountFlags framebufferColorSampleCounts;
    vk::SampleCountFlags framebufferDepthSampleCounts;
    vk::SampleCountFlags framebufferStencilSampleCounts;
    vk::SampleCountFlags framebufferNoAttachmentsSampleCounts;
    uint32_t maxColorAttachments;
    vk::SampleCountFlags sampledImageColorSampleCounts;
    vk::SampleCountFlags sampledImageIntegerSampleCounts;
    vk::SampleCountFlags sampledImageDepthSampleCounts;
    vk::SampleCountFlags sampledImageStencilSampleCounts;
    vk::SampleCountFlags storageImageSampleCounts;
    uint32_t maxSampleMaskWords;
    vk::Bool32 timestampComputeAndGraphics;
    float timestampPeriod;
    uint32_t maxClipDistances;
    uint32_t maxCullDistances;
    uint32_t maxCombinedClipAndCullDistances;
    uint32_t discreteQueuePriorities;
    float pointSizeRange[2];
    float lineWidthRange[2];
    float pointSizeGranularity;
    float lineWidthGranularity;
    vk::Bool32 strictLines;
    vk::Bool32 standardSampleLocations;
    vk::DeviceSize optimalBufferCopyOffsetAlignment;
    vk::DeviceSize optimalBufferCopyRowPitchAlignment;
    vk::DeviceSize nonCoherentAtomSize;
  };
  static_assert( sizeof( PhysicalDeviceLimits ) == sizeof( VkPhysicalDeviceLimits ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceLimits>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceLineRasterizationFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceLineRasterizationFeaturesEXT( vk::Bool32 rectangularLines_ = 0,
                                                                       vk::Bool32 bresenhamLines_ = 0,
                                                                       vk::Bool32 smoothLines_ = 0,
                                                                       vk::Bool32 stippledRectangularLines_ = 0,
                                                                       vk::Bool32 stippledBresenhamLines_ = 0,
                                                                       vk::Bool32 stippledSmoothLines_ = 0 ) VULKAN_HPP_NOEXCEPT
        : rectangularLines( rectangularLines_ )
        , bresenhamLines( bresenhamLines_ )
        , smoothLines( smoothLines_ )
        , stippledRectangularLines( stippledRectangularLines_ )
        , stippledBresenhamLines( stippledBresenhamLines_ )
        , stippledSmoothLines( stippledSmoothLines_ )
      {}

      PhysicalDeviceLineRasterizationFeaturesEXT( VkPhysicalDeviceLineRasterizationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceLineRasterizationFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceLineRasterizationFeaturesEXT& operator=( VkPhysicalDeviceLineRasterizationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceLineRasterizationFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceLineRasterizationFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 rectangularLines;
      vk::Bool32 bresenhamLines;
      vk::Bool32 smoothLines;
      vk::Bool32 stippledRectangularLines;
      vk::Bool32 stippledBresenhamLines;
      vk::Bool32 stippledSmoothLines;
    };
    static_assert( sizeof( PhysicalDeviceLineRasterizationFeaturesEXT ) == sizeof( VkPhysicalDeviceLineRasterizationFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceLineRasterizationFeaturesEXT : public layout::PhysicalDeviceLineRasterizationFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceLineRasterizationFeaturesEXT( vk::Bool32 rectangularLines_ = 0,
                                                                     vk::Bool32 bresenhamLines_ = 0,
                                                                     vk::Bool32 smoothLines_ = 0,
                                                                     vk::Bool32 stippledRectangularLines_ = 0,
                                                                     vk::Bool32 stippledBresenhamLines_ = 0,
                                                                     vk::Bool32 stippledSmoothLines_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceLineRasterizationFeaturesEXT( rectangularLines_, bresenhamLines_, smoothLines_, stippledRectangularLines_, stippledBresenhamLines_, stippledSmoothLines_ )
    {}

    PhysicalDeviceLineRasterizationFeaturesEXT( VkPhysicalDeviceLineRasterizationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceLineRasterizationFeaturesEXT( rhs )
    {}

    PhysicalDeviceLineRasterizationFeaturesEXT& operator=( VkPhysicalDeviceLineRasterizationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceLineRasterizationFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceLineRasterizationFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceLineRasterizationFeaturesEXT & setRectangularLines( vk::Bool32 rectangularLines_ ) VULKAN_HPP_NOEXCEPT
    {
      rectangularLines = rectangularLines_;
      return *this;
    }

    PhysicalDeviceLineRasterizationFeaturesEXT & setBresenhamLines( vk::Bool32 bresenhamLines_ ) VULKAN_HPP_NOEXCEPT
    {
      bresenhamLines = bresenhamLines_;
      return *this;
    }

    PhysicalDeviceLineRasterizationFeaturesEXT & setSmoothLines( vk::Bool32 smoothLines_ ) VULKAN_HPP_NOEXCEPT
    {
      smoothLines = smoothLines_;
      return *this;
    }

    PhysicalDeviceLineRasterizationFeaturesEXT & setStippledRectangularLines( vk::Bool32 stippledRectangularLines_ ) VULKAN_HPP_NOEXCEPT
    {
      stippledRectangularLines = stippledRectangularLines_;
      return *this;
    }

    PhysicalDeviceLineRasterizationFeaturesEXT & setStippledBresenhamLines( vk::Bool32 stippledBresenhamLines_ ) VULKAN_HPP_NOEXCEPT
    {
      stippledBresenhamLines = stippledBresenhamLines_;
      return *this;
    }

    PhysicalDeviceLineRasterizationFeaturesEXT & setStippledSmoothLines( vk::Bool32 stippledSmoothLines_ ) VULKAN_HPP_NOEXCEPT
    {
      stippledSmoothLines = stippledSmoothLines_;
      return *this;
    }

    operator VkPhysicalDeviceLineRasterizationFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceLineRasterizationFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceLineRasterizationFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceLineRasterizationFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceLineRasterizationFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( rectangularLines == rhs.rectangularLines )
          && ( bresenhamLines == rhs.bresenhamLines )
          && ( smoothLines == rhs.smoothLines )
          && ( stippledRectangularLines == rhs.stippledRectangularLines )
          && ( stippledBresenhamLines == rhs.stippledBresenhamLines )
          && ( stippledSmoothLines == rhs.stippledSmoothLines );
    }

    bool operator!=( PhysicalDeviceLineRasterizationFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceLineRasterizationFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceLineRasterizationFeaturesEXT ) == sizeof( VkPhysicalDeviceLineRasterizationFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceLineRasterizationFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceLineRasterizationPropertiesEXT
    {
    protected:
      PhysicalDeviceLineRasterizationPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceLineRasterizationPropertiesEXT( VkPhysicalDeviceLineRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceLineRasterizationPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceLineRasterizationPropertiesEXT& operator=( VkPhysicalDeviceLineRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceLineRasterizationPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceLineRasterizationPropertiesEXT;
      void* pNext = nullptr;
      uint32_t lineSubPixelPrecisionBits;
    };
    static_assert( sizeof( PhysicalDeviceLineRasterizationPropertiesEXT ) == sizeof( VkPhysicalDeviceLineRasterizationPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceLineRasterizationPropertiesEXT : public layout::PhysicalDeviceLineRasterizationPropertiesEXT
  {
    PhysicalDeviceLineRasterizationPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceLineRasterizationPropertiesEXT()
    {}

    PhysicalDeviceLineRasterizationPropertiesEXT( VkPhysicalDeviceLineRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceLineRasterizationPropertiesEXT( rhs )
    {}

    PhysicalDeviceLineRasterizationPropertiesEXT& operator=( VkPhysicalDeviceLineRasterizationPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceLineRasterizationPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceLineRasterizationPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceLineRasterizationPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceLineRasterizationPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceLineRasterizationPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceLineRasterizationPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( lineSubPixelPrecisionBits == rhs.lineSubPixelPrecisionBits );
    }

    bool operator!=( PhysicalDeviceLineRasterizationPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceLineRasterizationPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceLineRasterizationPropertiesEXT ) == sizeof( VkPhysicalDeviceLineRasterizationPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceLineRasterizationPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMaintenance3Properties
    {
    protected:
      PhysicalDeviceMaintenance3Properties() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceMaintenance3Properties( VkPhysicalDeviceMaintenance3Properties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMaintenance3Properties*>(this) = rhs;
      }

      PhysicalDeviceMaintenance3Properties& operator=( VkPhysicalDeviceMaintenance3Properties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMaintenance3Properties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMaintenance3Properties;
      void* pNext = nullptr;
      uint32_t maxPerSetDescriptors;
      vk::DeviceSize maxMemoryAllocationSize;
    };
    static_assert( sizeof( PhysicalDeviceMaintenance3Properties ) == sizeof( VkPhysicalDeviceMaintenance3Properties ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMaintenance3Properties : public layout::PhysicalDeviceMaintenance3Properties
  {
    PhysicalDeviceMaintenance3Properties() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMaintenance3Properties()
    {}

    PhysicalDeviceMaintenance3Properties( VkPhysicalDeviceMaintenance3Properties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMaintenance3Properties( rhs )
    {}

    PhysicalDeviceMaintenance3Properties& operator=( VkPhysicalDeviceMaintenance3Properties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMaintenance3Properties::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceMaintenance3Properties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMaintenance3Properties*>( this );
    }

    operator VkPhysicalDeviceMaintenance3Properties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMaintenance3Properties*>( this );
    }

    bool operator==( PhysicalDeviceMaintenance3Properties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxPerSetDescriptors == rhs.maxPerSetDescriptors )
          && ( maxMemoryAllocationSize == rhs.maxMemoryAllocationSize );
    }

    bool operator!=( PhysicalDeviceMaintenance3Properties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMaintenance3Properties::sType;
  };
  static_assert( sizeof( PhysicalDeviceMaintenance3Properties ) == sizeof( VkPhysicalDeviceMaintenance3Properties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMaintenance3Properties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMemoryBudgetPropertiesEXT
    {
    protected:
      PhysicalDeviceMemoryBudgetPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceMemoryBudgetPropertiesEXT( VkPhysicalDeviceMemoryBudgetPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMemoryBudgetPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceMemoryBudgetPropertiesEXT& operator=( VkPhysicalDeviceMemoryBudgetPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMemoryBudgetPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMemoryBudgetPropertiesEXT;
      void* pNext = nullptr;
      vk::DeviceSize heapBudget[VK_MAX_MEMORY_HEAPS];
      vk::DeviceSize heapUsage[VK_MAX_MEMORY_HEAPS];
    };
    static_assert( sizeof( PhysicalDeviceMemoryBudgetPropertiesEXT ) == sizeof( VkPhysicalDeviceMemoryBudgetPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMemoryBudgetPropertiesEXT : public layout::PhysicalDeviceMemoryBudgetPropertiesEXT
  {
    PhysicalDeviceMemoryBudgetPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMemoryBudgetPropertiesEXT()
    {}

    PhysicalDeviceMemoryBudgetPropertiesEXT( VkPhysicalDeviceMemoryBudgetPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMemoryBudgetPropertiesEXT( rhs )
    {}

    PhysicalDeviceMemoryBudgetPropertiesEXT& operator=( VkPhysicalDeviceMemoryBudgetPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMemoryBudgetPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceMemoryBudgetPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMemoryBudgetPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceMemoryBudgetPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMemoryBudgetPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceMemoryBudgetPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memcmp( heapBudget, rhs.heapBudget, VK_MAX_MEMORY_HEAPS * sizeof( vk::DeviceSize ) ) == 0 )
          && ( memcmp( heapUsage, rhs.heapUsage, VK_MAX_MEMORY_HEAPS * sizeof( vk::DeviceSize ) ) == 0 );
    }

    bool operator!=( PhysicalDeviceMemoryBudgetPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMemoryBudgetPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceMemoryBudgetPropertiesEXT ) == sizeof( VkPhysicalDeviceMemoryBudgetPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMemoryBudgetPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMemoryPriorityFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceMemoryPriorityFeaturesEXT( vk::Bool32 memoryPriority_ = 0 ) VULKAN_HPP_NOEXCEPT
        : memoryPriority( memoryPriority_ )
      {}

      PhysicalDeviceMemoryPriorityFeaturesEXT( VkPhysicalDeviceMemoryPriorityFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMemoryPriorityFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceMemoryPriorityFeaturesEXT& operator=( VkPhysicalDeviceMemoryPriorityFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMemoryPriorityFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMemoryPriorityFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 memoryPriority;
    };
    static_assert( sizeof( PhysicalDeviceMemoryPriorityFeaturesEXT ) == sizeof( VkPhysicalDeviceMemoryPriorityFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMemoryPriorityFeaturesEXT : public layout::PhysicalDeviceMemoryPriorityFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceMemoryPriorityFeaturesEXT( vk::Bool32 memoryPriority_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMemoryPriorityFeaturesEXT( memoryPriority_ )
    {}

    PhysicalDeviceMemoryPriorityFeaturesEXT( VkPhysicalDeviceMemoryPriorityFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMemoryPriorityFeaturesEXT( rhs )
    {}

    PhysicalDeviceMemoryPriorityFeaturesEXT& operator=( VkPhysicalDeviceMemoryPriorityFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMemoryPriorityFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceMemoryPriorityFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceMemoryPriorityFeaturesEXT & setMemoryPriority( vk::Bool32 memoryPriority_ ) VULKAN_HPP_NOEXCEPT
    {
      memoryPriority = memoryPriority_;
      return *this;
    }

    operator VkPhysicalDeviceMemoryPriorityFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMemoryPriorityFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceMemoryPriorityFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMemoryPriorityFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceMemoryPriorityFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memoryPriority == rhs.memoryPriority );
    }

    bool operator!=( PhysicalDeviceMemoryPriorityFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMemoryPriorityFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceMemoryPriorityFeaturesEXT ) == sizeof( VkPhysicalDeviceMemoryPriorityFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMemoryPriorityFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  struct PhysicalDeviceMemoryProperties
  {
    PhysicalDeviceMemoryProperties() VULKAN_HPP_NOEXCEPT
    {}

    PhysicalDeviceMemoryProperties( VkPhysicalDeviceMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceMemoryProperties*>(this) = rhs;
    }

    PhysicalDeviceMemoryProperties& operator=( VkPhysicalDeviceMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceMemoryProperties*>(this) = rhs;
      return *this;
    }

    operator VkPhysicalDeviceMemoryProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMemoryProperties*>( this );
    }

    operator VkPhysicalDeviceMemoryProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMemoryProperties*>( this );
    }

    bool operator==( PhysicalDeviceMemoryProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( memoryTypeCount == rhs.memoryTypeCount )
          && ( memcmp( memoryTypes, rhs.memoryTypes, VK_MAX_MEMORY_TYPES * sizeof( vk::MemoryType ) ) == 0 )
          && ( memoryHeapCount == rhs.memoryHeapCount )
          && ( memcmp( memoryHeaps, rhs.memoryHeaps, VK_MAX_MEMORY_HEAPS * sizeof( vk::MemoryHeap ) ) == 0 );
    }

    bool operator!=( PhysicalDeviceMemoryProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t memoryTypeCount;
    vk::MemoryType memoryTypes[VK_MAX_MEMORY_TYPES];
    uint32_t memoryHeapCount;
    vk::MemoryHeap memoryHeaps[VK_MAX_MEMORY_HEAPS];
  };
  static_assert( sizeof( PhysicalDeviceMemoryProperties ) == sizeof( VkPhysicalDeviceMemoryProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMemoryProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMemoryProperties2
    {
    protected:
      PhysicalDeviceMemoryProperties2() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceMemoryProperties2( VkPhysicalDeviceMemoryProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>(this) = rhs;
      }

      PhysicalDeviceMemoryProperties2& operator=( VkPhysicalDeviceMemoryProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMemoryProperties2;
      void* pNext = nullptr;
      vk::PhysicalDeviceMemoryProperties memoryProperties;
    };
    static_assert( sizeof( PhysicalDeviceMemoryProperties2 ) == sizeof( VkPhysicalDeviceMemoryProperties2 ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMemoryProperties2 : public layout::PhysicalDeviceMemoryProperties2
  {
    PhysicalDeviceMemoryProperties2() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMemoryProperties2()
    {}

    PhysicalDeviceMemoryProperties2( VkPhysicalDeviceMemoryProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMemoryProperties2( rhs )
    {}

    PhysicalDeviceMemoryProperties2& operator=( VkPhysicalDeviceMemoryProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMemoryProperties2::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceMemoryProperties2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMemoryProperties2*>( this );
    }

    operator VkPhysicalDeviceMemoryProperties2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>( this );
    }

    bool operator==( PhysicalDeviceMemoryProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memoryProperties == rhs.memoryProperties );
    }

    bool operator!=( PhysicalDeviceMemoryProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMemoryProperties2::sType;
  };
  static_assert( sizeof( PhysicalDeviceMemoryProperties2 ) == sizeof( VkPhysicalDeviceMemoryProperties2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMemoryProperties2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMeshShaderFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceMeshShaderFeaturesNV( vk::Bool32 taskShader_ = 0,
                                                               vk::Bool32 meshShader_ = 0 ) VULKAN_HPP_NOEXCEPT
        : taskShader( taskShader_ )
        , meshShader( meshShader_ )
      {}

      PhysicalDeviceMeshShaderFeaturesNV( VkPhysicalDeviceMeshShaderFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMeshShaderFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceMeshShaderFeaturesNV& operator=( VkPhysicalDeviceMeshShaderFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMeshShaderFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMeshShaderFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 taskShader;
      vk::Bool32 meshShader;
    };
    static_assert( sizeof( PhysicalDeviceMeshShaderFeaturesNV ) == sizeof( VkPhysicalDeviceMeshShaderFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMeshShaderFeaturesNV : public layout::PhysicalDeviceMeshShaderFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceMeshShaderFeaturesNV( vk::Bool32 taskShader_ = 0,
                                                             vk::Bool32 meshShader_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMeshShaderFeaturesNV( taskShader_, meshShader_ )
    {}

    PhysicalDeviceMeshShaderFeaturesNV( VkPhysicalDeviceMeshShaderFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMeshShaderFeaturesNV( rhs )
    {}

    PhysicalDeviceMeshShaderFeaturesNV& operator=( VkPhysicalDeviceMeshShaderFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMeshShaderFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceMeshShaderFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceMeshShaderFeaturesNV & setTaskShader( vk::Bool32 taskShader_ ) VULKAN_HPP_NOEXCEPT
    {
      taskShader = taskShader_;
      return *this;
    }

    PhysicalDeviceMeshShaderFeaturesNV & setMeshShader( vk::Bool32 meshShader_ ) VULKAN_HPP_NOEXCEPT
    {
      meshShader = meshShader_;
      return *this;
    }

    operator VkPhysicalDeviceMeshShaderFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMeshShaderFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceMeshShaderFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMeshShaderFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceMeshShaderFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( taskShader == rhs.taskShader )
          && ( meshShader == rhs.meshShader );
    }

    bool operator!=( PhysicalDeviceMeshShaderFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMeshShaderFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceMeshShaderFeaturesNV ) == sizeof( VkPhysicalDeviceMeshShaderFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMeshShaderFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMeshShaderPropertiesNV
    {
    protected:
      PhysicalDeviceMeshShaderPropertiesNV() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceMeshShaderPropertiesNV( VkPhysicalDeviceMeshShaderPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMeshShaderPropertiesNV*>(this) = rhs;
      }

      PhysicalDeviceMeshShaderPropertiesNV& operator=( VkPhysicalDeviceMeshShaderPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMeshShaderPropertiesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMeshShaderPropertiesNV;
      void* pNext = nullptr;
      uint32_t maxDrawMeshTasksCount;
      uint32_t maxTaskWorkGroupInvocations;
      uint32_t maxTaskWorkGroupSize[3];
      uint32_t maxTaskTotalMemorySize;
      uint32_t maxTaskOutputCount;
      uint32_t maxMeshWorkGroupInvocations;
      uint32_t maxMeshWorkGroupSize[3];
      uint32_t maxMeshTotalMemorySize;
      uint32_t maxMeshOutputVertices;
      uint32_t maxMeshOutputPrimitives;
      uint32_t maxMeshMultiviewViewCount;
      uint32_t meshOutputPerVertexGranularity;
      uint32_t meshOutputPerPrimitiveGranularity;
    };
    static_assert( sizeof( PhysicalDeviceMeshShaderPropertiesNV ) == sizeof( VkPhysicalDeviceMeshShaderPropertiesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMeshShaderPropertiesNV : public layout::PhysicalDeviceMeshShaderPropertiesNV
  {
    PhysicalDeviceMeshShaderPropertiesNV() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMeshShaderPropertiesNV()
    {}

    PhysicalDeviceMeshShaderPropertiesNV( VkPhysicalDeviceMeshShaderPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMeshShaderPropertiesNV( rhs )
    {}

    PhysicalDeviceMeshShaderPropertiesNV& operator=( VkPhysicalDeviceMeshShaderPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMeshShaderPropertiesNV::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceMeshShaderPropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMeshShaderPropertiesNV*>( this );
    }

    operator VkPhysicalDeviceMeshShaderPropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMeshShaderPropertiesNV*>( this );
    }

    bool operator==( PhysicalDeviceMeshShaderPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxDrawMeshTasksCount == rhs.maxDrawMeshTasksCount )
          && ( maxTaskWorkGroupInvocations == rhs.maxTaskWorkGroupInvocations )
          && ( memcmp( maxTaskWorkGroupSize, rhs.maxTaskWorkGroupSize, 3 * sizeof( uint32_t ) ) == 0 )
          && ( maxTaskTotalMemorySize == rhs.maxTaskTotalMemorySize )
          && ( maxTaskOutputCount == rhs.maxTaskOutputCount )
          && ( maxMeshWorkGroupInvocations == rhs.maxMeshWorkGroupInvocations )
          && ( memcmp( maxMeshWorkGroupSize, rhs.maxMeshWorkGroupSize, 3 * sizeof( uint32_t ) ) == 0 )
          && ( maxMeshTotalMemorySize == rhs.maxMeshTotalMemorySize )
          && ( maxMeshOutputVertices == rhs.maxMeshOutputVertices )
          && ( maxMeshOutputPrimitives == rhs.maxMeshOutputPrimitives )
          && ( maxMeshMultiviewViewCount == rhs.maxMeshMultiviewViewCount )
          && ( meshOutputPerVertexGranularity == rhs.meshOutputPerVertexGranularity )
          && ( meshOutputPerPrimitiveGranularity == rhs.meshOutputPerPrimitiveGranularity );
    }

    bool operator!=( PhysicalDeviceMeshShaderPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMeshShaderPropertiesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceMeshShaderPropertiesNV ) == sizeof( VkPhysicalDeviceMeshShaderPropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMeshShaderPropertiesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMultiviewFeatures
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceMultiviewFeatures( vk::Bool32 multiview_ = 0,
                                                            vk::Bool32 multiviewGeometryShader_ = 0,
                                                            vk::Bool32 multiviewTessellationShader_ = 0 ) VULKAN_HPP_NOEXCEPT
        : multiview( multiview_ )
        , multiviewGeometryShader( multiviewGeometryShader_ )
        , multiviewTessellationShader( multiviewTessellationShader_ )
      {}

      PhysicalDeviceMultiviewFeatures( VkPhysicalDeviceMultiviewFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMultiviewFeatures*>(this) = rhs;
      }

      PhysicalDeviceMultiviewFeatures& operator=( VkPhysicalDeviceMultiviewFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMultiviewFeatures*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMultiviewFeatures;
      void* pNext = nullptr;
      vk::Bool32 multiview;
      vk::Bool32 multiviewGeometryShader;
      vk::Bool32 multiviewTessellationShader;
    };
    static_assert( sizeof( PhysicalDeviceMultiviewFeatures ) == sizeof( VkPhysicalDeviceMultiviewFeatures ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMultiviewFeatures : public layout::PhysicalDeviceMultiviewFeatures
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceMultiviewFeatures( vk::Bool32 multiview_ = 0,
                                                          vk::Bool32 multiviewGeometryShader_ = 0,
                                                          vk::Bool32 multiviewTessellationShader_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMultiviewFeatures( multiview_, multiviewGeometryShader_, multiviewTessellationShader_ )
    {}

    PhysicalDeviceMultiviewFeatures( VkPhysicalDeviceMultiviewFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMultiviewFeatures( rhs )
    {}

    PhysicalDeviceMultiviewFeatures& operator=( VkPhysicalDeviceMultiviewFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMultiviewFeatures::operator=(rhs);
      return *this;
    }

    PhysicalDeviceMultiviewFeatures & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceMultiviewFeatures & setMultiview( vk::Bool32 multiview_ ) VULKAN_HPP_NOEXCEPT
    {
      multiview = multiview_;
      return *this;
    }

    PhysicalDeviceMultiviewFeatures & setMultiviewGeometryShader( vk::Bool32 multiviewGeometryShader_ ) VULKAN_HPP_NOEXCEPT
    {
      multiviewGeometryShader = multiviewGeometryShader_;
      return *this;
    }

    PhysicalDeviceMultiviewFeatures & setMultiviewTessellationShader( vk::Bool32 multiviewTessellationShader_ ) VULKAN_HPP_NOEXCEPT
    {
      multiviewTessellationShader = multiviewTessellationShader_;
      return *this;
    }

    operator VkPhysicalDeviceMultiviewFeatures const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMultiviewFeatures*>( this );
    }

    operator VkPhysicalDeviceMultiviewFeatures &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMultiviewFeatures*>( this );
    }

    bool operator==( PhysicalDeviceMultiviewFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( multiview == rhs.multiview )
          && ( multiviewGeometryShader == rhs.multiviewGeometryShader )
          && ( multiviewTessellationShader == rhs.multiviewTessellationShader );
    }

    bool operator!=( PhysicalDeviceMultiviewFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMultiviewFeatures::sType;
  };
  static_assert( sizeof( PhysicalDeviceMultiviewFeatures ) == sizeof( VkPhysicalDeviceMultiviewFeatures ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMultiviewFeatures>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX
    {
    protected:
      PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX( VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX*>(this) = rhs;
      }

      PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX& operator=( VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMultiviewPerViewAttributesPropertiesNVX;
      void* pNext = nullptr;
      vk::Bool32 perViewPositionAllComponents;
    };
    static_assert( sizeof( PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX ) == sizeof( VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX : public layout::PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX
  {
    PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX()
    {}

    PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX( VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX( rhs )
    {}

    PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX& operator=( VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX*>( this );
    }

    operator VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX*>( this );
    }

    bool operator==( PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( perViewPositionAllComponents == rhs.perViewPositionAllComponents );
    }

    bool operator!=( PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX::sType;
  };
  static_assert( sizeof( PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX ) == sizeof( VkPhysicalDeviceMultiviewPerViewAttributesPropertiesNVX ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceMultiviewProperties
    {
    protected:
      PhysicalDeviceMultiviewProperties() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceMultiviewProperties( VkPhysicalDeviceMultiviewProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMultiviewProperties*>(this) = rhs;
      }

      PhysicalDeviceMultiviewProperties& operator=( VkPhysicalDeviceMultiviewProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceMultiviewProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceMultiviewProperties;
      void* pNext = nullptr;
      uint32_t maxMultiviewViewCount;
      uint32_t maxMultiviewInstanceIndex;
    };
    static_assert( sizeof( PhysicalDeviceMultiviewProperties ) == sizeof( VkPhysicalDeviceMultiviewProperties ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceMultiviewProperties : public layout::PhysicalDeviceMultiviewProperties
  {
    PhysicalDeviceMultiviewProperties() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMultiviewProperties()
    {}

    PhysicalDeviceMultiviewProperties( VkPhysicalDeviceMultiviewProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceMultiviewProperties( rhs )
    {}

    PhysicalDeviceMultiviewProperties& operator=( VkPhysicalDeviceMultiviewProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceMultiviewProperties::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceMultiviewProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceMultiviewProperties*>( this );
    }

    operator VkPhysicalDeviceMultiviewProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceMultiviewProperties*>( this );
    }

    bool operator==( PhysicalDeviceMultiviewProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxMultiviewViewCount == rhs.maxMultiviewViewCount )
          && ( maxMultiviewInstanceIndex == rhs.maxMultiviewInstanceIndex );
    }

    bool operator!=( PhysicalDeviceMultiviewProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceMultiviewProperties::sType;
  };
  static_assert( sizeof( PhysicalDeviceMultiviewProperties ) == sizeof( VkPhysicalDeviceMultiviewProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceMultiviewProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDevicePCIBusInfoPropertiesEXT
    {
    protected:
      PhysicalDevicePCIBusInfoPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDevicePCIBusInfoPropertiesEXT( VkPhysicalDevicePCIBusInfoPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePCIBusInfoPropertiesEXT*>(this) = rhs;
      }

      PhysicalDevicePCIBusInfoPropertiesEXT& operator=( VkPhysicalDevicePCIBusInfoPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePCIBusInfoPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDevicePciBusInfoPropertiesEXT;
      void* pNext = nullptr;
      uint32_t pciDomain;
      uint32_t pciBus;
      uint32_t pciDevice;
      uint32_t pciFunction;
    };
    static_assert( sizeof( PhysicalDevicePCIBusInfoPropertiesEXT ) == sizeof( VkPhysicalDevicePCIBusInfoPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDevicePCIBusInfoPropertiesEXT : public layout::PhysicalDevicePCIBusInfoPropertiesEXT
  {
    PhysicalDevicePCIBusInfoPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePCIBusInfoPropertiesEXT()
    {}

    PhysicalDevicePCIBusInfoPropertiesEXT( VkPhysicalDevicePCIBusInfoPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePCIBusInfoPropertiesEXT( rhs )
    {}

    PhysicalDevicePCIBusInfoPropertiesEXT& operator=( VkPhysicalDevicePCIBusInfoPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDevicePCIBusInfoPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDevicePCIBusInfoPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDevicePCIBusInfoPropertiesEXT*>( this );
    }

    operator VkPhysicalDevicePCIBusInfoPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDevicePCIBusInfoPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDevicePCIBusInfoPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pciDomain == rhs.pciDomain )
          && ( pciBus == rhs.pciBus )
          && ( pciDevice == rhs.pciDevice )
          && ( pciFunction == rhs.pciFunction );
    }

    bool operator!=( PhysicalDevicePCIBusInfoPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDevicePCIBusInfoPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDevicePCIBusInfoPropertiesEXT ) == sizeof( VkPhysicalDevicePCIBusInfoPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDevicePCIBusInfoPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDevicePipelineExecutablePropertiesFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDevicePipelineExecutablePropertiesFeaturesKHR( vk::Bool32 pipelineExecutableInfo_ = 0 ) VULKAN_HPP_NOEXCEPT
        : pipelineExecutableInfo( pipelineExecutableInfo_ )
      {}

      PhysicalDevicePipelineExecutablePropertiesFeaturesKHR( VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR*>(this) = rhs;
      }

      PhysicalDevicePipelineExecutablePropertiesFeaturesKHR& operator=( VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDevicePipelineExecutablePropertiesFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 pipelineExecutableInfo;
    };
    static_assert( sizeof( PhysicalDevicePipelineExecutablePropertiesFeaturesKHR ) == sizeof( VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDevicePipelineExecutablePropertiesFeaturesKHR : public layout::PhysicalDevicePipelineExecutablePropertiesFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDevicePipelineExecutablePropertiesFeaturesKHR( vk::Bool32 pipelineExecutableInfo_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePipelineExecutablePropertiesFeaturesKHR( pipelineExecutableInfo_ )
    {}

    PhysicalDevicePipelineExecutablePropertiesFeaturesKHR( VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePipelineExecutablePropertiesFeaturesKHR( rhs )
    {}

    PhysicalDevicePipelineExecutablePropertiesFeaturesKHR& operator=( VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDevicePipelineExecutablePropertiesFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDevicePipelineExecutablePropertiesFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDevicePipelineExecutablePropertiesFeaturesKHR & setPipelineExecutableInfo( vk::Bool32 pipelineExecutableInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineExecutableInfo = pipelineExecutableInfo_;
      return *this;
    }

    operator VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR*>( this );
    }

    operator VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDevicePipelineExecutablePropertiesFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pipelineExecutableInfo == rhs.pipelineExecutableInfo );
    }

    bool operator!=( PhysicalDevicePipelineExecutablePropertiesFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDevicePipelineExecutablePropertiesFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDevicePipelineExecutablePropertiesFeaturesKHR ) == sizeof( VkPhysicalDevicePipelineExecutablePropertiesFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDevicePipelineExecutablePropertiesFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDevicePointClippingProperties
    {
    protected:
      PhysicalDevicePointClippingProperties() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDevicePointClippingProperties( VkPhysicalDevicePointClippingProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePointClippingProperties*>(this) = rhs;
      }

      PhysicalDevicePointClippingProperties& operator=( VkPhysicalDevicePointClippingProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePointClippingProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDevicePointClippingProperties;
      void* pNext = nullptr;
      vk::PointClippingBehavior pointClippingBehavior;
    };
    static_assert( sizeof( PhysicalDevicePointClippingProperties ) == sizeof( VkPhysicalDevicePointClippingProperties ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDevicePointClippingProperties : public layout::PhysicalDevicePointClippingProperties
  {
    PhysicalDevicePointClippingProperties() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePointClippingProperties()
    {}

    PhysicalDevicePointClippingProperties( VkPhysicalDevicePointClippingProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePointClippingProperties( rhs )
    {}

    PhysicalDevicePointClippingProperties& operator=( VkPhysicalDevicePointClippingProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDevicePointClippingProperties::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDevicePointClippingProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDevicePointClippingProperties*>( this );
    }

    operator VkPhysicalDevicePointClippingProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDevicePointClippingProperties*>( this );
    }

    bool operator==( PhysicalDevicePointClippingProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pointClippingBehavior == rhs.pointClippingBehavior );
    }

    bool operator!=( PhysicalDevicePointClippingProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDevicePointClippingProperties::sType;
  };
  static_assert( sizeof( PhysicalDevicePointClippingProperties ) == sizeof( VkPhysicalDevicePointClippingProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDevicePointClippingProperties>::value, "struct wrapper is not a standard layout!" );

  struct PhysicalDeviceSparseProperties
  {
    PhysicalDeviceSparseProperties() VULKAN_HPP_NOEXCEPT
    {}

    PhysicalDeviceSparseProperties( VkPhysicalDeviceSparseProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceSparseProperties*>(this) = rhs;
    }

    PhysicalDeviceSparseProperties& operator=( VkPhysicalDeviceSparseProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceSparseProperties*>(this) = rhs;
      return *this;
    }

    operator VkPhysicalDeviceSparseProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSparseProperties*>( this );
    }

    operator VkPhysicalDeviceSparseProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSparseProperties*>( this );
    }

    bool operator==( PhysicalDeviceSparseProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( residencyStandard2DBlockShape == rhs.residencyStandard2DBlockShape )
          && ( residencyStandard2DMultisampleBlockShape == rhs.residencyStandard2DMultisampleBlockShape )
          && ( residencyStandard3DBlockShape == rhs.residencyStandard3DBlockShape )
          && ( residencyAlignedMipSize == rhs.residencyAlignedMipSize )
          && ( residencyNonResidentStrict == rhs.residencyNonResidentStrict );
    }

    bool operator!=( PhysicalDeviceSparseProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Bool32 residencyStandard2DBlockShape;
    vk::Bool32 residencyStandard2DMultisampleBlockShape;
    vk::Bool32 residencyStandard3DBlockShape;
    vk::Bool32 residencyAlignedMipSize;
    vk::Bool32 residencyNonResidentStrict;
  };
  static_assert( sizeof( PhysicalDeviceSparseProperties ) == sizeof( VkPhysicalDeviceSparseProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSparseProperties>::value, "struct wrapper is not a standard layout!" );

  struct PhysicalDeviceProperties
  {
    PhysicalDeviceProperties() VULKAN_HPP_NOEXCEPT
    {}

    PhysicalDeviceProperties( VkPhysicalDeviceProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceProperties*>(this) = rhs;
    }

    PhysicalDeviceProperties& operator=( VkPhysicalDeviceProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPhysicalDeviceProperties*>(this) = rhs;
      return *this;
    }

    operator VkPhysicalDeviceProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceProperties*>( this );
    }

    operator VkPhysicalDeviceProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceProperties*>( this );
    }

    bool operator==( PhysicalDeviceProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( apiVersion == rhs.apiVersion )
          && ( driverVersion == rhs.driverVersion )
          && ( vendorID == rhs.vendorID )
          && ( deviceID == rhs.deviceID )
          && ( deviceType == rhs.deviceType )
          && ( memcmp( deviceName, rhs.deviceName, VK_MAX_PHYSICAL_DEVICE_NAME_SIZE * sizeof( char ) ) == 0 )
          && ( memcmp( pipelineCacheUUID, rhs.pipelineCacheUUID, VK_UUID_SIZE * sizeof( uint8_t ) ) == 0 )
          && ( limits == rhs.limits )
          && ( sparseProperties == rhs.sparseProperties );
    }

    bool operator!=( PhysicalDeviceProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t apiVersion;
    uint32_t driverVersion;
    uint32_t vendorID;
    uint32_t deviceID;
    vk::PhysicalDeviceType deviceType;
    char deviceName[VK_MAX_PHYSICAL_DEVICE_NAME_SIZE];
    uint8_t pipelineCacheUUID[VK_UUID_SIZE];
    vk::PhysicalDeviceLimits limits;
    vk::PhysicalDeviceSparseProperties sparseProperties;
  };
  static_assert( sizeof( PhysicalDeviceProperties ) == sizeof( VkPhysicalDeviceProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceProperties2
    {
    protected:
      PhysicalDeviceProperties2() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceProperties2( VkPhysicalDeviceProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceProperties2*>(this) = rhs;
      }

      PhysicalDeviceProperties2& operator=( VkPhysicalDeviceProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceProperties2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceProperties2;
      void* pNext = nullptr;
      vk::PhysicalDeviceProperties properties;
    };
    static_assert( sizeof( PhysicalDeviceProperties2 ) == sizeof( VkPhysicalDeviceProperties2 ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceProperties2 : public layout::PhysicalDeviceProperties2
  {
    PhysicalDeviceProperties2() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceProperties2()
    {}

    PhysicalDeviceProperties2( VkPhysicalDeviceProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceProperties2( rhs )
    {}

    PhysicalDeviceProperties2& operator=( VkPhysicalDeviceProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceProperties2::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceProperties2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceProperties2*>( this );
    }

    operator VkPhysicalDeviceProperties2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceProperties2*>( this );
    }

    bool operator==( PhysicalDeviceProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( properties == rhs.properties );
    }

    bool operator!=( PhysicalDeviceProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceProperties2::sType;
  };
  static_assert( sizeof( PhysicalDeviceProperties2 ) == sizeof( VkPhysicalDeviceProperties2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceProperties2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceProtectedMemoryFeatures
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceProtectedMemoryFeatures( vk::Bool32 protectedMemory_ = 0 ) VULKAN_HPP_NOEXCEPT
        : protectedMemory( protectedMemory_ )
      {}

      PhysicalDeviceProtectedMemoryFeatures( VkPhysicalDeviceProtectedMemoryFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceProtectedMemoryFeatures*>(this) = rhs;
      }

      PhysicalDeviceProtectedMemoryFeatures& operator=( VkPhysicalDeviceProtectedMemoryFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceProtectedMemoryFeatures*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceProtectedMemoryFeatures;
      void* pNext = nullptr;
      vk::Bool32 protectedMemory;
    };
    static_assert( sizeof( PhysicalDeviceProtectedMemoryFeatures ) == sizeof( VkPhysicalDeviceProtectedMemoryFeatures ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceProtectedMemoryFeatures : public layout::PhysicalDeviceProtectedMemoryFeatures
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceProtectedMemoryFeatures( vk::Bool32 protectedMemory_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceProtectedMemoryFeatures( protectedMemory_ )
    {}

    PhysicalDeviceProtectedMemoryFeatures( VkPhysicalDeviceProtectedMemoryFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceProtectedMemoryFeatures( rhs )
    {}

    PhysicalDeviceProtectedMemoryFeatures& operator=( VkPhysicalDeviceProtectedMemoryFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceProtectedMemoryFeatures::operator=(rhs);
      return *this;
    }

    PhysicalDeviceProtectedMemoryFeatures & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceProtectedMemoryFeatures & setProtectedMemory( vk::Bool32 protectedMemory_ ) VULKAN_HPP_NOEXCEPT
    {
      protectedMemory = protectedMemory_;
      return *this;
    }

    operator VkPhysicalDeviceProtectedMemoryFeatures const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceProtectedMemoryFeatures*>( this );
    }

    operator VkPhysicalDeviceProtectedMemoryFeatures &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceProtectedMemoryFeatures*>( this );
    }

    bool operator==( PhysicalDeviceProtectedMemoryFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( protectedMemory == rhs.protectedMemory );
    }

    bool operator!=( PhysicalDeviceProtectedMemoryFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceProtectedMemoryFeatures::sType;
  };
  static_assert( sizeof( PhysicalDeviceProtectedMemoryFeatures ) == sizeof( VkPhysicalDeviceProtectedMemoryFeatures ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceProtectedMemoryFeatures>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceProtectedMemoryProperties
    {
    protected:
      PhysicalDeviceProtectedMemoryProperties() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceProtectedMemoryProperties( VkPhysicalDeviceProtectedMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceProtectedMemoryProperties*>(this) = rhs;
      }

      PhysicalDeviceProtectedMemoryProperties& operator=( VkPhysicalDeviceProtectedMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceProtectedMemoryProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceProtectedMemoryProperties;
      void* pNext = nullptr;
      vk::Bool32 protectedNoFault;
    };
    static_assert( sizeof( PhysicalDeviceProtectedMemoryProperties ) == sizeof( VkPhysicalDeviceProtectedMemoryProperties ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceProtectedMemoryProperties : public layout::PhysicalDeviceProtectedMemoryProperties
  {
    PhysicalDeviceProtectedMemoryProperties() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceProtectedMemoryProperties()
    {}

    PhysicalDeviceProtectedMemoryProperties( VkPhysicalDeviceProtectedMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceProtectedMemoryProperties( rhs )
    {}

    PhysicalDeviceProtectedMemoryProperties& operator=( VkPhysicalDeviceProtectedMemoryProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceProtectedMemoryProperties::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceProtectedMemoryProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceProtectedMemoryProperties*>( this );
    }

    operator VkPhysicalDeviceProtectedMemoryProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceProtectedMemoryProperties*>( this );
    }

    bool operator==( PhysicalDeviceProtectedMemoryProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( protectedNoFault == rhs.protectedNoFault );
    }

    bool operator!=( PhysicalDeviceProtectedMemoryProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceProtectedMemoryProperties::sType;
  };
  static_assert( sizeof( PhysicalDeviceProtectedMemoryProperties ) == sizeof( VkPhysicalDeviceProtectedMemoryProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceProtectedMemoryProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDevicePushDescriptorPropertiesKHR
    {
    protected:
      PhysicalDevicePushDescriptorPropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDevicePushDescriptorPropertiesKHR( VkPhysicalDevicePushDescriptorPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePushDescriptorPropertiesKHR*>(this) = rhs;
      }

      PhysicalDevicePushDescriptorPropertiesKHR& operator=( VkPhysicalDevicePushDescriptorPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDevicePushDescriptorPropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDevicePushDescriptorPropertiesKHR;
      void* pNext = nullptr;
      uint32_t maxPushDescriptors;
    };
    static_assert( sizeof( PhysicalDevicePushDescriptorPropertiesKHR ) == sizeof( VkPhysicalDevicePushDescriptorPropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDevicePushDescriptorPropertiesKHR : public layout::PhysicalDevicePushDescriptorPropertiesKHR
  {
    PhysicalDevicePushDescriptorPropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePushDescriptorPropertiesKHR()
    {}

    PhysicalDevicePushDescriptorPropertiesKHR( VkPhysicalDevicePushDescriptorPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDevicePushDescriptorPropertiesKHR( rhs )
    {}

    PhysicalDevicePushDescriptorPropertiesKHR& operator=( VkPhysicalDevicePushDescriptorPropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDevicePushDescriptorPropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDevicePushDescriptorPropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDevicePushDescriptorPropertiesKHR*>( this );
    }

    operator VkPhysicalDevicePushDescriptorPropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDevicePushDescriptorPropertiesKHR*>( this );
    }

    bool operator==( PhysicalDevicePushDescriptorPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxPushDescriptors == rhs.maxPushDescriptors );
    }

    bool operator!=( PhysicalDevicePushDescriptorPropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDevicePushDescriptorPropertiesKHR::sType;
  };
  static_assert( sizeof( PhysicalDevicePushDescriptorPropertiesKHR ) == sizeof( VkPhysicalDevicePushDescriptorPropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDevicePushDescriptorPropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceRayTracingPropertiesNV
    {
    protected:
      PhysicalDeviceRayTracingPropertiesNV() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceRayTracingPropertiesNV( VkPhysicalDeviceRayTracingPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceRayTracingPropertiesNV*>(this) = rhs;
      }

      PhysicalDeviceRayTracingPropertiesNV& operator=( VkPhysicalDeviceRayTracingPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceRayTracingPropertiesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceRayTracingPropertiesNV;
      void* pNext = nullptr;
      uint32_t shaderGroupHandleSize;
      uint32_t maxRecursionDepth;
      uint32_t maxShaderGroupStride;
      uint32_t shaderGroupBaseAlignment;
      uint64_t maxGeometryCount;
      uint64_t maxInstanceCount;
      uint64_t maxTriangleCount;
      uint32_t maxDescriptorSetAccelerationStructures;
    };
    static_assert( sizeof( PhysicalDeviceRayTracingPropertiesNV ) == sizeof( VkPhysicalDeviceRayTracingPropertiesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceRayTracingPropertiesNV : public layout::PhysicalDeviceRayTracingPropertiesNV
  {
    PhysicalDeviceRayTracingPropertiesNV() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceRayTracingPropertiesNV()
    {}

    PhysicalDeviceRayTracingPropertiesNV( VkPhysicalDeviceRayTracingPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceRayTracingPropertiesNV( rhs )
    {}

    PhysicalDeviceRayTracingPropertiesNV& operator=( VkPhysicalDeviceRayTracingPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceRayTracingPropertiesNV::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceRayTracingPropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceRayTracingPropertiesNV*>( this );
    }

    operator VkPhysicalDeviceRayTracingPropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceRayTracingPropertiesNV*>( this );
    }

    bool operator==( PhysicalDeviceRayTracingPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderGroupHandleSize == rhs.shaderGroupHandleSize )
          && ( maxRecursionDepth == rhs.maxRecursionDepth )
          && ( maxShaderGroupStride == rhs.maxShaderGroupStride )
          && ( shaderGroupBaseAlignment == rhs.shaderGroupBaseAlignment )
          && ( maxGeometryCount == rhs.maxGeometryCount )
          && ( maxInstanceCount == rhs.maxInstanceCount )
          && ( maxTriangleCount == rhs.maxTriangleCount )
          && ( maxDescriptorSetAccelerationStructures == rhs.maxDescriptorSetAccelerationStructures );
    }

    bool operator!=( PhysicalDeviceRayTracingPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceRayTracingPropertiesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceRayTracingPropertiesNV ) == sizeof( VkPhysicalDeviceRayTracingPropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceRayTracingPropertiesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceRepresentativeFragmentTestFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceRepresentativeFragmentTestFeaturesNV( vk::Bool32 representativeFragmentTest_ = 0 ) VULKAN_HPP_NOEXCEPT
        : representativeFragmentTest( representativeFragmentTest_ )
      {}

      PhysicalDeviceRepresentativeFragmentTestFeaturesNV( VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceRepresentativeFragmentTestFeaturesNV& operator=( VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceRepresentativeFragmentTestFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 representativeFragmentTest;
    };
    static_assert( sizeof( PhysicalDeviceRepresentativeFragmentTestFeaturesNV ) == sizeof( VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceRepresentativeFragmentTestFeaturesNV : public layout::PhysicalDeviceRepresentativeFragmentTestFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceRepresentativeFragmentTestFeaturesNV( vk::Bool32 representativeFragmentTest_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceRepresentativeFragmentTestFeaturesNV( representativeFragmentTest_ )
    {}

    PhysicalDeviceRepresentativeFragmentTestFeaturesNV( VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceRepresentativeFragmentTestFeaturesNV( rhs )
    {}

    PhysicalDeviceRepresentativeFragmentTestFeaturesNV& operator=( VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceRepresentativeFragmentTestFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceRepresentativeFragmentTestFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceRepresentativeFragmentTestFeaturesNV & setRepresentativeFragmentTest( vk::Bool32 representativeFragmentTest_ ) VULKAN_HPP_NOEXCEPT
    {
      representativeFragmentTest = representativeFragmentTest_;
      return *this;
    }

    operator VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceRepresentativeFragmentTestFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( representativeFragmentTest == rhs.representativeFragmentTest );
    }

    bool operator!=( PhysicalDeviceRepresentativeFragmentTestFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceRepresentativeFragmentTestFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceRepresentativeFragmentTestFeaturesNV ) == sizeof( VkPhysicalDeviceRepresentativeFragmentTestFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceRepresentativeFragmentTestFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSampleLocationsPropertiesEXT
    {
    protected:
      PhysicalDeviceSampleLocationsPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceSampleLocationsPropertiesEXT( VkPhysicalDeviceSampleLocationsPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSampleLocationsPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceSampleLocationsPropertiesEXT& operator=( VkPhysicalDeviceSampleLocationsPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSampleLocationsPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSampleLocationsPropertiesEXT;
      void* pNext = nullptr;
      vk::SampleCountFlags sampleLocationSampleCounts;
      vk::Extent2D maxSampleLocationGridSize;
      float sampleLocationCoordinateRange[2];
      uint32_t sampleLocationSubPixelBits;
      vk::Bool32 variableSampleLocations;
    };
    static_assert( sizeof( PhysicalDeviceSampleLocationsPropertiesEXT ) == sizeof( VkPhysicalDeviceSampleLocationsPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSampleLocationsPropertiesEXT : public layout::PhysicalDeviceSampleLocationsPropertiesEXT
  {
    PhysicalDeviceSampleLocationsPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSampleLocationsPropertiesEXT()
    {}

    PhysicalDeviceSampleLocationsPropertiesEXT( VkPhysicalDeviceSampleLocationsPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSampleLocationsPropertiesEXT( rhs )
    {}

    PhysicalDeviceSampleLocationsPropertiesEXT& operator=( VkPhysicalDeviceSampleLocationsPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSampleLocationsPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceSampleLocationsPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSampleLocationsPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceSampleLocationsPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSampleLocationsPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceSampleLocationsPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( sampleLocationSampleCounts == rhs.sampleLocationSampleCounts )
          && ( maxSampleLocationGridSize == rhs.maxSampleLocationGridSize )
          && ( memcmp( sampleLocationCoordinateRange, rhs.sampleLocationCoordinateRange, 2 * sizeof( float ) ) == 0 )
          && ( sampleLocationSubPixelBits == rhs.sampleLocationSubPixelBits )
          && ( variableSampleLocations == rhs.variableSampleLocations );
    }

    bool operator!=( PhysicalDeviceSampleLocationsPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSampleLocationsPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceSampleLocationsPropertiesEXT ) == sizeof( VkPhysicalDeviceSampleLocationsPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSampleLocationsPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSamplerFilterMinmaxPropertiesEXT
    {
    protected:
      PhysicalDeviceSamplerFilterMinmaxPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceSamplerFilterMinmaxPropertiesEXT( VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceSamplerFilterMinmaxPropertiesEXT& operator=( VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSamplerFilterMinmaxPropertiesEXT;
      void* pNext = nullptr;
      vk::Bool32 filterMinmaxSingleComponentFormats;
      vk::Bool32 filterMinmaxImageComponentMapping;
    };
    static_assert( sizeof( PhysicalDeviceSamplerFilterMinmaxPropertiesEXT ) == sizeof( VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSamplerFilterMinmaxPropertiesEXT : public layout::PhysicalDeviceSamplerFilterMinmaxPropertiesEXT
  {
    PhysicalDeviceSamplerFilterMinmaxPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSamplerFilterMinmaxPropertiesEXT()
    {}

    PhysicalDeviceSamplerFilterMinmaxPropertiesEXT( VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSamplerFilterMinmaxPropertiesEXT( rhs )
    {}

    PhysicalDeviceSamplerFilterMinmaxPropertiesEXT& operator=( VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSamplerFilterMinmaxPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceSamplerFilterMinmaxPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( filterMinmaxSingleComponentFormats == rhs.filterMinmaxSingleComponentFormats )
          && ( filterMinmaxImageComponentMapping == rhs.filterMinmaxImageComponentMapping );
    }

    bool operator!=( PhysicalDeviceSamplerFilterMinmaxPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSamplerFilterMinmaxPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceSamplerFilterMinmaxPropertiesEXT ) == sizeof( VkPhysicalDeviceSamplerFilterMinmaxPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSamplerFilterMinmaxPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSamplerYcbcrConversionFeatures
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceSamplerYcbcrConversionFeatures( vk::Bool32 samplerYcbcrConversion_ = 0 ) VULKAN_HPP_NOEXCEPT
        : samplerYcbcrConversion( samplerYcbcrConversion_ )
      {}

      PhysicalDeviceSamplerYcbcrConversionFeatures( VkPhysicalDeviceSamplerYcbcrConversionFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSamplerYcbcrConversionFeatures*>(this) = rhs;
      }

      PhysicalDeviceSamplerYcbcrConversionFeatures& operator=( VkPhysicalDeviceSamplerYcbcrConversionFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSamplerYcbcrConversionFeatures*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSamplerYcbcrConversionFeatures;
      void* pNext = nullptr;
      vk::Bool32 samplerYcbcrConversion;
    };
    static_assert( sizeof( PhysicalDeviceSamplerYcbcrConversionFeatures ) == sizeof( VkPhysicalDeviceSamplerYcbcrConversionFeatures ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSamplerYcbcrConversionFeatures : public layout::PhysicalDeviceSamplerYcbcrConversionFeatures
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceSamplerYcbcrConversionFeatures( vk::Bool32 samplerYcbcrConversion_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSamplerYcbcrConversionFeatures( samplerYcbcrConversion_ )
    {}

    PhysicalDeviceSamplerYcbcrConversionFeatures( VkPhysicalDeviceSamplerYcbcrConversionFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSamplerYcbcrConversionFeatures( rhs )
    {}

    PhysicalDeviceSamplerYcbcrConversionFeatures& operator=( VkPhysicalDeviceSamplerYcbcrConversionFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSamplerYcbcrConversionFeatures::operator=(rhs);
      return *this;
    }

    PhysicalDeviceSamplerYcbcrConversionFeatures & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceSamplerYcbcrConversionFeatures & setSamplerYcbcrConversion( vk::Bool32 samplerYcbcrConversion_ ) VULKAN_HPP_NOEXCEPT
    {
      samplerYcbcrConversion = samplerYcbcrConversion_;
      return *this;
    }

    operator VkPhysicalDeviceSamplerYcbcrConversionFeatures const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSamplerYcbcrConversionFeatures*>( this );
    }

    operator VkPhysicalDeviceSamplerYcbcrConversionFeatures &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSamplerYcbcrConversionFeatures*>( this );
    }

    bool operator==( PhysicalDeviceSamplerYcbcrConversionFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( samplerYcbcrConversion == rhs.samplerYcbcrConversion );
    }

    bool operator!=( PhysicalDeviceSamplerYcbcrConversionFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSamplerYcbcrConversionFeatures::sType;
  };
  static_assert( sizeof( PhysicalDeviceSamplerYcbcrConversionFeatures ) == sizeof( VkPhysicalDeviceSamplerYcbcrConversionFeatures ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSamplerYcbcrConversionFeatures>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceScalarBlockLayoutFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceScalarBlockLayoutFeaturesEXT( vk::Bool32 scalarBlockLayout_ = 0 ) VULKAN_HPP_NOEXCEPT
        : scalarBlockLayout( scalarBlockLayout_ )
      {}

      PhysicalDeviceScalarBlockLayoutFeaturesEXT( VkPhysicalDeviceScalarBlockLayoutFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceScalarBlockLayoutFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceScalarBlockLayoutFeaturesEXT& operator=( VkPhysicalDeviceScalarBlockLayoutFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceScalarBlockLayoutFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceScalarBlockLayoutFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 scalarBlockLayout;
    };
    static_assert( sizeof( PhysicalDeviceScalarBlockLayoutFeaturesEXT ) == sizeof( VkPhysicalDeviceScalarBlockLayoutFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceScalarBlockLayoutFeaturesEXT : public layout::PhysicalDeviceScalarBlockLayoutFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceScalarBlockLayoutFeaturesEXT( vk::Bool32 scalarBlockLayout_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceScalarBlockLayoutFeaturesEXT( scalarBlockLayout_ )
    {}

    PhysicalDeviceScalarBlockLayoutFeaturesEXT( VkPhysicalDeviceScalarBlockLayoutFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceScalarBlockLayoutFeaturesEXT( rhs )
    {}

    PhysicalDeviceScalarBlockLayoutFeaturesEXT& operator=( VkPhysicalDeviceScalarBlockLayoutFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceScalarBlockLayoutFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceScalarBlockLayoutFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceScalarBlockLayoutFeaturesEXT & setScalarBlockLayout( vk::Bool32 scalarBlockLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      scalarBlockLayout = scalarBlockLayout_;
      return *this;
    }

    operator VkPhysicalDeviceScalarBlockLayoutFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceScalarBlockLayoutFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceScalarBlockLayoutFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceScalarBlockLayoutFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceScalarBlockLayoutFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( scalarBlockLayout == rhs.scalarBlockLayout );
    }

    bool operator!=( PhysicalDeviceScalarBlockLayoutFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceScalarBlockLayoutFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceScalarBlockLayoutFeaturesEXT ) == sizeof( VkPhysicalDeviceScalarBlockLayoutFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceScalarBlockLayoutFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderAtomicInt64FeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderAtomicInt64FeaturesKHR( vk::Bool32 shaderBufferInt64Atomics_ = 0,
                                                                       vk::Bool32 shaderSharedInt64Atomics_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderBufferInt64Atomics( shaderBufferInt64Atomics_ )
        , shaderSharedInt64Atomics( shaderSharedInt64Atomics_ )
      {}

      PhysicalDeviceShaderAtomicInt64FeaturesKHR( VkPhysicalDeviceShaderAtomicInt64FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderAtomicInt64FeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceShaderAtomicInt64FeaturesKHR& operator=( VkPhysicalDeviceShaderAtomicInt64FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderAtomicInt64FeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderAtomicInt64FeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 shaderBufferInt64Atomics;
      vk::Bool32 shaderSharedInt64Atomics;
    };
    static_assert( sizeof( PhysicalDeviceShaderAtomicInt64FeaturesKHR ) == sizeof( VkPhysicalDeviceShaderAtomicInt64FeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderAtomicInt64FeaturesKHR : public layout::PhysicalDeviceShaderAtomicInt64FeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderAtomicInt64FeaturesKHR( vk::Bool32 shaderBufferInt64Atomics_ = 0,
                                                                     vk::Bool32 shaderSharedInt64Atomics_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderAtomicInt64FeaturesKHR( shaderBufferInt64Atomics_, shaderSharedInt64Atomics_ )
    {}

    PhysicalDeviceShaderAtomicInt64FeaturesKHR( VkPhysicalDeviceShaderAtomicInt64FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderAtomicInt64FeaturesKHR( rhs )
    {}

    PhysicalDeviceShaderAtomicInt64FeaturesKHR& operator=( VkPhysicalDeviceShaderAtomicInt64FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderAtomicInt64FeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderAtomicInt64FeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderAtomicInt64FeaturesKHR & setShaderBufferInt64Atomics( vk::Bool32 shaderBufferInt64Atomics_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderBufferInt64Atomics = shaderBufferInt64Atomics_;
      return *this;
    }

    PhysicalDeviceShaderAtomicInt64FeaturesKHR & setShaderSharedInt64Atomics( vk::Bool32 shaderSharedInt64Atomics_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderSharedInt64Atomics = shaderSharedInt64Atomics_;
      return *this;
    }

    operator VkPhysicalDeviceShaderAtomicInt64FeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderAtomicInt64FeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceShaderAtomicInt64FeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderAtomicInt64FeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceShaderAtomicInt64FeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderBufferInt64Atomics == rhs.shaderBufferInt64Atomics )
          && ( shaderSharedInt64Atomics == rhs.shaderSharedInt64Atomics );
    }

    bool operator!=( PhysicalDeviceShaderAtomicInt64FeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderAtomicInt64FeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderAtomicInt64FeaturesKHR ) == sizeof( VkPhysicalDeviceShaderAtomicInt64FeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderAtomicInt64FeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderClockFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderClockFeaturesKHR( vk::Bool32 shaderSubgroupClock_ = 0,
                                                                 vk::Bool32 shaderDeviceClock_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderSubgroupClock( shaderSubgroupClock_ )
        , shaderDeviceClock( shaderDeviceClock_ )
      {}

      PhysicalDeviceShaderClockFeaturesKHR( VkPhysicalDeviceShaderClockFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderClockFeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceShaderClockFeaturesKHR& operator=( VkPhysicalDeviceShaderClockFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderClockFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderClockFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 shaderSubgroupClock;
      vk::Bool32 shaderDeviceClock;
    };
    static_assert( sizeof( PhysicalDeviceShaderClockFeaturesKHR ) == sizeof( VkPhysicalDeviceShaderClockFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderClockFeaturesKHR : public layout::PhysicalDeviceShaderClockFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderClockFeaturesKHR( vk::Bool32 shaderSubgroupClock_ = 0,
                                                               vk::Bool32 shaderDeviceClock_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderClockFeaturesKHR( shaderSubgroupClock_, shaderDeviceClock_ )
    {}

    PhysicalDeviceShaderClockFeaturesKHR( VkPhysicalDeviceShaderClockFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderClockFeaturesKHR( rhs )
    {}

    PhysicalDeviceShaderClockFeaturesKHR& operator=( VkPhysicalDeviceShaderClockFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderClockFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderClockFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderClockFeaturesKHR & setShaderSubgroupClock( vk::Bool32 shaderSubgroupClock_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderSubgroupClock = shaderSubgroupClock_;
      return *this;
    }

    PhysicalDeviceShaderClockFeaturesKHR & setShaderDeviceClock( vk::Bool32 shaderDeviceClock_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderDeviceClock = shaderDeviceClock_;
      return *this;
    }

    operator VkPhysicalDeviceShaderClockFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderClockFeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceShaderClockFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderClockFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceShaderClockFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderSubgroupClock == rhs.shaderSubgroupClock )
          && ( shaderDeviceClock == rhs.shaderDeviceClock );
    }

    bool operator!=( PhysicalDeviceShaderClockFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderClockFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderClockFeaturesKHR ) == sizeof( VkPhysicalDeviceShaderClockFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderClockFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderCoreProperties2AMD
    {
    protected:
      PhysicalDeviceShaderCoreProperties2AMD() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceShaderCoreProperties2AMD( VkPhysicalDeviceShaderCoreProperties2AMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderCoreProperties2AMD*>(this) = rhs;
      }

      PhysicalDeviceShaderCoreProperties2AMD& operator=( VkPhysicalDeviceShaderCoreProperties2AMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderCoreProperties2AMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderCoreProperties2AMD;
      void* pNext = nullptr;
      vk::ShaderCorePropertiesFlagsAMD shaderCoreFeatures;
      uint32_t activeComputeUnitCount;
    };
    static_assert( sizeof( PhysicalDeviceShaderCoreProperties2AMD ) == sizeof( VkPhysicalDeviceShaderCoreProperties2AMD ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderCoreProperties2AMD : public layout::PhysicalDeviceShaderCoreProperties2AMD
  {
    PhysicalDeviceShaderCoreProperties2AMD() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderCoreProperties2AMD()
    {}

    PhysicalDeviceShaderCoreProperties2AMD( VkPhysicalDeviceShaderCoreProperties2AMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderCoreProperties2AMD( rhs )
    {}

    PhysicalDeviceShaderCoreProperties2AMD& operator=( VkPhysicalDeviceShaderCoreProperties2AMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderCoreProperties2AMD::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceShaderCoreProperties2AMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderCoreProperties2AMD*>( this );
    }

    operator VkPhysicalDeviceShaderCoreProperties2AMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderCoreProperties2AMD*>( this );
    }

    bool operator==( PhysicalDeviceShaderCoreProperties2AMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderCoreFeatures == rhs.shaderCoreFeatures )
          && ( activeComputeUnitCount == rhs.activeComputeUnitCount );
    }

    bool operator!=( PhysicalDeviceShaderCoreProperties2AMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderCoreProperties2AMD::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderCoreProperties2AMD ) == sizeof( VkPhysicalDeviceShaderCoreProperties2AMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderCoreProperties2AMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderCorePropertiesAMD
    {
    protected:
      PhysicalDeviceShaderCorePropertiesAMD() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceShaderCorePropertiesAMD( VkPhysicalDeviceShaderCorePropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderCorePropertiesAMD*>(this) = rhs;
      }

      PhysicalDeviceShaderCorePropertiesAMD& operator=( VkPhysicalDeviceShaderCorePropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderCorePropertiesAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderCorePropertiesAMD;
      void* pNext = nullptr;
      uint32_t shaderEngineCount;
      uint32_t shaderArraysPerEngineCount;
      uint32_t computeUnitsPerShaderArray;
      uint32_t simdPerComputeUnit;
      uint32_t wavefrontsPerSimd;
      uint32_t wavefrontSize;
      uint32_t sgprsPerSimd;
      uint32_t minSgprAllocation;
      uint32_t maxSgprAllocation;
      uint32_t sgprAllocationGranularity;
      uint32_t vgprsPerSimd;
      uint32_t minVgprAllocation;
      uint32_t maxVgprAllocation;
      uint32_t vgprAllocationGranularity;
    };
    static_assert( sizeof( PhysicalDeviceShaderCorePropertiesAMD ) == sizeof( VkPhysicalDeviceShaderCorePropertiesAMD ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderCorePropertiesAMD : public layout::PhysicalDeviceShaderCorePropertiesAMD
  {
    PhysicalDeviceShaderCorePropertiesAMD() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderCorePropertiesAMD()
    {}

    PhysicalDeviceShaderCorePropertiesAMD( VkPhysicalDeviceShaderCorePropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderCorePropertiesAMD( rhs )
    {}

    PhysicalDeviceShaderCorePropertiesAMD& operator=( VkPhysicalDeviceShaderCorePropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderCorePropertiesAMD::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceShaderCorePropertiesAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderCorePropertiesAMD*>( this );
    }

    operator VkPhysicalDeviceShaderCorePropertiesAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderCorePropertiesAMD*>( this );
    }

    bool operator==( PhysicalDeviceShaderCorePropertiesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderEngineCount == rhs.shaderEngineCount )
          && ( shaderArraysPerEngineCount == rhs.shaderArraysPerEngineCount )
          && ( computeUnitsPerShaderArray == rhs.computeUnitsPerShaderArray )
          && ( simdPerComputeUnit == rhs.simdPerComputeUnit )
          && ( wavefrontsPerSimd == rhs.wavefrontsPerSimd )
          && ( wavefrontSize == rhs.wavefrontSize )
          && ( sgprsPerSimd == rhs.sgprsPerSimd )
          && ( minSgprAllocation == rhs.minSgprAllocation )
          && ( maxSgprAllocation == rhs.maxSgprAllocation )
          && ( sgprAllocationGranularity == rhs.sgprAllocationGranularity )
          && ( vgprsPerSimd == rhs.vgprsPerSimd )
          && ( minVgprAllocation == rhs.minVgprAllocation )
          && ( maxVgprAllocation == rhs.maxVgprAllocation )
          && ( vgprAllocationGranularity == rhs.vgprAllocationGranularity );
    }

    bool operator!=( PhysicalDeviceShaderCorePropertiesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderCorePropertiesAMD::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderCorePropertiesAMD ) == sizeof( VkPhysicalDeviceShaderCorePropertiesAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderCorePropertiesAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT( vk::Bool32 shaderDemoteToHelperInvocation_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderDemoteToHelperInvocation( shaderDemoteToHelperInvocation_ )
      {}

      PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT( VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT& operator=( VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 shaderDemoteToHelperInvocation;
    };
    static_assert( sizeof( PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT ) == sizeof( VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT : public layout::PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT( vk::Bool32 shaderDemoteToHelperInvocation_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT( shaderDemoteToHelperInvocation_ )
    {}

    PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT( VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT( rhs )
    {}

    PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT& operator=( VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT & setShaderDemoteToHelperInvocation( vk::Bool32 shaderDemoteToHelperInvocation_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderDemoteToHelperInvocation = shaderDemoteToHelperInvocation_;
      return *this;
    }

    operator VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderDemoteToHelperInvocation == rhs.shaderDemoteToHelperInvocation );
    }

    bool operator!=( PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT ) == sizeof( VkPhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderDrawParametersFeatures
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderDrawParametersFeatures( vk::Bool32 shaderDrawParameters_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderDrawParameters( shaderDrawParameters_ )
      {}

      PhysicalDeviceShaderDrawParametersFeatures( VkPhysicalDeviceShaderDrawParametersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderDrawParametersFeatures*>(this) = rhs;
      }

      PhysicalDeviceShaderDrawParametersFeatures& operator=( VkPhysicalDeviceShaderDrawParametersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderDrawParametersFeatures*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderDrawParametersFeatures;
      void* pNext = nullptr;
      vk::Bool32 shaderDrawParameters;
    };
    static_assert( sizeof( PhysicalDeviceShaderDrawParametersFeatures ) == sizeof( VkPhysicalDeviceShaderDrawParametersFeatures ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderDrawParametersFeatures : public layout::PhysicalDeviceShaderDrawParametersFeatures
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderDrawParametersFeatures( vk::Bool32 shaderDrawParameters_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderDrawParametersFeatures( shaderDrawParameters_ )
    {}

    PhysicalDeviceShaderDrawParametersFeatures( VkPhysicalDeviceShaderDrawParametersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderDrawParametersFeatures( rhs )
    {}

    PhysicalDeviceShaderDrawParametersFeatures& operator=( VkPhysicalDeviceShaderDrawParametersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderDrawParametersFeatures::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderDrawParametersFeatures & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderDrawParametersFeatures & setShaderDrawParameters( vk::Bool32 shaderDrawParameters_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderDrawParameters = shaderDrawParameters_;
      return *this;
    }

    operator VkPhysicalDeviceShaderDrawParametersFeatures const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderDrawParametersFeatures*>( this );
    }

    operator VkPhysicalDeviceShaderDrawParametersFeatures &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderDrawParametersFeatures*>( this );
    }

    bool operator==( PhysicalDeviceShaderDrawParametersFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderDrawParameters == rhs.shaderDrawParameters );
    }

    bool operator!=( PhysicalDeviceShaderDrawParametersFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderDrawParametersFeatures::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderDrawParametersFeatures ) == sizeof( VkPhysicalDeviceShaderDrawParametersFeatures ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderDrawParametersFeatures>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderFloat16Int8FeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderFloat16Int8FeaturesKHR( vk::Bool32 shaderFloat16_ = 0,
                                                                       vk::Bool32 shaderInt8_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderFloat16( shaderFloat16_ )
        , shaderInt8( shaderInt8_ )
      {}

      PhysicalDeviceShaderFloat16Int8FeaturesKHR( VkPhysicalDeviceShaderFloat16Int8FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderFloat16Int8FeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceShaderFloat16Int8FeaturesKHR& operator=( VkPhysicalDeviceShaderFloat16Int8FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderFloat16Int8FeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderFloat16Int8FeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 shaderFloat16;
      vk::Bool32 shaderInt8;
    };
    static_assert( sizeof( PhysicalDeviceShaderFloat16Int8FeaturesKHR ) == sizeof( VkPhysicalDeviceShaderFloat16Int8FeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderFloat16Int8FeaturesKHR : public layout::PhysicalDeviceShaderFloat16Int8FeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderFloat16Int8FeaturesKHR( vk::Bool32 shaderFloat16_ = 0,
                                                                     vk::Bool32 shaderInt8_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderFloat16Int8FeaturesKHR( shaderFloat16_, shaderInt8_ )
    {}

    PhysicalDeviceShaderFloat16Int8FeaturesKHR( VkPhysicalDeviceShaderFloat16Int8FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderFloat16Int8FeaturesKHR( rhs )
    {}

    PhysicalDeviceShaderFloat16Int8FeaturesKHR& operator=( VkPhysicalDeviceShaderFloat16Int8FeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderFloat16Int8FeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderFloat16Int8FeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderFloat16Int8FeaturesKHR & setShaderFloat16( vk::Bool32 shaderFloat16_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderFloat16 = shaderFloat16_;
      return *this;
    }

    PhysicalDeviceShaderFloat16Int8FeaturesKHR & setShaderInt8( vk::Bool32 shaderInt8_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderInt8 = shaderInt8_;
      return *this;
    }

    operator VkPhysicalDeviceShaderFloat16Int8FeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderFloat16Int8FeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceShaderFloat16Int8FeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderFloat16Int8FeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceShaderFloat16Int8FeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderFloat16 == rhs.shaderFloat16 )
          && ( shaderInt8 == rhs.shaderInt8 );
    }

    bool operator!=( PhysicalDeviceShaderFloat16Int8FeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderFloat16Int8FeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderFloat16Int8FeaturesKHR ) == sizeof( VkPhysicalDeviceShaderFloat16Int8FeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderFloat16Int8FeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderImageFootprintFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderImageFootprintFeaturesNV( vk::Bool32 imageFootprint_ = 0 ) VULKAN_HPP_NOEXCEPT
        : imageFootprint( imageFootprint_ )
      {}

      PhysicalDeviceShaderImageFootprintFeaturesNV( VkPhysicalDeviceShaderImageFootprintFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderImageFootprintFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceShaderImageFootprintFeaturesNV& operator=( VkPhysicalDeviceShaderImageFootprintFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderImageFootprintFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderImageFootprintFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 imageFootprint;
    };
    static_assert( sizeof( PhysicalDeviceShaderImageFootprintFeaturesNV ) == sizeof( VkPhysicalDeviceShaderImageFootprintFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderImageFootprintFeaturesNV : public layout::PhysicalDeviceShaderImageFootprintFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderImageFootprintFeaturesNV( vk::Bool32 imageFootprint_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderImageFootprintFeaturesNV( imageFootprint_ )
    {}

    PhysicalDeviceShaderImageFootprintFeaturesNV( VkPhysicalDeviceShaderImageFootprintFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderImageFootprintFeaturesNV( rhs )
    {}

    PhysicalDeviceShaderImageFootprintFeaturesNV& operator=( VkPhysicalDeviceShaderImageFootprintFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderImageFootprintFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderImageFootprintFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderImageFootprintFeaturesNV & setImageFootprint( vk::Bool32 imageFootprint_ ) VULKAN_HPP_NOEXCEPT
    {
      imageFootprint = imageFootprint_;
      return *this;
    }

    operator VkPhysicalDeviceShaderImageFootprintFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderImageFootprintFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceShaderImageFootprintFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderImageFootprintFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceShaderImageFootprintFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( imageFootprint == rhs.imageFootprint );
    }

    bool operator!=( PhysicalDeviceShaderImageFootprintFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderImageFootprintFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderImageFootprintFeaturesNV ) == sizeof( VkPhysicalDeviceShaderImageFootprintFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderImageFootprintFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL( vk::Bool32 shaderIntegerFunctions2_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderIntegerFunctions2( shaderIntegerFunctions2_ )
      {}

      PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL( VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL*>(this) = rhs;
      }

      PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL& operator=( VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderIntegerFunctions2FeaturesINTEL;
      void* pNext = nullptr;
      vk::Bool32 shaderIntegerFunctions2;
    };
    static_assert( sizeof( PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL ) == sizeof( VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL : public layout::PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL( vk::Bool32 shaderIntegerFunctions2_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL( shaderIntegerFunctions2_ )
    {}

    PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL( VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL( rhs )
    {}

    PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL& operator=( VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL & setShaderIntegerFunctions2( vk::Bool32 shaderIntegerFunctions2_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderIntegerFunctions2 = shaderIntegerFunctions2_;
      return *this;
    }

    operator VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL*>( this );
    }

    operator VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL*>( this );
    }

    bool operator==( PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderIntegerFunctions2 == rhs.shaderIntegerFunctions2 );
    }

    bool operator!=( PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL ) == sizeof( VkPhysicalDeviceShaderIntegerFunctions2FeaturesINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderSMBuiltinsFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderSMBuiltinsFeaturesNV( vk::Bool32 shaderSMBuiltins_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderSMBuiltins( shaderSMBuiltins_ )
      {}

      PhysicalDeviceShaderSMBuiltinsFeaturesNV( VkPhysicalDeviceShaderSMBuiltinsFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderSMBuiltinsFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceShaderSMBuiltinsFeaturesNV& operator=( VkPhysicalDeviceShaderSMBuiltinsFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderSMBuiltinsFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderSmBuiltinsFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 shaderSMBuiltins;
    };
    static_assert( sizeof( PhysicalDeviceShaderSMBuiltinsFeaturesNV ) == sizeof( VkPhysicalDeviceShaderSMBuiltinsFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderSMBuiltinsFeaturesNV : public layout::PhysicalDeviceShaderSMBuiltinsFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderSMBuiltinsFeaturesNV( vk::Bool32 shaderSMBuiltins_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderSMBuiltinsFeaturesNV( shaderSMBuiltins_ )
    {}

    PhysicalDeviceShaderSMBuiltinsFeaturesNV( VkPhysicalDeviceShaderSMBuiltinsFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderSMBuiltinsFeaturesNV( rhs )
    {}

    PhysicalDeviceShaderSMBuiltinsFeaturesNV& operator=( VkPhysicalDeviceShaderSMBuiltinsFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderSMBuiltinsFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderSMBuiltinsFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderSMBuiltinsFeaturesNV & setShaderSMBuiltins( vk::Bool32 shaderSMBuiltins_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderSMBuiltins = shaderSMBuiltins_;
      return *this;
    }

    operator VkPhysicalDeviceShaderSMBuiltinsFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderSMBuiltinsFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceShaderSMBuiltinsFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderSMBuiltinsFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceShaderSMBuiltinsFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderSMBuiltins == rhs.shaderSMBuiltins );
    }

    bool operator!=( PhysicalDeviceShaderSMBuiltinsFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderSMBuiltinsFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderSMBuiltinsFeaturesNV ) == sizeof( VkPhysicalDeviceShaderSMBuiltinsFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderSMBuiltinsFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderSMBuiltinsPropertiesNV
    {
    protected:
      PhysicalDeviceShaderSMBuiltinsPropertiesNV() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceShaderSMBuiltinsPropertiesNV( VkPhysicalDeviceShaderSMBuiltinsPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderSMBuiltinsPropertiesNV*>(this) = rhs;
      }

      PhysicalDeviceShaderSMBuiltinsPropertiesNV& operator=( VkPhysicalDeviceShaderSMBuiltinsPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderSMBuiltinsPropertiesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderSmBuiltinsPropertiesNV;
      void* pNext = nullptr;
      uint32_t shaderSMCount;
      uint32_t shaderWarpsPerSM;
    };
    static_assert( sizeof( PhysicalDeviceShaderSMBuiltinsPropertiesNV ) == sizeof( VkPhysicalDeviceShaderSMBuiltinsPropertiesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderSMBuiltinsPropertiesNV : public layout::PhysicalDeviceShaderSMBuiltinsPropertiesNV
  {
    PhysicalDeviceShaderSMBuiltinsPropertiesNV() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderSMBuiltinsPropertiesNV()
    {}

    PhysicalDeviceShaderSMBuiltinsPropertiesNV( VkPhysicalDeviceShaderSMBuiltinsPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderSMBuiltinsPropertiesNV( rhs )
    {}

    PhysicalDeviceShaderSMBuiltinsPropertiesNV& operator=( VkPhysicalDeviceShaderSMBuiltinsPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderSMBuiltinsPropertiesNV::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceShaderSMBuiltinsPropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderSMBuiltinsPropertiesNV*>( this );
    }

    operator VkPhysicalDeviceShaderSMBuiltinsPropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderSMBuiltinsPropertiesNV*>( this );
    }

    bool operator==( PhysicalDeviceShaderSMBuiltinsPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderSMCount == rhs.shaderSMCount )
          && ( shaderWarpsPerSM == rhs.shaderWarpsPerSM );
    }

    bool operator!=( PhysicalDeviceShaderSMBuiltinsPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderSMBuiltinsPropertiesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderSMBuiltinsPropertiesNV ) == sizeof( VkPhysicalDeviceShaderSMBuiltinsPropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderSMBuiltinsPropertiesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR( vk::Bool32 shaderSubgroupExtendedTypes_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shaderSubgroupExtendedTypes( shaderSubgroupExtendedTypes_ )
      {}

      PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR( VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR& operator=( VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 shaderSubgroupExtendedTypes;
    };
    static_assert( sizeof( PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR ) == sizeof( VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR : public layout::PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR( vk::Bool32 shaderSubgroupExtendedTypes_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR( shaderSubgroupExtendedTypes_ )
    {}

    PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR( VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR( rhs )
    {}

    PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR& operator=( VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR & setShaderSubgroupExtendedTypes( vk::Bool32 shaderSubgroupExtendedTypes_ ) VULKAN_HPP_NOEXCEPT
    {
      shaderSubgroupExtendedTypes = shaderSubgroupExtendedTypes_;
      return *this;
    }

    operator VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shaderSubgroupExtendedTypes == rhs.shaderSubgroupExtendedTypes );
    }

    bool operator!=( PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR ) == sizeof( VkPhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShadingRateImageFeaturesNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceShadingRateImageFeaturesNV( vk::Bool32 shadingRateImage_ = 0,
                                                                     vk::Bool32 shadingRateCoarseSampleOrder_ = 0 ) VULKAN_HPP_NOEXCEPT
        : shadingRateImage( shadingRateImage_ )
        , shadingRateCoarseSampleOrder( shadingRateCoarseSampleOrder_ )
      {}

      PhysicalDeviceShadingRateImageFeaturesNV( VkPhysicalDeviceShadingRateImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShadingRateImageFeaturesNV*>(this) = rhs;
      }

      PhysicalDeviceShadingRateImageFeaturesNV& operator=( VkPhysicalDeviceShadingRateImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShadingRateImageFeaturesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShadingRateImageFeaturesNV;
      void* pNext = nullptr;
      vk::Bool32 shadingRateImage;
      vk::Bool32 shadingRateCoarseSampleOrder;
    };
    static_assert( sizeof( PhysicalDeviceShadingRateImageFeaturesNV ) == sizeof( VkPhysicalDeviceShadingRateImageFeaturesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShadingRateImageFeaturesNV : public layout::PhysicalDeviceShadingRateImageFeaturesNV
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceShadingRateImageFeaturesNV( vk::Bool32 shadingRateImage_ = 0,
                                                                   vk::Bool32 shadingRateCoarseSampleOrder_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShadingRateImageFeaturesNV( shadingRateImage_, shadingRateCoarseSampleOrder_ )
    {}

    PhysicalDeviceShadingRateImageFeaturesNV( VkPhysicalDeviceShadingRateImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShadingRateImageFeaturesNV( rhs )
    {}

    PhysicalDeviceShadingRateImageFeaturesNV& operator=( VkPhysicalDeviceShadingRateImageFeaturesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShadingRateImageFeaturesNV::operator=(rhs);
      return *this;
    }

    PhysicalDeviceShadingRateImageFeaturesNV & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceShadingRateImageFeaturesNV & setShadingRateImage( vk::Bool32 shadingRateImage_ ) VULKAN_HPP_NOEXCEPT
    {
      shadingRateImage = shadingRateImage_;
      return *this;
    }

    PhysicalDeviceShadingRateImageFeaturesNV & setShadingRateCoarseSampleOrder( vk::Bool32 shadingRateCoarseSampleOrder_ ) VULKAN_HPP_NOEXCEPT
    {
      shadingRateCoarseSampleOrder = shadingRateCoarseSampleOrder_;
      return *this;
    }

    operator VkPhysicalDeviceShadingRateImageFeaturesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShadingRateImageFeaturesNV*>( this );
    }

    operator VkPhysicalDeviceShadingRateImageFeaturesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShadingRateImageFeaturesNV*>( this );
    }

    bool operator==( PhysicalDeviceShadingRateImageFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shadingRateImage == rhs.shadingRateImage )
          && ( shadingRateCoarseSampleOrder == rhs.shadingRateCoarseSampleOrder );
    }

    bool operator!=( PhysicalDeviceShadingRateImageFeaturesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShadingRateImageFeaturesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceShadingRateImageFeaturesNV ) == sizeof( VkPhysicalDeviceShadingRateImageFeaturesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShadingRateImageFeaturesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceShadingRateImagePropertiesNV
    {
    protected:
      PhysicalDeviceShadingRateImagePropertiesNV() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceShadingRateImagePropertiesNV( VkPhysicalDeviceShadingRateImagePropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShadingRateImagePropertiesNV*>(this) = rhs;
      }

      PhysicalDeviceShadingRateImagePropertiesNV& operator=( VkPhysicalDeviceShadingRateImagePropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceShadingRateImagePropertiesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceShadingRateImagePropertiesNV;
      void* pNext = nullptr;
      vk::Extent2D shadingRateTexelSize;
      uint32_t shadingRatePaletteSize;
      uint32_t shadingRateMaxCoarseSamples;
    };
    static_assert( sizeof( PhysicalDeviceShadingRateImagePropertiesNV ) == sizeof( VkPhysicalDeviceShadingRateImagePropertiesNV ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceShadingRateImagePropertiesNV : public layout::PhysicalDeviceShadingRateImagePropertiesNV
  {
    PhysicalDeviceShadingRateImagePropertiesNV() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShadingRateImagePropertiesNV()
    {}

    PhysicalDeviceShadingRateImagePropertiesNV( VkPhysicalDeviceShadingRateImagePropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceShadingRateImagePropertiesNV( rhs )
    {}

    PhysicalDeviceShadingRateImagePropertiesNV& operator=( VkPhysicalDeviceShadingRateImagePropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceShadingRateImagePropertiesNV::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceShadingRateImagePropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceShadingRateImagePropertiesNV*>( this );
    }

    operator VkPhysicalDeviceShadingRateImagePropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceShadingRateImagePropertiesNV*>( this );
    }

    bool operator==( PhysicalDeviceShadingRateImagePropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shadingRateTexelSize == rhs.shadingRateTexelSize )
          && ( shadingRatePaletteSize == rhs.shadingRatePaletteSize )
          && ( shadingRateMaxCoarseSamples == rhs.shadingRateMaxCoarseSamples );
    }

    bool operator!=( PhysicalDeviceShadingRateImagePropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceShadingRateImagePropertiesNV::sType;
  };
  static_assert( sizeof( PhysicalDeviceShadingRateImagePropertiesNV ) == sizeof( VkPhysicalDeviceShadingRateImagePropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceShadingRateImagePropertiesNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSparseImageFormatInfo2
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceSparseImageFormatInfo2( vk::Format format_ = vk::Format::eUndefined,
                                                                 vk::ImageType type_ = vk::ImageType::e1D,
                                                                 vk::SampleCountFlagBits samples_ = vk::SampleCountFlagBits::e1,
                                                                 vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                                                 vk::ImageTiling tiling_ = vk::ImageTiling::eOptimal ) VULKAN_HPP_NOEXCEPT
        : format( format_ )
        , type( type_ )
        , samples( samples_ )
        , usage( usage_ )
        , tiling( tiling_ )
      {}

      PhysicalDeviceSparseImageFormatInfo2( VkPhysicalDeviceSparseImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSparseImageFormatInfo2*>(this) = rhs;
      }

      PhysicalDeviceSparseImageFormatInfo2& operator=( VkPhysicalDeviceSparseImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSparseImageFormatInfo2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSparseImageFormatInfo2;
      const void* pNext = nullptr;
      vk::Format format;
      vk::ImageType type;
      vk::SampleCountFlagBits samples;
      vk::ImageUsageFlags usage;
      vk::ImageTiling tiling;
    };
    static_assert( sizeof( PhysicalDeviceSparseImageFormatInfo2 ) == sizeof( VkPhysicalDeviceSparseImageFormatInfo2 ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSparseImageFormatInfo2 : public layout::PhysicalDeviceSparseImageFormatInfo2
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceSparseImageFormatInfo2( vk::Format format_ = vk::Format::eUndefined,
                                                               vk::ImageType type_ = vk::ImageType::e1D,
                                                               vk::SampleCountFlagBits samples_ = vk::SampleCountFlagBits::e1,
                                                               vk::ImageUsageFlags usage_ = vk::ImageUsageFlags(),
                                                               vk::ImageTiling tiling_ = vk::ImageTiling::eOptimal ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSparseImageFormatInfo2( format_, type_, samples_, usage_, tiling_ )
    {}

    PhysicalDeviceSparseImageFormatInfo2( VkPhysicalDeviceSparseImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSparseImageFormatInfo2( rhs )
    {}

    PhysicalDeviceSparseImageFormatInfo2& operator=( VkPhysicalDeviceSparseImageFormatInfo2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSparseImageFormatInfo2::operator=(rhs);
      return *this;
    }

    PhysicalDeviceSparseImageFormatInfo2 & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceSparseImageFormatInfo2 & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    PhysicalDeviceSparseImageFormatInfo2 & setType( vk::ImageType type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    PhysicalDeviceSparseImageFormatInfo2 & setSamples( vk::SampleCountFlagBits samples_ ) VULKAN_HPP_NOEXCEPT
    {
      samples = samples_;
      return *this;
    }

    PhysicalDeviceSparseImageFormatInfo2 & setUsage( vk::ImageUsageFlags usage_ ) VULKAN_HPP_NOEXCEPT
    {
      usage = usage_;
      return *this;
    }

    PhysicalDeviceSparseImageFormatInfo2 & setTiling( vk::ImageTiling tiling_ ) VULKAN_HPP_NOEXCEPT
    {
      tiling = tiling_;
      return *this;
    }

    operator VkPhysicalDeviceSparseImageFormatInfo2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( this );
    }

    operator VkPhysicalDeviceSparseImageFormatInfo2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSparseImageFormatInfo2*>( this );
    }

    bool operator==( PhysicalDeviceSparseImageFormatInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( format == rhs.format )
          && ( type == rhs.type )
          && vk::operator==( samples, rhs.samples )
          && ( usage == rhs.usage )
          && ( tiling == rhs.tiling );
    }

    bool operator!=( PhysicalDeviceSparseImageFormatInfo2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSparseImageFormatInfo2::sType;
  };
  static_assert( sizeof( PhysicalDeviceSparseImageFormatInfo2 ) == sizeof( VkPhysicalDeviceSparseImageFormatInfo2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSparseImageFormatInfo2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSubgroupProperties
    {
    protected:
      PhysicalDeviceSubgroupProperties() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceSubgroupProperties( VkPhysicalDeviceSubgroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSubgroupProperties*>(this) = rhs;
      }

      PhysicalDeviceSubgroupProperties& operator=( VkPhysicalDeviceSubgroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSubgroupProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSubgroupProperties;
      void* pNext = nullptr;
      uint32_t subgroupSize;
      vk::ShaderStageFlags supportedStages;
      vk::SubgroupFeatureFlags supportedOperations;
      vk::Bool32 quadOperationsInAllStages;
    };
    static_assert( sizeof( PhysicalDeviceSubgroupProperties ) == sizeof( VkPhysicalDeviceSubgroupProperties ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSubgroupProperties : public layout::PhysicalDeviceSubgroupProperties
  {
    PhysicalDeviceSubgroupProperties() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSubgroupProperties()
    {}

    PhysicalDeviceSubgroupProperties( VkPhysicalDeviceSubgroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSubgroupProperties( rhs )
    {}

    PhysicalDeviceSubgroupProperties& operator=( VkPhysicalDeviceSubgroupProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSubgroupProperties::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceSubgroupProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSubgroupProperties*>( this );
    }

    operator VkPhysicalDeviceSubgroupProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSubgroupProperties*>( this );
    }

    bool operator==( PhysicalDeviceSubgroupProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( subgroupSize == rhs.subgroupSize )
          && ( supportedStages == rhs.supportedStages )
          && ( supportedOperations == rhs.supportedOperations )
          && ( quadOperationsInAllStages == rhs.quadOperationsInAllStages );
    }

    bool operator!=( PhysicalDeviceSubgroupProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSubgroupProperties::sType;
  };
  static_assert( sizeof( PhysicalDeviceSubgroupProperties ) == sizeof( VkPhysicalDeviceSubgroupProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSubgroupProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSubgroupSizeControlFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceSubgroupSizeControlFeaturesEXT( vk::Bool32 subgroupSizeControl_ = 0,
                                                                         vk::Bool32 computeFullSubgroups_ = 0 ) VULKAN_HPP_NOEXCEPT
        : subgroupSizeControl( subgroupSizeControl_ )
        , computeFullSubgroups( computeFullSubgroups_ )
      {}

      PhysicalDeviceSubgroupSizeControlFeaturesEXT( VkPhysicalDeviceSubgroupSizeControlFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSubgroupSizeControlFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceSubgroupSizeControlFeaturesEXT& operator=( VkPhysicalDeviceSubgroupSizeControlFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSubgroupSizeControlFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSubgroupSizeControlFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 subgroupSizeControl;
      vk::Bool32 computeFullSubgroups;
    };
    static_assert( sizeof( PhysicalDeviceSubgroupSizeControlFeaturesEXT ) == sizeof( VkPhysicalDeviceSubgroupSizeControlFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSubgroupSizeControlFeaturesEXT : public layout::PhysicalDeviceSubgroupSizeControlFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceSubgroupSizeControlFeaturesEXT( vk::Bool32 subgroupSizeControl_ = 0,
                                                                       vk::Bool32 computeFullSubgroups_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSubgroupSizeControlFeaturesEXT( subgroupSizeControl_, computeFullSubgroups_ )
    {}

    PhysicalDeviceSubgroupSizeControlFeaturesEXT( VkPhysicalDeviceSubgroupSizeControlFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSubgroupSizeControlFeaturesEXT( rhs )
    {}

    PhysicalDeviceSubgroupSizeControlFeaturesEXT& operator=( VkPhysicalDeviceSubgroupSizeControlFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSubgroupSizeControlFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceSubgroupSizeControlFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceSubgroupSizeControlFeaturesEXT & setSubgroupSizeControl( vk::Bool32 subgroupSizeControl_ ) VULKAN_HPP_NOEXCEPT
    {
      subgroupSizeControl = subgroupSizeControl_;
      return *this;
    }

    PhysicalDeviceSubgroupSizeControlFeaturesEXT & setComputeFullSubgroups( vk::Bool32 computeFullSubgroups_ ) VULKAN_HPP_NOEXCEPT
    {
      computeFullSubgroups = computeFullSubgroups_;
      return *this;
    }

    operator VkPhysicalDeviceSubgroupSizeControlFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSubgroupSizeControlFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceSubgroupSizeControlFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSubgroupSizeControlFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceSubgroupSizeControlFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( subgroupSizeControl == rhs.subgroupSizeControl )
          && ( computeFullSubgroups == rhs.computeFullSubgroups );
    }

    bool operator!=( PhysicalDeviceSubgroupSizeControlFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSubgroupSizeControlFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceSubgroupSizeControlFeaturesEXT ) == sizeof( VkPhysicalDeviceSubgroupSizeControlFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSubgroupSizeControlFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSubgroupSizeControlPropertiesEXT
    {
    protected:
      PhysicalDeviceSubgroupSizeControlPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceSubgroupSizeControlPropertiesEXT( VkPhysicalDeviceSubgroupSizeControlPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSubgroupSizeControlPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceSubgroupSizeControlPropertiesEXT& operator=( VkPhysicalDeviceSubgroupSizeControlPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSubgroupSizeControlPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSubgroupSizeControlPropertiesEXT;
      void* pNext = nullptr;
      uint32_t minSubgroupSize;
      uint32_t maxSubgroupSize;
      uint32_t maxComputeWorkgroupSubgroups;
      vk::ShaderStageFlags requiredSubgroupSizeStages;
    };
    static_assert( sizeof( PhysicalDeviceSubgroupSizeControlPropertiesEXT ) == sizeof( VkPhysicalDeviceSubgroupSizeControlPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSubgroupSizeControlPropertiesEXT : public layout::PhysicalDeviceSubgroupSizeControlPropertiesEXT
  {
    PhysicalDeviceSubgroupSizeControlPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSubgroupSizeControlPropertiesEXT()
    {}

    PhysicalDeviceSubgroupSizeControlPropertiesEXT( VkPhysicalDeviceSubgroupSizeControlPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSubgroupSizeControlPropertiesEXT( rhs )
    {}

    PhysicalDeviceSubgroupSizeControlPropertiesEXT& operator=( VkPhysicalDeviceSubgroupSizeControlPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSubgroupSizeControlPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceSubgroupSizeControlPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSubgroupSizeControlPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceSubgroupSizeControlPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSubgroupSizeControlPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceSubgroupSizeControlPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( minSubgroupSize == rhs.minSubgroupSize )
          && ( maxSubgroupSize == rhs.maxSubgroupSize )
          && ( maxComputeWorkgroupSubgroups == rhs.maxComputeWorkgroupSubgroups )
          && ( requiredSubgroupSizeStages == rhs.requiredSubgroupSizeStages );
    }

    bool operator!=( PhysicalDeviceSubgroupSizeControlPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSubgroupSizeControlPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceSubgroupSizeControlPropertiesEXT ) == sizeof( VkPhysicalDeviceSubgroupSizeControlPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSubgroupSizeControlPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceSurfaceInfo2KHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceSurfaceInfo2KHR( vk::SurfaceKHR surface_ = vk::SurfaceKHR() ) VULKAN_HPP_NOEXCEPT
        : surface( surface_ )
      {}

      PhysicalDeviceSurfaceInfo2KHR( VkPhysicalDeviceSurfaceInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSurfaceInfo2KHR*>(this) = rhs;
      }

      PhysicalDeviceSurfaceInfo2KHR& operator=( VkPhysicalDeviceSurfaceInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceSurfaceInfo2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceSurfaceInfo2KHR;
      const void* pNext = nullptr;
      vk::SurfaceKHR surface;
    };
    static_assert( sizeof( PhysicalDeviceSurfaceInfo2KHR ) == sizeof( VkPhysicalDeviceSurfaceInfo2KHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceSurfaceInfo2KHR : public layout::PhysicalDeviceSurfaceInfo2KHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceSurfaceInfo2KHR( vk::SurfaceKHR surface_ = vk::SurfaceKHR() ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSurfaceInfo2KHR( surface_ )
    {}

    PhysicalDeviceSurfaceInfo2KHR( VkPhysicalDeviceSurfaceInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceSurfaceInfo2KHR( rhs )
    {}

    PhysicalDeviceSurfaceInfo2KHR& operator=( VkPhysicalDeviceSurfaceInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceSurfaceInfo2KHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceSurfaceInfo2KHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceSurfaceInfo2KHR & setSurface( vk::SurfaceKHR surface_ ) VULKAN_HPP_NOEXCEPT
    {
      surface = surface_;
      return *this;
    }

    operator VkPhysicalDeviceSurfaceInfo2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( this );
    }

    operator VkPhysicalDeviceSurfaceInfo2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceSurfaceInfo2KHR*>( this );
    }

    bool operator==( PhysicalDeviceSurfaceInfo2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( surface == rhs.surface );
    }

    bool operator!=( PhysicalDeviceSurfaceInfo2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceSurfaceInfo2KHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceSurfaceInfo2KHR ) == sizeof( VkPhysicalDeviceSurfaceInfo2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceSurfaceInfo2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceTexelBufferAlignmentFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceTexelBufferAlignmentFeaturesEXT( vk::Bool32 texelBufferAlignment_ = 0 ) VULKAN_HPP_NOEXCEPT
        : texelBufferAlignment( texelBufferAlignment_ )
      {}

      PhysicalDeviceTexelBufferAlignmentFeaturesEXT( VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceTexelBufferAlignmentFeaturesEXT& operator=( VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceTexelBufferAlignmentFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 texelBufferAlignment;
    };
    static_assert( sizeof( PhysicalDeviceTexelBufferAlignmentFeaturesEXT ) == sizeof( VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceTexelBufferAlignmentFeaturesEXT : public layout::PhysicalDeviceTexelBufferAlignmentFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceTexelBufferAlignmentFeaturesEXT( vk::Bool32 texelBufferAlignment_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTexelBufferAlignmentFeaturesEXT( texelBufferAlignment_ )
    {}

    PhysicalDeviceTexelBufferAlignmentFeaturesEXT( VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTexelBufferAlignmentFeaturesEXT( rhs )
    {}

    PhysicalDeviceTexelBufferAlignmentFeaturesEXT& operator=( VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceTexelBufferAlignmentFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceTexelBufferAlignmentFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceTexelBufferAlignmentFeaturesEXT & setTexelBufferAlignment( vk::Bool32 texelBufferAlignment_ ) VULKAN_HPP_NOEXCEPT
    {
      texelBufferAlignment = texelBufferAlignment_;
      return *this;
    }

    operator VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceTexelBufferAlignmentFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( texelBufferAlignment == rhs.texelBufferAlignment );
    }

    bool operator!=( PhysicalDeviceTexelBufferAlignmentFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceTexelBufferAlignmentFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceTexelBufferAlignmentFeaturesEXT ) == sizeof( VkPhysicalDeviceTexelBufferAlignmentFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceTexelBufferAlignmentFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceTexelBufferAlignmentPropertiesEXT
    {
    protected:
      PhysicalDeviceTexelBufferAlignmentPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceTexelBufferAlignmentPropertiesEXT( VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceTexelBufferAlignmentPropertiesEXT& operator=( VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceTexelBufferAlignmentPropertiesEXT;
      void* pNext = nullptr;
      vk::DeviceSize storageTexelBufferOffsetAlignmentBytes;
      vk::Bool32 storageTexelBufferOffsetSingleTexelAlignment;
      vk::DeviceSize uniformTexelBufferOffsetAlignmentBytes;
      vk::Bool32 uniformTexelBufferOffsetSingleTexelAlignment;
    };
    static_assert( sizeof( PhysicalDeviceTexelBufferAlignmentPropertiesEXT ) == sizeof( VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceTexelBufferAlignmentPropertiesEXT : public layout::PhysicalDeviceTexelBufferAlignmentPropertiesEXT
  {
    PhysicalDeviceTexelBufferAlignmentPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTexelBufferAlignmentPropertiesEXT()
    {}

    PhysicalDeviceTexelBufferAlignmentPropertiesEXT( VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTexelBufferAlignmentPropertiesEXT( rhs )
    {}

    PhysicalDeviceTexelBufferAlignmentPropertiesEXT& operator=( VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceTexelBufferAlignmentPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceTexelBufferAlignmentPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( storageTexelBufferOffsetAlignmentBytes == rhs.storageTexelBufferOffsetAlignmentBytes )
          && ( storageTexelBufferOffsetSingleTexelAlignment == rhs.storageTexelBufferOffsetSingleTexelAlignment )
          && ( uniformTexelBufferOffsetAlignmentBytes == rhs.uniformTexelBufferOffsetAlignmentBytes )
          && ( uniformTexelBufferOffsetSingleTexelAlignment == rhs.uniformTexelBufferOffsetSingleTexelAlignment );
    }

    bool operator!=( PhysicalDeviceTexelBufferAlignmentPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceTexelBufferAlignmentPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceTexelBufferAlignmentPropertiesEXT ) == sizeof( VkPhysicalDeviceTexelBufferAlignmentPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceTexelBufferAlignmentPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT( vk::Bool32 textureCompressionASTC_HDR_ = 0 ) VULKAN_HPP_NOEXCEPT
        : textureCompressionASTC_HDR( textureCompressionASTC_HDR_ )
      {}

      PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT( VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT& operator=( VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceTextureCompressionAstcHdrFeaturesEXT;
      const void* pNext = nullptr;
      vk::Bool32 textureCompressionASTC_HDR;
    };
    static_assert( sizeof( PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT ) == sizeof( VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT : public layout::PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT( vk::Bool32 textureCompressionASTC_HDR_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT( textureCompressionASTC_HDR_ )
    {}

    PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT( VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT( rhs )
    {}

    PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT& operator=( VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT & setTextureCompressionASTC_HDR( vk::Bool32 textureCompressionASTC_HDR_ ) VULKAN_HPP_NOEXCEPT
    {
      textureCompressionASTC_HDR = textureCompressionASTC_HDR_;
      return *this;
    }

    operator VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( textureCompressionASTC_HDR == rhs.textureCompressionASTC_HDR );
    }

    bool operator!=( PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT ) == sizeof( VkPhysicalDeviceTextureCompressionASTCHDRFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceTimelineSemaphoreFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceTimelineSemaphoreFeaturesKHR( vk::Bool32 timelineSemaphore_ = 0 ) VULKAN_HPP_NOEXCEPT
        : timelineSemaphore( timelineSemaphore_ )
      {}

      PhysicalDeviceTimelineSemaphoreFeaturesKHR( VkPhysicalDeviceTimelineSemaphoreFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTimelineSemaphoreFeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceTimelineSemaphoreFeaturesKHR& operator=( VkPhysicalDeviceTimelineSemaphoreFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTimelineSemaphoreFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceTimelineSemaphoreFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 timelineSemaphore;
    };
    static_assert( sizeof( PhysicalDeviceTimelineSemaphoreFeaturesKHR ) == sizeof( VkPhysicalDeviceTimelineSemaphoreFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceTimelineSemaphoreFeaturesKHR : public layout::PhysicalDeviceTimelineSemaphoreFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceTimelineSemaphoreFeaturesKHR( vk::Bool32 timelineSemaphore_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTimelineSemaphoreFeaturesKHR( timelineSemaphore_ )
    {}

    PhysicalDeviceTimelineSemaphoreFeaturesKHR( VkPhysicalDeviceTimelineSemaphoreFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTimelineSemaphoreFeaturesKHR( rhs )
    {}

    PhysicalDeviceTimelineSemaphoreFeaturesKHR& operator=( VkPhysicalDeviceTimelineSemaphoreFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceTimelineSemaphoreFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceTimelineSemaphoreFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceTimelineSemaphoreFeaturesKHR & setTimelineSemaphore( vk::Bool32 timelineSemaphore_ ) VULKAN_HPP_NOEXCEPT
    {
      timelineSemaphore = timelineSemaphore_;
      return *this;
    }

    operator VkPhysicalDeviceTimelineSemaphoreFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceTimelineSemaphoreFeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceTimelineSemaphoreFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceTimelineSemaphoreFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceTimelineSemaphoreFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( timelineSemaphore == rhs.timelineSemaphore );
    }

    bool operator!=( PhysicalDeviceTimelineSemaphoreFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceTimelineSemaphoreFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceTimelineSemaphoreFeaturesKHR ) == sizeof( VkPhysicalDeviceTimelineSemaphoreFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceTimelineSemaphoreFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceTimelineSemaphorePropertiesKHR
    {
    protected:
      PhysicalDeviceTimelineSemaphorePropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceTimelineSemaphorePropertiesKHR( VkPhysicalDeviceTimelineSemaphorePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTimelineSemaphorePropertiesKHR*>(this) = rhs;
      }

      PhysicalDeviceTimelineSemaphorePropertiesKHR& operator=( VkPhysicalDeviceTimelineSemaphorePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTimelineSemaphorePropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceTimelineSemaphorePropertiesKHR;
      void* pNext = nullptr;
      uint64_t maxTimelineSemaphoreValueDifference;
    };
    static_assert( sizeof( PhysicalDeviceTimelineSemaphorePropertiesKHR ) == sizeof( VkPhysicalDeviceTimelineSemaphorePropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceTimelineSemaphorePropertiesKHR : public layout::PhysicalDeviceTimelineSemaphorePropertiesKHR
  {
    PhysicalDeviceTimelineSemaphorePropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTimelineSemaphorePropertiesKHR()
    {}

    PhysicalDeviceTimelineSemaphorePropertiesKHR( VkPhysicalDeviceTimelineSemaphorePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTimelineSemaphorePropertiesKHR( rhs )
    {}

    PhysicalDeviceTimelineSemaphorePropertiesKHR& operator=( VkPhysicalDeviceTimelineSemaphorePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceTimelineSemaphorePropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceTimelineSemaphorePropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceTimelineSemaphorePropertiesKHR*>( this );
    }

    operator VkPhysicalDeviceTimelineSemaphorePropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceTimelineSemaphorePropertiesKHR*>( this );
    }

    bool operator==( PhysicalDeviceTimelineSemaphorePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxTimelineSemaphoreValueDifference == rhs.maxTimelineSemaphoreValueDifference );
    }

    bool operator!=( PhysicalDeviceTimelineSemaphorePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceTimelineSemaphorePropertiesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceTimelineSemaphorePropertiesKHR ) == sizeof( VkPhysicalDeviceTimelineSemaphorePropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceTimelineSemaphorePropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceTransformFeedbackFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceTransformFeedbackFeaturesEXT( vk::Bool32 transformFeedback_ = 0,
                                                                       vk::Bool32 geometryStreams_ = 0 ) VULKAN_HPP_NOEXCEPT
        : transformFeedback( transformFeedback_ )
        , geometryStreams( geometryStreams_ )
      {}

      PhysicalDeviceTransformFeedbackFeaturesEXT( VkPhysicalDeviceTransformFeedbackFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTransformFeedbackFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceTransformFeedbackFeaturesEXT& operator=( VkPhysicalDeviceTransformFeedbackFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTransformFeedbackFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceTransformFeedbackFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 transformFeedback;
      vk::Bool32 geometryStreams;
    };
    static_assert( sizeof( PhysicalDeviceTransformFeedbackFeaturesEXT ) == sizeof( VkPhysicalDeviceTransformFeedbackFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceTransformFeedbackFeaturesEXT : public layout::PhysicalDeviceTransformFeedbackFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceTransformFeedbackFeaturesEXT( vk::Bool32 transformFeedback_ = 0,
                                                                     vk::Bool32 geometryStreams_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTransformFeedbackFeaturesEXT( transformFeedback_, geometryStreams_ )
    {}

    PhysicalDeviceTransformFeedbackFeaturesEXT( VkPhysicalDeviceTransformFeedbackFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTransformFeedbackFeaturesEXT( rhs )
    {}

    PhysicalDeviceTransformFeedbackFeaturesEXT& operator=( VkPhysicalDeviceTransformFeedbackFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceTransformFeedbackFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceTransformFeedbackFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceTransformFeedbackFeaturesEXT & setTransformFeedback( vk::Bool32 transformFeedback_ ) VULKAN_HPP_NOEXCEPT
    {
      transformFeedback = transformFeedback_;
      return *this;
    }

    PhysicalDeviceTransformFeedbackFeaturesEXT & setGeometryStreams( vk::Bool32 geometryStreams_ ) VULKAN_HPP_NOEXCEPT
    {
      geometryStreams = geometryStreams_;
      return *this;
    }

    operator VkPhysicalDeviceTransformFeedbackFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceTransformFeedbackFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceTransformFeedbackFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceTransformFeedbackFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceTransformFeedbackFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( transformFeedback == rhs.transformFeedback )
          && ( geometryStreams == rhs.geometryStreams );
    }

    bool operator!=( PhysicalDeviceTransformFeedbackFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceTransformFeedbackFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceTransformFeedbackFeaturesEXT ) == sizeof( VkPhysicalDeviceTransformFeedbackFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceTransformFeedbackFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceTransformFeedbackPropertiesEXT
    {
    protected:
      PhysicalDeviceTransformFeedbackPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceTransformFeedbackPropertiesEXT( VkPhysicalDeviceTransformFeedbackPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTransformFeedbackPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceTransformFeedbackPropertiesEXT& operator=( VkPhysicalDeviceTransformFeedbackPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceTransformFeedbackPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceTransformFeedbackPropertiesEXT;
      void* pNext = nullptr;
      uint32_t maxTransformFeedbackStreams;
      uint32_t maxTransformFeedbackBuffers;
      vk::DeviceSize maxTransformFeedbackBufferSize;
      uint32_t maxTransformFeedbackStreamDataSize;
      uint32_t maxTransformFeedbackBufferDataSize;
      uint32_t maxTransformFeedbackBufferDataStride;
      vk::Bool32 transformFeedbackQueries;
      vk::Bool32 transformFeedbackStreamsLinesTriangles;
      vk::Bool32 transformFeedbackRasterizationStreamSelect;
      vk::Bool32 transformFeedbackDraw;
    };
    static_assert( sizeof( PhysicalDeviceTransformFeedbackPropertiesEXT ) == sizeof( VkPhysicalDeviceTransformFeedbackPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceTransformFeedbackPropertiesEXT : public layout::PhysicalDeviceTransformFeedbackPropertiesEXT
  {
    PhysicalDeviceTransformFeedbackPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTransformFeedbackPropertiesEXT()
    {}

    PhysicalDeviceTransformFeedbackPropertiesEXT( VkPhysicalDeviceTransformFeedbackPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceTransformFeedbackPropertiesEXT( rhs )
    {}

    PhysicalDeviceTransformFeedbackPropertiesEXT& operator=( VkPhysicalDeviceTransformFeedbackPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceTransformFeedbackPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceTransformFeedbackPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceTransformFeedbackPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceTransformFeedbackPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceTransformFeedbackPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceTransformFeedbackPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxTransformFeedbackStreams == rhs.maxTransformFeedbackStreams )
          && ( maxTransformFeedbackBuffers == rhs.maxTransformFeedbackBuffers )
          && ( maxTransformFeedbackBufferSize == rhs.maxTransformFeedbackBufferSize )
          && ( maxTransformFeedbackStreamDataSize == rhs.maxTransformFeedbackStreamDataSize )
          && ( maxTransformFeedbackBufferDataSize == rhs.maxTransformFeedbackBufferDataSize )
          && ( maxTransformFeedbackBufferDataStride == rhs.maxTransformFeedbackBufferDataStride )
          && ( transformFeedbackQueries == rhs.transformFeedbackQueries )
          && ( transformFeedbackStreamsLinesTriangles == rhs.transformFeedbackStreamsLinesTriangles )
          && ( transformFeedbackRasterizationStreamSelect == rhs.transformFeedbackRasterizationStreamSelect )
          && ( transformFeedbackDraw == rhs.transformFeedbackDraw );
    }

    bool operator!=( PhysicalDeviceTransformFeedbackPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceTransformFeedbackPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceTransformFeedbackPropertiesEXT ) == sizeof( VkPhysicalDeviceTransformFeedbackPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceTransformFeedbackPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR( vk::Bool32 uniformBufferStandardLayout_ = 0 ) VULKAN_HPP_NOEXCEPT
        : uniformBufferStandardLayout( uniformBufferStandardLayout_ )
      {}

      PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR( VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR& operator=( VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceUniformBufferStandardLayoutFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 uniformBufferStandardLayout;
    };
    static_assert( sizeof( PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR ) == sizeof( VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR : public layout::PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR( vk::Bool32 uniformBufferStandardLayout_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR( uniformBufferStandardLayout_ )
    {}

    PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR( VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR( rhs )
    {}

    PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR& operator=( VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR & setUniformBufferStandardLayout( vk::Bool32 uniformBufferStandardLayout_ ) VULKAN_HPP_NOEXCEPT
    {
      uniformBufferStandardLayout = uniformBufferStandardLayout_;
      return *this;
    }

    operator VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( uniformBufferStandardLayout == rhs.uniformBufferStandardLayout );
    }

    bool operator!=( PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR ) == sizeof( VkPhysicalDeviceUniformBufferStandardLayoutFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceVariablePointersFeatures
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceVariablePointersFeatures( vk::Bool32 variablePointersStorageBuffer_ = 0,
                                                                   vk::Bool32 variablePointers_ = 0 ) VULKAN_HPP_NOEXCEPT
        : variablePointersStorageBuffer( variablePointersStorageBuffer_ )
        , variablePointers( variablePointers_ )
      {}

      PhysicalDeviceVariablePointersFeatures( VkPhysicalDeviceVariablePointersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVariablePointersFeatures*>(this) = rhs;
      }

      PhysicalDeviceVariablePointersFeatures& operator=( VkPhysicalDeviceVariablePointersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVariablePointersFeatures*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceVariablePointersFeatures;
      void* pNext = nullptr;
      vk::Bool32 variablePointersStorageBuffer;
      vk::Bool32 variablePointers;
    };
    static_assert( sizeof( PhysicalDeviceVariablePointersFeatures ) == sizeof( VkPhysicalDeviceVariablePointersFeatures ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceVariablePointersFeatures : public layout::PhysicalDeviceVariablePointersFeatures
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceVariablePointersFeatures( vk::Bool32 variablePointersStorageBuffer_ = 0,
                                                                 vk::Bool32 variablePointers_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVariablePointersFeatures( variablePointersStorageBuffer_, variablePointers_ )
    {}

    PhysicalDeviceVariablePointersFeatures( VkPhysicalDeviceVariablePointersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVariablePointersFeatures( rhs )
    {}

    PhysicalDeviceVariablePointersFeatures& operator=( VkPhysicalDeviceVariablePointersFeatures const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceVariablePointersFeatures::operator=(rhs);
      return *this;
    }

    PhysicalDeviceVariablePointersFeatures & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceVariablePointersFeatures & setVariablePointersStorageBuffer( vk::Bool32 variablePointersStorageBuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      variablePointersStorageBuffer = variablePointersStorageBuffer_;
      return *this;
    }

    PhysicalDeviceVariablePointersFeatures & setVariablePointers( vk::Bool32 variablePointers_ ) VULKAN_HPP_NOEXCEPT
    {
      variablePointers = variablePointers_;
      return *this;
    }

    operator VkPhysicalDeviceVariablePointersFeatures const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceVariablePointersFeatures*>( this );
    }

    operator VkPhysicalDeviceVariablePointersFeatures &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceVariablePointersFeatures*>( this );
    }

    bool operator==( PhysicalDeviceVariablePointersFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( variablePointersStorageBuffer == rhs.variablePointersStorageBuffer )
          && ( variablePointers == rhs.variablePointers );
    }

    bool operator!=( PhysicalDeviceVariablePointersFeatures const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceVariablePointersFeatures::sType;
  };
  static_assert( sizeof( PhysicalDeviceVariablePointersFeatures ) == sizeof( VkPhysicalDeviceVariablePointersFeatures ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceVariablePointersFeatures>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceVertexAttributeDivisorFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceVertexAttributeDivisorFeaturesEXT( vk::Bool32 vertexAttributeInstanceRateDivisor_ = 0,
                                                                            vk::Bool32 vertexAttributeInstanceRateZeroDivisor_ = 0 ) VULKAN_HPP_NOEXCEPT
        : vertexAttributeInstanceRateDivisor( vertexAttributeInstanceRateDivisor_ )
        , vertexAttributeInstanceRateZeroDivisor( vertexAttributeInstanceRateZeroDivisor_ )
      {}

      PhysicalDeviceVertexAttributeDivisorFeaturesEXT( VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceVertexAttributeDivisorFeaturesEXT& operator=( VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceVertexAttributeDivisorFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 vertexAttributeInstanceRateDivisor;
      vk::Bool32 vertexAttributeInstanceRateZeroDivisor;
    };
    static_assert( sizeof( PhysicalDeviceVertexAttributeDivisorFeaturesEXT ) == sizeof( VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceVertexAttributeDivisorFeaturesEXT : public layout::PhysicalDeviceVertexAttributeDivisorFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceVertexAttributeDivisorFeaturesEXT( vk::Bool32 vertexAttributeInstanceRateDivisor_ = 0,
                                                                          vk::Bool32 vertexAttributeInstanceRateZeroDivisor_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVertexAttributeDivisorFeaturesEXT( vertexAttributeInstanceRateDivisor_, vertexAttributeInstanceRateZeroDivisor_ )
    {}

    PhysicalDeviceVertexAttributeDivisorFeaturesEXT( VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVertexAttributeDivisorFeaturesEXT( rhs )
    {}

    PhysicalDeviceVertexAttributeDivisorFeaturesEXT& operator=( VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceVertexAttributeDivisorFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceVertexAttributeDivisorFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceVertexAttributeDivisorFeaturesEXT & setVertexAttributeInstanceRateDivisor( vk::Bool32 vertexAttributeInstanceRateDivisor_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexAttributeInstanceRateDivisor = vertexAttributeInstanceRateDivisor_;
      return *this;
    }

    PhysicalDeviceVertexAttributeDivisorFeaturesEXT & setVertexAttributeInstanceRateZeroDivisor( vk::Bool32 vertexAttributeInstanceRateZeroDivisor_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexAttributeInstanceRateZeroDivisor = vertexAttributeInstanceRateZeroDivisor_;
      return *this;
    }

    operator VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceVertexAttributeDivisorFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( vertexAttributeInstanceRateDivisor == rhs.vertexAttributeInstanceRateDivisor )
          && ( vertexAttributeInstanceRateZeroDivisor == rhs.vertexAttributeInstanceRateZeroDivisor );
    }

    bool operator!=( PhysicalDeviceVertexAttributeDivisorFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceVertexAttributeDivisorFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceVertexAttributeDivisorFeaturesEXT ) == sizeof( VkPhysicalDeviceVertexAttributeDivisorFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceVertexAttributeDivisorFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceVertexAttributeDivisorPropertiesEXT
    {
    protected:
      PhysicalDeviceVertexAttributeDivisorPropertiesEXT() VULKAN_HPP_NOEXCEPT
      {}

      PhysicalDeviceVertexAttributeDivisorPropertiesEXT( VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT*>(this) = rhs;
      }

      PhysicalDeviceVertexAttributeDivisorPropertiesEXT& operator=( VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceVertexAttributeDivisorPropertiesEXT;
      void* pNext = nullptr;
      uint32_t maxVertexAttribDivisor;
    };
    static_assert( sizeof( PhysicalDeviceVertexAttributeDivisorPropertiesEXT ) == sizeof( VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceVertexAttributeDivisorPropertiesEXT : public layout::PhysicalDeviceVertexAttributeDivisorPropertiesEXT
  {
    PhysicalDeviceVertexAttributeDivisorPropertiesEXT() VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVertexAttributeDivisorPropertiesEXT()
    {}

    PhysicalDeviceVertexAttributeDivisorPropertiesEXT( VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVertexAttributeDivisorPropertiesEXT( rhs )
    {}

    PhysicalDeviceVertexAttributeDivisorPropertiesEXT& operator=( VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceVertexAttributeDivisorPropertiesEXT::operator=(rhs);
      return *this;
    }

    operator VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT*>( this );
    }

    operator VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT*>( this );
    }

    bool operator==( PhysicalDeviceVertexAttributeDivisorPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( maxVertexAttribDivisor == rhs.maxVertexAttribDivisor );
    }

    bool operator!=( PhysicalDeviceVertexAttributeDivisorPropertiesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceVertexAttributeDivisorPropertiesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceVertexAttributeDivisorPropertiesEXT ) == sizeof( VkPhysicalDeviceVertexAttributeDivisorPropertiesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceVertexAttributeDivisorPropertiesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceVulkanMemoryModelFeaturesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceVulkanMemoryModelFeaturesKHR( vk::Bool32 vulkanMemoryModel_ = 0,
                                                                       vk::Bool32 vulkanMemoryModelDeviceScope_ = 0,
                                                                       vk::Bool32 vulkanMemoryModelAvailabilityVisibilityChains_ = 0 ) VULKAN_HPP_NOEXCEPT
        : vulkanMemoryModel( vulkanMemoryModel_ )
        , vulkanMemoryModelDeviceScope( vulkanMemoryModelDeviceScope_ )
        , vulkanMemoryModelAvailabilityVisibilityChains( vulkanMemoryModelAvailabilityVisibilityChains_ )
      {}

      PhysicalDeviceVulkanMemoryModelFeaturesKHR( VkPhysicalDeviceVulkanMemoryModelFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVulkanMemoryModelFeaturesKHR*>(this) = rhs;
      }

      PhysicalDeviceVulkanMemoryModelFeaturesKHR& operator=( VkPhysicalDeviceVulkanMemoryModelFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceVulkanMemoryModelFeaturesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceVulkanMemoryModelFeaturesKHR;
      void* pNext = nullptr;
      vk::Bool32 vulkanMemoryModel;
      vk::Bool32 vulkanMemoryModelDeviceScope;
      vk::Bool32 vulkanMemoryModelAvailabilityVisibilityChains;
    };
    static_assert( sizeof( PhysicalDeviceVulkanMemoryModelFeaturesKHR ) == sizeof( VkPhysicalDeviceVulkanMemoryModelFeaturesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceVulkanMemoryModelFeaturesKHR : public layout::PhysicalDeviceVulkanMemoryModelFeaturesKHR
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceVulkanMemoryModelFeaturesKHR( vk::Bool32 vulkanMemoryModel_ = 0,
                                                                     vk::Bool32 vulkanMemoryModelDeviceScope_ = 0,
                                                                     vk::Bool32 vulkanMemoryModelAvailabilityVisibilityChains_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVulkanMemoryModelFeaturesKHR( vulkanMemoryModel_, vulkanMemoryModelDeviceScope_, vulkanMemoryModelAvailabilityVisibilityChains_ )
    {}

    PhysicalDeviceVulkanMemoryModelFeaturesKHR( VkPhysicalDeviceVulkanMemoryModelFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceVulkanMemoryModelFeaturesKHR( rhs )
    {}

    PhysicalDeviceVulkanMemoryModelFeaturesKHR& operator=( VkPhysicalDeviceVulkanMemoryModelFeaturesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceVulkanMemoryModelFeaturesKHR::operator=(rhs);
      return *this;
    }

    PhysicalDeviceVulkanMemoryModelFeaturesKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceVulkanMemoryModelFeaturesKHR & setVulkanMemoryModel( vk::Bool32 vulkanMemoryModel_ ) VULKAN_HPP_NOEXCEPT
    {
      vulkanMemoryModel = vulkanMemoryModel_;
      return *this;
    }

    PhysicalDeviceVulkanMemoryModelFeaturesKHR & setVulkanMemoryModelDeviceScope( vk::Bool32 vulkanMemoryModelDeviceScope_ ) VULKAN_HPP_NOEXCEPT
    {
      vulkanMemoryModelDeviceScope = vulkanMemoryModelDeviceScope_;
      return *this;
    }

    PhysicalDeviceVulkanMemoryModelFeaturesKHR & setVulkanMemoryModelAvailabilityVisibilityChains( vk::Bool32 vulkanMemoryModelAvailabilityVisibilityChains_ ) VULKAN_HPP_NOEXCEPT
    {
      vulkanMemoryModelAvailabilityVisibilityChains = vulkanMemoryModelAvailabilityVisibilityChains_;
      return *this;
    }

    operator VkPhysicalDeviceVulkanMemoryModelFeaturesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceVulkanMemoryModelFeaturesKHR*>( this );
    }

    operator VkPhysicalDeviceVulkanMemoryModelFeaturesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceVulkanMemoryModelFeaturesKHR*>( this );
    }

    bool operator==( PhysicalDeviceVulkanMemoryModelFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( vulkanMemoryModel == rhs.vulkanMemoryModel )
          && ( vulkanMemoryModelDeviceScope == rhs.vulkanMemoryModelDeviceScope )
          && ( vulkanMemoryModelAvailabilityVisibilityChains == rhs.vulkanMemoryModelAvailabilityVisibilityChains );
    }

    bool operator!=( PhysicalDeviceVulkanMemoryModelFeaturesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceVulkanMemoryModelFeaturesKHR::sType;
  };
  static_assert( sizeof( PhysicalDeviceVulkanMemoryModelFeaturesKHR ) == sizeof( VkPhysicalDeviceVulkanMemoryModelFeaturesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceVulkanMemoryModelFeaturesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PhysicalDeviceYcbcrImageArraysFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PhysicalDeviceYcbcrImageArraysFeaturesEXT( vk::Bool32 ycbcrImageArrays_ = 0 ) VULKAN_HPP_NOEXCEPT
        : ycbcrImageArrays( ycbcrImageArrays_ )
      {}

      PhysicalDeviceYcbcrImageArraysFeaturesEXT( VkPhysicalDeviceYcbcrImageArraysFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceYcbcrImageArraysFeaturesEXT*>(this) = rhs;
      }

      PhysicalDeviceYcbcrImageArraysFeaturesEXT& operator=( VkPhysicalDeviceYcbcrImageArraysFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPhysicalDeviceYcbcrImageArraysFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePhysicalDeviceYcbcrImageArraysFeaturesEXT;
      void* pNext = nullptr;
      vk::Bool32 ycbcrImageArrays;
    };
    static_assert( sizeof( PhysicalDeviceYcbcrImageArraysFeaturesEXT ) == sizeof( VkPhysicalDeviceYcbcrImageArraysFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct PhysicalDeviceYcbcrImageArraysFeaturesEXT : public layout::PhysicalDeviceYcbcrImageArraysFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR PhysicalDeviceYcbcrImageArraysFeaturesEXT( vk::Bool32 ycbcrImageArrays_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceYcbcrImageArraysFeaturesEXT( ycbcrImageArrays_ )
    {}

    PhysicalDeviceYcbcrImageArraysFeaturesEXT( VkPhysicalDeviceYcbcrImageArraysFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PhysicalDeviceYcbcrImageArraysFeaturesEXT( rhs )
    {}

    PhysicalDeviceYcbcrImageArraysFeaturesEXT& operator=( VkPhysicalDeviceYcbcrImageArraysFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PhysicalDeviceYcbcrImageArraysFeaturesEXT::operator=(rhs);
      return *this;
    }

    PhysicalDeviceYcbcrImageArraysFeaturesEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PhysicalDeviceYcbcrImageArraysFeaturesEXT & setYcbcrImageArrays( vk::Bool32 ycbcrImageArrays_ ) VULKAN_HPP_NOEXCEPT
    {
      ycbcrImageArrays = ycbcrImageArrays_;
      return *this;
    }

    operator VkPhysicalDeviceYcbcrImageArraysFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPhysicalDeviceYcbcrImageArraysFeaturesEXT*>( this );
    }

    operator VkPhysicalDeviceYcbcrImageArraysFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPhysicalDeviceYcbcrImageArraysFeaturesEXT*>( this );
    }

    bool operator==( PhysicalDeviceYcbcrImageArraysFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( ycbcrImageArrays == rhs.ycbcrImageArrays );
    }

    bool operator!=( PhysicalDeviceYcbcrImageArraysFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PhysicalDeviceYcbcrImageArraysFeaturesEXT::sType;
  };
  static_assert( sizeof( PhysicalDeviceYcbcrImageArraysFeaturesEXT ) == sizeof( VkPhysicalDeviceYcbcrImageArraysFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PhysicalDeviceYcbcrImageArraysFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineCacheCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineCacheCreateInfo( vk::PipelineCacheCreateFlags flags_ = vk::PipelineCacheCreateFlags(),
                                                    size_t initialDataSize_ = 0,
                                                    const void* pInitialData_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , initialDataSize( initialDataSize_ )
        , pInitialData( pInitialData_ )
      {}

      PipelineCacheCreateInfo( VkPipelineCacheCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCacheCreateInfo*>(this) = rhs;
      }

      PipelineCacheCreateInfo& operator=( VkPipelineCacheCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCacheCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineCacheCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineCacheCreateFlags flags;
      size_t initialDataSize;
      const void* pInitialData;
    };
    static_assert( sizeof( PipelineCacheCreateInfo ) == sizeof( VkPipelineCacheCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineCacheCreateInfo : public layout::PipelineCacheCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineCacheCreateInfo( vk::PipelineCacheCreateFlags flags_ = vk::PipelineCacheCreateFlags(),
                                                  size_t initialDataSize_ = 0,
                                                  const void* pInitialData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCacheCreateInfo( flags_, initialDataSize_, pInitialData_ )
    {}

    PipelineCacheCreateInfo( VkPipelineCacheCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCacheCreateInfo( rhs )
    {}

    PipelineCacheCreateInfo& operator=( VkPipelineCacheCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineCacheCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineCacheCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineCacheCreateInfo & setFlags( vk::PipelineCacheCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineCacheCreateInfo & setInitialDataSize( size_t initialDataSize_ ) VULKAN_HPP_NOEXCEPT
    {
      initialDataSize = initialDataSize_;
      return *this;
    }

    PipelineCacheCreateInfo & setPInitialData( const void* pInitialData_ ) VULKAN_HPP_NOEXCEPT
    {
      pInitialData = pInitialData_;
      return *this;
    }

    operator VkPipelineCacheCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineCacheCreateInfo*>( this );
    }

    operator VkPipelineCacheCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineCacheCreateInfo*>( this );
    }

    bool operator==( PipelineCacheCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( initialDataSize == rhs.initialDataSize )
          && ( pInitialData == rhs.pInitialData );
    }

    bool operator!=( PipelineCacheCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineCacheCreateInfo::sType;
  };
  static_assert( sizeof( PipelineCacheCreateInfo ) == sizeof( VkPipelineCacheCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineCacheCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineColorBlendAdvancedStateCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineColorBlendAdvancedStateCreateInfoEXT( vk::Bool32 srcPremultiplied_ = 0,
                                                                         vk::Bool32 dstPremultiplied_ = 0,
                                                                         vk::BlendOverlapEXT blendOverlap_ = vk::BlendOverlapEXT::eUncorrelated ) VULKAN_HPP_NOEXCEPT
        : srcPremultiplied( srcPremultiplied_ )
        , dstPremultiplied( dstPremultiplied_ )
        , blendOverlap( blendOverlap_ )
      {}

      PipelineColorBlendAdvancedStateCreateInfoEXT( VkPipelineColorBlendAdvancedStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineColorBlendAdvancedStateCreateInfoEXT*>(this) = rhs;
      }

      PipelineColorBlendAdvancedStateCreateInfoEXT& operator=( VkPipelineColorBlendAdvancedStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineColorBlendAdvancedStateCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineColorBlendAdvancedStateCreateInfoEXT;
      const void* pNext = nullptr;
      vk::Bool32 srcPremultiplied;
      vk::Bool32 dstPremultiplied;
      vk::BlendOverlapEXT blendOverlap;
    };
    static_assert( sizeof( PipelineColorBlendAdvancedStateCreateInfoEXT ) == sizeof( VkPipelineColorBlendAdvancedStateCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineColorBlendAdvancedStateCreateInfoEXT : public layout::PipelineColorBlendAdvancedStateCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineColorBlendAdvancedStateCreateInfoEXT( vk::Bool32 srcPremultiplied_ = 0,
                                                                       vk::Bool32 dstPremultiplied_ = 0,
                                                                       vk::BlendOverlapEXT blendOverlap_ = vk::BlendOverlapEXT::eUncorrelated ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineColorBlendAdvancedStateCreateInfoEXT( srcPremultiplied_, dstPremultiplied_, blendOverlap_ )
    {}

    PipelineColorBlendAdvancedStateCreateInfoEXT( VkPipelineColorBlendAdvancedStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineColorBlendAdvancedStateCreateInfoEXT( rhs )
    {}

    PipelineColorBlendAdvancedStateCreateInfoEXT& operator=( VkPipelineColorBlendAdvancedStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineColorBlendAdvancedStateCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineColorBlendAdvancedStateCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineColorBlendAdvancedStateCreateInfoEXT & setSrcPremultiplied( vk::Bool32 srcPremultiplied_ ) VULKAN_HPP_NOEXCEPT
    {
      srcPremultiplied = srcPremultiplied_;
      return *this;
    }

    PipelineColorBlendAdvancedStateCreateInfoEXT & setDstPremultiplied( vk::Bool32 dstPremultiplied_ ) VULKAN_HPP_NOEXCEPT
    {
      dstPremultiplied = dstPremultiplied_;
      return *this;
    }

    PipelineColorBlendAdvancedStateCreateInfoEXT & setBlendOverlap( vk::BlendOverlapEXT blendOverlap_ ) VULKAN_HPP_NOEXCEPT
    {
      blendOverlap = blendOverlap_;
      return *this;
    }

    operator VkPipelineColorBlendAdvancedStateCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineColorBlendAdvancedStateCreateInfoEXT*>( this );
    }

    operator VkPipelineColorBlendAdvancedStateCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineColorBlendAdvancedStateCreateInfoEXT*>( this );
    }

    bool operator==( PipelineColorBlendAdvancedStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( srcPremultiplied == rhs.srcPremultiplied )
          && ( dstPremultiplied == rhs.dstPremultiplied )
          && ( blendOverlap == rhs.blendOverlap );
    }

    bool operator!=( PipelineColorBlendAdvancedStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineColorBlendAdvancedStateCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineColorBlendAdvancedStateCreateInfoEXT ) == sizeof( VkPipelineColorBlendAdvancedStateCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineColorBlendAdvancedStateCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineCompilerControlCreateInfoAMD
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineCompilerControlCreateInfoAMD( vk::PipelineCompilerControlFlagsAMD compilerControlFlags_ = vk::PipelineCompilerControlFlagsAMD() ) VULKAN_HPP_NOEXCEPT
        : compilerControlFlags( compilerControlFlags_ )
      {}

      PipelineCompilerControlCreateInfoAMD( VkPipelineCompilerControlCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCompilerControlCreateInfoAMD*>(this) = rhs;
      }

      PipelineCompilerControlCreateInfoAMD& operator=( VkPipelineCompilerControlCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCompilerControlCreateInfoAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineCompilerControlCreateInfoAMD;
      const void* pNext = nullptr;
      vk::PipelineCompilerControlFlagsAMD compilerControlFlags;
    };
    static_assert( sizeof( PipelineCompilerControlCreateInfoAMD ) == sizeof( VkPipelineCompilerControlCreateInfoAMD ), "layout struct and wrapper have different size!" );
  }

  struct PipelineCompilerControlCreateInfoAMD : public layout::PipelineCompilerControlCreateInfoAMD
  {
    VULKAN_HPP_CONSTEXPR PipelineCompilerControlCreateInfoAMD( vk::PipelineCompilerControlFlagsAMD compilerControlFlags_ = vk::PipelineCompilerControlFlagsAMD() ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCompilerControlCreateInfoAMD( compilerControlFlags_ )
    {}

    PipelineCompilerControlCreateInfoAMD( VkPipelineCompilerControlCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCompilerControlCreateInfoAMD( rhs )
    {}

    PipelineCompilerControlCreateInfoAMD& operator=( VkPipelineCompilerControlCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineCompilerControlCreateInfoAMD::operator=(rhs);
      return *this;
    }

    PipelineCompilerControlCreateInfoAMD & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineCompilerControlCreateInfoAMD & setCompilerControlFlags( vk::PipelineCompilerControlFlagsAMD compilerControlFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      compilerControlFlags = compilerControlFlags_;
      return *this;
    }

    operator VkPipelineCompilerControlCreateInfoAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineCompilerControlCreateInfoAMD*>( this );
    }

    operator VkPipelineCompilerControlCreateInfoAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineCompilerControlCreateInfoAMD*>( this );
    }

    bool operator==( PipelineCompilerControlCreateInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( compilerControlFlags == rhs.compilerControlFlags );
    }

    bool operator!=( PipelineCompilerControlCreateInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineCompilerControlCreateInfoAMD::sType;
  };
  static_assert( sizeof( PipelineCompilerControlCreateInfoAMD ) == sizeof( VkPipelineCompilerControlCreateInfoAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineCompilerControlCreateInfoAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineCoverageModulationStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineCoverageModulationStateCreateInfoNV( vk::PipelineCoverageModulationStateCreateFlagsNV flags_ = vk::PipelineCoverageModulationStateCreateFlagsNV(),
                                                                        vk::CoverageModulationModeNV coverageModulationMode_ = vk::CoverageModulationModeNV::eNone,
                                                                        vk::Bool32 coverageModulationTableEnable_ = 0,
                                                                        uint32_t coverageModulationTableCount_ = 0,
                                                                        const float* pCoverageModulationTable_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , coverageModulationMode( coverageModulationMode_ )
        , coverageModulationTableEnable( coverageModulationTableEnable_ )
        , coverageModulationTableCount( coverageModulationTableCount_ )
        , pCoverageModulationTable( pCoverageModulationTable_ )
      {}

      PipelineCoverageModulationStateCreateInfoNV( VkPipelineCoverageModulationStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCoverageModulationStateCreateInfoNV*>(this) = rhs;
      }

      PipelineCoverageModulationStateCreateInfoNV& operator=( VkPipelineCoverageModulationStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCoverageModulationStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineCoverageModulationStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::PipelineCoverageModulationStateCreateFlagsNV flags;
      vk::CoverageModulationModeNV coverageModulationMode;
      vk::Bool32 coverageModulationTableEnable;
      uint32_t coverageModulationTableCount;
      const float* pCoverageModulationTable;
    };
    static_assert( sizeof( PipelineCoverageModulationStateCreateInfoNV ) == sizeof( VkPipelineCoverageModulationStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineCoverageModulationStateCreateInfoNV : public layout::PipelineCoverageModulationStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineCoverageModulationStateCreateInfoNV( vk::PipelineCoverageModulationStateCreateFlagsNV flags_ = vk::PipelineCoverageModulationStateCreateFlagsNV(),
                                                                      vk::CoverageModulationModeNV coverageModulationMode_ = vk::CoverageModulationModeNV::eNone,
                                                                      vk::Bool32 coverageModulationTableEnable_ = 0,
                                                                      uint32_t coverageModulationTableCount_ = 0,
                                                                      const float* pCoverageModulationTable_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCoverageModulationStateCreateInfoNV( flags_, coverageModulationMode_, coverageModulationTableEnable_, coverageModulationTableCount_, pCoverageModulationTable_ )
    {}

    PipelineCoverageModulationStateCreateInfoNV( VkPipelineCoverageModulationStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCoverageModulationStateCreateInfoNV( rhs )
    {}

    PipelineCoverageModulationStateCreateInfoNV& operator=( VkPipelineCoverageModulationStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineCoverageModulationStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineCoverageModulationStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineCoverageModulationStateCreateInfoNV & setFlags( vk::PipelineCoverageModulationStateCreateFlagsNV flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineCoverageModulationStateCreateInfoNV & setCoverageModulationMode( vk::CoverageModulationModeNV coverageModulationMode_ ) VULKAN_HPP_NOEXCEPT
    {
      coverageModulationMode = coverageModulationMode_;
      return *this;
    }

    PipelineCoverageModulationStateCreateInfoNV & setCoverageModulationTableEnable( vk::Bool32 coverageModulationTableEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      coverageModulationTableEnable = coverageModulationTableEnable_;
      return *this;
    }

    PipelineCoverageModulationStateCreateInfoNV & setCoverageModulationTableCount( uint32_t coverageModulationTableCount_ ) VULKAN_HPP_NOEXCEPT
    {
      coverageModulationTableCount = coverageModulationTableCount_;
      return *this;
    }

    PipelineCoverageModulationStateCreateInfoNV & setPCoverageModulationTable( const float* pCoverageModulationTable_ ) VULKAN_HPP_NOEXCEPT
    {
      pCoverageModulationTable = pCoverageModulationTable_;
      return *this;
    }

    operator VkPipelineCoverageModulationStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineCoverageModulationStateCreateInfoNV*>( this );
    }

    operator VkPipelineCoverageModulationStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineCoverageModulationStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineCoverageModulationStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( coverageModulationMode == rhs.coverageModulationMode )
          && ( coverageModulationTableEnable == rhs.coverageModulationTableEnable )
          && ( coverageModulationTableCount == rhs.coverageModulationTableCount )
          && ( pCoverageModulationTable == rhs.pCoverageModulationTable );
    }

    bool operator!=( PipelineCoverageModulationStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineCoverageModulationStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineCoverageModulationStateCreateInfoNV ) == sizeof( VkPipelineCoverageModulationStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineCoverageModulationStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineCoverageReductionStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineCoverageReductionStateCreateInfoNV( vk::PipelineCoverageReductionStateCreateFlagsNV flags_ = vk::PipelineCoverageReductionStateCreateFlagsNV(),
                                                                       vk::CoverageReductionModeNV coverageReductionMode_ = vk::CoverageReductionModeNV::eMerge ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , coverageReductionMode( coverageReductionMode_ )
      {}

      PipelineCoverageReductionStateCreateInfoNV( VkPipelineCoverageReductionStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCoverageReductionStateCreateInfoNV*>(this) = rhs;
      }

      PipelineCoverageReductionStateCreateInfoNV& operator=( VkPipelineCoverageReductionStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCoverageReductionStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineCoverageReductionStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::PipelineCoverageReductionStateCreateFlagsNV flags;
      vk::CoverageReductionModeNV coverageReductionMode;
    };
    static_assert( sizeof( PipelineCoverageReductionStateCreateInfoNV ) == sizeof( VkPipelineCoverageReductionStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineCoverageReductionStateCreateInfoNV : public layout::PipelineCoverageReductionStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineCoverageReductionStateCreateInfoNV( vk::PipelineCoverageReductionStateCreateFlagsNV flags_ = vk::PipelineCoverageReductionStateCreateFlagsNV(),
                                                                     vk::CoverageReductionModeNV coverageReductionMode_ = vk::CoverageReductionModeNV::eMerge ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCoverageReductionStateCreateInfoNV( flags_, coverageReductionMode_ )
    {}

    PipelineCoverageReductionStateCreateInfoNV( VkPipelineCoverageReductionStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCoverageReductionStateCreateInfoNV( rhs )
    {}

    PipelineCoverageReductionStateCreateInfoNV& operator=( VkPipelineCoverageReductionStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineCoverageReductionStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineCoverageReductionStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineCoverageReductionStateCreateInfoNV & setFlags( vk::PipelineCoverageReductionStateCreateFlagsNV flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineCoverageReductionStateCreateInfoNV & setCoverageReductionMode( vk::CoverageReductionModeNV coverageReductionMode_ ) VULKAN_HPP_NOEXCEPT
    {
      coverageReductionMode = coverageReductionMode_;
      return *this;
    }

    operator VkPipelineCoverageReductionStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineCoverageReductionStateCreateInfoNV*>( this );
    }

    operator VkPipelineCoverageReductionStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineCoverageReductionStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineCoverageReductionStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( coverageReductionMode == rhs.coverageReductionMode );
    }

    bool operator!=( PipelineCoverageReductionStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineCoverageReductionStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineCoverageReductionStateCreateInfoNV ) == sizeof( VkPipelineCoverageReductionStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineCoverageReductionStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineCoverageToColorStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineCoverageToColorStateCreateInfoNV( vk::PipelineCoverageToColorStateCreateFlagsNV flags_ = vk::PipelineCoverageToColorStateCreateFlagsNV(),
                                                                     vk::Bool32 coverageToColorEnable_ = 0,
                                                                     uint32_t coverageToColorLocation_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , coverageToColorEnable( coverageToColorEnable_ )
        , coverageToColorLocation( coverageToColorLocation_ )
      {}

      PipelineCoverageToColorStateCreateInfoNV( VkPipelineCoverageToColorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCoverageToColorStateCreateInfoNV*>(this) = rhs;
      }

      PipelineCoverageToColorStateCreateInfoNV& operator=( VkPipelineCoverageToColorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCoverageToColorStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineCoverageToColorStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::PipelineCoverageToColorStateCreateFlagsNV flags;
      vk::Bool32 coverageToColorEnable;
      uint32_t coverageToColorLocation;
    };
    static_assert( sizeof( PipelineCoverageToColorStateCreateInfoNV ) == sizeof( VkPipelineCoverageToColorStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineCoverageToColorStateCreateInfoNV : public layout::PipelineCoverageToColorStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineCoverageToColorStateCreateInfoNV( vk::PipelineCoverageToColorStateCreateFlagsNV flags_ = vk::PipelineCoverageToColorStateCreateFlagsNV(),
                                                                   vk::Bool32 coverageToColorEnable_ = 0,
                                                                   uint32_t coverageToColorLocation_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCoverageToColorStateCreateInfoNV( flags_, coverageToColorEnable_, coverageToColorLocation_ )
    {}

    PipelineCoverageToColorStateCreateInfoNV( VkPipelineCoverageToColorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCoverageToColorStateCreateInfoNV( rhs )
    {}

    PipelineCoverageToColorStateCreateInfoNV& operator=( VkPipelineCoverageToColorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineCoverageToColorStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineCoverageToColorStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineCoverageToColorStateCreateInfoNV & setFlags( vk::PipelineCoverageToColorStateCreateFlagsNV flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineCoverageToColorStateCreateInfoNV & setCoverageToColorEnable( vk::Bool32 coverageToColorEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      coverageToColorEnable = coverageToColorEnable_;
      return *this;
    }

    PipelineCoverageToColorStateCreateInfoNV & setCoverageToColorLocation( uint32_t coverageToColorLocation_ ) VULKAN_HPP_NOEXCEPT
    {
      coverageToColorLocation = coverageToColorLocation_;
      return *this;
    }

    operator VkPipelineCoverageToColorStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineCoverageToColorStateCreateInfoNV*>( this );
    }

    operator VkPipelineCoverageToColorStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineCoverageToColorStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineCoverageToColorStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( coverageToColorEnable == rhs.coverageToColorEnable )
          && ( coverageToColorLocation == rhs.coverageToColorLocation );
    }

    bool operator!=( PipelineCoverageToColorStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineCoverageToColorStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineCoverageToColorStateCreateInfoNV ) == sizeof( VkPipelineCoverageToColorStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineCoverageToColorStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  struct PipelineCreationFeedbackEXT
  {
    PipelineCreationFeedbackEXT() VULKAN_HPP_NOEXCEPT
    {}

    PipelineCreationFeedbackEXT( VkPipelineCreationFeedbackEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPipelineCreationFeedbackEXT*>(this) = rhs;
    }

    PipelineCreationFeedbackEXT& operator=( VkPipelineCreationFeedbackEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPipelineCreationFeedbackEXT*>(this) = rhs;
      return *this;
    }

    operator VkPipelineCreationFeedbackEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineCreationFeedbackEXT*>( this );
    }

    operator VkPipelineCreationFeedbackEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineCreationFeedbackEXT*>( this );
    }

    bool operator==( PipelineCreationFeedbackEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( flags == rhs.flags )
          && ( duration == rhs.duration );
    }

    bool operator!=( PipelineCreationFeedbackEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::PipelineCreationFeedbackFlagsEXT flags;
    uint64_t duration;
  };
  static_assert( sizeof( PipelineCreationFeedbackEXT ) == sizeof( VkPipelineCreationFeedbackEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineCreationFeedbackEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineCreationFeedbackCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineCreationFeedbackCreateInfoEXT( vk::PipelineCreationFeedbackEXT* pPipelineCreationFeedback_ = nullptr,
                                                                  uint32_t pipelineStageCreationFeedbackCount_ = 0,
                                                                  vk::PipelineCreationFeedbackEXT* pPipelineStageCreationFeedbacks_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : pPipelineCreationFeedback( pPipelineCreationFeedback_ )
        , pipelineStageCreationFeedbackCount( pipelineStageCreationFeedbackCount_ )
        , pPipelineStageCreationFeedbacks( pPipelineStageCreationFeedbacks_ )
      {}

      PipelineCreationFeedbackCreateInfoEXT( VkPipelineCreationFeedbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCreationFeedbackCreateInfoEXT*>(this) = rhs;
      }

      PipelineCreationFeedbackCreateInfoEXT& operator=( VkPipelineCreationFeedbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineCreationFeedbackCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineCreationFeedbackCreateInfoEXT;
      const void* pNext = nullptr;
      vk::PipelineCreationFeedbackEXT* pPipelineCreationFeedback;
      uint32_t pipelineStageCreationFeedbackCount;
      vk::PipelineCreationFeedbackEXT* pPipelineStageCreationFeedbacks;
    };
    static_assert( sizeof( PipelineCreationFeedbackCreateInfoEXT ) == sizeof( VkPipelineCreationFeedbackCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineCreationFeedbackCreateInfoEXT : public layout::PipelineCreationFeedbackCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineCreationFeedbackCreateInfoEXT( vk::PipelineCreationFeedbackEXT* pPipelineCreationFeedback_ = nullptr,
                                                                uint32_t pipelineStageCreationFeedbackCount_ = 0,
                                                                vk::PipelineCreationFeedbackEXT* pPipelineStageCreationFeedbacks_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCreationFeedbackCreateInfoEXT( pPipelineCreationFeedback_, pipelineStageCreationFeedbackCount_, pPipelineStageCreationFeedbacks_ )
    {}

    PipelineCreationFeedbackCreateInfoEXT( VkPipelineCreationFeedbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineCreationFeedbackCreateInfoEXT( rhs )
    {}

    PipelineCreationFeedbackCreateInfoEXT& operator=( VkPipelineCreationFeedbackCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineCreationFeedbackCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineCreationFeedbackCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineCreationFeedbackCreateInfoEXT & setPPipelineCreationFeedback( vk::PipelineCreationFeedbackEXT* pPipelineCreationFeedback_ ) VULKAN_HPP_NOEXCEPT
    {
      pPipelineCreationFeedback = pPipelineCreationFeedback_;
      return *this;
    }

    PipelineCreationFeedbackCreateInfoEXT & setPipelineStageCreationFeedbackCount( uint32_t pipelineStageCreationFeedbackCount_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineStageCreationFeedbackCount = pipelineStageCreationFeedbackCount_;
      return *this;
    }

    PipelineCreationFeedbackCreateInfoEXT & setPPipelineStageCreationFeedbacks( vk::PipelineCreationFeedbackEXT* pPipelineStageCreationFeedbacks_ ) VULKAN_HPP_NOEXCEPT
    {
      pPipelineStageCreationFeedbacks = pPipelineStageCreationFeedbacks_;
      return *this;
    }

    operator VkPipelineCreationFeedbackCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineCreationFeedbackCreateInfoEXT*>( this );
    }

    operator VkPipelineCreationFeedbackCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineCreationFeedbackCreateInfoEXT*>( this );
    }

    bool operator==( PipelineCreationFeedbackCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pPipelineCreationFeedback == rhs.pPipelineCreationFeedback )
          && ( pipelineStageCreationFeedbackCount == rhs.pipelineStageCreationFeedbackCount )
          && ( pPipelineStageCreationFeedbacks == rhs.pPipelineStageCreationFeedbacks );
    }

    bool operator!=( PipelineCreationFeedbackCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineCreationFeedbackCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineCreationFeedbackCreateInfoEXT ) == sizeof( VkPipelineCreationFeedbackCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineCreationFeedbackCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineDiscardRectangleStateCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineDiscardRectangleStateCreateInfoEXT( vk::PipelineDiscardRectangleStateCreateFlagsEXT flags_ = vk::PipelineDiscardRectangleStateCreateFlagsEXT(),
                                                                       vk::DiscardRectangleModeEXT discardRectangleMode_ = vk::DiscardRectangleModeEXT::eInclusive,
                                                                       uint32_t discardRectangleCount_ = 0,
                                                                       const vk::Rect2D* pDiscardRectangles_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , discardRectangleMode( discardRectangleMode_ )
        , discardRectangleCount( discardRectangleCount_ )
        , pDiscardRectangles( pDiscardRectangles_ )
      {}

      PipelineDiscardRectangleStateCreateInfoEXT( VkPipelineDiscardRectangleStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineDiscardRectangleStateCreateInfoEXT*>(this) = rhs;
      }

      PipelineDiscardRectangleStateCreateInfoEXT& operator=( VkPipelineDiscardRectangleStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineDiscardRectangleStateCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineDiscardRectangleStateCreateInfoEXT;
      const void* pNext = nullptr;
      vk::PipelineDiscardRectangleStateCreateFlagsEXT flags;
      vk::DiscardRectangleModeEXT discardRectangleMode;
      uint32_t discardRectangleCount;
      const vk::Rect2D* pDiscardRectangles;
    };
    static_assert( sizeof( PipelineDiscardRectangleStateCreateInfoEXT ) == sizeof( VkPipelineDiscardRectangleStateCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineDiscardRectangleStateCreateInfoEXT : public layout::PipelineDiscardRectangleStateCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineDiscardRectangleStateCreateInfoEXT( vk::PipelineDiscardRectangleStateCreateFlagsEXT flags_ = vk::PipelineDiscardRectangleStateCreateFlagsEXT(),
                                                                     vk::DiscardRectangleModeEXT discardRectangleMode_ = vk::DiscardRectangleModeEXT::eInclusive,
                                                                     uint32_t discardRectangleCount_ = 0,
                                                                     const vk::Rect2D* pDiscardRectangles_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineDiscardRectangleStateCreateInfoEXT( flags_, discardRectangleMode_, discardRectangleCount_, pDiscardRectangles_ )
    {}

    PipelineDiscardRectangleStateCreateInfoEXT( VkPipelineDiscardRectangleStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineDiscardRectangleStateCreateInfoEXT( rhs )
    {}

    PipelineDiscardRectangleStateCreateInfoEXT& operator=( VkPipelineDiscardRectangleStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineDiscardRectangleStateCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineDiscardRectangleStateCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineDiscardRectangleStateCreateInfoEXT & setFlags( vk::PipelineDiscardRectangleStateCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineDiscardRectangleStateCreateInfoEXT & setDiscardRectangleMode( vk::DiscardRectangleModeEXT discardRectangleMode_ ) VULKAN_HPP_NOEXCEPT
    {
      discardRectangleMode = discardRectangleMode_;
      return *this;
    }

    PipelineDiscardRectangleStateCreateInfoEXT & setDiscardRectangleCount( uint32_t discardRectangleCount_ ) VULKAN_HPP_NOEXCEPT
    {
      discardRectangleCount = discardRectangleCount_;
      return *this;
    }

    PipelineDiscardRectangleStateCreateInfoEXT & setPDiscardRectangles( const vk::Rect2D* pDiscardRectangles_ ) VULKAN_HPP_NOEXCEPT
    {
      pDiscardRectangles = pDiscardRectangles_;
      return *this;
    }

    operator VkPipelineDiscardRectangleStateCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineDiscardRectangleStateCreateInfoEXT*>( this );
    }

    operator VkPipelineDiscardRectangleStateCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineDiscardRectangleStateCreateInfoEXT*>( this );
    }

    bool operator==( PipelineDiscardRectangleStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( discardRectangleMode == rhs.discardRectangleMode )
          && ( discardRectangleCount == rhs.discardRectangleCount )
          && ( pDiscardRectangles == rhs.pDiscardRectangles );
    }

    bool operator!=( PipelineDiscardRectangleStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineDiscardRectangleStateCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineDiscardRectangleStateCreateInfoEXT ) == sizeof( VkPipelineDiscardRectangleStateCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineDiscardRectangleStateCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineExecutableInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineExecutableInfoKHR( vk::Pipeline pipeline_ = vk::Pipeline(),
                                                      uint32_t executableIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : pipeline( pipeline_ )
        , executableIndex( executableIndex_ )
      {}

      PipelineExecutableInfoKHR( VkPipelineExecutableInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutableInfoKHR*>(this) = rhs;
      }

      PipelineExecutableInfoKHR& operator=( VkPipelineExecutableInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutableInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineExecutableInfoKHR;
      const void* pNext = nullptr;
      vk::Pipeline pipeline;
      uint32_t executableIndex;
    };
    static_assert( sizeof( PipelineExecutableInfoKHR ) == sizeof( VkPipelineExecutableInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct PipelineExecutableInfoKHR : public layout::PipelineExecutableInfoKHR
  {
    VULKAN_HPP_CONSTEXPR PipelineExecutableInfoKHR( vk::Pipeline pipeline_ = vk::Pipeline(),
                                                    uint32_t executableIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutableInfoKHR( pipeline_, executableIndex_ )
    {}

    PipelineExecutableInfoKHR( VkPipelineExecutableInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutableInfoKHR( rhs )
    {}

    PipelineExecutableInfoKHR& operator=( VkPipelineExecutableInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineExecutableInfoKHR::operator=(rhs);
      return *this;
    }

    PipelineExecutableInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineExecutableInfoKHR & setPipeline( vk::Pipeline pipeline_ ) VULKAN_HPP_NOEXCEPT
    {
      pipeline = pipeline_;
      return *this;
    }

    PipelineExecutableInfoKHR & setExecutableIndex( uint32_t executableIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      executableIndex = executableIndex_;
      return *this;
    }

    operator VkPipelineExecutableInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineExecutableInfoKHR*>( this );
    }

    operator VkPipelineExecutableInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineExecutableInfoKHR*>( this );
    }

    bool operator==( PipelineExecutableInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pipeline == rhs.pipeline )
          && ( executableIndex == rhs.executableIndex );
    }

    bool operator!=( PipelineExecutableInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineExecutableInfoKHR::sType;
  };
  static_assert( sizeof( PipelineExecutableInfoKHR ) == sizeof( VkPipelineExecutableInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineExecutableInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineExecutableInternalRepresentationKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR_14 PipelineExecutableInternalRepresentationKHR( std::array<char,VK_MAX_DESCRIPTION_SIZE> const& name_ = { { 0 } },
                                                                           std::array<char,VK_MAX_DESCRIPTION_SIZE> const& description_ = { { 0 } },
                                                                           vk::Bool32 isText_ = 0,
                                                                           size_t dataSize_ = 0,
                                                                           void* pData_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : name{}
        , description{}
        , isText( isText_ )
        , dataSize( dataSize_ )
        , pData( pData_ )
      {
        vk::ConstExpressionArrayCopy<char,VK_MAX_DESCRIPTION_SIZE,VK_MAX_DESCRIPTION_SIZE>::copy( name, name_ );
        vk::ConstExpressionArrayCopy<char,VK_MAX_DESCRIPTION_SIZE,VK_MAX_DESCRIPTION_SIZE>::copy( description, description_ );
      }

      PipelineExecutableInternalRepresentationKHR( VkPipelineExecutableInternalRepresentationKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutableInternalRepresentationKHR*>(this) = rhs;
      }

      PipelineExecutableInternalRepresentationKHR& operator=( VkPipelineExecutableInternalRepresentationKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutableInternalRepresentationKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineExecutableInternalRepresentationKHR;
      void* pNext = nullptr;
      char name[VK_MAX_DESCRIPTION_SIZE];
      char description[VK_MAX_DESCRIPTION_SIZE];
      vk::Bool32 isText;
      size_t dataSize;
      void* pData;
    };
    static_assert( sizeof( PipelineExecutableInternalRepresentationKHR ) == sizeof( VkPipelineExecutableInternalRepresentationKHR ), "layout struct and wrapper have different size!" );
  }

  struct PipelineExecutableInternalRepresentationKHR : public layout::PipelineExecutableInternalRepresentationKHR
  {
    VULKAN_HPP_CONSTEXPR_14 PipelineExecutableInternalRepresentationKHR( std::array<char,VK_MAX_DESCRIPTION_SIZE> const& name_ = { { 0 } },
                                                                         std::array<char,VK_MAX_DESCRIPTION_SIZE> const& description_ = { { 0 } },
                                                                         vk::Bool32 isText_ = 0,
                                                                         size_t dataSize_ = 0,
                                                                         void* pData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutableInternalRepresentationKHR( name_, description_, isText_, dataSize_, pData_ )
    {}

    PipelineExecutableInternalRepresentationKHR( VkPipelineExecutableInternalRepresentationKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutableInternalRepresentationKHR( rhs )
    {}

    PipelineExecutableInternalRepresentationKHR& operator=( VkPipelineExecutableInternalRepresentationKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineExecutableInternalRepresentationKHR::operator=(rhs);
      return *this;
    }

    PipelineExecutableInternalRepresentationKHR & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineExecutableInternalRepresentationKHR & setName( std::array<char,VK_MAX_DESCRIPTION_SIZE> name_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( name, name_.data(), VK_MAX_DESCRIPTION_SIZE * sizeof( char ) );
      return *this;
    }

    PipelineExecutableInternalRepresentationKHR & setDescription( std::array<char,VK_MAX_DESCRIPTION_SIZE> description_ ) VULKAN_HPP_NOEXCEPT
    {
      memcpy( description, description_.data(), VK_MAX_DESCRIPTION_SIZE * sizeof( char ) );
      return *this;
    }

    PipelineExecutableInternalRepresentationKHR & setIsText( vk::Bool32 isText_ ) VULKAN_HPP_NOEXCEPT
    {
      isText = isText_;
      return *this;
    }

    PipelineExecutableInternalRepresentationKHR & setDataSize( size_t dataSize_ ) VULKAN_HPP_NOEXCEPT
    {
      dataSize = dataSize_;
      return *this;
    }

    PipelineExecutableInternalRepresentationKHR & setPData( void* pData_ ) VULKAN_HPP_NOEXCEPT
    {
      pData = pData_;
      return *this;
    }

    operator VkPipelineExecutableInternalRepresentationKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineExecutableInternalRepresentationKHR*>( this );
    }

    operator VkPipelineExecutableInternalRepresentationKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineExecutableInternalRepresentationKHR*>( this );
    }

    bool operator==( PipelineExecutableInternalRepresentationKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memcmp( name, rhs.name, VK_MAX_DESCRIPTION_SIZE * sizeof( char ) ) == 0 )
          && ( memcmp( description, rhs.description, VK_MAX_DESCRIPTION_SIZE * sizeof( char ) ) == 0 )
          && ( isText == rhs.isText )
          && ( dataSize == rhs.dataSize )
          && ( pData == rhs.pData );
    }

    bool operator!=( PipelineExecutableInternalRepresentationKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineExecutableInternalRepresentationKHR::sType;
  };
  static_assert( sizeof( PipelineExecutableInternalRepresentationKHR ) == sizeof( VkPipelineExecutableInternalRepresentationKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineExecutableInternalRepresentationKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineExecutablePropertiesKHR
    {
    protected:
      PipelineExecutablePropertiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      PipelineExecutablePropertiesKHR( VkPipelineExecutablePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutablePropertiesKHR*>(this) = rhs;
      }

      PipelineExecutablePropertiesKHR& operator=( VkPipelineExecutablePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutablePropertiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineExecutablePropertiesKHR;
      void* pNext = nullptr;
      vk::ShaderStageFlags stages;
      char name[VK_MAX_DESCRIPTION_SIZE];
      char description[VK_MAX_DESCRIPTION_SIZE];
      uint32_t subgroupSize;
    };
    static_assert( sizeof( PipelineExecutablePropertiesKHR ) == sizeof( VkPipelineExecutablePropertiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct PipelineExecutablePropertiesKHR : public layout::PipelineExecutablePropertiesKHR
  {
    PipelineExecutablePropertiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutablePropertiesKHR()
    {}

    PipelineExecutablePropertiesKHR( VkPipelineExecutablePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutablePropertiesKHR( rhs )
    {}

    PipelineExecutablePropertiesKHR& operator=( VkPipelineExecutablePropertiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineExecutablePropertiesKHR::operator=(rhs);
      return *this;
    }

    operator VkPipelineExecutablePropertiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineExecutablePropertiesKHR*>( this );
    }

    operator VkPipelineExecutablePropertiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineExecutablePropertiesKHR*>( this );
    }

    bool operator==( PipelineExecutablePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( stages == rhs.stages )
          && ( memcmp( name, rhs.name, VK_MAX_DESCRIPTION_SIZE * sizeof( char ) ) == 0 )
          && ( memcmp( description, rhs.description, VK_MAX_DESCRIPTION_SIZE * sizeof( char ) ) == 0 )
          && ( subgroupSize == rhs.subgroupSize );
    }

    bool operator!=( PipelineExecutablePropertiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineExecutablePropertiesKHR::sType;
  };
  static_assert( sizeof( PipelineExecutablePropertiesKHR ) == sizeof( VkPipelineExecutablePropertiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineExecutablePropertiesKHR>::value, "struct wrapper is not a standard layout!" );

  union PipelineExecutableStatisticValueKHR
  {
    operator VkPipelineExecutableStatisticValueKHR const&() const
    {
      return *reinterpret_cast<const VkPipelineExecutableStatisticValueKHR*>(this);
    }

    operator VkPipelineExecutableStatisticValueKHR &()
    {
      return *reinterpret_cast<VkPipelineExecutableStatisticValueKHR*>(this);
    }

#ifdef VULKAN_HPP_HAS_UNRESTRICTED_UNIONS
    vk::Bool32 b32;
    int64_t i64;
    uint64_t u64;
    double f64;
#else
    VkBool32 b32;
    int64_t i64;
    uint64_t u64;
    double f64;
#endif  /*VULKAN_HPP_HAS_UNRESTRICTED_UNIONS*/
  };

  namespace layout
  {
    struct PipelineExecutableStatisticKHR
    {
    protected:
      PipelineExecutableStatisticKHR() VULKAN_HPP_NOEXCEPT
      {}

      PipelineExecutableStatisticKHR( VkPipelineExecutableStatisticKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutableStatisticKHR*>(this) = rhs;
      }

      PipelineExecutableStatisticKHR& operator=( VkPipelineExecutableStatisticKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineExecutableStatisticKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineExecutableStatisticKHR;
      void* pNext = nullptr;
      char name[VK_MAX_DESCRIPTION_SIZE];
      char description[VK_MAX_DESCRIPTION_SIZE];
      vk::PipelineExecutableStatisticFormatKHR format;
      vk::PipelineExecutableStatisticValueKHR value;
    };
    static_assert( sizeof( PipelineExecutableStatisticKHR ) == sizeof( VkPipelineExecutableStatisticKHR ), "layout struct and wrapper have different size!" );
  }

  struct PipelineExecutableStatisticKHR : public layout::PipelineExecutableStatisticKHR
  {
    PipelineExecutableStatisticKHR() VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutableStatisticKHR()
    {}

    PipelineExecutableStatisticKHR( VkPipelineExecutableStatisticKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineExecutableStatisticKHR( rhs )
    {}

    PipelineExecutableStatisticKHR& operator=( VkPipelineExecutableStatisticKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineExecutableStatisticKHR::operator=(rhs);
      return *this;
    }

    operator VkPipelineExecutableStatisticKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineExecutableStatisticKHR*>( this );
    }

    operator VkPipelineExecutableStatisticKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineExecutableStatisticKHR*>( this );
    }

  private:
    using layout::PipelineExecutableStatisticKHR::sType;
  };
  static_assert( sizeof( PipelineExecutableStatisticKHR ) == sizeof( VkPipelineExecutableStatisticKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineExecutableStatisticKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineInfoKHR( vk::Pipeline pipeline_ = vk::Pipeline() ) VULKAN_HPP_NOEXCEPT
        : pipeline( pipeline_ )
      {}

      PipelineInfoKHR( VkPipelineInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineInfoKHR*>(this) = rhs;
      }

      PipelineInfoKHR& operator=( VkPipelineInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineInfoKHR;
      const void* pNext = nullptr;
      vk::Pipeline pipeline;
    };
    static_assert( sizeof( PipelineInfoKHR ) == sizeof( VkPipelineInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct PipelineInfoKHR : public layout::PipelineInfoKHR
  {
    VULKAN_HPP_CONSTEXPR PipelineInfoKHR( vk::Pipeline pipeline_ = vk::Pipeline() ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineInfoKHR( pipeline_ )
    {}

    PipelineInfoKHR( VkPipelineInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineInfoKHR( rhs )
    {}

    PipelineInfoKHR& operator=( VkPipelineInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineInfoKHR::operator=(rhs);
      return *this;
    }

    PipelineInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineInfoKHR & setPipeline( vk::Pipeline pipeline_ ) VULKAN_HPP_NOEXCEPT
    {
      pipeline = pipeline_;
      return *this;
    }

    operator VkPipelineInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineInfoKHR*>( this );
    }

    operator VkPipelineInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineInfoKHR*>( this );
    }

    bool operator==( PipelineInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( pipeline == rhs.pipeline );
    }

    bool operator!=( PipelineInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineInfoKHR::sType;
  };
  static_assert( sizeof( PipelineInfoKHR ) == sizeof( VkPipelineInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineInfoKHR>::value, "struct wrapper is not a standard layout!" );

  struct PushConstantRange
  {
    VULKAN_HPP_CONSTEXPR PushConstantRange( vk::ShaderStageFlags stageFlags_ = vk::ShaderStageFlags(),
                                            uint32_t offset_ = 0,
                                            uint32_t size_ = 0 ) VULKAN_HPP_NOEXCEPT
      : stageFlags( stageFlags_ )
      , offset( offset_ )
      , size( size_ )
    {}

    PushConstantRange( VkPushConstantRange const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPushConstantRange*>(this) = rhs;
    }

    PushConstantRange& operator=( VkPushConstantRange const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPushConstantRange*>(this) = rhs;
      return *this;
    }

    PushConstantRange & setStageFlags( vk::ShaderStageFlags stageFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      stageFlags = stageFlags_;
      return *this;
    }

    PushConstantRange & setOffset( uint32_t offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    PushConstantRange & setSize( uint32_t size_ ) VULKAN_HPP_NOEXCEPT
    {
      size = size_;
      return *this;
    }

    operator VkPushConstantRange const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPushConstantRange*>( this );
    }

    operator VkPushConstantRange &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPushConstantRange*>( this );
    }

    bool operator==( PushConstantRange const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( stageFlags == rhs.stageFlags )
          && ( offset == rhs.offset )
          && ( size == rhs.size );
    }

    bool operator!=( PushConstantRange const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ShaderStageFlags stageFlags;
    uint32_t offset;
    uint32_t size;
  };
  static_assert( sizeof( PushConstantRange ) == sizeof( VkPushConstantRange ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PushConstantRange>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineLayoutCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineLayoutCreateInfo( vk::PipelineLayoutCreateFlags flags_ = vk::PipelineLayoutCreateFlags(),
                                                     uint32_t setLayoutCount_ = 0,
                                                     const vk::DescriptorSetLayout* pSetLayouts_ = nullptr,
                                                     uint32_t pushConstantRangeCount_ = 0,
                                                     const vk::PushConstantRange* pPushConstantRanges_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , setLayoutCount( setLayoutCount_ )
        , pSetLayouts( pSetLayouts_ )
        , pushConstantRangeCount( pushConstantRangeCount_ )
        , pPushConstantRanges( pPushConstantRanges_ )
      {}

      PipelineLayoutCreateInfo( VkPipelineLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineLayoutCreateInfo*>(this) = rhs;
      }

      PipelineLayoutCreateInfo& operator=( VkPipelineLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineLayoutCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineLayoutCreateInfo;
      const void* pNext = nullptr;
      vk::PipelineLayoutCreateFlags flags;
      uint32_t setLayoutCount;
      const vk::DescriptorSetLayout* pSetLayouts;
      uint32_t pushConstantRangeCount;
      const vk::PushConstantRange* pPushConstantRanges;
    };
    static_assert( sizeof( PipelineLayoutCreateInfo ) == sizeof( VkPipelineLayoutCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineLayoutCreateInfo : public layout::PipelineLayoutCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineLayoutCreateInfo( vk::PipelineLayoutCreateFlags flags_ = vk::PipelineLayoutCreateFlags(),
                                                   uint32_t setLayoutCount_ = 0,
                                                   const vk::DescriptorSetLayout* pSetLayouts_ = nullptr,
                                                   uint32_t pushConstantRangeCount_ = 0,
                                                   const vk::PushConstantRange* pPushConstantRanges_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineLayoutCreateInfo( flags_, setLayoutCount_, pSetLayouts_, pushConstantRangeCount_, pPushConstantRanges_ )
    {}

    PipelineLayoutCreateInfo( VkPipelineLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineLayoutCreateInfo( rhs )
    {}

    PipelineLayoutCreateInfo& operator=( VkPipelineLayoutCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineLayoutCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineLayoutCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineLayoutCreateInfo & setFlags( vk::PipelineLayoutCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineLayoutCreateInfo & setSetLayoutCount( uint32_t setLayoutCount_ ) VULKAN_HPP_NOEXCEPT
    {
      setLayoutCount = setLayoutCount_;
      return *this;
    }

    PipelineLayoutCreateInfo & setPSetLayouts( const vk::DescriptorSetLayout* pSetLayouts_ ) VULKAN_HPP_NOEXCEPT
    {
      pSetLayouts = pSetLayouts_;
      return *this;
    }

    PipelineLayoutCreateInfo & setPushConstantRangeCount( uint32_t pushConstantRangeCount_ ) VULKAN_HPP_NOEXCEPT
    {
      pushConstantRangeCount = pushConstantRangeCount_;
      return *this;
    }

    PipelineLayoutCreateInfo & setPPushConstantRanges( const vk::PushConstantRange* pPushConstantRanges_ ) VULKAN_HPP_NOEXCEPT
    {
      pPushConstantRanges = pPushConstantRanges_;
      return *this;
    }

    operator VkPipelineLayoutCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineLayoutCreateInfo*>( this );
    }

    operator VkPipelineLayoutCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineLayoutCreateInfo*>( this );
    }

    bool operator==( PipelineLayoutCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( setLayoutCount == rhs.setLayoutCount )
          && ( pSetLayouts == rhs.pSetLayouts )
          && ( pushConstantRangeCount == rhs.pushConstantRangeCount )
          && ( pPushConstantRanges == rhs.pPushConstantRanges );
    }

    bool operator!=( PipelineLayoutCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineLayoutCreateInfo::sType;
  };
  static_assert( sizeof( PipelineLayoutCreateInfo ) == sizeof( VkPipelineLayoutCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineLayoutCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineRasterizationConservativeStateCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineRasterizationConservativeStateCreateInfoEXT( vk::PipelineRasterizationConservativeStateCreateFlagsEXT flags_ = vk::PipelineRasterizationConservativeStateCreateFlagsEXT(),
                                                                                vk::ConservativeRasterizationModeEXT conservativeRasterizationMode_ = vk::ConservativeRasterizationModeEXT::eDisabled,
                                                                                float extraPrimitiveOverestimationSize_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , conservativeRasterizationMode( conservativeRasterizationMode_ )
        , extraPrimitiveOverestimationSize( extraPrimitiveOverestimationSize_ )
      {}

      PipelineRasterizationConservativeStateCreateInfoEXT( VkPipelineRasterizationConservativeStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationConservativeStateCreateInfoEXT*>(this) = rhs;
      }

      PipelineRasterizationConservativeStateCreateInfoEXT& operator=( VkPipelineRasterizationConservativeStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationConservativeStateCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineRasterizationConservativeStateCreateInfoEXT;
      const void* pNext = nullptr;
      vk::PipelineRasterizationConservativeStateCreateFlagsEXT flags;
      vk::ConservativeRasterizationModeEXT conservativeRasterizationMode;
      float extraPrimitiveOverestimationSize;
    };
    static_assert( sizeof( PipelineRasterizationConservativeStateCreateInfoEXT ) == sizeof( VkPipelineRasterizationConservativeStateCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineRasterizationConservativeStateCreateInfoEXT : public layout::PipelineRasterizationConservativeStateCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineRasterizationConservativeStateCreateInfoEXT( vk::PipelineRasterizationConservativeStateCreateFlagsEXT flags_ = vk::PipelineRasterizationConservativeStateCreateFlagsEXT(),
                                                                              vk::ConservativeRasterizationModeEXT conservativeRasterizationMode_ = vk::ConservativeRasterizationModeEXT::eDisabled,
                                                                              float extraPrimitiveOverestimationSize_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationConservativeStateCreateInfoEXT( flags_, conservativeRasterizationMode_, extraPrimitiveOverestimationSize_ )
    {}

    PipelineRasterizationConservativeStateCreateInfoEXT( VkPipelineRasterizationConservativeStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationConservativeStateCreateInfoEXT( rhs )
    {}

    PipelineRasterizationConservativeStateCreateInfoEXT& operator=( VkPipelineRasterizationConservativeStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineRasterizationConservativeStateCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineRasterizationConservativeStateCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineRasterizationConservativeStateCreateInfoEXT & setFlags( vk::PipelineRasterizationConservativeStateCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineRasterizationConservativeStateCreateInfoEXT & setConservativeRasterizationMode( vk::ConservativeRasterizationModeEXT conservativeRasterizationMode_ ) VULKAN_HPP_NOEXCEPT
    {
      conservativeRasterizationMode = conservativeRasterizationMode_;
      return *this;
    }

    PipelineRasterizationConservativeStateCreateInfoEXT & setExtraPrimitiveOverestimationSize( float extraPrimitiveOverestimationSize_ ) VULKAN_HPP_NOEXCEPT
    {
      extraPrimitiveOverestimationSize = extraPrimitiveOverestimationSize_;
      return *this;
    }

    operator VkPipelineRasterizationConservativeStateCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineRasterizationConservativeStateCreateInfoEXT*>( this );
    }

    operator VkPipelineRasterizationConservativeStateCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineRasterizationConservativeStateCreateInfoEXT*>( this );
    }

    bool operator==( PipelineRasterizationConservativeStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( conservativeRasterizationMode == rhs.conservativeRasterizationMode )
          && ( extraPrimitiveOverestimationSize == rhs.extraPrimitiveOverestimationSize );
    }

    bool operator!=( PipelineRasterizationConservativeStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineRasterizationConservativeStateCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineRasterizationConservativeStateCreateInfoEXT ) == sizeof( VkPipelineRasterizationConservativeStateCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineRasterizationConservativeStateCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineRasterizationDepthClipStateCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineRasterizationDepthClipStateCreateInfoEXT( vk::PipelineRasterizationDepthClipStateCreateFlagsEXT flags_ = vk::PipelineRasterizationDepthClipStateCreateFlagsEXT(),
                                                                             vk::Bool32 depthClipEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , depthClipEnable( depthClipEnable_ )
      {}

      PipelineRasterizationDepthClipStateCreateInfoEXT( VkPipelineRasterizationDepthClipStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationDepthClipStateCreateInfoEXT*>(this) = rhs;
      }

      PipelineRasterizationDepthClipStateCreateInfoEXT& operator=( VkPipelineRasterizationDepthClipStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationDepthClipStateCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineRasterizationDepthClipStateCreateInfoEXT;
      const void* pNext = nullptr;
      vk::PipelineRasterizationDepthClipStateCreateFlagsEXT flags;
      vk::Bool32 depthClipEnable;
    };
    static_assert( sizeof( PipelineRasterizationDepthClipStateCreateInfoEXT ) == sizeof( VkPipelineRasterizationDepthClipStateCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineRasterizationDepthClipStateCreateInfoEXT : public layout::PipelineRasterizationDepthClipStateCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineRasterizationDepthClipStateCreateInfoEXT( vk::PipelineRasterizationDepthClipStateCreateFlagsEXT flags_ = vk::PipelineRasterizationDepthClipStateCreateFlagsEXT(),
                                                                           vk::Bool32 depthClipEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationDepthClipStateCreateInfoEXT( flags_, depthClipEnable_ )
    {}

    PipelineRasterizationDepthClipStateCreateInfoEXT( VkPipelineRasterizationDepthClipStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationDepthClipStateCreateInfoEXT( rhs )
    {}

    PipelineRasterizationDepthClipStateCreateInfoEXT& operator=( VkPipelineRasterizationDepthClipStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineRasterizationDepthClipStateCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineRasterizationDepthClipStateCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineRasterizationDepthClipStateCreateInfoEXT & setFlags( vk::PipelineRasterizationDepthClipStateCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineRasterizationDepthClipStateCreateInfoEXT & setDepthClipEnable( vk::Bool32 depthClipEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      depthClipEnable = depthClipEnable_;
      return *this;
    }

    operator VkPipelineRasterizationDepthClipStateCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineRasterizationDepthClipStateCreateInfoEXT*>( this );
    }

    operator VkPipelineRasterizationDepthClipStateCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineRasterizationDepthClipStateCreateInfoEXT*>( this );
    }

    bool operator==( PipelineRasterizationDepthClipStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( depthClipEnable == rhs.depthClipEnable );
    }

    bool operator!=( PipelineRasterizationDepthClipStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineRasterizationDepthClipStateCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineRasterizationDepthClipStateCreateInfoEXT ) == sizeof( VkPipelineRasterizationDepthClipStateCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineRasterizationDepthClipStateCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineRasterizationLineStateCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineRasterizationLineStateCreateInfoEXT( vk::LineRasterizationModeEXT lineRasterizationMode_ = vk::LineRasterizationModeEXT::eDefault,
                                                                        vk::Bool32 stippledLineEnable_ = 0,
                                                                        uint32_t lineStippleFactor_ = 0,
                                                                        uint16_t lineStipplePattern_ = 0 ) VULKAN_HPP_NOEXCEPT
        : lineRasterizationMode( lineRasterizationMode_ )
        , stippledLineEnable( stippledLineEnable_ )
        , lineStippleFactor( lineStippleFactor_ )
        , lineStipplePattern( lineStipplePattern_ )
      {}

      PipelineRasterizationLineStateCreateInfoEXT( VkPipelineRasterizationLineStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationLineStateCreateInfoEXT*>(this) = rhs;
      }

      PipelineRasterizationLineStateCreateInfoEXT& operator=( VkPipelineRasterizationLineStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationLineStateCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineRasterizationLineStateCreateInfoEXT;
      const void* pNext = nullptr;
      vk::LineRasterizationModeEXT lineRasterizationMode;
      vk::Bool32 stippledLineEnable;
      uint32_t lineStippleFactor;
      uint16_t lineStipplePattern;
    };
    static_assert( sizeof( PipelineRasterizationLineStateCreateInfoEXT ) == sizeof( VkPipelineRasterizationLineStateCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineRasterizationLineStateCreateInfoEXT : public layout::PipelineRasterizationLineStateCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineRasterizationLineStateCreateInfoEXT( vk::LineRasterizationModeEXT lineRasterizationMode_ = vk::LineRasterizationModeEXT::eDefault,
                                                                      vk::Bool32 stippledLineEnable_ = 0,
                                                                      uint32_t lineStippleFactor_ = 0,
                                                                      uint16_t lineStipplePattern_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationLineStateCreateInfoEXT( lineRasterizationMode_, stippledLineEnable_, lineStippleFactor_, lineStipplePattern_ )
    {}

    PipelineRasterizationLineStateCreateInfoEXT( VkPipelineRasterizationLineStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationLineStateCreateInfoEXT( rhs )
    {}

    PipelineRasterizationLineStateCreateInfoEXT& operator=( VkPipelineRasterizationLineStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineRasterizationLineStateCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineRasterizationLineStateCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineRasterizationLineStateCreateInfoEXT & setLineRasterizationMode( vk::LineRasterizationModeEXT lineRasterizationMode_ ) VULKAN_HPP_NOEXCEPT
    {
      lineRasterizationMode = lineRasterizationMode_;
      return *this;
    }

    PipelineRasterizationLineStateCreateInfoEXT & setStippledLineEnable( vk::Bool32 stippledLineEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      stippledLineEnable = stippledLineEnable_;
      return *this;
    }

    PipelineRasterizationLineStateCreateInfoEXT & setLineStippleFactor( uint32_t lineStippleFactor_ ) VULKAN_HPP_NOEXCEPT
    {
      lineStippleFactor = lineStippleFactor_;
      return *this;
    }

    PipelineRasterizationLineStateCreateInfoEXT & setLineStipplePattern( uint16_t lineStipplePattern_ ) VULKAN_HPP_NOEXCEPT
    {
      lineStipplePattern = lineStipplePattern_;
      return *this;
    }

    operator VkPipelineRasterizationLineStateCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineRasterizationLineStateCreateInfoEXT*>( this );
    }

    operator VkPipelineRasterizationLineStateCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineRasterizationLineStateCreateInfoEXT*>( this );
    }

    bool operator==( PipelineRasterizationLineStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( lineRasterizationMode == rhs.lineRasterizationMode )
          && ( stippledLineEnable == rhs.stippledLineEnable )
          && ( lineStippleFactor == rhs.lineStippleFactor )
          && ( lineStipplePattern == rhs.lineStipplePattern );
    }

    bool operator!=( PipelineRasterizationLineStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineRasterizationLineStateCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineRasterizationLineStateCreateInfoEXT ) == sizeof( VkPipelineRasterizationLineStateCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineRasterizationLineStateCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineRasterizationStateRasterizationOrderAMD
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineRasterizationStateRasterizationOrderAMD( vk::RasterizationOrderAMD rasterizationOrder_ = vk::RasterizationOrderAMD::eStrict ) VULKAN_HPP_NOEXCEPT
        : rasterizationOrder( rasterizationOrder_ )
      {}

      PipelineRasterizationStateRasterizationOrderAMD( VkPipelineRasterizationStateRasterizationOrderAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationStateRasterizationOrderAMD*>(this) = rhs;
      }

      PipelineRasterizationStateRasterizationOrderAMD& operator=( VkPipelineRasterizationStateRasterizationOrderAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationStateRasterizationOrderAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineRasterizationStateRasterizationOrderAMD;
      const void* pNext = nullptr;
      vk::RasterizationOrderAMD rasterizationOrder;
    };
    static_assert( sizeof( PipelineRasterizationStateRasterizationOrderAMD ) == sizeof( VkPipelineRasterizationStateRasterizationOrderAMD ), "layout struct and wrapper have different size!" );
  }

  struct PipelineRasterizationStateRasterizationOrderAMD : public layout::PipelineRasterizationStateRasterizationOrderAMD
  {
    VULKAN_HPP_CONSTEXPR PipelineRasterizationStateRasterizationOrderAMD( vk::RasterizationOrderAMD rasterizationOrder_ = vk::RasterizationOrderAMD::eStrict ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationStateRasterizationOrderAMD( rasterizationOrder_ )
    {}

    PipelineRasterizationStateRasterizationOrderAMD( VkPipelineRasterizationStateRasterizationOrderAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationStateRasterizationOrderAMD( rhs )
    {}

    PipelineRasterizationStateRasterizationOrderAMD& operator=( VkPipelineRasterizationStateRasterizationOrderAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineRasterizationStateRasterizationOrderAMD::operator=(rhs);
      return *this;
    }

    PipelineRasterizationStateRasterizationOrderAMD & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineRasterizationStateRasterizationOrderAMD & setRasterizationOrder( vk::RasterizationOrderAMD rasterizationOrder_ ) VULKAN_HPP_NOEXCEPT
    {
      rasterizationOrder = rasterizationOrder_;
      return *this;
    }

    operator VkPipelineRasterizationStateRasterizationOrderAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineRasterizationStateRasterizationOrderAMD*>( this );
    }

    operator VkPipelineRasterizationStateRasterizationOrderAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineRasterizationStateRasterizationOrderAMD*>( this );
    }

    bool operator==( PipelineRasterizationStateRasterizationOrderAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( rasterizationOrder == rhs.rasterizationOrder );
    }

    bool operator!=( PipelineRasterizationStateRasterizationOrderAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineRasterizationStateRasterizationOrderAMD::sType;
  };
  static_assert( sizeof( PipelineRasterizationStateRasterizationOrderAMD ) == sizeof( VkPipelineRasterizationStateRasterizationOrderAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineRasterizationStateRasterizationOrderAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineRasterizationStateStreamCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineRasterizationStateStreamCreateInfoEXT( vk::PipelineRasterizationStateStreamCreateFlagsEXT flags_ = vk::PipelineRasterizationStateStreamCreateFlagsEXT(),
                                                                          uint32_t rasterizationStream_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , rasterizationStream( rasterizationStream_ )
      {}

      PipelineRasterizationStateStreamCreateInfoEXT( VkPipelineRasterizationStateStreamCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationStateStreamCreateInfoEXT*>(this) = rhs;
      }

      PipelineRasterizationStateStreamCreateInfoEXT& operator=( VkPipelineRasterizationStateStreamCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRasterizationStateStreamCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineRasterizationStateStreamCreateInfoEXT;
      const void* pNext = nullptr;
      vk::PipelineRasterizationStateStreamCreateFlagsEXT flags;
      uint32_t rasterizationStream;
    };
    static_assert( sizeof( PipelineRasterizationStateStreamCreateInfoEXT ) == sizeof( VkPipelineRasterizationStateStreamCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineRasterizationStateStreamCreateInfoEXT : public layout::PipelineRasterizationStateStreamCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineRasterizationStateStreamCreateInfoEXT( vk::PipelineRasterizationStateStreamCreateFlagsEXT flags_ = vk::PipelineRasterizationStateStreamCreateFlagsEXT(),
                                                                        uint32_t rasterizationStream_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationStateStreamCreateInfoEXT( flags_, rasterizationStream_ )
    {}

    PipelineRasterizationStateStreamCreateInfoEXT( VkPipelineRasterizationStateStreamCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRasterizationStateStreamCreateInfoEXT( rhs )
    {}

    PipelineRasterizationStateStreamCreateInfoEXT& operator=( VkPipelineRasterizationStateStreamCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineRasterizationStateStreamCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineRasterizationStateStreamCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineRasterizationStateStreamCreateInfoEXT & setFlags( vk::PipelineRasterizationStateStreamCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineRasterizationStateStreamCreateInfoEXT & setRasterizationStream( uint32_t rasterizationStream_ ) VULKAN_HPP_NOEXCEPT
    {
      rasterizationStream = rasterizationStream_;
      return *this;
    }

    operator VkPipelineRasterizationStateStreamCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineRasterizationStateStreamCreateInfoEXT*>( this );
    }

    operator VkPipelineRasterizationStateStreamCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineRasterizationStateStreamCreateInfoEXT*>( this );
    }

    bool operator==( PipelineRasterizationStateStreamCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( rasterizationStream == rhs.rasterizationStream );
    }

    bool operator!=( PipelineRasterizationStateStreamCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineRasterizationStateStreamCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineRasterizationStateStreamCreateInfoEXT ) == sizeof( VkPipelineRasterizationStateStreamCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineRasterizationStateStreamCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineRepresentativeFragmentTestStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineRepresentativeFragmentTestStateCreateInfoNV( vk::Bool32 representativeFragmentTestEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
        : representativeFragmentTestEnable( representativeFragmentTestEnable_ )
      {}

      PipelineRepresentativeFragmentTestStateCreateInfoNV( VkPipelineRepresentativeFragmentTestStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRepresentativeFragmentTestStateCreateInfoNV*>(this) = rhs;
      }

      PipelineRepresentativeFragmentTestStateCreateInfoNV& operator=( VkPipelineRepresentativeFragmentTestStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineRepresentativeFragmentTestStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineRepresentativeFragmentTestStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::Bool32 representativeFragmentTestEnable;
    };
    static_assert( sizeof( PipelineRepresentativeFragmentTestStateCreateInfoNV ) == sizeof( VkPipelineRepresentativeFragmentTestStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineRepresentativeFragmentTestStateCreateInfoNV : public layout::PipelineRepresentativeFragmentTestStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineRepresentativeFragmentTestStateCreateInfoNV( vk::Bool32 representativeFragmentTestEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRepresentativeFragmentTestStateCreateInfoNV( representativeFragmentTestEnable_ )
    {}

    PipelineRepresentativeFragmentTestStateCreateInfoNV( VkPipelineRepresentativeFragmentTestStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineRepresentativeFragmentTestStateCreateInfoNV( rhs )
    {}

    PipelineRepresentativeFragmentTestStateCreateInfoNV& operator=( VkPipelineRepresentativeFragmentTestStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineRepresentativeFragmentTestStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineRepresentativeFragmentTestStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineRepresentativeFragmentTestStateCreateInfoNV & setRepresentativeFragmentTestEnable( vk::Bool32 representativeFragmentTestEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      representativeFragmentTestEnable = representativeFragmentTestEnable_;
      return *this;
    }

    operator VkPipelineRepresentativeFragmentTestStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineRepresentativeFragmentTestStateCreateInfoNV*>( this );
    }

    operator VkPipelineRepresentativeFragmentTestStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineRepresentativeFragmentTestStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineRepresentativeFragmentTestStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( representativeFragmentTestEnable == rhs.representativeFragmentTestEnable );
    }

    bool operator!=( PipelineRepresentativeFragmentTestStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineRepresentativeFragmentTestStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineRepresentativeFragmentTestStateCreateInfoNV ) == sizeof( VkPipelineRepresentativeFragmentTestStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineRepresentativeFragmentTestStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineSampleLocationsStateCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineSampleLocationsStateCreateInfoEXT( vk::Bool32 sampleLocationsEnable_ = 0,
                                                                      vk::SampleLocationsInfoEXT sampleLocationsInfo_ = vk::SampleLocationsInfoEXT() ) VULKAN_HPP_NOEXCEPT
        : sampleLocationsEnable( sampleLocationsEnable_ )
        , sampleLocationsInfo( sampleLocationsInfo_ )
      {}

      PipelineSampleLocationsStateCreateInfoEXT( VkPipelineSampleLocationsStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineSampleLocationsStateCreateInfoEXT*>(this) = rhs;
      }

      PipelineSampleLocationsStateCreateInfoEXT& operator=( VkPipelineSampleLocationsStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineSampleLocationsStateCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineSampleLocationsStateCreateInfoEXT;
      const void* pNext = nullptr;
      vk::Bool32 sampleLocationsEnable;
      vk::SampleLocationsInfoEXT sampleLocationsInfo;
    };
    static_assert( sizeof( PipelineSampleLocationsStateCreateInfoEXT ) == sizeof( VkPipelineSampleLocationsStateCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineSampleLocationsStateCreateInfoEXT : public layout::PipelineSampleLocationsStateCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineSampleLocationsStateCreateInfoEXT( vk::Bool32 sampleLocationsEnable_ = 0,
                                                                    vk::SampleLocationsInfoEXT sampleLocationsInfo_ = vk::SampleLocationsInfoEXT() ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineSampleLocationsStateCreateInfoEXT( sampleLocationsEnable_, sampleLocationsInfo_ )
    {}

    PipelineSampleLocationsStateCreateInfoEXT( VkPipelineSampleLocationsStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineSampleLocationsStateCreateInfoEXT( rhs )
    {}

    PipelineSampleLocationsStateCreateInfoEXT& operator=( VkPipelineSampleLocationsStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineSampleLocationsStateCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineSampleLocationsStateCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineSampleLocationsStateCreateInfoEXT & setSampleLocationsEnable( vk::Bool32 sampleLocationsEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationsEnable = sampleLocationsEnable_;
      return *this;
    }

    PipelineSampleLocationsStateCreateInfoEXT & setSampleLocationsInfo( vk::SampleLocationsInfoEXT sampleLocationsInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationsInfo = sampleLocationsInfo_;
      return *this;
    }

    operator VkPipelineSampleLocationsStateCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineSampleLocationsStateCreateInfoEXT*>( this );
    }

    operator VkPipelineSampleLocationsStateCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineSampleLocationsStateCreateInfoEXT*>( this );
    }

    bool operator==( PipelineSampleLocationsStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( sampleLocationsEnable == rhs.sampleLocationsEnable )
          && ( sampleLocationsInfo == rhs.sampleLocationsInfo );
    }

    bool operator!=( PipelineSampleLocationsStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineSampleLocationsStateCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineSampleLocationsStateCreateInfoEXT ) == sizeof( VkPipelineSampleLocationsStateCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineSampleLocationsStateCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT
    {
    protected:
      PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT() VULKAN_HPP_NOEXCEPT
      {}

      PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT( VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT*>(this) = rhs;
      }

      PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT& operator=( VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineShaderStageRequiredSubgroupSizeCreateInfoEXT;
      void* pNext = nullptr;
      uint32_t requiredSubgroupSize;
    };
    static_assert( sizeof( PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT ) == sizeof( VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT : public layout::PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT
  {
    PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT() VULKAN_HPP_NOEXCEPT
      : layout::PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT()
    {}

    PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT( VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT( rhs )
    {}

    PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT& operator=( VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT::operator=(rhs);
      return *this;
    }

    operator VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT*>( this );
    }

    operator VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT*>( this );
    }

    bool operator==( PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( requiredSubgroupSize == rhs.requiredSubgroupSize );
    }

    bool operator!=( PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT ) == sizeof( VkPipelineShaderStageRequiredSubgroupSizeCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineTessellationDomainOriginStateCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineTessellationDomainOriginStateCreateInfo( vk::TessellationDomainOrigin domainOrigin_ = vk::TessellationDomainOrigin::eUpperLeft ) VULKAN_HPP_NOEXCEPT
        : domainOrigin( domainOrigin_ )
      {}

      PipelineTessellationDomainOriginStateCreateInfo( VkPipelineTessellationDomainOriginStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineTessellationDomainOriginStateCreateInfo*>(this) = rhs;
      }

      PipelineTessellationDomainOriginStateCreateInfo& operator=( VkPipelineTessellationDomainOriginStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineTessellationDomainOriginStateCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineTessellationDomainOriginStateCreateInfo;
      const void* pNext = nullptr;
      vk::TessellationDomainOrigin domainOrigin;
    };
    static_assert( sizeof( PipelineTessellationDomainOriginStateCreateInfo ) == sizeof( VkPipelineTessellationDomainOriginStateCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct PipelineTessellationDomainOriginStateCreateInfo : public layout::PipelineTessellationDomainOriginStateCreateInfo
  {
    VULKAN_HPP_CONSTEXPR PipelineTessellationDomainOriginStateCreateInfo( vk::TessellationDomainOrigin domainOrigin_ = vk::TessellationDomainOrigin::eUpperLeft ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineTessellationDomainOriginStateCreateInfo( domainOrigin_ )
    {}

    PipelineTessellationDomainOriginStateCreateInfo( VkPipelineTessellationDomainOriginStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineTessellationDomainOriginStateCreateInfo( rhs )
    {}

    PipelineTessellationDomainOriginStateCreateInfo& operator=( VkPipelineTessellationDomainOriginStateCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineTessellationDomainOriginStateCreateInfo::operator=(rhs);
      return *this;
    }

    PipelineTessellationDomainOriginStateCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineTessellationDomainOriginStateCreateInfo & setDomainOrigin( vk::TessellationDomainOrigin domainOrigin_ ) VULKAN_HPP_NOEXCEPT
    {
      domainOrigin = domainOrigin_;
      return *this;
    }

    operator VkPipelineTessellationDomainOriginStateCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineTessellationDomainOriginStateCreateInfo*>( this );
    }

    operator VkPipelineTessellationDomainOriginStateCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineTessellationDomainOriginStateCreateInfo*>( this );
    }

    bool operator==( PipelineTessellationDomainOriginStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( domainOrigin == rhs.domainOrigin );
    }

    bool operator!=( PipelineTessellationDomainOriginStateCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineTessellationDomainOriginStateCreateInfo::sType;
  };
  static_assert( sizeof( PipelineTessellationDomainOriginStateCreateInfo ) == sizeof( VkPipelineTessellationDomainOriginStateCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineTessellationDomainOriginStateCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct VertexInputBindingDivisorDescriptionEXT
  {
    VULKAN_HPP_CONSTEXPR VertexInputBindingDivisorDescriptionEXT( uint32_t binding_ = 0,
                                                                  uint32_t divisor_ = 0 ) VULKAN_HPP_NOEXCEPT
      : binding( binding_ )
      , divisor( divisor_ )
    {}

    VertexInputBindingDivisorDescriptionEXT( VkVertexInputBindingDivisorDescriptionEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkVertexInputBindingDivisorDescriptionEXT*>(this) = rhs;
    }

    VertexInputBindingDivisorDescriptionEXT& operator=( VkVertexInputBindingDivisorDescriptionEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkVertexInputBindingDivisorDescriptionEXT*>(this) = rhs;
      return *this;
    }

    VertexInputBindingDivisorDescriptionEXT & setBinding( uint32_t binding_ ) VULKAN_HPP_NOEXCEPT
    {
      binding = binding_;
      return *this;
    }

    VertexInputBindingDivisorDescriptionEXT & setDivisor( uint32_t divisor_ ) VULKAN_HPP_NOEXCEPT
    {
      divisor = divisor_;
      return *this;
    }

    operator VkVertexInputBindingDivisorDescriptionEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkVertexInputBindingDivisorDescriptionEXT*>( this );
    }

    operator VkVertexInputBindingDivisorDescriptionEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkVertexInputBindingDivisorDescriptionEXT*>( this );
    }

    bool operator==( VertexInputBindingDivisorDescriptionEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( binding == rhs.binding )
          && ( divisor == rhs.divisor );
    }

    bool operator!=( VertexInputBindingDivisorDescriptionEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t binding;
    uint32_t divisor;
  };
  static_assert( sizeof( VertexInputBindingDivisorDescriptionEXT ) == sizeof( VkVertexInputBindingDivisorDescriptionEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<VertexInputBindingDivisorDescriptionEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineVertexInputDivisorStateCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineVertexInputDivisorStateCreateInfoEXT( uint32_t vertexBindingDivisorCount_ = 0,
                                                                         const vk::VertexInputBindingDivisorDescriptionEXT* pVertexBindingDivisors_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : vertexBindingDivisorCount( vertexBindingDivisorCount_ )
        , pVertexBindingDivisors( pVertexBindingDivisors_ )
      {}

      PipelineVertexInputDivisorStateCreateInfoEXT( VkPipelineVertexInputDivisorStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineVertexInputDivisorStateCreateInfoEXT*>(this) = rhs;
      }

      PipelineVertexInputDivisorStateCreateInfoEXT& operator=( VkPipelineVertexInputDivisorStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineVertexInputDivisorStateCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineVertexInputDivisorStateCreateInfoEXT;
      const void* pNext = nullptr;
      uint32_t vertexBindingDivisorCount;
      const vk::VertexInputBindingDivisorDescriptionEXT* pVertexBindingDivisors;
    };
    static_assert( sizeof( PipelineVertexInputDivisorStateCreateInfoEXT ) == sizeof( VkPipelineVertexInputDivisorStateCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct PipelineVertexInputDivisorStateCreateInfoEXT : public layout::PipelineVertexInputDivisorStateCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR PipelineVertexInputDivisorStateCreateInfoEXT( uint32_t vertexBindingDivisorCount_ = 0,
                                                                       const vk::VertexInputBindingDivisorDescriptionEXT* pVertexBindingDivisors_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineVertexInputDivisorStateCreateInfoEXT( vertexBindingDivisorCount_, pVertexBindingDivisors_ )
    {}

    PipelineVertexInputDivisorStateCreateInfoEXT( VkPipelineVertexInputDivisorStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineVertexInputDivisorStateCreateInfoEXT( rhs )
    {}

    PipelineVertexInputDivisorStateCreateInfoEXT& operator=( VkPipelineVertexInputDivisorStateCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineVertexInputDivisorStateCreateInfoEXT::operator=(rhs);
      return *this;
    }

    PipelineVertexInputDivisorStateCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineVertexInputDivisorStateCreateInfoEXT & setVertexBindingDivisorCount( uint32_t vertexBindingDivisorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      vertexBindingDivisorCount = vertexBindingDivisorCount_;
      return *this;
    }

    PipelineVertexInputDivisorStateCreateInfoEXT & setPVertexBindingDivisors( const vk::VertexInputBindingDivisorDescriptionEXT* pVertexBindingDivisors_ ) VULKAN_HPP_NOEXCEPT
    {
      pVertexBindingDivisors = pVertexBindingDivisors_;
      return *this;
    }

    operator VkPipelineVertexInputDivisorStateCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineVertexInputDivisorStateCreateInfoEXT*>( this );
    }

    operator VkPipelineVertexInputDivisorStateCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineVertexInputDivisorStateCreateInfoEXT*>( this );
    }

    bool operator==( PipelineVertexInputDivisorStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( vertexBindingDivisorCount == rhs.vertexBindingDivisorCount )
          && ( pVertexBindingDivisors == rhs.pVertexBindingDivisors );
    }

    bool operator!=( PipelineVertexInputDivisorStateCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineVertexInputDivisorStateCreateInfoEXT::sType;
  };
  static_assert( sizeof( PipelineVertexInputDivisorStateCreateInfoEXT ) == sizeof( VkPipelineVertexInputDivisorStateCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineVertexInputDivisorStateCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineViewportCoarseSampleOrderStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineViewportCoarseSampleOrderStateCreateInfoNV( vk::CoarseSampleOrderTypeNV sampleOrderType_ = vk::CoarseSampleOrderTypeNV::eDefault,
                                                                               uint32_t customSampleOrderCount_ = 0,
                                                                               const vk::CoarseSampleOrderCustomNV* pCustomSampleOrders_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : sampleOrderType( sampleOrderType_ )
        , customSampleOrderCount( customSampleOrderCount_ )
        , pCustomSampleOrders( pCustomSampleOrders_ )
      {}

      PipelineViewportCoarseSampleOrderStateCreateInfoNV( VkPipelineViewportCoarseSampleOrderStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportCoarseSampleOrderStateCreateInfoNV*>(this) = rhs;
      }

      PipelineViewportCoarseSampleOrderStateCreateInfoNV& operator=( VkPipelineViewportCoarseSampleOrderStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportCoarseSampleOrderStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineViewportCoarseSampleOrderStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::CoarseSampleOrderTypeNV sampleOrderType;
      uint32_t customSampleOrderCount;
      const vk::CoarseSampleOrderCustomNV* pCustomSampleOrders;
    };
    static_assert( sizeof( PipelineViewportCoarseSampleOrderStateCreateInfoNV ) == sizeof( VkPipelineViewportCoarseSampleOrderStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineViewportCoarseSampleOrderStateCreateInfoNV : public layout::PipelineViewportCoarseSampleOrderStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineViewportCoarseSampleOrderStateCreateInfoNV( vk::CoarseSampleOrderTypeNV sampleOrderType_ = vk::CoarseSampleOrderTypeNV::eDefault,
                                                                             uint32_t customSampleOrderCount_ = 0,
                                                                             const vk::CoarseSampleOrderCustomNV* pCustomSampleOrders_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportCoarseSampleOrderStateCreateInfoNV( sampleOrderType_, customSampleOrderCount_, pCustomSampleOrders_ )
    {}

    PipelineViewportCoarseSampleOrderStateCreateInfoNV( VkPipelineViewportCoarseSampleOrderStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportCoarseSampleOrderStateCreateInfoNV( rhs )
    {}

    PipelineViewportCoarseSampleOrderStateCreateInfoNV& operator=( VkPipelineViewportCoarseSampleOrderStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineViewportCoarseSampleOrderStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineViewportCoarseSampleOrderStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineViewportCoarseSampleOrderStateCreateInfoNV & setSampleOrderType( vk::CoarseSampleOrderTypeNV sampleOrderType_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleOrderType = sampleOrderType_;
      return *this;
    }

    PipelineViewportCoarseSampleOrderStateCreateInfoNV & setCustomSampleOrderCount( uint32_t customSampleOrderCount_ ) VULKAN_HPP_NOEXCEPT
    {
      customSampleOrderCount = customSampleOrderCount_;
      return *this;
    }

    PipelineViewportCoarseSampleOrderStateCreateInfoNV & setPCustomSampleOrders( const vk::CoarseSampleOrderCustomNV* pCustomSampleOrders_ ) VULKAN_HPP_NOEXCEPT
    {
      pCustomSampleOrders = pCustomSampleOrders_;
      return *this;
    }

    operator VkPipelineViewportCoarseSampleOrderStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineViewportCoarseSampleOrderStateCreateInfoNV*>( this );
    }

    operator VkPipelineViewportCoarseSampleOrderStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineViewportCoarseSampleOrderStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineViewportCoarseSampleOrderStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( sampleOrderType == rhs.sampleOrderType )
          && ( customSampleOrderCount == rhs.customSampleOrderCount )
          && ( pCustomSampleOrders == rhs.pCustomSampleOrders );
    }

    bool operator!=( PipelineViewportCoarseSampleOrderStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineViewportCoarseSampleOrderStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineViewportCoarseSampleOrderStateCreateInfoNV ) == sizeof( VkPipelineViewportCoarseSampleOrderStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineViewportCoarseSampleOrderStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineViewportExclusiveScissorStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineViewportExclusiveScissorStateCreateInfoNV( uint32_t exclusiveScissorCount_ = 0,
                                                                              const vk::Rect2D* pExclusiveScissors_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : exclusiveScissorCount( exclusiveScissorCount_ )
        , pExclusiveScissors( pExclusiveScissors_ )
      {}

      PipelineViewportExclusiveScissorStateCreateInfoNV( VkPipelineViewportExclusiveScissorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportExclusiveScissorStateCreateInfoNV*>(this) = rhs;
      }

      PipelineViewportExclusiveScissorStateCreateInfoNV& operator=( VkPipelineViewportExclusiveScissorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportExclusiveScissorStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineViewportExclusiveScissorStateCreateInfoNV;
      const void* pNext = nullptr;
      uint32_t exclusiveScissorCount;
      const vk::Rect2D* pExclusiveScissors;
    };
    static_assert( sizeof( PipelineViewportExclusiveScissorStateCreateInfoNV ) == sizeof( VkPipelineViewportExclusiveScissorStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineViewportExclusiveScissorStateCreateInfoNV : public layout::PipelineViewportExclusiveScissorStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineViewportExclusiveScissorStateCreateInfoNV( uint32_t exclusiveScissorCount_ = 0,
                                                                            const vk::Rect2D* pExclusiveScissors_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportExclusiveScissorStateCreateInfoNV( exclusiveScissorCount_, pExclusiveScissors_ )
    {}

    PipelineViewportExclusiveScissorStateCreateInfoNV( VkPipelineViewportExclusiveScissorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportExclusiveScissorStateCreateInfoNV( rhs )
    {}

    PipelineViewportExclusiveScissorStateCreateInfoNV& operator=( VkPipelineViewportExclusiveScissorStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineViewportExclusiveScissorStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineViewportExclusiveScissorStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineViewportExclusiveScissorStateCreateInfoNV & setExclusiveScissorCount( uint32_t exclusiveScissorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      exclusiveScissorCount = exclusiveScissorCount_;
      return *this;
    }

    PipelineViewportExclusiveScissorStateCreateInfoNV & setPExclusiveScissors( const vk::Rect2D* pExclusiveScissors_ ) VULKAN_HPP_NOEXCEPT
    {
      pExclusiveScissors = pExclusiveScissors_;
      return *this;
    }

    operator VkPipelineViewportExclusiveScissorStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineViewportExclusiveScissorStateCreateInfoNV*>( this );
    }

    operator VkPipelineViewportExclusiveScissorStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineViewportExclusiveScissorStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineViewportExclusiveScissorStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( exclusiveScissorCount == rhs.exclusiveScissorCount )
          && ( pExclusiveScissors == rhs.pExclusiveScissors );
    }

    bool operator!=( PipelineViewportExclusiveScissorStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineViewportExclusiveScissorStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineViewportExclusiveScissorStateCreateInfoNV ) == sizeof( VkPipelineViewportExclusiveScissorStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineViewportExclusiveScissorStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  struct ShadingRatePaletteNV
  {
    VULKAN_HPP_CONSTEXPR ShadingRatePaletteNV( uint32_t shadingRatePaletteEntryCount_ = 0,
                                               const vk::ShadingRatePaletteEntryNV* pShadingRatePaletteEntries_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : shadingRatePaletteEntryCount( shadingRatePaletteEntryCount_ )
      , pShadingRatePaletteEntries( pShadingRatePaletteEntries_ )
    {}

    ShadingRatePaletteNV( VkShadingRatePaletteNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkShadingRatePaletteNV*>(this) = rhs;
    }

    ShadingRatePaletteNV& operator=( VkShadingRatePaletteNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkShadingRatePaletteNV*>(this) = rhs;
      return *this;
    }

    ShadingRatePaletteNV & setShadingRatePaletteEntryCount( uint32_t shadingRatePaletteEntryCount_ ) VULKAN_HPP_NOEXCEPT
    {
      shadingRatePaletteEntryCount = shadingRatePaletteEntryCount_;
      return *this;
    }

    ShadingRatePaletteNV & setPShadingRatePaletteEntries( const vk::ShadingRatePaletteEntryNV* pShadingRatePaletteEntries_ ) VULKAN_HPP_NOEXCEPT
    {
      pShadingRatePaletteEntries = pShadingRatePaletteEntries_;
      return *this;
    }

    operator VkShadingRatePaletteNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkShadingRatePaletteNV*>( this );
    }

    operator VkShadingRatePaletteNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkShadingRatePaletteNV*>( this );
    }

    bool operator==( ShadingRatePaletteNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( shadingRatePaletteEntryCount == rhs.shadingRatePaletteEntryCount )
          && ( pShadingRatePaletteEntries == rhs.pShadingRatePaletteEntries );
    }

    bool operator!=( ShadingRatePaletteNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t shadingRatePaletteEntryCount;
    const vk::ShadingRatePaletteEntryNV* pShadingRatePaletteEntries;
  };
  static_assert( sizeof( ShadingRatePaletteNV ) == sizeof( VkShadingRatePaletteNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ShadingRatePaletteNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineViewportShadingRateImageStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineViewportShadingRateImageStateCreateInfoNV( vk::Bool32 shadingRateImageEnable_ = 0,
                                                                              uint32_t viewportCount_ = 0,
                                                                              const vk::ShadingRatePaletteNV* pShadingRatePalettes_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : shadingRateImageEnable( shadingRateImageEnable_ )
        , viewportCount( viewportCount_ )
        , pShadingRatePalettes( pShadingRatePalettes_ )
      {}

      PipelineViewportShadingRateImageStateCreateInfoNV( VkPipelineViewportShadingRateImageStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportShadingRateImageStateCreateInfoNV*>(this) = rhs;
      }

      PipelineViewportShadingRateImageStateCreateInfoNV& operator=( VkPipelineViewportShadingRateImageStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportShadingRateImageStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineViewportShadingRateImageStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::Bool32 shadingRateImageEnable;
      uint32_t viewportCount;
      const vk::ShadingRatePaletteNV* pShadingRatePalettes;
    };
    static_assert( sizeof( PipelineViewportShadingRateImageStateCreateInfoNV ) == sizeof( VkPipelineViewportShadingRateImageStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineViewportShadingRateImageStateCreateInfoNV : public layout::PipelineViewportShadingRateImageStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineViewportShadingRateImageStateCreateInfoNV( vk::Bool32 shadingRateImageEnable_ = 0,
                                                                            uint32_t viewportCount_ = 0,
                                                                            const vk::ShadingRatePaletteNV* pShadingRatePalettes_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportShadingRateImageStateCreateInfoNV( shadingRateImageEnable_, viewportCount_, pShadingRatePalettes_ )
    {}

    PipelineViewportShadingRateImageStateCreateInfoNV( VkPipelineViewportShadingRateImageStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportShadingRateImageStateCreateInfoNV( rhs )
    {}

    PipelineViewportShadingRateImageStateCreateInfoNV& operator=( VkPipelineViewportShadingRateImageStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineViewportShadingRateImageStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineViewportShadingRateImageStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineViewportShadingRateImageStateCreateInfoNV & setShadingRateImageEnable( vk::Bool32 shadingRateImageEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      shadingRateImageEnable = shadingRateImageEnable_;
      return *this;
    }

    PipelineViewportShadingRateImageStateCreateInfoNV & setViewportCount( uint32_t viewportCount_ ) VULKAN_HPP_NOEXCEPT
    {
      viewportCount = viewportCount_;
      return *this;
    }

    PipelineViewportShadingRateImageStateCreateInfoNV & setPShadingRatePalettes( const vk::ShadingRatePaletteNV* pShadingRatePalettes_ ) VULKAN_HPP_NOEXCEPT
    {
      pShadingRatePalettes = pShadingRatePalettes_;
      return *this;
    }

    operator VkPipelineViewportShadingRateImageStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineViewportShadingRateImageStateCreateInfoNV*>( this );
    }

    operator VkPipelineViewportShadingRateImageStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineViewportShadingRateImageStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineViewportShadingRateImageStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( shadingRateImageEnable == rhs.shadingRateImageEnable )
          && ( viewportCount == rhs.viewportCount )
          && ( pShadingRatePalettes == rhs.pShadingRatePalettes );
    }

    bool operator!=( PipelineViewportShadingRateImageStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineViewportShadingRateImageStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineViewportShadingRateImageStateCreateInfoNV ) == sizeof( VkPipelineViewportShadingRateImageStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineViewportShadingRateImageStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  struct ViewportSwizzleNV
  {
    VULKAN_HPP_CONSTEXPR ViewportSwizzleNV( vk::ViewportCoordinateSwizzleNV x_ = vk::ViewportCoordinateSwizzleNV::ePositiveX,
                                            vk::ViewportCoordinateSwizzleNV y_ = vk::ViewportCoordinateSwizzleNV::ePositiveX,
                                            vk::ViewportCoordinateSwizzleNV z_ = vk::ViewportCoordinateSwizzleNV::ePositiveX,
                                            vk::ViewportCoordinateSwizzleNV w_ = vk::ViewportCoordinateSwizzleNV::ePositiveX ) VULKAN_HPP_NOEXCEPT
      : x( x_ )
      , y( y_ )
      , z( z_ )
      , w( w_ )
    {}

    ViewportSwizzleNV( VkViewportSwizzleNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkViewportSwizzleNV*>(this) = rhs;
    }

    ViewportSwizzleNV& operator=( VkViewportSwizzleNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkViewportSwizzleNV*>(this) = rhs;
      return *this;
    }

    ViewportSwizzleNV & setX( vk::ViewportCoordinateSwizzleNV x_ ) VULKAN_HPP_NOEXCEPT
    {
      x = x_;
      return *this;
    }

    ViewportSwizzleNV & setY( vk::ViewportCoordinateSwizzleNV y_ ) VULKAN_HPP_NOEXCEPT
    {
      y = y_;
      return *this;
    }

    ViewportSwizzleNV & setZ( vk::ViewportCoordinateSwizzleNV z_ ) VULKAN_HPP_NOEXCEPT
    {
      z = z_;
      return *this;
    }

    ViewportSwizzleNV & setW( vk::ViewportCoordinateSwizzleNV w_ ) VULKAN_HPP_NOEXCEPT
    {
      w = w_;
      return *this;
    }

    operator VkViewportSwizzleNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkViewportSwizzleNV*>( this );
    }

    operator VkViewportSwizzleNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkViewportSwizzleNV*>( this );
    }

    bool operator==( ViewportSwizzleNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( x == rhs.x )
          && ( y == rhs.y )
          && ( z == rhs.z )
          && ( w == rhs.w );
    }

    bool operator!=( ViewportSwizzleNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ViewportCoordinateSwizzleNV x;
    vk::ViewportCoordinateSwizzleNV y;
    vk::ViewportCoordinateSwizzleNV z;
    vk::ViewportCoordinateSwizzleNV w;
  };
  static_assert( sizeof( ViewportSwizzleNV ) == sizeof( VkViewportSwizzleNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ViewportSwizzleNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineViewportSwizzleStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineViewportSwizzleStateCreateInfoNV( vk::PipelineViewportSwizzleStateCreateFlagsNV flags_ = vk::PipelineViewportSwizzleStateCreateFlagsNV(),
                                                                     uint32_t viewportCount_ = 0,
                                                                     const vk::ViewportSwizzleNV* pViewportSwizzles_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , viewportCount( viewportCount_ )
        , pViewportSwizzles( pViewportSwizzles_ )
      {}

      PipelineViewportSwizzleStateCreateInfoNV( VkPipelineViewportSwizzleStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportSwizzleStateCreateInfoNV*>(this) = rhs;
      }

      PipelineViewportSwizzleStateCreateInfoNV& operator=( VkPipelineViewportSwizzleStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportSwizzleStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineViewportSwizzleStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::PipelineViewportSwizzleStateCreateFlagsNV flags;
      uint32_t viewportCount;
      const vk::ViewportSwizzleNV* pViewportSwizzles;
    };
    static_assert( sizeof( PipelineViewportSwizzleStateCreateInfoNV ) == sizeof( VkPipelineViewportSwizzleStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineViewportSwizzleStateCreateInfoNV : public layout::PipelineViewportSwizzleStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineViewportSwizzleStateCreateInfoNV( vk::PipelineViewportSwizzleStateCreateFlagsNV flags_ = vk::PipelineViewportSwizzleStateCreateFlagsNV(),
                                                                   uint32_t viewportCount_ = 0,
                                                                   const vk::ViewportSwizzleNV* pViewportSwizzles_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportSwizzleStateCreateInfoNV( flags_, viewportCount_, pViewportSwizzles_ )
    {}

    PipelineViewportSwizzleStateCreateInfoNV( VkPipelineViewportSwizzleStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportSwizzleStateCreateInfoNV( rhs )
    {}

    PipelineViewportSwizzleStateCreateInfoNV& operator=( VkPipelineViewportSwizzleStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineViewportSwizzleStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineViewportSwizzleStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineViewportSwizzleStateCreateInfoNV & setFlags( vk::PipelineViewportSwizzleStateCreateFlagsNV flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    PipelineViewportSwizzleStateCreateInfoNV & setViewportCount( uint32_t viewportCount_ ) VULKAN_HPP_NOEXCEPT
    {
      viewportCount = viewportCount_;
      return *this;
    }

    PipelineViewportSwizzleStateCreateInfoNV & setPViewportSwizzles( const vk::ViewportSwizzleNV* pViewportSwizzles_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewportSwizzles = pViewportSwizzles_;
      return *this;
    }

    operator VkPipelineViewportSwizzleStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineViewportSwizzleStateCreateInfoNV*>( this );
    }

    operator VkPipelineViewportSwizzleStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineViewportSwizzleStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineViewportSwizzleStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( viewportCount == rhs.viewportCount )
          && ( pViewportSwizzles == rhs.pViewportSwizzles );
    }

    bool operator!=( PipelineViewportSwizzleStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineViewportSwizzleStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineViewportSwizzleStateCreateInfoNV ) == sizeof( VkPipelineViewportSwizzleStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineViewportSwizzleStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  struct ViewportWScalingNV
  {
    VULKAN_HPP_CONSTEXPR ViewportWScalingNV( float xcoeff_ = 0,
                                             float ycoeff_ = 0 ) VULKAN_HPP_NOEXCEPT
      : xcoeff( xcoeff_ )
      , ycoeff( ycoeff_ )
    {}

    ViewportWScalingNV( VkViewportWScalingNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkViewportWScalingNV*>(this) = rhs;
    }

    ViewportWScalingNV& operator=( VkViewportWScalingNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkViewportWScalingNV*>(this) = rhs;
      return *this;
    }

    ViewportWScalingNV & setXcoeff( float xcoeff_ ) VULKAN_HPP_NOEXCEPT
    {
      xcoeff = xcoeff_;
      return *this;
    }

    ViewportWScalingNV & setYcoeff( float ycoeff_ ) VULKAN_HPP_NOEXCEPT
    {
      ycoeff = ycoeff_;
      return *this;
    }

    operator VkViewportWScalingNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkViewportWScalingNV*>( this );
    }

    operator VkViewportWScalingNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkViewportWScalingNV*>( this );
    }

    bool operator==( ViewportWScalingNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( xcoeff == rhs.xcoeff )
          && ( ycoeff == rhs.ycoeff );
    }

    bool operator!=( ViewportWScalingNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    float xcoeff;
    float ycoeff;
  };
  static_assert( sizeof( ViewportWScalingNV ) == sizeof( VkViewportWScalingNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ViewportWScalingNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PipelineViewportWScalingStateCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR PipelineViewportWScalingStateCreateInfoNV( vk::Bool32 viewportWScalingEnable_ = 0,
                                                                      uint32_t viewportCount_ = 0,
                                                                      const vk::ViewportWScalingNV* pViewportWScalings_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : viewportWScalingEnable( viewportWScalingEnable_ )
        , viewportCount( viewportCount_ )
        , pViewportWScalings( pViewportWScalings_ )
      {}

      PipelineViewportWScalingStateCreateInfoNV( VkPipelineViewportWScalingStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportWScalingStateCreateInfoNV*>(this) = rhs;
      }

      PipelineViewportWScalingStateCreateInfoNV& operator=( VkPipelineViewportWScalingStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPipelineViewportWScalingStateCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePipelineViewportWScalingStateCreateInfoNV;
      const void* pNext = nullptr;
      vk::Bool32 viewportWScalingEnable;
      uint32_t viewportCount;
      const vk::ViewportWScalingNV* pViewportWScalings;
    };
    static_assert( sizeof( PipelineViewportWScalingStateCreateInfoNV ) == sizeof( VkPipelineViewportWScalingStateCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct PipelineViewportWScalingStateCreateInfoNV : public layout::PipelineViewportWScalingStateCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR PipelineViewportWScalingStateCreateInfoNV( vk::Bool32 viewportWScalingEnable_ = 0,
                                                                    uint32_t viewportCount_ = 0,
                                                                    const vk::ViewportWScalingNV* pViewportWScalings_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportWScalingStateCreateInfoNV( viewportWScalingEnable_, viewportCount_, pViewportWScalings_ )
    {}

    PipelineViewportWScalingStateCreateInfoNV( VkPipelineViewportWScalingStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PipelineViewportWScalingStateCreateInfoNV( rhs )
    {}

    PipelineViewportWScalingStateCreateInfoNV& operator=( VkPipelineViewportWScalingStateCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PipelineViewportWScalingStateCreateInfoNV::operator=(rhs);
      return *this;
    }

    PipelineViewportWScalingStateCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PipelineViewportWScalingStateCreateInfoNV & setViewportWScalingEnable( vk::Bool32 viewportWScalingEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      viewportWScalingEnable = viewportWScalingEnable_;
      return *this;
    }

    PipelineViewportWScalingStateCreateInfoNV & setViewportCount( uint32_t viewportCount_ ) VULKAN_HPP_NOEXCEPT
    {
      viewportCount = viewportCount_;
      return *this;
    }

    PipelineViewportWScalingStateCreateInfoNV & setPViewportWScalings( const vk::ViewportWScalingNV* pViewportWScalings_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewportWScalings = pViewportWScalings_;
      return *this;
    }

    operator VkPipelineViewportWScalingStateCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPipelineViewportWScalingStateCreateInfoNV*>( this );
    }

    operator VkPipelineViewportWScalingStateCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPipelineViewportWScalingStateCreateInfoNV*>( this );
    }

    bool operator==( PipelineViewportWScalingStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( viewportWScalingEnable == rhs.viewportWScalingEnable )
          && ( viewportCount == rhs.viewportCount )
          && ( pViewportWScalings == rhs.pViewportWScalings );
    }

    bool operator!=( PipelineViewportWScalingStateCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PipelineViewportWScalingStateCreateInfoNV::sType;
  };
  static_assert( sizeof( PipelineViewportWScalingStateCreateInfoNV ) == sizeof( VkPipelineViewportWScalingStateCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PipelineViewportWScalingStateCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_GGP

  namespace layout
  {
    struct PresentFrameTokenGGP
    {
    protected:
      VULKAN_HPP_CONSTEXPR PresentFrameTokenGGP( GgpFrameToken frameToken_ = 0 ) VULKAN_HPP_NOEXCEPT
        : frameToken( frameToken_ )
      {}

      PresentFrameTokenGGP( VkPresentFrameTokenGGP const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentFrameTokenGGP*>(this) = rhs;
      }

      PresentFrameTokenGGP& operator=( VkPresentFrameTokenGGP const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentFrameTokenGGP*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePresentFrameTokenGGP;
      const void* pNext = nullptr;
      GgpFrameToken frameToken;
    };
    static_assert( sizeof( PresentFrameTokenGGP ) == sizeof( VkPresentFrameTokenGGP ), "layout struct and wrapper have different size!" );
  }

  struct PresentFrameTokenGGP : public layout::PresentFrameTokenGGP
  {
    VULKAN_HPP_CONSTEXPR PresentFrameTokenGGP( GgpFrameToken frameToken_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::PresentFrameTokenGGP( frameToken_ )
    {}

    PresentFrameTokenGGP( VkPresentFrameTokenGGP const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PresentFrameTokenGGP( rhs )
    {}

    PresentFrameTokenGGP& operator=( VkPresentFrameTokenGGP const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PresentFrameTokenGGP::operator=(rhs);
      return *this;
    }

    PresentFrameTokenGGP & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PresentFrameTokenGGP & setFrameToken( GgpFrameToken frameToken_ ) VULKAN_HPP_NOEXCEPT
    {
      frameToken = frameToken_;
      return *this;
    }

    operator VkPresentFrameTokenGGP const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPresentFrameTokenGGP*>( this );
    }

    operator VkPresentFrameTokenGGP &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPresentFrameTokenGGP*>( this );
    }

    bool operator==( PresentFrameTokenGGP const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( frameToken == rhs.frameToken );
    }

    bool operator!=( PresentFrameTokenGGP const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PresentFrameTokenGGP::sType;
  };
  static_assert( sizeof( PresentFrameTokenGGP ) == sizeof( VkPresentFrameTokenGGP ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PresentFrameTokenGGP>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_GGP*/

  namespace layout
  {
    struct PresentInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PresentInfoKHR( uint32_t waitSemaphoreCount_ = 0,
                                           const vk::Semaphore* pWaitSemaphores_ = nullptr,
                                           uint32_t swapchainCount_ = 0,
                                           const vk::SwapchainKHR* pSwapchains_ = nullptr,
                                           const uint32_t* pImageIndices_ = nullptr,
                                           vk::Result* pResults_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : waitSemaphoreCount( waitSemaphoreCount_ )
        , pWaitSemaphores( pWaitSemaphores_ )
        , swapchainCount( swapchainCount_ )
        , pSwapchains( pSwapchains_ )
        , pImageIndices( pImageIndices_ )
        , pResults( pResults_ )
      {}

      PresentInfoKHR( VkPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentInfoKHR*>(this) = rhs;
      }

      PresentInfoKHR& operator=( VkPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePresentInfoKHR;
      const void* pNext = nullptr;
      uint32_t waitSemaphoreCount;
      const vk::Semaphore* pWaitSemaphores;
      uint32_t swapchainCount;
      const vk::SwapchainKHR* pSwapchains;
      const uint32_t* pImageIndices;
      vk::Result* pResults;
    };
    static_assert( sizeof( PresentInfoKHR ) == sizeof( VkPresentInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct PresentInfoKHR : public layout::PresentInfoKHR
  {
    VULKAN_HPP_CONSTEXPR PresentInfoKHR( uint32_t waitSemaphoreCount_ = 0,
                                         const vk::Semaphore* pWaitSemaphores_ = nullptr,
                                         uint32_t swapchainCount_ = 0,
                                         const vk::SwapchainKHR* pSwapchains_ = nullptr,
                                         const uint32_t* pImageIndices_ = nullptr,
                                         vk::Result* pResults_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PresentInfoKHR( waitSemaphoreCount_, pWaitSemaphores_, swapchainCount_, pSwapchains_, pImageIndices_, pResults_ )
    {}

    PresentInfoKHR( VkPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PresentInfoKHR( rhs )
    {}

    PresentInfoKHR& operator=( VkPresentInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PresentInfoKHR::operator=(rhs);
      return *this;
    }

    PresentInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PresentInfoKHR & setWaitSemaphoreCount( uint32_t waitSemaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      waitSemaphoreCount = waitSemaphoreCount_;
      return *this;
    }

    PresentInfoKHR & setPWaitSemaphores( const vk::Semaphore* pWaitSemaphores_ ) VULKAN_HPP_NOEXCEPT
    {
      pWaitSemaphores = pWaitSemaphores_;
      return *this;
    }

    PresentInfoKHR & setSwapchainCount( uint32_t swapchainCount_ ) VULKAN_HPP_NOEXCEPT
    {
      swapchainCount = swapchainCount_;
      return *this;
    }

    PresentInfoKHR & setPSwapchains( const vk::SwapchainKHR* pSwapchains_ ) VULKAN_HPP_NOEXCEPT
    {
      pSwapchains = pSwapchains_;
      return *this;
    }

    PresentInfoKHR & setPImageIndices( const uint32_t* pImageIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pImageIndices = pImageIndices_;
      return *this;
    }

    PresentInfoKHR & setPResults( vk::Result* pResults_ ) VULKAN_HPP_NOEXCEPT
    {
      pResults = pResults_;
      return *this;
    }

    operator VkPresentInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPresentInfoKHR*>( this );
    }

    operator VkPresentInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPresentInfoKHR*>( this );
    }

    bool operator==( PresentInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( waitSemaphoreCount == rhs.waitSemaphoreCount )
          && ( pWaitSemaphores == rhs.pWaitSemaphores )
          && ( swapchainCount == rhs.swapchainCount )
          && ( pSwapchains == rhs.pSwapchains )
          && ( pImageIndices == rhs.pImageIndices )
          && ( pResults == rhs.pResults );
    }

    bool operator!=( PresentInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PresentInfoKHR::sType;
  };
  static_assert( sizeof( PresentInfoKHR ) == sizeof( VkPresentInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PresentInfoKHR>::value, "struct wrapper is not a standard layout!" );

  struct RectLayerKHR
  {
    VULKAN_HPP_CONSTEXPR RectLayerKHR( vk::Offset2D offset_ = vk::Offset2D(),
                                       vk::Extent2D extent_ = vk::Extent2D(),
                                       uint32_t layer_ = 0 ) VULKAN_HPP_NOEXCEPT
      : offset( offset_ )
      , extent( extent_ )
      , layer( layer_ )
    {}

    explicit RectLayerKHR( Rect2D const& rect2D,
                           uint32_t layer_ = 0 )
      : offset( rect2D.offset )
      , extent( rect2D.extent )
      , layer( layer_ )
    {}

    RectLayerKHR( VkRectLayerKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkRectLayerKHR*>(this) = rhs;
    }

    RectLayerKHR& operator=( VkRectLayerKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkRectLayerKHR*>(this) = rhs;
      return *this;
    }

    RectLayerKHR & setOffset( vk::Offset2D offset_ ) VULKAN_HPP_NOEXCEPT
    {
      offset = offset_;
      return *this;
    }

    RectLayerKHR & setExtent( vk::Extent2D extent_ ) VULKAN_HPP_NOEXCEPT
    {
      extent = extent_;
      return *this;
    }

    RectLayerKHR & setLayer( uint32_t layer_ ) VULKAN_HPP_NOEXCEPT
    {
      layer = layer_;
      return *this;
    }

    operator VkRectLayerKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRectLayerKHR*>( this );
    }

    operator VkRectLayerKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRectLayerKHR*>( this );
    }

    bool operator==( RectLayerKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( offset == rhs.offset )
          && ( extent == rhs.extent )
          && ( layer == rhs.layer );
    }

    bool operator!=( RectLayerKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Offset2D offset;
    vk::Extent2D extent;
    uint32_t layer;
  };
  static_assert( sizeof( RectLayerKHR ) == sizeof( VkRectLayerKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RectLayerKHR>::value, "struct wrapper is not a standard layout!" );

  struct PresentRegionKHR
  {
    VULKAN_HPP_CONSTEXPR PresentRegionKHR( uint32_t rectangleCount_ = 0,
                                           const vk::RectLayerKHR* pRectangles_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : rectangleCount( rectangleCount_ )
      , pRectangles( pRectangles_ )
    {}

    PresentRegionKHR( VkPresentRegionKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPresentRegionKHR*>(this) = rhs;
    }

    PresentRegionKHR& operator=( VkPresentRegionKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPresentRegionKHR*>(this) = rhs;
      return *this;
    }

    PresentRegionKHR & setRectangleCount( uint32_t rectangleCount_ ) VULKAN_HPP_NOEXCEPT
    {
      rectangleCount = rectangleCount_;
      return *this;
    }

    PresentRegionKHR & setPRectangles( const vk::RectLayerKHR* pRectangles_ ) VULKAN_HPP_NOEXCEPT
    {
      pRectangles = pRectangles_;
      return *this;
    }

    operator VkPresentRegionKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPresentRegionKHR*>( this );
    }

    operator VkPresentRegionKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPresentRegionKHR*>( this );
    }

    bool operator==( PresentRegionKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( rectangleCount == rhs.rectangleCount )
          && ( pRectangles == rhs.pRectangles );
    }

    bool operator!=( PresentRegionKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t rectangleCount;
    const vk::RectLayerKHR* pRectangles;
  };
  static_assert( sizeof( PresentRegionKHR ) == sizeof( VkPresentRegionKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PresentRegionKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PresentRegionsKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR PresentRegionsKHR( uint32_t swapchainCount_ = 0,
                                              const vk::PresentRegionKHR* pRegions_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : swapchainCount( swapchainCount_ )
        , pRegions( pRegions_ )
      {}

      PresentRegionsKHR( VkPresentRegionsKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentRegionsKHR*>(this) = rhs;
      }

      PresentRegionsKHR& operator=( VkPresentRegionsKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentRegionsKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePresentRegionsKHR;
      const void* pNext = nullptr;
      uint32_t swapchainCount;
      const vk::PresentRegionKHR* pRegions;
    };
    static_assert( sizeof( PresentRegionsKHR ) == sizeof( VkPresentRegionsKHR ), "layout struct and wrapper have different size!" );
  }

  struct PresentRegionsKHR : public layout::PresentRegionsKHR
  {
    VULKAN_HPP_CONSTEXPR PresentRegionsKHR( uint32_t swapchainCount_ = 0,
                                            const vk::PresentRegionKHR* pRegions_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PresentRegionsKHR( swapchainCount_, pRegions_ )
    {}

    PresentRegionsKHR( VkPresentRegionsKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PresentRegionsKHR( rhs )
    {}

    PresentRegionsKHR& operator=( VkPresentRegionsKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PresentRegionsKHR::operator=(rhs);
      return *this;
    }

    PresentRegionsKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PresentRegionsKHR & setSwapchainCount( uint32_t swapchainCount_ ) VULKAN_HPP_NOEXCEPT
    {
      swapchainCount = swapchainCount_;
      return *this;
    }

    PresentRegionsKHR & setPRegions( const vk::PresentRegionKHR* pRegions_ ) VULKAN_HPP_NOEXCEPT
    {
      pRegions = pRegions_;
      return *this;
    }

    operator VkPresentRegionsKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPresentRegionsKHR*>( this );
    }

    operator VkPresentRegionsKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPresentRegionsKHR*>( this );
    }

    bool operator==( PresentRegionsKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( swapchainCount == rhs.swapchainCount )
          && ( pRegions == rhs.pRegions );
    }

    bool operator!=( PresentRegionsKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PresentRegionsKHR::sType;
  };
  static_assert( sizeof( PresentRegionsKHR ) == sizeof( VkPresentRegionsKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PresentRegionsKHR>::value, "struct wrapper is not a standard layout!" );

  struct PresentTimeGOOGLE
  {
    VULKAN_HPP_CONSTEXPR PresentTimeGOOGLE( uint32_t presentID_ = 0,
                                            uint64_t desiredPresentTime_ = 0 ) VULKAN_HPP_NOEXCEPT
      : presentID( presentID_ )
      , desiredPresentTime( desiredPresentTime_ )
    {}

    PresentTimeGOOGLE( VkPresentTimeGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPresentTimeGOOGLE*>(this) = rhs;
    }

    PresentTimeGOOGLE& operator=( VkPresentTimeGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkPresentTimeGOOGLE*>(this) = rhs;
      return *this;
    }

    PresentTimeGOOGLE & setPresentID( uint32_t presentID_ ) VULKAN_HPP_NOEXCEPT
    {
      presentID = presentID_;
      return *this;
    }

    PresentTimeGOOGLE & setDesiredPresentTime( uint64_t desiredPresentTime_ ) VULKAN_HPP_NOEXCEPT
    {
      desiredPresentTime = desiredPresentTime_;
      return *this;
    }

    operator VkPresentTimeGOOGLE const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPresentTimeGOOGLE*>( this );
    }

    operator VkPresentTimeGOOGLE &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPresentTimeGOOGLE*>( this );
    }

    bool operator==( PresentTimeGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( presentID == rhs.presentID )
          && ( desiredPresentTime == rhs.desiredPresentTime );
    }

    bool operator!=( PresentTimeGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t presentID;
    uint64_t desiredPresentTime;
  };
  static_assert( sizeof( PresentTimeGOOGLE ) == sizeof( VkPresentTimeGOOGLE ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PresentTimeGOOGLE>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct PresentTimesInfoGOOGLE
    {
    protected:
      VULKAN_HPP_CONSTEXPR PresentTimesInfoGOOGLE( uint32_t swapchainCount_ = 0,
                                                   const vk::PresentTimeGOOGLE* pTimes_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : swapchainCount( swapchainCount_ )
        , pTimes( pTimes_ )
      {}

      PresentTimesInfoGOOGLE( VkPresentTimesInfoGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentTimesInfoGOOGLE*>(this) = rhs;
      }

      PresentTimesInfoGOOGLE& operator=( VkPresentTimesInfoGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkPresentTimesInfoGOOGLE*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::ePresentTimesInfoGOOGLE;
      const void* pNext = nullptr;
      uint32_t swapchainCount;
      const vk::PresentTimeGOOGLE* pTimes;
    };
    static_assert( sizeof( PresentTimesInfoGOOGLE ) == sizeof( VkPresentTimesInfoGOOGLE ), "layout struct and wrapper have different size!" );
  }

  struct PresentTimesInfoGOOGLE : public layout::PresentTimesInfoGOOGLE
  {
    VULKAN_HPP_CONSTEXPR PresentTimesInfoGOOGLE( uint32_t swapchainCount_ = 0,
                                                 const vk::PresentTimeGOOGLE* pTimes_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::PresentTimesInfoGOOGLE( swapchainCount_, pTimes_ )
    {}

    PresentTimesInfoGOOGLE( VkPresentTimesInfoGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::PresentTimesInfoGOOGLE( rhs )
    {}

    PresentTimesInfoGOOGLE& operator=( VkPresentTimesInfoGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::PresentTimesInfoGOOGLE::operator=(rhs);
      return *this;
    }

    PresentTimesInfoGOOGLE & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    PresentTimesInfoGOOGLE & setSwapchainCount( uint32_t swapchainCount_ ) VULKAN_HPP_NOEXCEPT
    {
      swapchainCount = swapchainCount_;
      return *this;
    }

    PresentTimesInfoGOOGLE & setPTimes( const vk::PresentTimeGOOGLE* pTimes_ ) VULKAN_HPP_NOEXCEPT
    {
      pTimes = pTimes_;
      return *this;
    }

    operator VkPresentTimesInfoGOOGLE const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkPresentTimesInfoGOOGLE*>( this );
    }

    operator VkPresentTimesInfoGOOGLE &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkPresentTimesInfoGOOGLE*>( this );
    }

    bool operator==( PresentTimesInfoGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( swapchainCount == rhs.swapchainCount )
          && ( pTimes == rhs.pTimes );
    }

    bool operator!=( PresentTimesInfoGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::PresentTimesInfoGOOGLE::sType;
  };
  static_assert( sizeof( PresentTimesInfoGOOGLE ) == sizeof( VkPresentTimesInfoGOOGLE ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<PresentTimesInfoGOOGLE>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ProtectedSubmitInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ProtectedSubmitInfo( vk::Bool32 protectedSubmit_ = 0 ) VULKAN_HPP_NOEXCEPT
        : protectedSubmit( protectedSubmit_ )
      {}

      ProtectedSubmitInfo( VkProtectedSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkProtectedSubmitInfo*>(this) = rhs;
      }

      ProtectedSubmitInfo& operator=( VkProtectedSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkProtectedSubmitInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eProtectedSubmitInfo;
      const void* pNext = nullptr;
      vk::Bool32 protectedSubmit;
    };
    static_assert( sizeof( ProtectedSubmitInfo ) == sizeof( VkProtectedSubmitInfo ), "layout struct and wrapper have different size!" );
  }

  struct ProtectedSubmitInfo : public layout::ProtectedSubmitInfo
  {
    VULKAN_HPP_CONSTEXPR ProtectedSubmitInfo( vk::Bool32 protectedSubmit_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::ProtectedSubmitInfo( protectedSubmit_ )
    {}

    ProtectedSubmitInfo( VkProtectedSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ProtectedSubmitInfo( rhs )
    {}

    ProtectedSubmitInfo& operator=( VkProtectedSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ProtectedSubmitInfo::operator=(rhs);
      return *this;
    }

    ProtectedSubmitInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ProtectedSubmitInfo & setProtectedSubmit( vk::Bool32 protectedSubmit_ ) VULKAN_HPP_NOEXCEPT
    {
      protectedSubmit = protectedSubmit_;
      return *this;
    }

    operator VkProtectedSubmitInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkProtectedSubmitInfo*>( this );
    }

    operator VkProtectedSubmitInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkProtectedSubmitInfo*>( this );
    }

    bool operator==( ProtectedSubmitInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( protectedSubmit == rhs.protectedSubmit );
    }

    bool operator!=( ProtectedSubmitInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ProtectedSubmitInfo::sType;
  };
  static_assert( sizeof( ProtectedSubmitInfo ) == sizeof( VkProtectedSubmitInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ProtectedSubmitInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct QueryPoolCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR QueryPoolCreateInfo( vk::QueryPoolCreateFlags flags_ = vk::QueryPoolCreateFlags(),
                                                vk::QueryType queryType_ = vk::QueryType::eOcclusion,
                                                uint32_t queryCount_ = 0,
                                                vk::QueryPipelineStatisticFlags pipelineStatistics_ = vk::QueryPipelineStatisticFlags() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , queryType( queryType_ )
        , queryCount( queryCount_ )
        , pipelineStatistics( pipelineStatistics_ )
      {}

      QueryPoolCreateInfo( VkQueryPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueryPoolCreateInfo*>(this) = rhs;
      }

      QueryPoolCreateInfo& operator=( VkQueryPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueryPoolCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eQueryPoolCreateInfo;
      const void* pNext = nullptr;
      vk::QueryPoolCreateFlags flags;
      vk::QueryType queryType;
      uint32_t queryCount;
      vk::QueryPipelineStatisticFlags pipelineStatistics;
    };
    static_assert( sizeof( QueryPoolCreateInfo ) == sizeof( VkQueryPoolCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct QueryPoolCreateInfo : public layout::QueryPoolCreateInfo
  {
    VULKAN_HPP_CONSTEXPR QueryPoolCreateInfo( vk::QueryPoolCreateFlags flags_ = vk::QueryPoolCreateFlags(),
                                              vk::QueryType queryType_ = vk::QueryType::eOcclusion,
                                              uint32_t queryCount_ = 0,
                                              vk::QueryPipelineStatisticFlags pipelineStatistics_ = vk::QueryPipelineStatisticFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::QueryPoolCreateInfo( flags_, queryType_, queryCount_, pipelineStatistics_ )
    {}

    QueryPoolCreateInfo( VkQueryPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::QueryPoolCreateInfo( rhs )
    {}

    QueryPoolCreateInfo& operator=( VkQueryPoolCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::QueryPoolCreateInfo::operator=(rhs);
      return *this;
    }

    QueryPoolCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    QueryPoolCreateInfo & setFlags( vk::QueryPoolCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    QueryPoolCreateInfo & setQueryType( vk::QueryType queryType_ ) VULKAN_HPP_NOEXCEPT
    {
      queryType = queryType_;
      return *this;
    }

    QueryPoolCreateInfo & setQueryCount( uint32_t queryCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queryCount = queryCount_;
      return *this;
    }

    QueryPoolCreateInfo & setPipelineStatistics( vk::QueryPipelineStatisticFlags pipelineStatistics_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineStatistics = pipelineStatistics_;
      return *this;
    }

    operator VkQueryPoolCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkQueryPoolCreateInfo*>( this );
    }

    operator VkQueryPoolCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkQueryPoolCreateInfo*>( this );
    }

    bool operator==( QueryPoolCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( queryType == rhs.queryType )
          && ( queryCount == rhs.queryCount )
          && ( pipelineStatistics == rhs.pipelineStatistics );
    }

    bool operator!=( QueryPoolCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::QueryPoolCreateInfo::sType;
  };
  static_assert( sizeof( QueryPoolCreateInfo ) == sizeof( VkQueryPoolCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<QueryPoolCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct QueryPoolCreateInfoINTEL
    {
    protected:
      VULKAN_HPP_CONSTEXPR QueryPoolCreateInfoINTEL( vk::QueryPoolSamplingModeINTEL performanceCountersSampling_ = vk::QueryPoolSamplingModeINTEL::eManual ) VULKAN_HPP_NOEXCEPT
        : performanceCountersSampling( performanceCountersSampling_ )
      {}

      QueryPoolCreateInfoINTEL( VkQueryPoolCreateInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueryPoolCreateInfoINTEL*>(this) = rhs;
      }

      QueryPoolCreateInfoINTEL& operator=( VkQueryPoolCreateInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueryPoolCreateInfoINTEL*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eQueryPoolCreateInfoINTEL;
      const void* pNext = nullptr;
      vk::QueryPoolSamplingModeINTEL performanceCountersSampling;
    };
    static_assert( sizeof( QueryPoolCreateInfoINTEL ) == sizeof( VkQueryPoolCreateInfoINTEL ), "layout struct and wrapper have different size!" );
  }

  struct QueryPoolCreateInfoINTEL : public layout::QueryPoolCreateInfoINTEL
  {
    VULKAN_HPP_CONSTEXPR QueryPoolCreateInfoINTEL( vk::QueryPoolSamplingModeINTEL performanceCountersSampling_ = vk::QueryPoolSamplingModeINTEL::eManual ) VULKAN_HPP_NOEXCEPT
      : layout::QueryPoolCreateInfoINTEL( performanceCountersSampling_ )
    {}

    QueryPoolCreateInfoINTEL( VkQueryPoolCreateInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::QueryPoolCreateInfoINTEL( rhs )
    {}

    QueryPoolCreateInfoINTEL& operator=( VkQueryPoolCreateInfoINTEL const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::QueryPoolCreateInfoINTEL::operator=(rhs);
      return *this;
    }

    QueryPoolCreateInfoINTEL & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    QueryPoolCreateInfoINTEL & setPerformanceCountersSampling( vk::QueryPoolSamplingModeINTEL performanceCountersSampling_ ) VULKAN_HPP_NOEXCEPT
    {
      performanceCountersSampling = performanceCountersSampling_;
      return *this;
    }

    operator VkQueryPoolCreateInfoINTEL const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkQueryPoolCreateInfoINTEL*>( this );
    }

    operator VkQueryPoolCreateInfoINTEL &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkQueryPoolCreateInfoINTEL*>( this );
    }

    bool operator==( QueryPoolCreateInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( performanceCountersSampling == rhs.performanceCountersSampling );
    }

    bool operator!=( QueryPoolCreateInfoINTEL const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::QueryPoolCreateInfoINTEL::sType;
  };
  static_assert( sizeof( QueryPoolCreateInfoINTEL ) == sizeof( VkQueryPoolCreateInfoINTEL ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<QueryPoolCreateInfoINTEL>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct QueueFamilyCheckpointPropertiesNV
    {
    protected:
      QueueFamilyCheckpointPropertiesNV() VULKAN_HPP_NOEXCEPT
      {}

      QueueFamilyCheckpointPropertiesNV( VkQueueFamilyCheckpointPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueueFamilyCheckpointPropertiesNV*>(this) = rhs;
      }

      QueueFamilyCheckpointPropertiesNV& operator=( VkQueueFamilyCheckpointPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueueFamilyCheckpointPropertiesNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eQueueFamilyCheckpointPropertiesNV;
      void* pNext = nullptr;
      vk::PipelineStageFlags checkpointExecutionStageMask;
    };
    static_assert( sizeof( QueueFamilyCheckpointPropertiesNV ) == sizeof( VkQueueFamilyCheckpointPropertiesNV ), "layout struct and wrapper have different size!" );
  }

  struct QueueFamilyCheckpointPropertiesNV : public layout::QueueFamilyCheckpointPropertiesNV
  {
    QueueFamilyCheckpointPropertiesNV() VULKAN_HPP_NOEXCEPT
      : layout::QueueFamilyCheckpointPropertiesNV()
    {}

    QueueFamilyCheckpointPropertiesNV( VkQueueFamilyCheckpointPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::QueueFamilyCheckpointPropertiesNV( rhs )
    {}

    QueueFamilyCheckpointPropertiesNV& operator=( VkQueueFamilyCheckpointPropertiesNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::QueueFamilyCheckpointPropertiesNV::operator=(rhs);
      return *this;
    }

    operator VkQueueFamilyCheckpointPropertiesNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkQueueFamilyCheckpointPropertiesNV*>( this );
    }

    operator VkQueueFamilyCheckpointPropertiesNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkQueueFamilyCheckpointPropertiesNV*>( this );
    }

    bool operator==( QueueFamilyCheckpointPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( checkpointExecutionStageMask == rhs.checkpointExecutionStageMask );
    }

    bool operator!=( QueueFamilyCheckpointPropertiesNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::QueueFamilyCheckpointPropertiesNV::sType;
  };
  static_assert( sizeof( QueueFamilyCheckpointPropertiesNV ) == sizeof( VkQueueFamilyCheckpointPropertiesNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<QueueFamilyCheckpointPropertiesNV>::value, "struct wrapper is not a standard layout!" );

  struct QueueFamilyProperties
  {
    QueueFamilyProperties() VULKAN_HPP_NOEXCEPT
    {}

    QueueFamilyProperties( VkQueueFamilyProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkQueueFamilyProperties*>(this) = rhs;
    }

    QueueFamilyProperties& operator=( VkQueueFamilyProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkQueueFamilyProperties*>(this) = rhs;
      return *this;
    }

    operator VkQueueFamilyProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkQueueFamilyProperties*>( this );
    }

    operator VkQueueFamilyProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkQueueFamilyProperties*>( this );
    }

    bool operator==( QueueFamilyProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( queueFlags == rhs.queueFlags )
          && ( queueCount == rhs.queueCount )
          && ( timestampValidBits == rhs.timestampValidBits )
          && ( minImageTransferGranularity == rhs.minImageTransferGranularity );
    }

    bool operator!=( QueueFamilyProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::QueueFlags queueFlags;
    uint32_t queueCount;
    uint32_t timestampValidBits;
    vk::Extent3D minImageTransferGranularity;
  };
  static_assert( sizeof( QueueFamilyProperties ) == sizeof( VkQueueFamilyProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<QueueFamilyProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct QueueFamilyProperties2
    {
    protected:
      QueueFamilyProperties2() VULKAN_HPP_NOEXCEPT
      {}

      QueueFamilyProperties2( VkQueueFamilyProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueueFamilyProperties2*>(this) = rhs;
      }

      QueueFamilyProperties2& operator=( VkQueueFamilyProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkQueueFamilyProperties2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eQueueFamilyProperties2;
      void* pNext = nullptr;
      vk::QueueFamilyProperties queueFamilyProperties;
    };
    static_assert( sizeof( QueueFamilyProperties2 ) == sizeof( VkQueueFamilyProperties2 ), "layout struct and wrapper have different size!" );
  }

  struct QueueFamilyProperties2 : public layout::QueueFamilyProperties2
  {
    QueueFamilyProperties2() VULKAN_HPP_NOEXCEPT
      : layout::QueueFamilyProperties2()
    {}

    QueueFamilyProperties2( VkQueueFamilyProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::QueueFamilyProperties2( rhs )
    {}

    QueueFamilyProperties2& operator=( VkQueueFamilyProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::QueueFamilyProperties2::operator=(rhs);
      return *this;
    }

    operator VkQueueFamilyProperties2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkQueueFamilyProperties2*>( this );
    }

    operator VkQueueFamilyProperties2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkQueueFamilyProperties2*>( this );
    }

    bool operator==( QueueFamilyProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( queueFamilyProperties == rhs.queueFamilyProperties );
    }

    bool operator!=( QueueFamilyProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::QueueFamilyProperties2::sType;
  };
  static_assert( sizeof( QueueFamilyProperties2 ) == sizeof( VkQueueFamilyProperties2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<QueueFamilyProperties2>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RayTracingShaderGroupCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR RayTracingShaderGroupCreateInfoNV( vk::RayTracingShaderGroupTypeNV type_ = vk::RayTracingShaderGroupTypeNV::eGeneral,
                                                              uint32_t generalShader_ = 0,
                                                              uint32_t closestHitShader_ = 0,
                                                              uint32_t anyHitShader_ = 0,
                                                              uint32_t intersectionShader_ = 0 ) VULKAN_HPP_NOEXCEPT
        : type( type_ )
        , generalShader( generalShader_ )
        , closestHitShader( closestHitShader_ )
        , anyHitShader( anyHitShader_ )
        , intersectionShader( intersectionShader_ )
      {}

      RayTracingShaderGroupCreateInfoNV( VkRayTracingShaderGroupCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRayTracingShaderGroupCreateInfoNV*>(this) = rhs;
      }

      RayTracingShaderGroupCreateInfoNV& operator=( VkRayTracingShaderGroupCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRayTracingShaderGroupCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRayTracingShaderGroupCreateInfoNV;
      const void* pNext = nullptr;
      vk::RayTracingShaderGroupTypeNV type;
      uint32_t generalShader;
      uint32_t closestHitShader;
      uint32_t anyHitShader;
      uint32_t intersectionShader;
    };
    static_assert( sizeof( RayTracingShaderGroupCreateInfoNV ) == sizeof( VkRayTracingShaderGroupCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct RayTracingShaderGroupCreateInfoNV : public layout::RayTracingShaderGroupCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR RayTracingShaderGroupCreateInfoNV( vk::RayTracingShaderGroupTypeNV type_ = vk::RayTracingShaderGroupTypeNV::eGeneral,
                                                            uint32_t generalShader_ = 0,
                                                            uint32_t closestHitShader_ = 0,
                                                            uint32_t anyHitShader_ = 0,
                                                            uint32_t intersectionShader_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::RayTracingShaderGroupCreateInfoNV( type_, generalShader_, closestHitShader_, anyHitShader_, intersectionShader_ )
    {}

    RayTracingShaderGroupCreateInfoNV( VkRayTracingShaderGroupCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RayTracingShaderGroupCreateInfoNV( rhs )
    {}

    RayTracingShaderGroupCreateInfoNV& operator=( VkRayTracingShaderGroupCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RayTracingShaderGroupCreateInfoNV::operator=(rhs);
      return *this;
    }

    RayTracingShaderGroupCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RayTracingShaderGroupCreateInfoNV & setType( vk::RayTracingShaderGroupTypeNV type_ ) VULKAN_HPP_NOEXCEPT
    {
      type = type_;
      return *this;
    }

    RayTracingShaderGroupCreateInfoNV & setGeneralShader( uint32_t generalShader_ ) VULKAN_HPP_NOEXCEPT
    {
      generalShader = generalShader_;
      return *this;
    }

    RayTracingShaderGroupCreateInfoNV & setClosestHitShader( uint32_t closestHitShader_ ) VULKAN_HPP_NOEXCEPT
    {
      closestHitShader = closestHitShader_;
      return *this;
    }

    RayTracingShaderGroupCreateInfoNV & setAnyHitShader( uint32_t anyHitShader_ ) VULKAN_HPP_NOEXCEPT
    {
      anyHitShader = anyHitShader_;
      return *this;
    }

    RayTracingShaderGroupCreateInfoNV & setIntersectionShader( uint32_t intersectionShader_ ) VULKAN_HPP_NOEXCEPT
    {
      intersectionShader = intersectionShader_;
      return *this;
    }

    operator VkRayTracingShaderGroupCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRayTracingShaderGroupCreateInfoNV*>( this );
    }

    operator VkRayTracingShaderGroupCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRayTracingShaderGroupCreateInfoNV*>( this );
    }

    bool operator==( RayTracingShaderGroupCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( type == rhs.type )
          && ( generalShader == rhs.generalShader )
          && ( closestHitShader == rhs.closestHitShader )
          && ( anyHitShader == rhs.anyHitShader )
          && ( intersectionShader == rhs.intersectionShader );
    }

    bool operator!=( RayTracingShaderGroupCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RayTracingShaderGroupCreateInfoNV::sType;
  };
  static_assert( sizeof( RayTracingShaderGroupCreateInfoNV ) == sizeof( VkRayTracingShaderGroupCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RayTracingShaderGroupCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RayTracingPipelineCreateInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR RayTracingPipelineCreateInfoNV( vk::PipelineCreateFlags flags_ = vk::PipelineCreateFlags(),
                                                           uint32_t stageCount_ = 0,
                                                           const vk::PipelineShaderStageCreateInfo* pStages_ = nullptr,
                                                           uint32_t groupCount_ = 0,
                                                           const vk::RayTracingShaderGroupCreateInfoNV* pGroups_ = nullptr,
                                                           uint32_t maxRecursionDepth_ = 0,
                                                           vk::PipelineLayout layout_ = vk::PipelineLayout(),
                                                           vk::Pipeline basePipelineHandle_ = vk::Pipeline(),
                                                           int32_t basePipelineIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , stageCount( stageCount_ )
        , pStages( pStages_ )
        , groupCount( groupCount_ )
        , pGroups( pGroups_ )
        , maxRecursionDepth( maxRecursionDepth_ )
        , layout( layout_ )
        , basePipelineHandle( basePipelineHandle_ )
        , basePipelineIndex( basePipelineIndex_ )
      {}

      RayTracingPipelineCreateInfoNV( VkRayTracingPipelineCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRayTracingPipelineCreateInfoNV*>(this) = rhs;
      }

      RayTracingPipelineCreateInfoNV& operator=( VkRayTracingPipelineCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRayTracingPipelineCreateInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRayTracingPipelineCreateInfoNV;
      const void* pNext = nullptr;
      vk::PipelineCreateFlags flags;
      uint32_t stageCount;
      const vk::PipelineShaderStageCreateInfo* pStages;
      uint32_t groupCount;
      const vk::RayTracingShaderGroupCreateInfoNV* pGroups;
      uint32_t maxRecursionDepth;
      vk::PipelineLayout layout;
      vk::Pipeline basePipelineHandle;
      int32_t basePipelineIndex;
    };
    static_assert( sizeof( RayTracingPipelineCreateInfoNV ) == sizeof( VkRayTracingPipelineCreateInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct RayTracingPipelineCreateInfoNV : public layout::RayTracingPipelineCreateInfoNV
  {
    VULKAN_HPP_CONSTEXPR RayTracingPipelineCreateInfoNV( vk::PipelineCreateFlags flags_ = vk::PipelineCreateFlags(),
                                                         uint32_t stageCount_ = 0,
                                                         const vk::PipelineShaderStageCreateInfo* pStages_ = nullptr,
                                                         uint32_t groupCount_ = 0,
                                                         const vk::RayTracingShaderGroupCreateInfoNV* pGroups_ = nullptr,
                                                         uint32_t maxRecursionDepth_ = 0,
                                                         vk::PipelineLayout layout_ = vk::PipelineLayout(),
                                                         vk::Pipeline basePipelineHandle_ = vk::Pipeline(),
                                                         int32_t basePipelineIndex_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::RayTracingPipelineCreateInfoNV( flags_, stageCount_, pStages_, groupCount_, pGroups_, maxRecursionDepth_, layout_, basePipelineHandle_, basePipelineIndex_ )
    {}

    RayTracingPipelineCreateInfoNV( VkRayTracingPipelineCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RayTracingPipelineCreateInfoNV( rhs )
    {}

    RayTracingPipelineCreateInfoNV& operator=( VkRayTracingPipelineCreateInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RayTracingPipelineCreateInfoNV::operator=(rhs);
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setFlags( vk::PipelineCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setStageCount( uint32_t stageCount_ ) VULKAN_HPP_NOEXCEPT
    {
      stageCount = stageCount_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setPStages( const vk::PipelineShaderStageCreateInfo* pStages_ ) VULKAN_HPP_NOEXCEPT
    {
      pStages = pStages_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setGroupCount( uint32_t groupCount_ ) VULKAN_HPP_NOEXCEPT
    {
      groupCount = groupCount_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setPGroups( const vk::RayTracingShaderGroupCreateInfoNV* pGroups_ ) VULKAN_HPP_NOEXCEPT
    {
      pGroups = pGroups_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setMaxRecursionDepth( uint32_t maxRecursionDepth_ ) VULKAN_HPP_NOEXCEPT
    {
      maxRecursionDepth = maxRecursionDepth_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setLayout( vk::PipelineLayout layout_ ) VULKAN_HPP_NOEXCEPT
    {
      layout = layout_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setBasePipelineHandle( vk::Pipeline basePipelineHandle_ ) VULKAN_HPP_NOEXCEPT
    {
      basePipelineHandle = basePipelineHandle_;
      return *this;
    }

    RayTracingPipelineCreateInfoNV & setBasePipelineIndex( int32_t basePipelineIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      basePipelineIndex = basePipelineIndex_;
      return *this;
    }

    operator VkRayTracingPipelineCreateInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( this );
    }

    operator VkRayTracingPipelineCreateInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRayTracingPipelineCreateInfoNV*>( this );
    }

    bool operator==( RayTracingPipelineCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( stageCount == rhs.stageCount )
          && ( pStages == rhs.pStages )
          && ( groupCount == rhs.groupCount )
          && ( pGroups == rhs.pGroups )
          && ( maxRecursionDepth == rhs.maxRecursionDepth )
          && ( layout == rhs.layout )
          && ( basePipelineHandle == rhs.basePipelineHandle )
          && ( basePipelineIndex == rhs.basePipelineIndex );
    }

    bool operator!=( RayTracingPipelineCreateInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RayTracingPipelineCreateInfoNV::sType;
  };
  static_assert( sizeof( RayTracingPipelineCreateInfoNV ) == sizeof( VkRayTracingPipelineCreateInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RayTracingPipelineCreateInfoNV>::value, "struct wrapper is not a standard layout!" );

  struct RefreshCycleDurationGOOGLE
  {
    RefreshCycleDurationGOOGLE() VULKAN_HPP_NOEXCEPT
    {}

    RefreshCycleDurationGOOGLE( VkRefreshCycleDurationGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkRefreshCycleDurationGOOGLE*>(this) = rhs;
    }

    RefreshCycleDurationGOOGLE& operator=( VkRefreshCycleDurationGOOGLE const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkRefreshCycleDurationGOOGLE*>(this) = rhs;
      return *this;
    }

    operator VkRefreshCycleDurationGOOGLE const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRefreshCycleDurationGOOGLE*>( this );
    }

    operator VkRefreshCycleDurationGOOGLE &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRefreshCycleDurationGOOGLE*>( this );
    }

    bool operator==( RefreshCycleDurationGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( refreshDuration == rhs.refreshDuration );
    }

    bool operator!=( RefreshCycleDurationGOOGLE const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint64_t refreshDuration;
  };
  static_assert( sizeof( RefreshCycleDurationGOOGLE ) == sizeof( VkRefreshCycleDurationGOOGLE ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RefreshCycleDurationGOOGLE>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassAttachmentBeginInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassAttachmentBeginInfoKHR( uint32_t attachmentCount_ = 0,
                                                             const vk::ImageView* pAttachments_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : attachmentCount( attachmentCount_ )
        , pAttachments( pAttachments_ )
      {}

      RenderPassAttachmentBeginInfoKHR( VkRenderPassAttachmentBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassAttachmentBeginInfoKHR*>(this) = rhs;
      }

      RenderPassAttachmentBeginInfoKHR& operator=( VkRenderPassAttachmentBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassAttachmentBeginInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassAttachmentBeginInfoKHR;
      const void* pNext = nullptr;
      uint32_t attachmentCount;
      const vk::ImageView* pAttachments;
    };
    static_assert( sizeof( RenderPassAttachmentBeginInfoKHR ) == sizeof( VkRenderPassAttachmentBeginInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassAttachmentBeginInfoKHR : public layout::RenderPassAttachmentBeginInfoKHR
  {
    VULKAN_HPP_CONSTEXPR RenderPassAttachmentBeginInfoKHR( uint32_t attachmentCount_ = 0,
                                                           const vk::ImageView* pAttachments_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassAttachmentBeginInfoKHR( attachmentCount_, pAttachments_ )
    {}

    RenderPassAttachmentBeginInfoKHR( VkRenderPassAttachmentBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassAttachmentBeginInfoKHR( rhs )
    {}

    RenderPassAttachmentBeginInfoKHR& operator=( VkRenderPassAttachmentBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassAttachmentBeginInfoKHR::operator=(rhs);
      return *this;
    }

    RenderPassAttachmentBeginInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassAttachmentBeginInfoKHR & setAttachmentCount( uint32_t attachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentCount = attachmentCount_;
      return *this;
    }

    RenderPassAttachmentBeginInfoKHR & setPAttachments( const vk::ImageView* pAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttachments = pAttachments_;
      return *this;
    }

    operator VkRenderPassAttachmentBeginInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassAttachmentBeginInfoKHR*>( this );
    }

    operator VkRenderPassAttachmentBeginInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassAttachmentBeginInfoKHR*>( this );
    }

    bool operator==( RenderPassAttachmentBeginInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( attachmentCount == rhs.attachmentCount )
          && ( pAttachments == rhs.pAttachments );
    }

    bool operator!=( RenderPassAttachmentBeginInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassAttachmentBeginInfoKHR::sType;
  };
  static_assert( sizeof( RenderPassAttachmentBeginInfoKHR ) == sizeof( VkRenderPassAttachmentBeginInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassAttachmentBeginInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassBeginInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassBeginInfo( vk::RenderPass renderPass_ = vk::RenderPass(),
                                                vk::Framebuffer framebuffer_ = vk::Framebuffer(),
                                                vk::Rect2D renderArea_ = vk::Rect2D(),
                                                uint32_t clearValueCount_ = 0,
                                                const vk::ClearValue* pClearValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : renderPass( renderPass_ )
        , framebuffer( framebuffer_ )
        , renderArea( renderArea_ )
        , clearValueCount( clearValueCount_ )
        , pClearValues( pClearValues_ )
      {}

      RenderPassBeginInfo( VkRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassBeginInfo*>(this) = rhs;
      }

      RenderPassBeginInfo& operator=( VkRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassBeginInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassBeginInfo;
      const void* pNext = nullptr;
      vk::RenderPass renderPass;
      vk::Framebuffer framebuffer;
      vk::Rect2D renderArea;
      uint32_t clearValueCount;
      const vk::ClearValue* pClearValues;
    };
    static_assert( sizeof( RenderPassBeginInfo ) == sizeof( VkRenderPassBeginInfo ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassBeginInfo : public layout::RenderPassBeginInfo
  {
    VULKAN_HPP_CONSTEXPR RenderPassBeginInfo( vk::RenderPass renderPass_ = vk::RenderPass(),
                                              vk::Framebuffer framebuffer_ = vk::Framebuffer(),
                                              vk::Rect2D renderArea_ = vk::Rect2D(),
                                              uint32_t clearValueCount_ = 0,
                                              const vk::ClearValue* pClearValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassBeginInfo( renderPass_, framebuffer_, renderArea_, clearValueCount_, pClearValues_ )
    {}

    RenderPassBeginInfo( VkRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassBeginInfo( rhs )
    {}

    RenderPassBeginInfo& operator=( VkRenderPassBeginInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassBeginInfo::operator=(rhs);
      return *this;
    }

    RenderPassBeginInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassBeginInfo & setRenderPass( vk::RenderPass renderPass_ ) VULKAN_HPP_NOEXCEPT
    {
      renderPass = renderPass_;
      return *this;
    }

    RenderPassBeginInfo & setFramebuffer( vk::Framebuffer framebuffer_ ) VULKAN_HPP_NOEXCEPT
    {
      framebuffer = framebuffer_;
      return *this;
    }

    RenderPassBeginInfo & setRenderArea( vk::Rect2D renderArea_ ) VULKAN_HPP_NOEXCEPT
    {
      renderArea = renderArea_;
      return *this;
    }

    RenderPassBeginInfo & setClearValueCount( uint32_t clearValueCount_ ) VULKAN_HPP_NOEXCEPT
    {
      clearValueCount = clearValueCount_;
      return *this;
    }

    RenderPassBeginInfo & setPClearValues( const vk::ClearValue* pClearValues_ ) VULKAN_HPP_NOEXCEPT
    {
      pClearValues = pClearValues_;
      return *this;
    }

    operator VkRenderPassBeginInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassBeginInfo*>( this );
    }

    operator VkRenderPassBeginInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassBeginInfo*>( this );
    }

    bool operator==( RenderPassBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( renderPass == rhs.renderPass )
          && ( framebuffer == rhs.framebuffer )
          && ( renderArea == rhs.renderArea )
          && ( clearValueCount == rhs.clearValueCount )
          && ( pClearValues == rhs.pClearValues );
    }

    bool operator!=( RenderPassBeginInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassBeginInfo::sType;
  };
  static_assert( sizeof( RenderPassBeginInfo ) == sizeof( VkRenderPassBeginInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassBeginInfo>::value, "struct wrapper is not a standard layout!" );

  struct SubpassDescription
  {
    VULKAN_HPP_CONSTEXPR SubpassDescription( vk::SubpassDescriptionFlags flags_ = vk::SubpassDescriptionFlags(),
                                             vk::PipelineBindPoint pipelineBindPoint_ = vk::PipelineBindPoint::eGraphics,
                                             uint32_t inputAttachmentCount_ = 0,
                                             const vk::AttachmentReference* pInputAttachments_ = nullptr,
                                             uint32_t colorAttachmentCount_ = 0,
                                             const vk::AttachmentReference* pColorAttachments_ = nullptr,
                                             const vk::AttachmentReference* pResolveAttachments_ = nullptr,
                                             const vk::AttachmentReference* pDepthStencilAttachment_ = nullptr,
                                             uint32_t preserveAttachmentCount_ = 0,
                                             const uint32_t* pPreserveAttachments_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : flags( flags_ )
      , pipelineBindPoint( pipelineBindPoint_ )
      , inputAttachmentCount( inputAttachmentCount_ )
      , pInputAttachments( pInputAttachments_ )
      , colorAttachmentCount( colorAttachmentCount_ )
      , pColorAttachments( pColorAttachments_ )
      , pResolveAttachments( pResolveAttachments_ )
      , pDepthStencilAttachment( pDepthStencilAttachment_ )
      , preserveAttachmentCount( preserveAttachmentCount_ )
      , pPreserveAttachments( pPreserveAttachments_ )
    {}

    SubpassDescription( VkSubpassDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubpassDescription*>(this) = rhs;
    }

    SubpassDescription& operator=( VkSubpassDescription const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubpassDescription*>(this) = rhs;
      return *this;
    }

    SubpassDescription & setFlags( vk::SubpassDescriptionFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    SubpassDescription & setPipelineBindPoint( vk::PipelineBindPoint pipelineBindPoint_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineBindPoint = pipelineBindPoint_;
      return *this;
    }

    SubpassDescription & setInputAttachmentCount( uint32_t inputAttachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      inputAttachmentCount = inputAttachmentCount_;
      return *this;
    }

    SubpassDescription & setPInputAttachments( const vk::AttachmentReference* pInputAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pInputAttachments = pInputAttachments_;
      return *this;
    }

    SubpassDescription & setColorAttachmentCount( uint32_t colorAttachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      colorAttachmentCount = colorAttachmentCount_;
      return *this;
    }

    SubpassDescription & setPColorAttachments( const vk::AttachmentReference* pColorAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pColorAttachments = pColorAttachments_;
      return *this;
    }

    SubpassDescription & setPResolveAttachments( const vk::AttachmentReference* pResolveAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pResolveAttachments = pResolveAttachments_;
      return *this;
    }

    SubpassDescription & setPDepthStencilAttachment( const vk::AttachmentReference* pDepthStencilAttachment_ ) VULKAN_HPP_NOEXCEPT
    {
      pDepthStencilAttachment = pDepthStencilAttachment_;
      return *this;
    }

    SubpassDescription & setPreserveAttachmentCount( uint32_t preserveAttachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      preserveAttachmentCount = preserveAttachmentCount_;
      return *this;
    }

    SubpassDescription & setPPreserveAttachments( const uint32_t* pPreserveAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pPreserveAttachments = pPreserveAttachments_;
      return *this;
    }

    operator VkSubpassDescription const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassDescription*>( this );
    }

    operator VkSubpassDescription &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassDescription*>( this );
    }

    bool operator==( SubpassDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( flags == rhs.flags )
          && ( pipelineBindPoint == rhs.pipelineBindPoint )
          && ( inputAttachmentCount == rhs.inputAttachmentCount )
          && ( pInputAttachments == rhs.pInputAttachments )
          && ( colorAttachmentCount == rhs.colorAttachmentCount )
          && ( pColorAttachments == rhs.pColorAttachments )
          && ( pResolveAttachments == rhs.pResolveAttachments )
          && ( pDepthStencilAttachment == rhs.pDepthStencilAttachment )
          && ( preserveAttachmentCount == rhs.preserveAttachmentCount )
          && ( pPreserveAttachments == rhs.pPreserveAttachments );
    }

    bool operator!=( SubpassDescription const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::SubpassDescriptionFlags flags;
    vk::PipelineBindPoint pipelineBindPoint;
    uint32_t inputAttachmentCount;
    const vk::AttachmentReference* pInputAttachments;
    uint32_t colorAttachmentCount;
    const vk::AttachmentReference* pColorAttachments;
    const vk::AttachmentReference* pResolveAttachments;
    const vk::AttachmentReference* pDepthStencilAttachment;
    uint32_t preserveAttachmentCount;
    const uint32_t* pPreserveAttachments;
  };
  static_assert( sizeof( SubpassDescription ) == sizeof( VkSubpassDescription ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassDescription>::value, "struct wrapper is not a standard layout!" );

  struct SubpassDependency
  {
    VULKAN_HPP_CONSTEXPR SubpassDependency( uint32_t srcSubpass_ = 0,
                                            uint32_t dstSubpass_ = 0,
                                            vk::PipelineStageFlags srcStageMask_ = vk::PipelineStageFlags(),
                                            vk::PipelineStageFlags dstStageMask_ = vk::PipelineStageFlags(),
                                            vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                            vk::AccessFlags dstAccessMask_ = vk::AccessFlags(),
                                            vk::DependencyFlags dependencyFlags_ = vk::DependencyFlags() ) VULKAN_HPP_NOEXCEPT
      : srcSubpass( srcSubpass_ )
      , dstSubpass( dstSubpass_ )
      , srcStageMask( srcStageMask_ )
      , dstStageMask( dstStageMask_ )
      , srcAccessMask( srcAccessMask_ )
      , dstAccessMask( dstAccessMask_ )
      , dependencyFlags( dependencyFlags_ )
    {}

    SubpassDependency( VkSubpassDependency const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubpassDependency*>(this) = rhs;
    }

    SubpassDependency& operator=( VkSubpassDependency const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubpassDependency*>(this) = rhs;
      return *this;
    }

    SubpassDependency & setSrcSubpass( uint32_t srcSubpass_ ) VULKAN_HPP_NOEXCEPT
    {
      srcSubpass = srcSubpass_;
      return *this;
    }

    SubpassDependency & setDstSubpass( uint32_t dstSubpass_ ) VULKAN_HPP_NOEXCEPT
    {
      dstSubpass = dstSubpass_;
      return *this;
    }

    SubpassDependency & setSrcStageMask( vk::PipelineStageFlags srcStageMask_ ) VULKAN_HPP_NOEXCEPT
    {
      srcStageMask = srcStageMask_;
      return *this;
    }

    SubpassDependency & setDstStageMask( vk::PipelineStageFlags dstStageMask_ ) VULKAN_HPP_NOEXCEPT
    {
      dstStageMask = dstStageMask_;
      return *this;
    }

    SubpassDependency & setSrcAccessMask( vk::AccessFlags srcAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      srcAccessMask = srcAccessMask_;
      return *this;
    }

    SubpassDependency & setDstAccessMask( vk::AccessFlags dstAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      dstAccessMask = dstAccessMask_;
      return *this;
    }

    SubpassDependency & setDependencyFlags( vk::DependencyFlags dependencyFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      dependencyFlags = dependencyFlags_;
      return *this;
    }

    operator VkSubpassDependency const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassDependency*>( this );
    }

    operator VkSubpassDependency &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassDependency*>( this );
    }

    bool operator==( SubpassDependency const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( srcSubpass == rhs.srcSubpass )
          && ( dstSubpass == rhs.dstSubpass )
          && ( srcStageMask == rhs.srcStageMask )
          && ( dstStageMask == rhs.dstStageMask )
          && ( srcAccessMask == rhs.srcAccessMask )
          && ( dstAccessMask == rhs.dstAccessMask )
          && ( dependencyFlags == rhs.dependencyFlags );
    }

    bool operator!=( SubpassDependency const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t srcSubpass;
    uint32_t dstSubpass;
    vk::PipelineStageFlags srcStageMask;
    vk::PipelineStageFlags dstStageMask;
    vk::AccessFlags srcAccessMask;
    vk::AccessFlags dstAccessMask;
    vk::DependencyFlags dependencyFlags;
  };
  static_assert( sizeof( SubpassDependency ) == sizeof( VkSubpassDependency ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassDependency>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassCreateInfo( vk::RenderPassCreateFlags flags_ = vk::RenderPassCreateFlags(),
                                                 uint32_t attachmentCount_ = 0,
                                                 const vk::AttachmentDescription* pAttachments_ = nullptr,
                                                 uint32_t subpassCount_ = 0,
                                                 const vk::SubpassDescription* pSubpasses_ = nullptr,
                                                 uint32_t dependencyCount_ = 0,
                                                 const vk::SubpassDependency* pDependencies_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , attachmentCount( attachmentCount_ )
        , pAttachments( pAttachments_ )
        , subpassCount( subpassCount_ )
        , pSubpasses( pSubpasses_ )
        , dependencyCount( dependencyCount_ )
        , pDependencies( pDependencies_ )
      {}

      RenderPassCreateInfo( VkRenderPassCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassCreateInfo*>(this) = rhs;
      }

      RenderPassCreateInfo& operator=( VkRenderPassCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassCreateInfo;
      const void* pNext = nullptr;
      vk::RenderPassCreateFlags flags;
      uint32_t attachmentCount;
      const vk::AttachmentDescription* pAttachments;
      uint32_t subpassCount;
      const vk::SubpassDescription* pSubpasses;
      uint32_t dependencyCount;
      const vk::SubpassDependency* pDependencies;
    };
    static_assert( sizeof( RenderPassCreateInfo ) == sizeof( VkRenderPassCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassCreateInfo : public layout::RenderPassCreateInfo
  {
    VULKAN_HPP_CONSTEXPR RenderPassCreateInfo( vk::RenderPassCreateFlags flags_ = vk::RenderPassCreateFlags(),
                                               uint32_t attachmentCount_ = 0,
                                               const vk::AttachmentDescription* pAttachments_ = nullptr,
                                               uint32_t subpassCount_ = 0,
                                               const vk::SubpassDescription* pSubpasses_ = nullptr,
                                               uint32_t dependencyCount_ = 0,
                                               const vk::SubpassDependency* pDependencies_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassCreateInfo( flags_, attachmentCount_, pAttachments_, subpassCount_, pSubpasses_, dependencyCount_, pDependencies_ )
    {}

    RenderPassCreateInfo( VkRenderPassCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassCreateInfo( rhs )
    {}

    RenderPassCreateInfo& operator=( VkRenderPassCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassCreateInfo::operator=(rhs);
      return *this;
    }

    RenderPassCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassCreateInfo & setFlags( vk::RenderPassCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    RenderPassCreateInfo & setAttachmentCount( uint32_t attachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentCount = attachmentCount_;
      return *this;
    }

    RenderPassCreateInfo & setPAttachments( const vk::AttachmentDescription* pAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttachments = pAttachments_;
      return *this;
    }

    RenderPassCreateInfo & setSubpassCount( uint32_t subpassCount_ ) VULKAN_HPP_NOEXCEPT
    {
      subpassCount = subpassCount_;
      return *this;
    }

    RenderPassCreateInfo & setPSubpasses( const vk::SubpassDescription* pSubpasses_ ) VULKAN_HPP_NOEXCEPT
    {
      pSubpasses = pSubpasses_;
      return *this;
    }

    RenderPassCreateInfo & setDependencyCount( uint32_t dependencyCount_ ) VULKAN_HPP_NOEXCEPT
    {
      dependencyCount = dependencyCount_;
      return *this;
    }

    RenderPassCreateInfo & setPDependencies( const vk::SubpassDependency* pDependencies_ ) VULKAN_HPP_NOEXCEPT
    {
      pDependencies = pDependencies_;
      return *this;
    }

    operator VkRenderPassCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassCreateInfo*>( this );
    }

    operator VkRenderPassCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassCreateInfo*>( this );
    }

    bool operator==( RenderPassCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( attachmentCount == rhs.attachmentCount )
          && ( pAttachments == rhs.pAttachments )
          && ( subpassCount == rhs.subpassCount )
          && ( pSubpasses == rhs.pSubpasses )
          && ( dependencyCount == rhs.dependencyCount )
          && ( pDependencies == rhs.pDependencies );
    }

    bool operator!=( RenderPassCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassCreateInfo::sType;
  };
  static_assert( sizeof( RenderPassCreateInfo ) == sizeof( VkRenderPassCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SubpassDescription2KHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SubpassDescription2KHR( vk::SubpassDescriptionFlags flags_ = vk::SubpassDescriptionFlags(),
                                                   vk::PipelineBindPoint pipelineBindPoint_ = vk::PipelineBindPoint::eGraphics,
                                                   uint32_t viewMask_ = 0,
                                                   uint32_t inputAttachmentCount_ = 0,
                                                   const vk::AttachmentReference2KHR* pInputAttachments_ = nullptr,
                                                   uint32_t colorAttachmentCount_ = 0,
                                                   const vk::AttachmentReference2KHR* pColorAttachments_ = nullptr,
                                                   const vk::AttachmentReference2KHR* pResolveAttachments_ = nullptr,
                                                   const vk::AttachmentReference2KHR* pDepthStencilAttachment_ = nullptr,
                                                   uint32_t preserveAttachmentCount_ = 0,
                                                   const uint32_t* pPreserveAttachments_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , pipelineBindPoint( pipelineBindPoint_ )
        , viewMask( viewMask_ )
        , inputAttachmentCount( inputAttachmentCount_ )
        , pInputAttachments( pInputAttachments_ )
        , colorAttachmentCount( colorAttachmentCount_ )
        , pColorAttachments( pColorAttachments_ )
        , pResolveAttachments( pResolveAttachments_ )
        , pDepthStencilAttachment( pDepthStencilAttachment_ )
        , preserveAttachmentCount( preserveAttachmentCount_ )
        , pPreserveAttachments( pPreserveAttachments_ )
      {}

      SubpassDescription2KHR( VkSubpassDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassDescription2KHR*>(this) = rhs;
      }

      SubpassDescription2KHR& operator=( VkSubpassDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassDescription2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSubpassDescription2KHR;
      const void* pNext = nullptr;
      vk::SubpassDescriptionFlags flags;
      vk::PipelineBindPoint pipelineBindPoint;
      uint32_t viewMask;
      uint32_t inputAttachmentCount;
      const vk::AttachmentReference2KHR* pInputAttachments;
      uint32_t colorAttachmentCount;
      const vk::AttachmentReference2KHR* pColorAttachments;
      const vk::AttachmentReference2KHR* pResolveAttachments;
      const vk::AttachmentReference2KHR* pDepthStencilAttachment;
      uint32_t preserveAttachmentCount;
      const uint32_t* pPreserveAttachments;
    };
    static_assert( sizeof( SubpassDescription2KHR ) == sizeof( VkSubpassDescription2KHR ), "layout struct and wrapper have different size!" );
  }

  struct SubpassDescription2KHR : public layout::SubpassDescription2KHR
  {
    VULKAN_HPP_CONSTEXPR SubpassDescription2KHR( vk::SubpassDescriptionFlags flags_ = vk::SubpassDescriptionFlags(),
                                                 vk::PipelineBindPoint pipelineBindPoint_ = vk::PipelineBindPoint::eGraphics,
                                                 uint32_t viewMask_ = 0,
                                                 uint32_t inputAttachmentCount_ = 0,
                                                 const vk::AttachmentReference2KHR* pInputAttachments_ = nullptr,
                                                 uint32_t colorAttachmentCount_ = 0,
                                                 const vk::AttachmentReference2KHR* pColorAttachments_ = nullptr,
                                                 const vk::AttachmentReference2KHR* pResolveAttachments_ = nullptr,
                                                 const vk::AttachmentReference2KHR* pDepthStencilAttachment_ = nullptr,
                                                 uint32_t preserveAttachmentCount_ = 0,
                                                 const uint32_t* pPreserveAttachments_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassDescription2KHR( flags_, pipelineBindPoint_, viewMask_, inputAttachmentCount_, pInputAttachments_, colorAttachmentCount_, pColorAttachments_, pResolveAttachments_, pDepthStencilAttachment_, preserveAttachmentCount_, pPreserveAttachments_ )
    {}

    SubpassDescription2KHR( VkSubpassDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassDescription2KHR( rhs )
    {}

    SubpassDescription2KHR& operator=( VkSubpassDescription2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SubpassDescription2KHR::operator=(rhs);
      return *this;
    }

    SubpassDescription2KHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SubpassDescription2KHR & setFlags( vk::SubpassDescriptionFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    SubpassDescription2KHR & setPipelineBindPoint( vk::PipelineBindPoint pipelineBindPoint_ ) VULKAN_HPP_NOEXCEPT
    {
      pipelineBindPoint = pipelineBindPoint_;
      return *this;
    }

    SubpassDescription2KHR & setViewMask( uint32_t viewMask_ ) VULKAN_HPP_NOEXCEPT
    {
      viewMask = viewMask_;
      return *this;
    }

    SubpassDescription2KHR & setInputAttachmentCount( uint32_t inputAttachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      inputAttachmentCount = inputAttachmentCount_;
      return *this;
    }

    SubpassDescription2KHR & setPInputAttachments( const vk::AttachmentReference2KHR* pInputAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pInputAttachments = pInputAttachments_;
      return *this;
    }

    SubpassDescription2KHR & setColorAttachmentCount( uint32_t colorAttachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      colorAttachmentCount = colorAttachmentCount_;
      return *this;
    }

    SubpassDescription2KHR & setPColorAttachments( const vk::AttachmentReference2KHR* pColorAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pColorAttachments = pColorAttachments_;
      return *this;
    }

    SubpassDescription2KHR & setPResolveAttachments( const vk::AttachmentReference2KHR* pResolveAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pResolveAttachments = pResolveAttachments_;
      return *this;
    }

    SubpassDescription2KHR & setPDepthStencilAttachment( const vk::AttachmentReference2KHR* pDepthStencilAttachment_ ) VULKAN_HPP_NOEXCEPT
    {
      pDepthStencilAttachment = pDepthStencilAttachment_;
      return *this;
    }

    SubpassDescription2KHR & setPreserveAttachmentCount( uint32_t preserveAttachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      preserveAttachmentCount = preserveAttachmentCount_;
      return *this;
    }

    SubpassDescription2KHR & setPPreserveAttachments( const uint32_t* pPreserveAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pPreserveAttachments = pPreserveAttachments_;
      return *this;
    }

    operator VkSubpassDescription2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassDescription2KHR*>( this );
    }

    operator VkSubpassDescription2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassDescription2KHR*>( this );
    }

    bool operator==( SubpassDescription2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( pipelineBindPoint == rhs.pipelineBindPoint )
          && ( viewMask == rhs.viewMask )
          && ( inputAttachmentCount == rhs.inputAttachmentCount )
          && ( pInputAttachments == rhs.pInputAttachments )
          && ( colorAttachmentCount == rhs.colorAttachmentCount )
          && ( pColorAttachments == rhs.pColorAttachments )
          && ( pResolveAttachments == rhs.pResolveAttachments )
          && ( pDepthStencilAttachment == rhs.pDepthStencilAttachment )
          && ( preserveAttachmentCount == rhs.preserveAttachmentCount )
          && ( pPreserveAttachments == rhs.pPreserveAttachments );
    }

    bool operator!=( SubpassDescription2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SubpassDescription2KHR::sType;
  };
  static_assert( sizeof( SubpassDescription2KHR ) == sizeof( VkSubpassDescription2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassDescription2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SubpassDependency2KHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SubpassDependency2KHR( uint32_t srcSubpass_ = 0,
                                                  uint32_t dstSubpass_ = 0,
                                                  vk::PipelineStageFlags srcStageMask_ = vk::PipelineStageFlags(),
                                                  vk::PipelineStageFlags dstStageMask_ = vk::PipelineStageFlags(),
                                                  vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                                  vk::AccessFlags dstAccessMask_ = vk::AccessFlags(),
                                                  vk::DependencyFlags dependencyFlags_ = vk::DependencyFlags(),
                                                  int32_t viewOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
        : srcSubpass( srcSubpass_ )
        , dstSubpass( dstSubpass_ )
        , srcStageMask( srcStageMask_ )
        , dstStageMask( dstStageMask_ )
        , srcAccessMask( srcAccessMask_ )
        , dstAccessMask( dstAccessMask_ )
        , dependencyFlags( dependencyFlags_ )
        , viewOffset( viewOffset_ )
      {}

      SubpassDependency2KHR( VkSubpassDependency2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassDependency2KHR*>(this) = rhs;
      }

      SubpassDependency2KHR& operator=( VkSubpassDependency2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassDependency2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSubpassDependency2KHR;
      const void* pNext = nullptr;
      uint32_t srcSubpass;
      uint32_t dstSubpass;
      vk::PipelineStageFlags srcStageMask;
      vk::PipelineStageFlags dstStageMask;
      vk::AccessFlags srcAccessMask;
      vk::AccessFlags dstAccessMask;
      vk::DependencyFlags dependencyFlags;
      int32_t viewOffset;
    };
    static_assert( sizeof( SubpassDependency2KHR ) == sizeof( VkSubpassDependency2KHR ), "layout struct and wrapper have different size!" );
  }

  struct SubpassDependency2KHR : public layout::SubpassDependency2KHR
  {
    VULKAN_HPP_CONSTEXPR SubpassDependency2KHR( uint32_t srcSubpass_ = 0,
                                                uint32_t dstSubpass_ = 0,
                                                vk::PipelineStageFlags srcStageMask_ = vk::PipelineStageFlags(),
                                                vk::PipelineStageFlags dstStageMask_ = vk::PipelineStageFlags(),
                                                vk::AccessFlags srcAccessMask_ = vk::AccessFlags(),
                                                vk::AccessFlags dstAccessMask_ = vk::AccessFlags(),
                                                vk::DependencyFlags dependencyFlags_ = vk::DependencyFlags(),
                                                int32_t viewOffset_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassDependency2KHR( srcSubpass_, dstSubpass_, srcStageMask_, dstStageMask_, srcAccessMask_, dstAccessMask_, dependencyFlags_, viewOffset_ )
    {}

    SubpassDependency2KHR( VkSubpassDependency2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassDependency2KHR( rhs )
    {}

    SubpassDependency2KHR& operator=( VkSubpassDependency2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SubpassDependency2KHR::operator=(rhs);
      return *this;
    }

    SubpassDependency2KHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SubpassDependency2KHR & setSrcSubpass( uint32_t srcSubpass_ ) VULKAN_HPP_NOEXCEPT
    {
      srcSubpass = srcSubpass_;
      return *this;
    }

    SubpassDependency2KHR & setDstSubpass( uint32_t dstSubpass_ ) VULKAN_HPP_NOEXCEPT
    {
      dstSubpass = dstSubpass_;
      return *this;
    }

    SubpassDependency2KHR & setSrcStageMask( vk::PipelineStageFlags srcStageMask_ ) VULKAN_HPP_NOEXCEPT
    {
      srcStageMask = srcStageMask_;
      return *this;
    }

    SubpassDependency2KHR & setDstStageMask( vk::PipelineStageFlags dstStageMask_ ) VULKAN_HPP_NOEXCEPT
    {
      dstStageMask = dstStageMask_;
      return *this;
    }

    SubpassDependency2KHR & setSrcAccessMask( vk::AccessFlags srcAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      srcAccessMask = srcAccessMask_;
      return *this;
    }

    SubpassDependency2KHR & setDstAccessMask( vk::AccessFlags dstAccessMask_ ) VULKAN_HPP_NOEXCEPT
    {
      dstAccessMask = dstAccessMask_;
      return *this;
    }

    SubpassDependency2KHR & setDependencyFlags( vk::DependencyFlags dependencyFlags_ ) VULKAN_HPP_NOEXCEPT
    {
      dependencyFlags = dependencyFlags_;
      return *this;
    }

    SubpassDependency2KHR & setViewOffset( int32_t viewOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      viewOffset = viewOffset_;
      return *this;
    }

    operator VkSubpassDependency2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassDependency2KHR*>( this );
    }

    operator VkSubpassDependency2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassDependency2KHR*>( this );
    }

    bool operator==( SubpassDependency2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( srcSubpass == rhs.srcSubpass )
          && ( dstSubpass == rhs.dstSubpass )
          && ( srcStageMask == rhs.srcStageMask )
          && ( dstStageMask == rhs.dstStageMask )
          && ( srcAccessMask == rhs.srcAccessMask )
          && ( dstAccessMask == rhs.dstAccessMask )
          && ( dependencyFlags == rhs.dependencyFlags )
          && ( viewOffset == rhs.viewOffset );
    }

    bool operator!=( SubpassDependency2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SubpassDependency2KHR::sType;
  };
  static_assert( sizeof( SubpassDependency2KHR ) == sizeof( VkSubpassDependency2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassDependency2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassCreateInfo2KHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassCreateInfo2KHR( vk::RenderPassCreateFlags flags_ = vk::RenderPassCreateFlags(),
                                                     uint32_t attachmentCount_ = 0,
                                                     const vk::AttachmentDescription2KHR* pAttachments_ = nullptr,
                                                     uint32_t subpassCount_ = 0,
                                                     const vk::SubpassDescription2KHR* pSubpasses_ = nullptr,
                                                     uint32_t dependencyCount_ = 0,
                                                     const vk::SubpassDependency2KHR* pDependencies_ = nullptr,
                                                     uint32_t correlatedViewMaskCount_ = 0,
                                                     const uint32_t* pCorrelatedViewMasks_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , attachmentCount( attachmentCount_ )
        , pAttachments( pAttachments_ )
        , subpassCount( subpassCount_ )
        , pSubpasses( pSubpasses_ )
        , dependencyCount( dependencyCount_ )
        , pDependencies( pDependencies_ )
        , correlatedViewMaskCount( correlatedViewMaskCount_ )
        , pCorrelatedViewMasks( pCorrelatedViewMasks_ )
      {}

      RenderPassCreateInfo2KHR( VkRenderPassCreateInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassCreateInfo2KHR*>(this) = rhs;
      }

      RenderPassCreateInfo2KHR& operator=( VkRenderPassCreateInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassCreateInfo2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassCreateInfo2KHR;
      const void* pNext = nullptr;
      vk::RenderPassCreateFlags flags;
      uint32_t attachmentCount;
      const vk::AttachmentDescription2KHR* pAttachments;
      uint32_t subpassCount;
      const vk::SubpassDescription2KHR* pSubpasses;
      uint32_t dependencyCount;
      const vk::SubpassDependency2KHR* pDependencies;
      uint32_t correlatedViewMaskCount;
      const uint32_t* pCorrelatedViewMasks;
    };
    static_assert( sizeof( RenderPassCreateInfo2KHR ) == sizeof( VkRenderPassCreateInfo2KHR ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassCreateInfo2KHR : public layout::RenderPassCreateInfo2KHR
  {
    VULKAN_HPP_CONSTEXPR RenderPassCreateInfo2KHR( vk::RenderPassCreateFlags flags_ = vk::RenderPassCreateFlags(),
                                                   uint32_t attachmentCount_ = 0,
                                                   const vk::AttachmentDescription2KHR* pAttachments_ = nullptr,
                                                   uint32_t subpassCount_ = 0,
                                                   const vk::SubpassDescription2KHR* pSubpasses_ = nullptr,
                                                   uint32_t dependencyCount_ = 0,
                                                   const vk::SubpassDependency2KHR* pDependencies_ = nullptr,
                                                   uint32_t correlatedViewMaskCount_ = 0,
                                                   const uint32_t* pCorrelatedViewMasks_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassCreateInfo2KHR( flags_, attachmentCount_, pAttachments_, subpassCount_, pSubpasses_, dependencyCount_, pDependencies_, correlatedViewMaskCount_, pCorrelatedViewMasks_ )
    {}

    RenderPassCreateInfo2KHR( VkRenderPassCreateInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassCreateInfo2KHR( rhs )
    {}

    RenderPassCreateInfo2KHR& operator=( VkRenderPassCreateInfo2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassCreateInfo2KHR::operator=(rhs);
      return *this;
    }

    RenderPassCreateInfo2KHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setFlags( vk::RenderPassCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setAttachmentCount( uint32_t attachmentCount_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentCount = attachmentCount_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setPAttachments( const vk::AttachmentDescription2KHR* pAttachments_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttachments = pAttachments_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setSubpassCount( uint32_t subpassCount_ ) VULKAN_HPP_NOEXCEPT
    {
      subpassCount = subpassCount_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setPSubpasses( const vk::SubpassDescription2KHR* pSubpasses_ ) VULKAN_HPP_NOEXCEPT
    {
      pSubpasses = pSubpasses_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setDependencyCount( uint32_t dependencyCount_ ) VULKAN_HPP_NOEXCEPT
    {
      dependencyCount = dependencyCount_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setPDependencies( const vk::SubpassDependency2KHR* pDependencies_ ) VULKAN_HPP_NOEXCEPT
    {
      pDependencies = pDependencies_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setCorrelatedViewMaskCount( uint32_t correlatedViewMaskCount_ ) VULKAN_HPP_NOEXCEPT
    {
      correlatedViewMaskCount = correlatedViewMaskCount_;
      return *this;
    }

    RenderPassCreateInfo2KHR & setPCorrelatedViewMasks( const uint32_t* pCorrelatedViewMasks_ ) VULKAN_HPP_NOEXCEPT
    {
      pCorrelatedViewMasks = pCorrelatedViewMasks_;
      return *this;
    }

    operator VkRenderPassCreateInfo2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassCreateInfo2KHR*>( this );
    }

    operator VkRenderPassCreateInfo2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassCreateInfo2KHR*>( this );
    }

    bool operator==( RenderPassCreateInfo2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( attachmentCount == rhs.attachmentCount )
          && ( pAttachments == rhs.pAttachments )
          && ( subpassCount == rhs.subpassCount )
          && ( pSubpasses == rhs.pSubpasses )
          && ( dependencyCount == rhs.dependencyCount )
          && ( pDependencies == rhs.pDependencies )
          && ( correlatedViewMaskCount == rhs.correlatedViewMaskCount )
          && ( pCorrelatedViewMasks == rhs.pCorrelatedViewMasks );
    }

    bool operator!=( RenderPassCreateInfo2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassCreateInfo2KHR::sType;
  };
  static_assert( sizeof( RenderPassCreateInfo2KHR ) == sizeof( VkRenderPassCreateInfo2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassCreateInfo2KHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassFragmentDensityMapCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassFragmentDensityMapCreateInfoEXT( vk::AttachmentReference fragmentDensityMapAttachment_ = vk::AttachmentReference() ) VULKAN_HPP_NOEXCEPT
        : fragmentDensityMapAttachment( fragmentDensityMapAttachment_ )
      {}

      RenderPassFragmentDensityMapCreateInfoEXT( VkRenderPassFragmentDensityMapCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassFragmentDensityMapCreateInfoEXT*>(this) = rhs;
      }

      RenderPassFragmentDensityMapCreateInfoEXT& operator=( VkRenderPassFragmentDensityMapCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassFragmentDensityMapCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassFragmentDensityMapCreateInfoEXT;
      const void* pNext = nullptr;
      vk::AttachmentReference fragmentDensityMapAttachment;
    };
    static_assert( sizeof( RenderPassFragmentDensityMapCreateInfoEXT ) == sizeof( VkRenderPassFragmentDensityMapCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassFragmentDensityMapCreateInfoEXT : public layout::RenderPassFragmentDensityMapCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR RenderPassFragmentDensityMapCreateInfoEXT( vk::AttachmentReference fragmentDensityMapAttachment_ = vk::AttachmentReference() ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassFragmentDensityMapCreateInfoEXT( fragmentDensityMapAttachment_ )
    {}

    RenderPassFragmentDensityMapCreateInfoEXT( VkRenderPassFragmentDensityMapCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassFragmentDensityMapCreateInfoEXT( rhs )
    {}

    RenderPassFragmentDensityMapCreateInfoEXT& operator=( VkRenderPassFragmentDensityMapCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassFragmentDensityMapCreateInfoEXT::operator=(rhs);
      return *this;
    }

    RenderPassFragmentDensityMapCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassFragmentDensityMapCreateInfoEXT & setFragmentDensityMapAttachment( vk::AttachmentReference fragmentDensityMapAttachment_ ) VULKAN_HPP_NOEXCEPT
    {
      fragmentDensityMapAttachment = fragmentDensityMapAttachment_;
      return *this;
    }

    operator VkRenderPassFragmentDensityMapCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassFragmentDensityMapCreateInfoEXT*>( this );
    }

    operator VkRenderPassFragmentDensityMapCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassFragmentDensityMapCreateInfoEXT*>( this );
    }

    bool operator==( RenderPassFragmentDensityMapCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fragmentDensityMapAttachment == rhs.fragmentDensityMapAttachment );
    }

    bool operator!=( RenderPassFragmentDensityMapCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassFragmentDensityMapCreateInfoEXT::sType;
  };
  static_assert( sizeof( RenderPassFragmentDensityMapCreateInfoEXT ) == sizeof( VkRenderPassFragmentDensityMapCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassFragmentDensityMapCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassInputAttachmentAspectCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassInputAttachmentAspectCreateInfo( uint32_t aspectReferenceCount_ = 0,
                                                                      const vk::InputAttachmentAspectReference* pAspectReferences_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : aspectReferenceCount( aspectReferenceCount_ )
        , pAspectReferences( pAspectReferences_ )
      {}

      RenderPassInputAttachmentAspectCreateInfo( VkRenderPassInputAttachmentAspectCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassInputAttachmentAspectCreateInfo*>(this) = rhs;
      }

      RenderPassInputAttachmentAspectCreateInfo& operator=( VkRenderPassInputAttachmentAspectCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassInputAttachmentAspectCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassInputAttachmentAspectCreateInfo;
      const void* pNext = nullptr;
      uint32_t aspectReferenceCount;
      const vk::InputAttachmentAspectReference* pAspectReferences;
    };
    static_assert( sizeof( RenderPassInputAttachmentAspectCreateInfo ) == sizeof( VkRenderPassInputAttachmentAspectCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassInputAttachmentAspectCreateInfo : public layout::RenderPassInputAttachmentAspectCreateInfo
  {
    VULKAN_HPP_CONSTEXPR RenderPassInputAttachmentAspectCreateInfo( uint32_t aspectReferenceCount_ = 0,
                                                                    const vk::InputAttachmentAspectReference* pAspectReferences_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassInputAttachmentAspectCreateInfo( aspectReferenceCount_, pAspectReferences_ )
    {}

    RenderPassInputAttachmentAspectCreateInfo( VkRenderPassInputAttachmentAspectCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassInputAttachmentAspectCreateInfo( rhs )
    {}

    RenderPassInputAttachmentAspectCreateInfo& operator=( VkRenderPassInputAttachmentAspectCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassInputAttachmentAspectCreateInfo::operator=(rhs);
      return *this;
    }

    RenderPassInputAttachmentAspectCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassInputAttachmentAspectCreateInfo & setAspectReferenceCount( uint32_t aspectReferenceCount_ ) VULKAN_HPP_NOEXCEPT
    {
      aspectReferenceCount = aspectReferenceCount_;
      return *this;
    }

    RenderPassInputAttachmentAspectCreateInfo & setPAspectReferences( const vk::InputAttachmentAspectReference* pAspectReferences_ ) VULKAN_HPP_NOEXCEPT
    {
      pAspectReferences = pAspectReferences_;
      return *this;
    }

    operator VkRenderPassInputAttachmentAspectCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassInputAttachmentAspectCreateInfo*>( this );
    }

    operator VkRenderPassInputAttachmentAspectCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassInputAttachmentAspectCreateInfo*>( this );
    }

    bool operator==( RenderPassInputAttachmentAspectCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( aspectReferenceCount == rhs.aspectReferenceCount )
          && ( pAspectReferences == rhs.pAspectReferences );
    }

    bool operator!=( RenderPassInputAttachmentAspectCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassInputAttachmentAspectCreateInfo::sType;
  };
  static_assert( sizeof( RenderPassInputAttachmentAspectCreateInfo ) == sizeof( VkRenderPassInputAttachmentAspectCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassInputAttachmentAspectCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassMultiviewCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassMultiviewCreateInfo( uint32_t subpassCount_ = 0,
                                                          const uint32_t* pViewMasks_ = nullptr,
                                                          uint32_t dependencyCount_ = 0,
                                                          const int32_t* pViewOffsets_ = nullptr,
                                                          uint32_t correlationMaskCount_ = 0,
                                                          const uint32_t* pCorrelationMasks_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : subpassCount( subpassCount_ )
        , pViewMasks( pViewMasks_ )
        , dependencyCount( dependencyCount_ )
        , pViewOffsets( pViewOffsets_ )
        , correlationMaskCount( correlationMaskCount_ )
        , pCorrelationMasks( pCorrelationMasks_ )
      {}

      RenderPassMultiviewCreateInfo( VkRenderPassMultiviewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassMultiviewCreateInfo*>(this) = rhs;
      }

      RenderPassMultiviewCreateInfo& operator=( VkRenderPassMultiviewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassMultiviewCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassMultiviewCreateInfo;
      const void* pNext = nullptr;
      uint32_t subpassCount;
      const uint32_t* pViewMasks;
      uint32_t dependencyCount;
      const int32_t* pViewOffsets;
      uint32_t correlationMaskCount;
      const uint32_t* pCorrelationMasks;
    };
    static_assert( sizeof( RenderPassMultiviewCreateInfo ) == sizeof( VkRenderPassMultiviewCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassMultiviewCreateInfo : public layout::RenderPassMultiviewCreateInfo
  {
    VULKAN_HPP_CONSTEXPR RenderPassMultiviewCreateInfo( uint32_t subpassCount_ = 0,
                                                        const uint32_t* pViewMasks_ = nullptr,
                                                        uint32_t dependencyCount_ = 0,
                                                        const int32_t* pViewOffsets_ = nullptr,
                                                        uint32_t correlationMaskCount_ = 0,
                                                        const uint32_t* pCorrelationMasks_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassMultiviewCreateInfo( subpassCount_, pViewMasks_, dependencyCount_, pViewOffsets_, correlationMaskCount_, pCorrelationMasks_ )
    {}

    RenderPassMultiviewCreateInfo( VkRenderPassMultiviewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassMultiviewCreateInfo( rhs )
    {}

    RenderPassMultiviewCreateInfo& operator=( VkRenderPassMultiviewCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassMultiviewCreateInfo::operator=(rhs);
      return *this;
    }

    RenderPassMultiviewCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassMultiviewCreateInfo & setSubpassCount( uint32_t subpassCount_ ) VULKAN_HPP_NOEXCEPT
    {
      subpassCount = subpassCount_;
      return *this;
    }

    RenderPassMultiviewCreateInfo & setPViewMasks( const uint32_t* pViewMasks_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewMasks = pViewMasks_;
      return *this;
    }

    RenderPassMultiviewCreateInfo & setDependencyCount( uint32_t dependencyCount_ ) VULKAN_HPP_NOEXCEPT
    {
      dependencyCount = dependencyCount_;
      return *this;
    }

    RenderPassMultiviewCreateInfo & setPViewOffsets( const int32_t* pViewOffsets_ ) VULKAN_HPP_NOEXCEPT
    {
      pViewOffsets = pViewOffsets_;
      return *this;
    }

    RenderPassMultiviewCreateInfo & setCorrelationMaskCount( uint32_t correlationMaskCount_ ) VULKAN_HPP_NOEXCEPT
    {
      correlationMaskCount = correlationMaskCount_;
      return *this;
    }

    RenderPassMultiviewCreateInfo & setPCorrelationMasks( const uint32_t* pCorrelationMasks_ ) VULKAN_HPP_NOEXCEPT
    {
      pCorrelationMasks = pCorrelationMasks_;
      return *this;
    }

    operator VkRenderPassMultiviewCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassMultiviewCreateInfo*>( this );
    }

    operator VkRenderPassMultiviewCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassMultiviewCreateInfo*>( this );
    }

    bool operator==( RenderPassMultiviewCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( subpassCount == rhs.subpassCount )
          && ( pViewMasks == rhs.pViewMasks )
          && ( dependencyCount == rhs.dependencyCount )
          && ( pViewOffsets == rhs.pViewOffsets )
          && ( correlationMaskCount == rhs.correlationMaskCount )
          && ( pCorrelationMasks == rhs.pCorrelationMasks );
    }

    bool operator!=( RenderPassMultiviewCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassMultiviewCreateInfo::sType;
  };
  static_assert( sizeof( RenderPassMultiviewCreateInfo ) == sizeof( VkRenderPassMultiviewCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassMultiviewCreateInfo>::value, "struct wrapper is not a standard layout!" );

  struct SubpassSampleLocationsEXT
  {
    VULKAN_HPP_CONSTEXPR SubpassSampleLocationsEXT( uint32_t subpassIndex_ = 0,
                                                    vk::SampleLocationsInfoEXT sampleLocationsInfo_ = vk::SampleLocationsInfoEXT() ) VULKAN_HPP_NOEXCEPT
      : subpassIndex( subpassIndex_ )
      , sampleLocationsInfo( sampleLocationsInfo_ )
    {}

    SubpassSampleLocationsEXT( VkSubpassSampleLocationsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubpassSampleLocationsEXT*>(this) = rhs;
    }

    SubpassSampleLocationsEXT& operator=( VkSubpassSampleLocationsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSubpassSampleLocationsEXT*>(this) = rhs;
      return *this;
    }

    SubpassSampleLocationsEXT & setSubpassIndex( uint32_t subpassIndex_ ) VULKAN_HPP_NOEXCEPT
    {
      subpassIndex = subpassIndex_;
      return *this;
    }

    SubpassSampleLocationsEXT & setSampleLocationsInfo( vk::SampleLocationsInfoEXT sampleLocationsInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      sampleLocationsInfo = sampleLocationsInfo_;
      return *this;
    }

    operator VkSubpassSampleLocationsEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassSampleLocationsEXT*>( this );
    }

    operator VkSubpassSampleLocationsEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassSampleLocationsEXT*>( this );
    }

    bool operator==( SubpassSampleLocationsEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( subpassIndex == rhs.subpassIndex )
          && ( sampleLocationsInfo == rhs.sampleLocationsInfo );
    }

    bool operator!=( SubpassSampleLocationsEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t subpassIndex;
    vk::SampleLocationsInfoEXT sampleLocationsInfo;
  };
  static_assert( sizeof( SubpassSampleLocationsEXT ) == sizeof( VkSubpassSampleLocationsEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassSampleLocationsEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct RenderPassSampleLocationsBeginInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR RenderPassSampleLocationsBeginInfoEXT( uint32_t attachmentInitialSampleLocationsCount_ = 0,
                                                                  const vk::AttachmentSampleLocationsEXT* pAttachmentInitialSampleLocations_ = nullptr,
                                                                  uint32_t postSubpassSampleLocationsCount_ = 0,
                                                                  const vk::SubpassSampleLocationsEXT* pPostSubpassSampleLocations_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : attachmentInitialSampleLocationsCount( attachmentInitialSampleLocationsCount_ )
        , pAttachmentInitialSampleLocations( pAttachmentInitialSampleLocations_ )
        , postSubpassSampleLocationsCount( postSubpassSampleLocationsCount_ )
        , pPostSubpassSampleLocations( pPostSubpassSampleLocations_ )
      {}

      RenderPassSampleLocationsBeginInfoEXT( VkRenderPassSampleLocationsBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassSampleLocationsBeginInfoEXT*>(this) = rhs;
      }

      RenderPassSampleLocationsBeginInfoEXT& operator=( VkRenderPassSampleLocationsBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkRenderPassSampleLocationsBeginInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eRenderPassSampleLocationsBeginInfoEXT;
      const void* pNext = nullptr;
      uint32_t attachmentInitialSampleLocationsCount;
      const vk::AttachmentSampleLocationsEXT* pAttachmentInitialSampleLocations;
      uint32_t postSubpassSampleLocationsCount;
      const vk::SubpassSampleLocationsEXT* pPostSubpassSampleLocations;
    };
    static_assert( sizeof( RenderPassSampleLocationsBeginInfoEXT ) == sizeof( VkRenderPassSampleLocationsBeginInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct RenderPassSampleLocationsBeginInfoEXT : public layout::RenderPassSampleLocationsBeginInfoEXT
  {
    VULKAN_HPP_CONSTEXPR RenderPassSampleLocationsBeginInfoEXT( uint32_t attachmentInitialSampleLocationsCount_ = 0,
                                                                const vk::AttachmentSampleLocationsEXT* pAttachmentInitialSampleLocations_ = nullptr,
                                                                uint32_t postSubpassSampleLocationsCount_ = 0,
                                                                const vk::SubpassSampleLocationsEXT* pPostSubpassSampleLocations_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassSampleLocationsBeginInfoEXT( attachmentInitialSampleLocationsCount_, pAttachmentInitialSampleLocations_, postSubpassSampleLocationsCount_, pPostSubpassSampleLocations_ )
    {}

    RenderPassSampleLocationsBeginInfoEXT( VkRenderPassSampleLocationsBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::RenderPassSampleLocationsBeginInfoEXT( rhs )
    {}

    RenderPassSampleLocationsBeginInfoEXT& operator=( VkRenderPassSampleLocationsBeginInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::RenderPassSampleLocationsBeginInfoEXT::operator=(rhs);
      return *this;
    }

    RenderPassSampleLocationsBeginInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    RenderPassSampleLocationsBeginInfoEXT & setAttachmentInitialSampleLocationsCount( uint32_t attachmentInitialSampleLocationsCount_ ) VULKAN_HPP_NOEXCEPT
    {
      attachmentInitialSampleLocationsCount = attachmentInitialSampleLocationsCount_;
      return *this;
    }

    RenderPassSampleLocationsBeginInfoEXT & setPAttachmentInitialSampleLocations( const vk::AttachmentSampleLocationsEXT* pAttachmentInitialSampleLocations_ ) VULKAN_HPP_NOEXCEPT
    {
      pAttachmentInitialSampleLocations = pAttachmentInitialSampleLocations_;
      return *this;
    }

    RenderPassSampleLocationsBeginInfoEXT & setPostSubpassSampleLocationsCount( uint32_t postSubpassSampleLocationsCount_ ) VULKAN_HPP_NOEXCEPT
    {
      postSubpassSampleLocationsCount = postSubpassSampleLocationsCount_;
      return *this;
    }

    RenderPassSampleLocationsBeginInfoEXT & setPPostSubpassSampleLocations( const vk::SubpassSampleLocationsEXT* pPostSubpassSampleLocations_ ) VULKAN_HPP_NOEXCEPT
    {
      pPostSubpassSampleLocations = pPostSubpassSampleLocations_;
      return *this;
    }

    operator VkRenderPassSampleLocationsBeginInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkRenderPassSampleLocationsBeginInfoEXT*>( this );
    }

    operator VkRenderPassSampleLocationsBeginInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkRenderPassSampleLocationsBeginInfoEXT*>( this );
    }

    bool operator==( RenderPassSampleLocationsBeginInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( attachmentInitialSampleLocationsCount == rhs.attachmentInitialSampleLocationsCount )
          && ( pAttachmentInitialSampleLocations == rhs.pAttachmentInitialSampleLocations )
          && ( postSubpassSampleLocationsCount == rhs.postSubpassSampleLocationsCount )
          && ( pPostSubpassSampleLocations == rhs.pPostSubpassSampleLocations );
    }

    bool operator!=( RenderPassSampleLocationsBeginInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::RenderPassSampleLocationsBeginInfoEXT::sType;
  };
  static_assert( sizeof( RenderPassSampleLocationsBeginInfoEXT ) == sizeof( VkRenderPassSampleLocationsBeginInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<RenderPassSampleLocationsBeginInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SamplerCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR SamplerCreateInfo( vk::SamplerCreateFlags flags_ = vk::SamplerCreateFlags(),
                                              vk::Filter magFilter_ = vk::Filter::eNearest,
                                              vk::Filter minFilter_ = vk::Filter::eNearest,
                                              vk::SamplerMipmapMode mipmapMode_ = vk::SamplerMipmapMode::eNearest,
                                              vk::SamplerAddressMode addressModeU_ = vk::SamplerAddressMode::eRepeat,
                                              vk::SamplerAddressMode addressModeV_ = vk::SamplerAddressMode::eRepeat,
                                              vk::SamplerAddressMode addressModeW_ = vk::SamplerAddressMode::eRepeat,
                                              float mipLodBias_ = 0,
                                              vk::Bool32 anisotropyEnable_ = 0,
                                              float maxAnisotropy_ = 0,
                                              vk::Bool32 compareEnable_ = 0,
                                              vk::CompareOp compareOp_ = vk::CompareOp::eNever,
                                              float minLod_ = 0,
                                              float maxLod_ = 0,
                                              vk::BorderColor borderColor_ = vk::BorderColor::eFloatTransparentBlack,
                                              vk::Bool32 unnormalizedCoordinates_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , magFilter( magFilter_ )
        , minFilter( minFilter_ )
        , mipmapMode( mipmapMode_ )
        , addressModeU( addressModeU_ )
        , addressModeV( addressModeV_ )
        , addressModeW( addressModeW_ )
        , mipLodBias( mipLodBias_ )
        , anisotropyEnable( anisotropyEnable_ )
        , maxAnisotropy( maxAnisotropy_ )
        , compareEnable( compareEnable_ )
        , compareOp( compareOp_ )
        , minLod( minLod_ )
        , maxLod( maxLod_ )
        , borderColor( borderColor_ )
        , unnormalizedCoordinates( unnormalizedCoordinates_ )
      {}

      SamplerCreateInfo( VkSamplerCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerCreateInfo*>(this) = rhs;
      }

      SamplerCreateInfo& operator=( VkSamplerCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSamplerCreateInfo;
      const void* pNext = nullptr;
      vk::SamplerCreateFlags flags;
      vk::Filter magFilter;
      vk::Filter minFilter;
      vk::SamplerMipmapMode mipmapMode;
      vk::SamplerAddressMode addressModeU;
      vk::SamplerAddressMode addressModeV;
      vk::SamplerAddressMode addressModeW;
      float mipLodBias;
      vk::Bool32 anisotropyEnable;
      float maxAnisotropy;
      vk::Bool32 compareEnable;
      vk::CompareOp compareOp;
      float minLod;
      float maxLod;
      vk::BorderColor borderColor;
      vk::Bool32 unnormalizedCoordinates;
    };
    static_assert( sizeof( SamplerCreateInfo ) == sizeof( VkSamplerCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct SamplerCreateInfo : public layout::SamplerCreateInfo
  {
    VULKAN_HPP_CONSTEXPR SamplerCreateInfo( vk::SamplerCreateFlags flags_ = vk::SamplerCreateFlags(),
                                            vk::Filter magFilter_ = vk::Filter::eNearest,
                                            vk::Filter minFilter_ = vk::Filter::eNearest,
                                            vk::SamplerMipmapMode mipmapMode_ = vk::SamplerMipmapMode::eNearest,
                                            vk::SamplerAddressMode addressModeU_ = vk::SamplerAddressMode::eRepeat,
                                            vk::SamplerAddressMode addressModeV_ = vk::SamplerAddressMode::eRepeat,
                                            vk::SamplerAddressMode addressModeW_ = vk::SamplerAddressMode::eRepeat,
                                            float mipLodBias_ = 0,
                                            vk::Bool32 anisotropyEnable_ = 0,
                                            float maxAnisotropy_ = 0,
                                            vk::Bool32 compareEnable_ = 0,
                                            vk::CompareOp compareOp_ = vk::CompareOp::eNever,
                                            float minLod_ = 0,
                                            float maxLod_ = 0,
                                            vk::BorderColor borderColor_ = vk::BorderColor::eFloatTransparentBlack,
                                            vk::Bool32 unnormalizedCoordinates_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerCreateInfo( flags_, magFilter_, minFilter_, mipmapMode_, addressModeU_, addressModeV_, addressModeW_, mipLodBias_, anisotropyEnable_, maxAnisotropy_, compareEnable_, compareOp_, minLod_, maxLod_, borderColor_, unnormalizedCoordinates_ )
    {}

    SamplerCreateInfo( VkSamplerCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerCreateInfo( rhs )
    {}

    SamplerCreateInfo& operator=( VkSamplerCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SamplerCreateInfo::operator=(rhs);
      return *this;
    }

    SamplerCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SamplerCreateInfo & setFlags( vk::SamplerCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    SamplerCreateInfo & setMagFilter( vk::Filter magFilter_ ) VULKAN_HPP_NOEXCEPT
    {
      magFilter = magFilter_;
      return *this;
    }

    SamplerCreateInfo & setMinFilter( vk::Filter minFilter_ ) VULKAN_HPP_NOEXCEPT
    {
      minFilter = minFilter_;
      return *this;
    }

    SamplerCreateInfo & setMipmapMode( vk::SamplerMipmapMode mipmapMode_ ) VULKAN_HPP_NOEXCEPT
    {
      mipmapMode = mipmapMode_;
      return *this;
    }

    SamplerCreateInfo & setAddressModeU( vk::SamplerAddressMode addressModeU_ ) VULKAN_HPP_NOEXCEPT
    {
      addressModeU = addressModeU_;
      return *this;
    }

    SamplerCreateInfo & setAddressModeV( vk::SamplerAddressMode addressModeV_ ) VULKAN_HPP_NOEXCEPT
    {
      addressModeV = addressModeV_;
      return *this;
    }

    SamplerCreateInfo & setAddressModeW( vk::SamplerAddressMode addressModeW_ ) VULKAN_HPP_NOEXCEPT
    {
      addressModeW = addressModeW_;
      return *this;
    }

    SamplerCreateInfo & setMipLodBias( float mipLodBias_ ) VULKAN_HPP_NOEXCEPT
    {
      mipLodBias = mipLodBias_;
      return *this;
    }

    SamplerCreateInfo & setAnisotropyEnable( vk::Bool32 anisotropyEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      anisotropyEnable = anisotropyEnable_;
      return *this;
    }

    SamplerCreateInfo & setMaxAnisotropy( float maxAnisotropy_ ) VULKAN_HPP_NOEXCEPT
    {
      maxAnisotropy = maxAnisotropy_;
      return *this;
    }

    SamplerCreateInfo & setCompareEnable( vk::Bool32 compareEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      compareEnable = compareEnable_;
      return *this;
    }

    SamplerCreateInfo & setCompareOp( vk::CompareOp compareOp_ ) VULKAN_HPP_NOEXCEPT
    {
      compareOp = compareOp_;
      return *this;
    }

    SamplerCreateInfo & setMinLod( float minLod_ ) VULKAN_HPP_NOEXCEPT
    {
      minLod = minLod_;
      return *this;
    }

    SamplerCreateInfo & setMaxLod( float maxLod_ ) VULKAN_HPP_NOEXCEPT
    {
      maxLod = maxLod_;
      return *this;
    }

    SamplerCreateInfo & setBorderColor( vk::BorderColor borderColor_ ) VULKAN_HPP_NOEXCEPT
    {
      borderColor = borderColor_;
      return *this;
    }

    SamplerCreateInfo & setUnnormalizedCoordinates( vk::Bool32 unnormalizedCoordinates_ ) VULKAN_HPP_NOEXCEPT
    {
      unnormalizedCoordinates = unnormalizedCoordinates_;
      return *this;
    }

    operator VkSamplerCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSamplerCreateInfo*>( this );
    }

    operator VkSamplerCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSamplerCreateInfo*>( this );
    }

    bool operator==( SamplerCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( magFilter == rhs.magFilter )
          && ( minFilter == rhs.minFilter )
          && ( mipmapMode == rhs.mipmapMode )
          && ( addressModeU == rhs.addressModeU )
          && ( addressModeV == rhs.addressModeV )
          && ( addressModeW == rhs.addressModeW )
          && ( mipLodBias == rhs.mipLodBias )
          && ( anisotropyEnable == rhs.anisotropyEnable )
          && ( maxAnisotropy == rhs.maxAnisotropy )
          && ( compareEnable == rhs.compareEnable )
          && ( compareOp == rhs.compareOp )
          && ( minLod == rhs.minLod )
          && ( maxLod == rhs.maxLod )
          && ( borderColor == rhs.borderColor )
          && ( unnormalizedCoordinates == rhs.unnormalizedCoordinates );
    }

    bool operator!=( SamplerCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SamplerCreateInfo::sType;
  };
  static_assert( sizeof( SamplerCreateInfo ) == sizeof( VkSamplerCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SamplerCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SamplerReductionModeCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR SamplerReductionModeCreateInfoEXT( vk::SamplerReductionModeEXT reductionMode_ = vk::SamplerReductionModeEXT::eWeightedAverage ) VULKAN_HPP_NOEXCEPT
        : reductionMode( reductionMode_ )
      {}

      SamplerReductionModeCreateInfoEXT( VkSamplerReductionModeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerReductionModeCreateInfoEXT*>(this) = rhs;
      }

      SamplerReductionModeCreateInfoEXT& operator=( VkSamplerReductionModeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerReductionModeCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSamplerReductionModeCreateInfoEXT;
      const void* pNext = nullptr;
      vk::SamplerReductionModeEXT reductionMode;
    };
    static_assert( sizeof( SamplerReductionModeCreateInfoEXT ) == sizeof( VkSamplerReductionModeCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct SamplerReductionModeCreateInfoEXT : public layout::SamplerReductionModeCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR SamplerReductionModeCreateInfoEXT( vk::SamplerReductionModeEXT reductionMode_ = vk::SamplerReductionModeEXT::eWeightedAverage ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerReductionModeCreateInfoEXT( reductionMode_ )
    {}

    SamplerReductionModeCreateInfoEXT( VkSamplerReductionModeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerReductionModeCreateInfoEXT( rhs )
    {}

    SamplerReductionModeCreateInfoEXT& operator=( VkSamplerReductionModeCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SamplerReductionModeCreateInfoEXT::operator=(rhs);
      return *this;
    }

    SamplerReductionModeCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SamplerReductionModeCreateInfoEXT & setReductionMode( vk::SamplerReductionModeEXT reductionMode_ ) VULKAN_HPP_NOEXCEPT
    {
      reductionMode = reductionMode_;
      return *this;
    }

    operator VkSamplerReductionModeCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSamplerReductionModeCreateInfoEXT*>( this );
    }

    operator VkSamplerReductionModeCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSamplerReductionModeCreateInfoEXT*>( this );
    }

    bool operator==( SamplerReductionModeCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( reductionMode == rhs.reductionMode );
    }

    bool operator!=( SamplerReductionModeCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SamplerReductionModeCreateInfoEXT::sType;
  };
  static_assert( sizeof( SamplerReductionModeCreateInfoEXT ) == sizeof( VkSamplerReductionModeCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SamplerReductionModeCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SamplerYcbcrConversionCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR SamplerYcbcrConversionCreateInfo( vk::Format format_ = vk::Format::eUndefined,
                                                             vk::SamplerYcbcrModelConversion ycbcrModel_ = vk::SamplerYcbcrModelConversion::eRgbIdentity,
                                                             vk::SamplerYcbcrRange ycbcrRange_ = vk::SamplerYcbcrRange::eItuFull,
                                                             vk::ComponentMapping components_ = vk::ComponentMapping(),
                                                             vk::ChromaLocation xChromaOffset_ = vk::ChromaLocation::eCositedEven,
                                                             vk::ChromaLocation yChromaOffset_ = vk::ChromaLocation::eCositedEven,
                                                             vk::Filter chromaFilter_ = vk::Filter::eNearest,
                                                             vk::Bool32 forceExplicitReconstruction_ = 0 ) VULKAN_HPP_NOEXCEPT
        : format( format_ )
        , ycbcrModel( ycbcrModel_ )
        , ycbcrRange( ycbcrRange_ )
        , components( components_ )
        , xChromaOffset( xChromaOffset_ )
        , yChromaOffset( yChromaOffset_ )
        , chromaFilter( chromaFilter_ )
        , forceExplicitReconstruction( forceExplicitReconstruction_ )
      {}

      SamplerYcbcrConversionCreateInfo( VkSamplerYcbcrConversionCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerYcbcrConversionCreateInfo*>(this) = rhs;
      }

      SamplerYcbcrConversionCreateInfo& operator=( VkSamplerYcbcrConversionCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerYcbcrConversionCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSamplerYcbcrConversionCreateInfo;
      const void* pNext = nullptr;
      vk::Format format;
      vk::SamplerYcbcrModelConversion ycbcrModel;
      vk::SamplerYcbcrRange ycbcrRange;
      vk::ComponentMapping components;
      vk::ChromaLocation xChromaOffset;
      vk::ChromaLocation yChromaOffset;
      vk::Filter chromaFilter;
      vk::Bool32 forceExplicitReconstruction;
    };
    static_assert( sizeof( SamplerYcbcrConversionCreateInfo ) == sizeof( VkSamplerYcbcrConversionCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct SamplerYcbcrConversionCreateInfo : public layout::SamplerYcbcrConversionCreateInfo
  {
    VULKAN_HPP_CONSTEXPR SamplerYcbcrConversionCreateInfo( vk::Format format_ = vk::Format::eUndefined,
                                                           vk::SamplerYcbcrModelConversion ycbcrModel_ = vk::SamplerYcbcrModelConversion::eRgbIdentity,
                                                           vk::SamplerYcbcrRange ycbcrRange_ = vk::SamplerYcbcrRange::eItuFull,
                                                           vk::ComponentMapping components_ = vk::ComponentMapping(),
                                                           vk::ChromaLocation xChromaOffset_ = vk::ChromaLocation::eCositedEven,
                                                           vk::ChromaLocation yChromaOffset_ = vk::ChromaLocation::eCositedEven,
                                                           vk::Filter chromaFilter_ = vk::Filter::eNearest,
                                                           vk::Bool32 forceExplicitReconstruction_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerYcbcrConversionCreateInfo( format_, ycbcrModel_, ycbcrRange_, components_, xChromaOffset_, yChromaOffset_, chromaFilter_, forceExplicitReconstruction_ )
    {}

    SamplerYcbcrConversionCreateInfo( VkSamplerYcbcrConversionCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerYcbcrConversionCreateInfo( rhs )
    {}

    SamplerYcbcrConversionCreateInfo& operator=( VkSamplerYcbcrConversionCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SamplerYcbcrConversionCreateInfo::operator=(rhs);
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setFormat( vk::Format format_ ) VULKAN_HPP_NOEXCEPT
    {
      format = format_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setYcbcrModel( vk::SamplerYcbcrModelConversion ycbcrModel_ ) VULKAN_HPP_NOEXCEPT
    {
      ycbcrModel = ycbcrModel_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setYcbcrRange( vk::SamplerYcbcrRange ycbcrRange_ ) VULKAN_HPP_NOEXCEPT
    {
      ycbcrRange = ycbcrRange_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setComponents( vk::ComponentMapping components_ ) VULKAN_HPP_NOEXCEPT
    {
      components = components_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setXChromaOffset( vk::ChromaLocation xChromaOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      xChromaOffset = xChromaOffset_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setYChromaOffset( vk::ChromaLocation yChromaOffset_ ) VULKAN_HPP_NOEXCEPT
    {
      yChromaOffset = yChromaOffset_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setChromaFilter( vk::Filter chromaFilter_ ) VULKAN_HPP_NOEXCEPT
    {
      chromaFilter = chromaFilter_;
      return *this;
    }

    SamplerYcbcrConversionCreateInfo & setForceExplicitReconstruction( vk::Bool32 forceExplicitReconstruction_ ) VULKAN_HPP_NOEXCEPT
    {
      forceExplicitReconstruction = forceExplicitReconstruction_;
      return *this;
    }

    operator VkSamplerYcbcrConversionCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>( this );
    }

    operator VkSamplerYcbcrConversionCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSamplerYcbcrConversionCreateInfo*>( this );
    }

    bool operator==( SamplerYcbcrConversionCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( format == rhs.format )
          && ( ycbcrModel == rhs.ycbcrModel )
          && ( ycbcrRange == rhs.ycbcrRange )
          && ( components == rhs.components )
          && ( xChromaOffset == rhs.xChromaOffset )
          && ( yChromaOffset == rhs.yChromaOffset )
          && ( chromaFilter == rhs.chromaFilter )
          && ( forceExplicitReconstruction == rhs.forceExplicitReconstruction );
    }

    bool operator!=( SamplerYcbcrConversionCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SamplerYcbcrConversionCreateInfo::sType;
  };
  static_assert( sizeof( SamplerYcbcrConversionCreateInfo ) == sizeof( VkSamplerYcbcrConversionCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SamplerYcbcrConversionCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SamplerYcbcrConversionImageFormatProperties
    {
    protected:
      SamplerYcbcrConversionImageFormatProperties() VULKAN_HPP_NOEXCEPT
      {}

      SamplerYcbcrConversionImageFormatProperties( VkSamplerYcbcrConversionImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerYcbcrConversionImageFormatProperties*>(this) = rhs;
      }

      SamplerYcbcrConversionImageFormatProperties& operator=( VkSamplerYcbcrConversionImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerYcbcrConversionImageFormatProperties*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSamplerYcbcrConversionImageFormatProperties;
      void* pNext = nullptr;
      uint32_t combinedImageSamplerDescriptorCount;
    };
    static_assert( sizeof( SamplerYcbcrConversionImageFormatProperties ) == sizeof( VkSamplerYcbcrConversionImageFormatProperties ), "layout struct and wrapper have different size!" );
  }

  struct SamplerYcbcrConversionImageFormatProperties : public layout::SamplerYcbcrConversionImageFormatProperties
  {
    SamplerYcbcrConversionImageFormatProperties() VULKAN_HPP_NOEXCEPT
      : layout::SamplerYcbcrConversionImageFormatProperties()
    {}

    SamplerYcbcrConversionImageFormatProperties( VkSamplerYcbcrConversionImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerYcbcrConversionImageFormatProperties( rhs )
    {}

    SamplerYcbcrConversionImageFormatProperties& operator=( VkSamplerYcbcrConversionImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SamplerYcbcrConversionImageFormatProperties::operator=(rhs);
      return *this;
    }

    operator VkSamplerYcbcrConversionImageFormatProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSamplerYcbcrConversionImageFormatProperties*>( this );
    }

    operator VkSamplerYcbcrConversionImageFormatProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSamplerYcbcrConversionImageFormatProperties*>( this );
    }

    bool operator==( SamplerYcbcrConversionImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( combinedImageSamplerDescriptorCount == rhs.combinedImageSamplerDescriptorCount );
    }

    bool operator!=( SamplerYcbcrConversionImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SamplerYcbcrConversionImageFormatProperties::sType;
  };
  static_assert( sizeof( SamplerYcbcrConversionImageFormatProperties ) == sizeof( VkSamplerYcbcrConversionImageFormatProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SamplerYcbcrConversionImageFormatProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SamplerYcbcrConversionInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR SamplerYcbcrConversionInfo( vk::SamplerYcbcrConversion conversion_ = vk::SamplerYcbcrConversion() ) VULKAN_HPP_NOEXCEPT
        : conversion( conversion_ )
      {}

      SamplerYcbcrConversionInfo( VkSamplerYcbcrConversionInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerYcbcrConversionInfo*>(this) = rhs;
      }

      SamplerYcbcrConversionInfo& operator=( VkSamplerYcbcrConversionInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSamplerYcbcrConversionInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSamplerYcbcrConversionInfo;
      const void* pNext = nullptr;
      vk::SamplerYcbcrConversion conversion;
    };
    static_assert( sizeof( SamplerYcbcrConversionInfo ) == sizeof( VkSamplerYcbcrConversionInfo ), "layout struct and wrapper have different size!" );
  }

  struct SamplerYcbcrConversionInfo : public layout::SamplerYcbcrConversionInfo
  {
    VULKAN_HPP_CONSTEXPR SamplerYcbcrConversionInfo( vk::SamplerYcbcrConversion conversion_ = vk::SamplerYcbcrConversion() ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerYcbcrConversionInfo( conversion_ )
    {}

    SamplerYcbcrConversionInfo( VkSamplerYcbcrConversionInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SamplerYcbcrConversionInfo( rhs )
    {}

    SamplerYcbcrConversionInfo& operator=( VkSamplerYcbcrConversionInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SamplerYcbcrConversionInfo::operator=(rhs);
      return *this;
    }

    SamplerYcbcrConversionInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SamplerYcbcrConversionInfo & setConversion( vk::SamplerYcbcrConversion conversion_ ) VULKAN_HPP_NOEXCEPT
    {
      conversion = conversion_;
      return *this;
    }

    operator VkSamplerYcbcrConversionInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSamplerYcbcrConversionInfo*>( this );
    }

    operator VkSamplerYcbcrConversionInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSamplerYcbcrConversionInfo*>( this );
    }

    bool operator==( SamplerYcbcrConversionInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( conversion == rhs.conversion );
    }

    bool operator!=( SamplerYcbcrConversionInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SamplerYcbcrConversionInfo::sType;
  };
  static_assert( sizeof( SamplerYcbcrConversionInfo ) == sizeof( VkSamplerYcbcrConversionInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SamplerYcbcrConversionInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SemaphoreCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR SemaphoreCreateInfo( vk::SemaphoreCreateFlags flags_ = vk::SemaphoreCreateFlags() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
      {}

      SemaphoreCreateInfo( VkSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreCreateInfo*>(this) = rhs;
      }

      SemaphoreCreateInfo& operator=( VkSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSemaphoreCreateInfo;
      const void* pNext = nullptr;
      vk::SemaphoreCreateFlags flags;
    };
    static_assert( sizeof( SemaphoreCreateInfo ) == sizeof( VkSemaphoreCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct SemaphoreCreateInfo : public layout::SemaphoreCreateInfo
  {
    VULKAN_HPP_CONSTEXPR SemaphoreCreateInfo( vk::SemaphoreCreateFlags flags_ = vk::SemaphoreCreateFlags() ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreCreateInfo( flags_ )
    {}

    SemaphoreCreateInfo( VkSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreCreateInfo( rhs )
    {}

    SemaphoreCreateInfo& operator=( VkSemaphoreCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SemaphoreCreateInfo::operator=(rhs);
      return *this;
    }

    SemaphoreCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SemaphoreCreateInfo & setFlags( vk::SemaphoreCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    operator VkSemaphoreCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSemaphoreCreateInfo*>( this );
    }

    operator VkSemaphoreCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSemaphoreCreateInfo*>( this );
    }

    bool operator==( SemaphoreCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags );
    }

    bool operator!=( SemaphoreCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SemaphoreCreateInfo::sType;
  };
  static_assert( sizeof( SemaphoreCreateInfo ) == sizeof( VkSemaphoreCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SemaphoreCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SemaphoreGetFdInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SemaphoreGetFdInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                  vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : semaphore( semaphore_ )
        , handleType( handleType_ )
      {}

      SemaphoreGetFdInfoKHR( VkSemaphoreGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreGetFdInfoKHR*>(this) = rhs;
      }

      SemaphoreGetFdInfoKHR& operator=( VkSemaphoreGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreGetFdInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSemaphoreGetFdInfoKHR;
      const void* pNext = nullptr;
      vk::Semaphore semaphore;
      vk::ExternalSemaphoreHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( SemaphoreGetFdInfoKHR ) == sizeof( VkSemaphoreGetFdInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SemaphoreGetFdInfoKHR : public layout::SemaphoreGetFdInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SemaphoreGetFdInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreGetFdInfoKHR( semaphore_, handleType_ )
    {}

    SemaphoreGetFdInfoKHR( VkSemaphoreGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreGetFdInfoKHR( rhs )
    {}

    SemaphoreGetFdInfoKHR& operator=( VkSemaphoreGetFdInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SemaphoreGetFdInfoKHR::operator=(rhs);
      return *this;
    }

    SemaphoreGetFdInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SemaphoreGetFdInfoKHR & setSemaphore( vk::Semaphore semaphore_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphore = semaphore_;
      return *this;
    }

    SemaphoreGetFdInfoKHR & setHandleType( vk::ExternalSemaphoreHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkSemaphoreGetFdInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSemaphoreGetFdInfoKHR*>( this );
    }

    operator VkSemaphoreGetFdInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSemaphoreGetFdInfoKHR*>( this );
    }

    bool operator==( SemaphoreGetFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( semaphore == rhs.semaphore )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( SemaphoreGetFdInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SemaphoreGetFdInfoKHR::sType;
  };
  static_assert( sizeof( SemaphoreGetFdInfoKHR ) == sizeof( VkSemaphoreGetFdInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SemaphoreGetFdInfoKHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct SemaphoreGetWin32HandleInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SemaphoreGetWin32HandleInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                           vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
        : semaphore( semaphore_ )
        , handleType( handleType_ )
      {}

      SemaphoreGetWin32HandleInfoKHR( VkSemaphoreGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreGetWin32HandleInfoKHR*>(this) = rhs;
      }

      SemaphoreGetWin32HandleInfoKHR& operator=( VkSemaphoreGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreGetWin32HandleInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSemaphoreGetWin32HandleInfoKHR;
      const void* pNext = nullptr;
      vk::Semaphore semaphore;
      vk::ExternalSemaphoreHandleTypeFlagBits handleType;
    };
    static_assert( sizeof( SemaphoreGetWin32HandleInfoKHR ) == sizeof( VkSemaphoreGetWin32HandleInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SemaphoreGetWin32HandleInfoKHR : public layout::SemaphoreGetWin32HandleInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SemaphoreGetWin32HandleInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                         vk::ExternalSemaphoreHandleTypeFlagBits handleType_ = vk::ExternalSemaphoreHandleTypeFlagBits::eOpaqueFd ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreGetWin32HandleInfoKHR( semaphore_, handleType_ )
    {}

    SemaphoreGetWin32HandleInfoKHR( VkSemaphoreGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreGetWin32HandleInfoKHR( rhs )
    {}

    SemaphoreGetWin32HandleInfoKHR& operator=( VkSemaphoreGetWin32HandleInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SemaphoreGetWin32HandleInfoKHR::operator=(rhs);
      return *this;
    }

    SemaphoreGetWin32HandleInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SemaphoreGetWin32HandleInfoKHR & setSemaphore( vk::Semaphore semaphore_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphore = semaphore_;
      return *this;
    }

    SemaphoreGetWin32HandleInfoKHR & setHandleType( vk::ExternalSemaphoreHandleTypeFlagBits handleType_ ) VULKAN_HPP_NOEXCEPT
    {
      handleType = handleType_;
      return *this;
    }

    operator VkSemaphoreGetWin32HandleInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSemaphoreGetWin32HandleInfoKHR*>( this );
    }

    operator VkSemaphoreGetWin32HandleInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSemaphoreGetWin32HandleInfoKHR*>( this );
    }

    bool operator==( SemaphoreGetWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( semaphore == rhs.semaphore )
          && vk::operator==( handleType, rhs.handleType );
    }

    bool operator!=( SemaphoreGetWin32HandleInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SemaphoreGetWin32HandleInfoKHR::sType;
  };
  static_assert( sizeof( SemaphoreGetWin32HandleInfoKHR ) == sizeof( VkSemaphoreGetWin32HandleInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SemaphoreGetWin32HandleInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct SemaphoreSignalInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SemaphoreSignalInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                   uint64_t value_ = 0 ) VULKAN_HPP_NOEXCEPT
        : semaphore( semaphore_ )
        , value( value_ )
      {}

      SemaphoreSignalInfoKHR( VkSemaphoreSignalInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreSignalInfoKHR*>(this) = rhs;
      }

      SemaphoreSignalInfoKHR& operator=( VkSemaphoreSignalInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreSignalInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSemaphoreSignalInfoKHR;
      const void* pNext = nullptr;
      vk::Semaphore semaphore;
      uint64_t value;
    };
    static_assert( sizeof( SemaphoreSignalInfoKHR ) == sizeof( VkSemaphoreSignalInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SemaphoreSignalInfoKHR : public layout::SemaphoreSignalInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SemaphoreSignalInfoKHR( vk::Semaphore semaphore_ = vk::Semaphore(),
                                                 uint64_t value_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreSignalInfoKHR( semaphore_, value_ )
    {}

    SemaphoreSignalInfoKHR( VkSemaphoreSignalInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreSignalInfoKHR( rhs )
    {}

    SemaphoreSignalInfoKHR& operator=( VkSemaphoreSignalInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SemaphoreSignalInfoKHR::operator=(rhs);
      return *this;
    }

    SemaphoreSignalInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SemaphoreSignalInfoKHR & setSemaphore( vk::Semaphore semaphore_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphore = semaphore_;
      return *this;
    }

    SemaphoreSignalInfoKHR & setValue( uint64_t value_ ) VULKAN_HPP_NOEXCEPT
    {
      value = value_;
      return *this;
    }

    operator VkSemaphoreSignalInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSemaphoreSignalInfoKHR*>( this );
    }

    operator VkSemaphoreSignalInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSemaphoreSignalInfoKHR*>( this );
    }

    bool operator==( SemaphoreSignalInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( semaphore == rhs.semaphore )
          && ( value == rhs.value );
    }

    bool operator!=( SemaphoreSignalInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SemaphoreSignalInfoKHR::sType;
  };
  static_assert( sizeof( SemaphoreSignalInfoKHR ) == sizeof( VkSemaphoreSignalInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SemaphoreSignalInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SemaphoreTypeCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SemaphoreTypeCreateInfoKHR( vk::SemaphoreTypeKHR semaphoreType_ = vk::SemaphoreTypeKHR::eBinary,
                                                       uint64_t initialValue_ = 0 ) VULKAN_HPP_NOEXCEPT
        : semaphoreType( semaphoreType_ )
        , initialValue( initialValue_ )
      {}

      SemaphoreTypeCreateInfoKHR( VkSemaphoreTypeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreTypeCreateInfoKHR*>(this) = rhs;
      }

      SemaphoreTypeCreateInfoKHR& operator=( VkSemaphoreTypeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreTypeCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSemaphoreTypeCreateInfoKHR;
      const void* pNext = nullptr;
      vk::SemaphoreTypeKHR semaphoreType;
      uint64_t initialValue;
    };
    static_assert( sizeof( SemaphoreTypeCreateInfoKHR ) == sizeof( VkSemaphoreTypeCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SemaphoreTypeCreateInfoKHR : public layout::SemaphoreTypeCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SemaphoreTypeCreateInfoKHR( vk::SemaphoreTypeKHR semaphoreType_ = vk::SemaphoreTypeKHR::eBinary,
                                                     uint64_t initialValue_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreTypeCreateInfoKHR( semaphoreType_, initialValue_ )
    {}

    SemaphoreTypeCreateInfoKHR( VkSemaphoreTypeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreTypeCreateInfoKHR( rhs )
    {}

    SemaphoreTypeCreateInfoKHR& operator=( VkSemaphoreTypeCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SemaphoreTypeCreateInfoKHR::operator=(rhs);
      return *this;
    }

    SemaphoreTypeCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SemaphoreTypeCreateInfoKHR & setSemaphoreType( vk::SemaphoreTypeKHR semaphoreType_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphoreType = semaphoreType_;
      return *this;
    }

    SemaphoreTypeCreateInfoKHR & setInitialValue( uint64_t initialValue_ ) VULKAN_HPP_NOEXCEPT
    {
      initialValue = initialValue_;
      return *this;
    }

    operator VkSemaphoreTypeCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSemaphoreTypeCreateInfoKHR*>( this );
    }

    operator VkSemaphoreTypeCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSemaphoreTypeCreateInfoKHR*>( this );
    }

    bool operator==( SemaphoreTypeCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( semaphoreType == rhs.semaphoreType )
          && ( initialValue == rhs.initialValue );
    }

    bool operator!=( SemaphoreTypeCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SemaphoreTypeCreateInfoKHR::sType;
  };
  static_assert( sizeof( SemaphoreTypeCreateInfoKHR ) == sizeof( VkSemaphoreTypeCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SemaphoreTypeCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SemaphoreWaitInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SemaphoreWaitInfoKHR( vk::SemaphoreWaitFlagsKHR flags_ = vk::SemaphoreWaitFlagsKHR(),
                                                 uint32_t semaphoreCount_ = 0,
                                                 const vk::Semaphore* pSemaphores_ = nullptr,
                                                 const uint64_t* pValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , semaphoreCount( semaphoreCount_ )
        , pSemaphores( pSemaphores_ )
        , pValues( pValues_ )
      {}

      SemaphoreWaitInfoKHR( VkSemaphoreWaitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreWaitInfoKHR*>(this) = rhs;
      }

      SemaphoreWaitInfoKHR& operator=( VkSemaphoreWaitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSemaphoreWaitInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSemaphoreWaitInfoKHR;
      const void* pNext = nullptr;
      vk::SemaphoreWaitFlagsKHR flags;
      uint32_t semaphoreCount;
      const vk::Semaphore* pSemaphores;
      const uint64_t* pValues;
    };
    static_assert( sizeof( SemaphoreWaitInfoKHR ) == sizeof( VkSemaphoreWaitInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SemaphoreWaitInfoKHR : public layout::SemaphoreWaitInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SemaphoreWaitInfoKHR( vk::SemaphoreWaitFlagsKHR flags_ = vk::SemaphoreWaitFlagsKHR(),
                                               uint32_t semaphoreCount_ = 0,
                                               const vk::Semaphore* pSemaphores_ = nullptr,
                                               const uint64_t* pValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreWaitInfoKHR( flags_, semaphoreCount_, pSemaphores_, pValues_ )
    {}

    SemaphoreWaitInfoKHR( VkSemaphoreWaitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SemaphoreWaitInfoKHR( rhs )
    {}

    SemaphoreWaitInfoKHR& operator=( VkSemaphoreWaitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SemaphoreWaitInfoKHR::operator=(rhs);
      return *this;
    }

    SemaphoreWaitInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SemaphoreWaitInfoKHR & setFlags( vk::SemaphoreWaitFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    SemaphoreWaitInfoKHR & setSemaphoreCount( uint32_t semaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      semaphoreCount = semaphoreCount_;
      return *this;
    }

    SemaphoreWaitInfoKHR & setPSemaphores( const vk::Semaphore* pSemaphores_ ) VULKAN_HPP_NOEXCEPT
    {
      pSemaphores = pSemaphores_;
      return *this;
    }

    SemaphoreWaitInfoKHR & setPValues( const uint64_t* pValues_ ) VULKAN_HPP_NOEXCEPT
    {
      pValues = pValues_;
      return *this;
    }

    operator VkSemaphoreWaitInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSemaphoreWaitInfoKHR*>( this );
    }

    operator VkSemaphoreWaitInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSemaphoreWaitInfoKHR*>( this );
    }

    bool operator==( SemaphoreWaitInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( semaphoreCount == rhs.semaphoreCount )
          && ( pSemaphores == rhs.pSemaphores )
          && ( pValues == rhs.pValues );
    }

    bool operator!=( SemaphoreWaitInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SemaphoreWaitInfoKHR::sType;
  };
  static_assert( sizeof( SemaphoreWaitInfoKHR ) == sizeof( VkSemaphoreWaitInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SemaphoreWaitInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ShaderModuleCreateInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR ShaderModuleCreateInfo( vk::ShaderModuleCreateFlags flags_ = vk::ShaderModuleCreateFlags(),
                                                   size_t codeSize_ = 0,
                                                   const uint32_t* pCode_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , codeSize( codeSize_ )
        , pCode( pCode_ )
      {}

      ShaderModuleCreateInfo( VkShaderModuleCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkShaderModuleCreateInfo*>(this) = rhs;
      }

      ShaderModuleCreateInfo& operator=( VkShaderModuleCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkShaderModuleCreateInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eShaderModuleCreateInfo;
      const void* pNext = nullptr;
      vk::ShaderModuleCreateFlags flags;
      size_t codeSize;
      const uint32_t* pCode;
    };
    static_assert( sizeof( ShaderModuleCreateInfo ) == sizeof( VkShaderModuleCreateInfo ), "layout struct and wrapper have different size!" );
  }

  struct ShaderModuleCreateInfo : public layout::ShaderModuleCreateInfo
  {
    VULKAN_HPP_CONSTEXPR ShaderModuleCreateInfo( vk::ShaderModuleCreateFlags flags_ = vk::ShaderModuleCreateFlags(),
                                                 size_t codeSize_ = 0,
                                                 const uint32_t* pCode_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ShaderModuleCreateInfo( flags_, codeSize_, pCode_ )
    {}

    ShaderModuleCreateInfo( VkShaderModuleCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ShaderModuleCreateInfo( rhs )
    {}

    ShaderModuleCreateInfo& operator=( VkShaderModuleCreateInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ShaderModuleCreateInfo::operator=(rhs);
      return *this;
    }

    ShaderModuleCreateInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ShaderModuleCreateInfo & setFlags( vk::ShaderModuleCreateFlags flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ShaderModuleCreateInfo & setCodeSize( size_t codeSize_ ) VULKAN_HPP_NOEXCEPT
    {
      codeSize = codeSize_;
      return *this;
    }

    ShaderModuleCreateInfo & setPCode( const uint32_t* pCode_ ) VULKAN_HPP_NOEXCEPT
    {
      pCode = pCode_;
      return *this;
    }

    operator VkShaderModuleCreateInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkShaderModuleCreateInfo*>( this );
    }

    operator VkShaderModuleCreateInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkShaderModuleCreateInfo*>( this );
    }

    bool operator==( ShaderModuleCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( codeSize == rhs.codeSize )
          && ( pCode == rhs.pCode );
    }

    bool operator!=( ShaderModuleCreateInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ShaderModuleCreateInfo::sType;
  };
  static_assert( sizeof( ShaderModuleCreateInfo ) == sizeof( VkShaderModuleCreateInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ShaderModuleCreateInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ShaderModuleValidationCacheCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ShaderModuleValidationCacheCreateInfoEXT( vk::ValidationCacheEXT validationCache_ = vk::ValidationCacheEXT() ) VULKAN_HPP_NOEXCEPT
        : validationCache( validationCache_ )
      {}

      ShaderModuleValidationCacheCreateInfoEXT( VkShaderModuleValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkShaderModuleValidationCacheCreateInfoEXT*>(this) = rhs;
      }

      ShaderModuleValidationCacheCreateInfoEXT& operator=( VkShaderModuleValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkShaderModuleValidationCacheCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eShaderModuleValidationCacheCreateInfoEXT;
      const void* pNext = nullptr;
      vk::ValidationCacheEXT validationCache;
    };
    static_assert( sizeof( ShaderModuleValidationCacheCreateInfoEXT ) == sizeof( VkShaderModuleValidationCacheCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct ShaderModuleValidationCacheCreateInfoEXT : public layout::ShaderModuleValidationCacheCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR ShaderModuleValidationCacheCreateInfoEXT( vk::ValidationCacheEXT validationCache_ = vk::ValidationCacheEXT() ) VULKAN_HPP_NOEXCEPT
      : layout::ShaderModuleValidationCacheCreateInfoEXT( validationCache_ )
    {}

    ShaderModuleValidationCacheCreateInfoEXT( VkShaderModuleValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ShaderModuleValidationCacheCreateInfoEXT( rhs )
    {}

    ShaderModuleValidationCacheCreateInfoEXT& operator=( VkShaderModuleValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ShaderModuleValidationCacheCreateInfoEXT::operator=(rhs);
      return *this;
    }

    ShaderModuleValidationCacheCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ShaderModuleValidationCacheCreateInfoEXT & setValidationCache( vk::ValidationCacheEXT validationCache_ ) VULKAN_HPP_NOEXCEPT
    {
      validationCache = validationCache_;
      return *this;
    }

    operator VkShaderModuleValidationCacheCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkShaderModuleValidationCacheCreateInfoEXT*>( this );
    }

    operator VkShaderModuleValidationCacheCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkShaderModuleValidationCacheCreateInfoEXT*>( this );
    }

    bool operator==( ShaderModuleValidationCacheCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( validationCache == rhs.validationCache );
    }

    bool operator!=( ShaderModuleValidationCacheCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ShaderModuleValidationCacheCreateInfoEXT::sType;
  };
  static_assert( sizeof( ShaderModuleValidationCacheCreateInfoEXT ) == sizeof( VkShaderModuleValidationCacheCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ShaderModuleValidationCacheCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  struct ShaderResourceUsageAMD
  {
    ShaderResourceUsageAMD() VULKAN_HPP_NOEXCEPT
    {}

    ShaderResourceUsageAMD( VkShaderResourceUsageAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkShaderResourceUsageAMD*>(this) = rhs;
    }

    ShaderResourceUsageAMD& operator=( VkShaderResourceUsageAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkShaderResourceUsageAMD*>(this) = rhs;
      return *this;
    }

    operator VkShaderResourceUsageAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkShaderResourceUsageAMD*>( this );
    }

    operator VkShaderResourceUsageAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkShaderResourceUsageAMD*>( this );
    }

    bool operator==( ShaderResourceUsageAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( numUsedVgprs == rhs.numUsedVgprs )
          && ( numUsedSgprs == rhs.numUsedSgprs )
          && ( ldsSizePerLocalWorkGroup == rhs.ldsSizePerLocalWorkGroup )
          && ( ldsUsageSizeInBytes == rhs.ldsUsageSizeInBytes )
          && ( scratchMemUsageInBytes == rhs.scratchMemUsageInBytes );
    }

    bool operator!=( ShaderResourceUsageAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t numUsedVgprs;
    uint32_t numUsedSgprs;
    uint32_t ldsSizePerLocalWorkGroup;
    size_t ldsUsageSizeInBytes;
    size_t scratchMemUsageInBytes;
  };
  static_assert( sizeof( ShaderResourceUsageAMD ) == sizeof( VkShaderResourceUsageAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ShaderResourceUsageAMD>::value, "struct wrapper is not a standard layout!" );

  struct ShaderStatisticsInfoAMD
  {
    ShaderStatisticsInfoAMD() VULKAN_HPP_NOEXCEPT
    {}

    ShaderStatisticsInfoAMD( VkShaderStatisticsInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkShaderStatisticsInfoAMD*>(this) = rhs;
    }

    ShaderStatisticsInfoAMD& operator=( VkShaderStatisticsInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkShaderStatisticsInfoAMD*>(this) = rhs;
      return *this;
    }

    operator VkShaderStatisticsInfoAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkShaderStatisticsInfoAMD*>( this );
    }

    operator VkShaderStatisticsInfoAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkShaderStatisticsInfoAMD*>( this );
    }

    bool operator==( ShaderStatisticsInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( shaderStageMask == rhs.shaderStageMask )
          && ( resourceUsage == rhs.resourceUsage )
          && ( numPhysicalVgprs == rhs.numPhysicalVgprs )
          && ( numPhysicalSgprs == rhs.numPhysicalSgprs )
          && ( numAvailableVgprs == rhs.numAvailableVgprs )
          && ( numAvailableSgprs == rhs.numAvailableSgprs )
          && ( memcmp( computeWorkGroupSize, rhs.computeWorkGroupSize, 3 * sizeof( uint32_t ) ) == 0 );
    }

    bool operator!=( ShaderStatisticsInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ShaderStageFlags shaderStageMask;
    vk::ShaderResourceUsageAMD resourceUsage;
    uint32_t numPhysicalVgprs;
    uint32_t numPhysicalSgprs;
    uint32_t numAvailableVgprs;
    uint32_t numAvailableSgprs;
    uint32_t computeWorkGroupSize[3];
  };
  static_assert( sizeof( ShaderStatisticsInfoAMD ) == sizeof( VkShaderStatisticsInfoAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ShaderStatisticsInfoAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SharedPresentSurfaceCapabilitiesKHR
    {
    protected:
      SharedPresentSurfaceCapabilitiesKHR() VULKAN_HPP_NOEXCEPT
      {}

      SharedPresentSurfaceCapabilitiesKHR( VkSharedPresentSurfaceCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSharedPresentSurfaceCapabilitiesKHR*>(this) = rhs;
      }

      SharedPresentSurfaceCapabilitiesKHR& operator=( VkSharedPresentSurfaceCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSharedPresentSurfaceCapabilitiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSharedPresentSurfaceCapabilitiesKHR;
      void* pNext = nullptr;
      vk::ImageUsageFlags sharedPresentSupportedUsageFlags;
    };
    static_assert( sizeof( SharedPresentSurfaceCapabilitiesKHR ) == sizeof( VkSharedPresentSurfaceCapabilitiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct SharedPresentSurfaceCapabilitiesKHR : public layout::SharedPresentSurfaceCapabilitiesKHR
  {
    SharedPresentSurfaceCapabilitiesKHR() VULKAN_HPP_NOEXCEPT
      : layout::SharedPresentSurfaceCapabilitiesKHR()
    {}

    SharedPresentSurfaceCapabilitiesKHR( VkSharedPresentSurfaceCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SharedPresentSurfaceCapabilitiesKHR( rhs )
    {}

    SharedPresentSurfaceCapabilitiesKHR& operator=( VkSharedPresentSurfaceCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SharedPresentSurfaceCapabilitiesKHR::operator=(rhs);
      return *this;
    }

    operator VkSharedPresentSurfaceCapabilitiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSharedPresentSurfaceCapabilitiesKHR*>( this );
    }

    operator VkSharedPresentSurfaceCapabilitiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSharedPresentSurfaceCapabilitiesKHR*>( this );
    }

    bool operator==( SharedPresentSurfaceCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( sharedPresentSupportedUsageFlags == rhs.sharedPresentSupportedUsageFlags );
    }

    bool operator!=( SharedPresentSurfaceCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SharedPresentSurfaceCapabilitiesKHR::sType;
  };
  static_assert( sizeof( SharedPresentSurfaceCapabilitiesKHR ) == sizeof( VkSharedPresentSurfaceCapabilitiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SharedPresentSurfaceCapabilitiesKHR>::value, "struct wrapper is not a standard layout!" );

  struct SparseImageFormatProperties
  {
    SparseImageFormatProperties() VULKAN_HPP_NOEXCEPT
    {}

    SparseImageFormatProperties( VkSparseImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageFormatProperties*>(this) = rhs;
    }

    SparseImageFormatProperties& operator=( VkSparseImageFormatProperties const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageFormatProperties*>(this) = rhs;
      return *this;
    }

    operator VkSparseImageFormatProperties const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseImageFormatProperties*>( this );
    }

    operator VkSparseImageFormatProperties &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseImageFormatProperties*>( this );
    }

    bool operator==( SparseImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( aspectMask == rhs.aspectMask )
          && ( imageGranularity == rhs.imageGranularity )
          && ( flags == rhs.flags );
    }

    bool operator!=( SparseImageFormatProperties const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::ImageAspectFlags aspectMask;
    vk::Extent3D imageGranularity;
    vk::SparseImageFormatFlags flags;
  };
  static_assert( sizeof( SparseImageFormatProperties ) == sizeof( VkSparseImageFormatProperties ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseImageFormatProperties>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SparseImageFormatProperties2
    {
    protected:
      SparseImageFormatProperties2() VULKAN_HPP_NOEXCEPT
      {}

      SparseImageFormatProperties2( VkSparseImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSparseImageFormatProperties2*>(this) = rhs;
      }

      SparseImageFormatProperties2& operator=( VkSparseImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSparseImageFormatProperties2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSparseImageFormatProperties2;
      void* pNext = nullptr;
      vk::SparseImageFormatProperties properties;
    };
    static_assert( sizeof( SparseImageFormatProperties2 ) == sizeof( VkSparseImageFormatProperties2 ), "layout struct and wrapper have different size!" );
  }

  struct SparseImageFormatProperties2 : public layout::SparseImageFormatProperties2
  {
    SparseImageFormatProperties2() VULKAN_HPP_NOEXCEPT
      : layout::SparseImageFormatProperties2()
    {}

    SparseImageFormatProperties2( VkSparseImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SparseImageFormatProperties2( rhs )
    {}

    SparseImageFormatProperties2& operator=( VkSparseImageFormatProperties2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SparseImageFormatProperties2::operator=(rhs);
      return *this;
    }

    operator VkSparseImageFormatProperties2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseImageFormatProperties2*>( this );
    }

    operator VkSparseImageFormatProperties2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseImageFormatProperties2*>( this );
    }

    bool operator==( SparseImageFormatProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( properties == rhs.properties );
    }

    bool operator!=( SparseImageFormatProperties2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SparseImageFormatProperties2::sType;
  };
  static_assert( sizeof( SparseImageFormatProperties2 ) == sizeof( VkSparseImageFormatProperties2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseImageFormatProperties2>::value, "struct wrapper is not a standard layout!" );

  struct SparseImageMemoryRequirements
  {
    SparseImageMemoryRequirements() VULKAN_HPP_NOEXCEPT
    {}

    SparseImageMemoryRequirements( VkSparseImageMemoryRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageMemoryRequirements*>(this) = rhs;
    }

    SparseImageMemoryRequirements& operator=( VkSparseImageMemoryRequirements const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSparseImageMemoryRequirements*>(this) = rhs;
      return *this;
    }

    operator VkSparseImageMemoryRequirements const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseImageMemoryRequirements*>( this );
    }

    operator VkSparseImageMemoryRequirements &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseImageMemoryRequirements*>( this );
    }

    bool operator==( SparseImageMemoryRequirements const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( formatProperties == rhs.formatProperties )
          && ( imageMipTailFirstLod == rhs.imageMipTailFirstLod )
          && ( imageMipTailSize == rhs.imageMipTailSize )
          && ( imageMipTailOffset == rhs.imageMipTailOffset )
          && ( imageMipTailStride == rhs.imageMipTailStride );
    }

    bool operator!=( SparseImageMemoryRequirements const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::SparseImageFormatProperties formatProperties;
    uint32_t imageMipTailFirstLod;
    vk::DeviceSize imageMipTailSize;
    vk::DeviceSize imageMipTailOffset;
    vk::DeviceSize imageMipTailStride;
  };
  static_assert( sizeof( SparseImageMemoryRequirements ) == sizeof( VkSparseImageMemoryRequirements ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseImageMemoryRequirements>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SparseImageMemoryRequirements2
    {
    protected:
      SparseImageMemoryRequirements2() VULKAN_HPP_NOEXCEPT
      {}

      SparseImageMemoryRequirements2( VkSparseImageMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSparseImageMemoryRequirements2*>(this) = rhs;
      }

      SparseImageMemoryRequirements2& operator=( VkSparseImageMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSparseImageMemoryRequirements2*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSparseImageMemoryRequirements2;
      void* pNext = nullptr;
      vk::SparseImageMemoryRequirements memoryRequirements;
    };
    static_assert( sizeof( SparseImageMemoryRequirements2 ) == sizeof( VkSparseImageMemoryRequirements2 ), "layout struct and wrapper have different size!" );
  }

  struct SparseImageMemoryRequirements2 : public layout::SparseImageMemoryRequirements2
  {
    SparseImageMemoryRequirements2() VULKAN_HPP_NOEXCEPT
      : layout::SparseImageMemoryRequirements2()
    {}

    SparseImageMemoryRequirements2( VkSparseImageMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SparseImageMemoryRequirements2( rhs )
    {}

    SparseImageMemoryRequirements2& operator=( VkSparseImageMemoryRequirements2 const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SparseImageMemoryRequirements2::operator=(rhs);
      return *this;
    }

    operator VkSparseImageMemoryRequirements2 const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSparseImageMemoryRequirements2*>( this );
    }

    operator VkSparseImageMemoryRequirements2 &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSparseImageMemoryRequirements2*>( this );
    }

    bool operator==( SparseImageMemoryRequirements2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( memoryRequirements == rhs.memoryRequirements );
    }

    bool operator!=( SparseImageMemoryRequirements2 const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SparseImageMemoryRequirements2::sType;
  };
  static_assert( sizeof( SparseImageMemoryRequirements2 ) == sizeof( VkSparseImageMemoryRequirements2 ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SparseImageMemoryRequirements2>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_GGP

  namespace layout
  {
    struct StreamDescriptorSurfaceCreateInfoGGP
    {
    protected:
      VULKAN_HPP_CONSTEXPR StreamDescriptorSurfaceCreateInfoGGP( vk::StreamDescriptorSurfaceCreateFlagsGGP flags_ = vk::StreamDescriptorSurfaceCreateFlagsGGP(),
                                                                 GgpStreamDescriptor streamDescriptor_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , streamDescriptor( streamDescriptor_ )
      {}

      StreamDescriptorSurfaceCreateInfoGGP( VkStreamDescriptorSurfaceCreateInfoGGP const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkStreamDescriptorSurfaceCreateInfoGGP*>(this) = rhs;
      }

      StreamDescriptorSurfaceCreateInfoGGP& operator=( VkStreamDescriptorSurfaceCreateInfoGGP const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkStreamDescriptorSurfaceCreateInfoGGP*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eStreamDescriptorSurfaceCreateInfoGGP;
      const void* pNext = nullptr;
      vk::StreamDescriptorSurfaceCreateFlagsGGP flags;
      GgpStreamDescriptor streamDescriptor;
    };
    static_assert( sizeof( StreamDescriptorSurfaceCreateInfoGGP ) == sizeof( VkStreamDescriptorSurfaceCreateInfoGGP ), "layout struct and wrapper have different size!" );
  }

  struct StreamDescriptorSurfaceCreateInfoGGP : public layout::StreamDescriptorSurfaceCreateInfoGGP
  {
    VULKAN_HPP_CONSTEXPR StreamDescriptorSurfaceCreateInfoGGP( vk::StreamDescriptorSurfaceCreateFlagsGGP flags_ = vk::StreamDescriptorSurfaceCreateFlagsGGP(),
                                                               GgpStreamDescriptor streamDescriptor_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::StreamDescriptorSurfaceCreateInfoGGP( flags_, streamDescriptor_ )
    {}

    StreamDescriptorSurfaceCreateInfoGGP( VkStreamDescriptorSurfaceCreateInfoGGP const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::StreamDescriptorSurfaceCreateInfoGGP( rhs )
    {}

    StreamDescriptorSurfaceCreateInfoGGP& operator=( VkStreamDescriptorSurfaceCreateInfoGGP const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::StreamDescriptorSurfaceCreateInfoGGP::operator=(rhs);
      return *this;
    }

    StreamDescriptorSurfaceCreateInfoGGP & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    StreamDescriptorSurfaceCreateInfoGGP & setFlags( vk::StreamDescriptorSurfaceCreateFlagsGGP flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    StreamDescriptorSurfaceCreateInfoGGP & setStreamDescriptor( GgpStreamDescriptor streamDescriptor_ ) VULKAN_HPP_NOEXCEPT
    {
      streamDescriptor = streamDescriptor_;
      return *this;
    }

    operator VkStreamDescriptorSurfaceCreateInfoGGP const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkStreamDescriptorSurfaceCreateInfoGGP*>( this );
    }

    operator VkStreamDescriptorSurfaceCreateInfoGGP &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkStreamDescriptorSurfaceCreateInfoGGP*>( this );
    }

    bool operator==( StreamDescriptorSurfaceCreateInfoGGP const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( streamDescriptor == rhs.streamDescriptor );
    }

    bool operator!=( StreamDescriptorSurfaceCreateInfoGGP const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::StreamDescriptorSurfaceCreateInfoGGP::sType;
  };
  static_assert( sizeof( StreamDescriptorSurfaceCreateInfoGGP ) == sizeof( VkStreamDescriptorSurfaceCreateInfoGGP ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<StreamDescriptorSurfaceCreateInfoGGP>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_GGP*/

  namespace layout
  {
    struct SubmitInfo
    {
    protected:
      VULKAN_HPP_CONSTEXPR SubmitInfo( uint32_t waitSemaphoreCount_ = 0,
                                       const vk::Semaphore* pWaitSemaphores_ = nullptr,
                                       const vk::PipelineStageFlags* pWaitDstStageMask_ = nullptr,
                                       uint32_t commandBufferCount_ = 0,
                                       const vk::CommandBuffer* pCommandBuffers_ = nullptr,
                                       uint32_t signalSemaphoreCount_ = 0,
                                       const vk::Semaphore* pSignalSemaphores_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : waitSemaphoreCount( waitSemaphoreCount_ )
        , pWaitSemaphores( pWaitSemaphores_ )
        , pWaitDstStageMask( pWaitDstStageMask_ )
        , commandBufferCount( commandBufferCount_ )
        , pCommandBuffers( pCommandBuffers_ )
        , signalSemaphoreCount( signalSemaphoreCount_ )
        , pSignalSemaphores( pSignalSemaphores_ )
      {}

      SubmitInfo( VkSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubmitInfo*>(this) = rhs;
      }

      SubmitInfo& operator=( VkSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubmitInfo*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSubmitInfo;
      const void* pNext = nullptr;
      uint32_t waitSemaphoreCount;
      const vk::Semaphore* pWaitSemaphores;
      const vk::PipelineStageFlags* pWaitDstStageMask;
      uint32_t commandBufferCount;
      const vk::CommandBuffer* pCommandBuffers;
      uint32_t signalSemaphoreCount;
      const vk::Semaphore* pSignalSemaphores;
    };
    static_assert( sizeof( SubmitInfo ) == sizeof( VkSubmitInfo ), "layout struct and wrapper have different size!" );
  }

  struct SubmitInfo : public layout::SubmitInfo
  {
    VULKAN_HPP_CONSTEXPR SubmitInfo( uint32_t waitSemaphoreCount_ = 0,
                                     const vk::Semaphore* pWaitSemaphores_ = nullptr,
                                     const vk::PipelineStageFlags* pWaitDstStageMask_ = nullptr,
                                     uint32_t commandBufferCount_ = 0,
                                     const vk::CommandBuffer* pCommandBuffers_ = nullptr,
                                     uint32_t signalSemaphoreCount_ = 0,
                                     const vk::Semaphore* pSignalSemaphores_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::SubmitInfo( waitSemaphoreCount_, pWaitSemaphores_, pWaitDstStageMask_, commandBufferCount_, pCommandBuffers_, signalSemaphoreCount_, pSignalSemaphores_ )
    {}

    SubmitInfo( VkSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SubmitInfo( rhs )
    {}

    SubmitInfo& operator=( VkSubmitInfo const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SubmitInfo::operator=(rhs);
      return *this;
    }

    SubmitInfo & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SubmitInfo & setWaitSemaphoreCount( uint32_t waitSemaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      waitSemaphoreCount = waitSemaphoreCount_;
      return *this;
    }

    SubmitInfo & setPWaitSemaphores( const vk::Semaphore* pWaitSemaphores_ ) VULKAN_HPP_NOEXCEPT
    {
      pWaitSemaphores = pWaitSemaphores_;
      return *this;
    }

    SubmitInfo & setPWaitDstStageMask( const vk::PipelineStageFlags* pWaitDstStageMask_ ) VULKAN_HPP_NOEXCEPT
    {
      pWaitDstStageMask = pWaitDstStageMask_;
      return *this;
    }

    SubmitInfo & setCommandBufferCount( uint32_t commandBufferCount_ ) VULKAN_HPP_NOEXCEPT
    {
      commandBufferCount = commandBufferCount_;
      return *this;
    }

    SubmitInfo & setPCommandBuffers( const vk::CommandBuffer* pCommandBuffers_ ) VULKAN_HPP_NOEXCEPT
    {
      pCommandBuffers = pCommandBuffers_;
      return *this;
    }

    SubmitInfo & setSignalSemaphoreCount( uint32_t signalSemaphoreCount_ ) VULKAN_HPP_NOEXCEPT
    {
      signalSemaphoreCount = signalSemaphoreCount_;
      return *this;
    }

    SubmitInfo & setPSignalSemaphores( const vk::Semaphore* pSignalSemaphores_ ) VULKAN_HPP_NOEXCEPT
    {
      pSignalSemaphores = pSignalSemaphores_;
      return *this;
    }

    operator VkSubmitInfo const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubmitInfo*>( this );
    }

    operator VkSubmitInfo &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubmitInfo*>( this );
    }

    bool operator==( SubmitInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( waitSemaphoreCount == rhs.waitSemaphoreCount )
          && ( pWaitSemaphores == rhs.pWaitSemaphores )
          && ( pWaitDstStageMask == rhs.pWaitDstStageMask )
          && ( commandBufferCount == rhs.commandBufferCount )
          && ( pCommandBuffers == rhs.pCommandBuffers )
          && ( signalSemaphoreCount == rhs.signalSemaphoreCount )
          && ( pSignalSemaphores == rhs.pSignalSemaphores );
    }

    bool operator!=( SubmitInfo const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SubmitInfo::sType;
  };
  static_assert( sizeof( SubmitInfo ) == sizeof( VkSubmitInfo ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubmitInfo>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SubpassBeginInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SubpassBeginInfoKHR( vk::SubpassContents contents_ = vk::SubpassContents::eInline ) VULKAN_HPP_NOEXCEPT
        : contents( contents_ )
      {}

      SubpassBeginInfoKHR( VkSubpassBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassBeginInfoKHR*>(this) = rhs;
      }

      SubpassBeginInfoKHR& operator=( VkSubpassBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassBeginInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSubpassBeginInfoKHR;
      const void* pNext = nullptr;
      vk::SubpassContents contents;
    };
    static_assert( sizeof( SubpassBeginInfoKHR ) == sizeof( VkSubpassBeginInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SubpassBeginInfoKHR : public layout::SubpassBeginInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SubpassBeginInfoKHR( vk::SubpassContents contents_ = vk::SubpassContents::eInline ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassBeginInfoKHR( contents_ )
    {}

    SubpassBeginInfoKHR( VkSubpassBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassBeginInfoKHR( rhs )
    {}

    SubpassBeginInfoKHR& operator=( VkSubpassBeginInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SubpassBeginInfoKHR::operator=(rhs);
      return *this;
    }

    SubpassBeginInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SubpassBeginInfoKHR & setContents( vk::SubpassContents contents_ ) VULKAN_HPP_NOEXCEPT
    {
      contents = contents_;
      return *this;
    }

    operator VkSubpassBeginInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassBeginInfoKHR*>( this );
    }

    operator VkSubpassBeginInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassBeginInfoKHR*>( this );
    }

    bool operator==( SubpassBeginInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( contents == rhs.contents );
    }

    bool operator!=( SubpassBeginInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SubpassBeginInfoKHR::sType;
  };
  static_assert( sizeof( SubpassBeginInfoKHR ) == sizeof( VkSubpassBeginInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassBeginInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SubpassDescriptionDepthStencilResolveKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SubpassDescriptionDepthStencilResolveKHR( vk::ResolveModeFlagBitsKHR depthResolveMode_ = vk::ResolveModeFlagBitsKHR::eNone,
                                                                     vk::ResolveModeFlagBitsKHR stencilResolveMode_ = vk::ResolveModeFlagBitsKHR::eNone,
                                                                     const vk::AttachmentReference2KHR* pDepthStencilResolveAttachment_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : depthResolveMode( depthResolveMode_ )
        , stencilResolveMode( stencilResolveMode_ )
        , pDepthStencilResolveAttachment( pDepthStencilResolveAttachment_ )
      {}

      SubpassDescriptionDepthStencilResolveKHR( VkSubpassDescriptionDepthStencilResolveKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassDescriptionDepthStencilResolveKHR*>(this) = rhs;
      }

      SubpassDescriptionDepthStencilResolveKHR& operator=( VkSubpassDescriptionDepthStencilResolveKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassDescriptionDepthStencilResolveKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSubpassDescriptionDepthStencilResolveKHR;
      const void* pNext = nullptr;
      vk::ResolveModeFlagBitsKHR depthResolveMode;
      vk::ResolveModeFlagBitsKHR stencilResolveMode;
      const vk::AttachmentReference2KHR* pDepthStencilResolveAttachment;
    };
    static_assert( sizeof( SubpassDescriptionDepthStencilResolveKHR ) == sizeof( VkSubpassDescriptionDepthStencilResolveKHR ), "layout struct and wrapper have different size!" );
  }

  struct SubpassDescriptionDepthStencilResolveKHR : public layout::SubpassDescriptionDepthStencilResolveKHR
  {
    VULKAN_HPP_CONSTEXPR SubpassDescriptionDepthStencilResolveKHR( vk::ResolveModeFlagBitsKHR depthResolveMode_ = vk::ResolveModeFlagBitsKHR::eNone,
                                                                   vk::ResolveModeFlagBitsKHR stencilResolveMode_ = vk::ResolveModeFlagBitsKHR::eNone,
                                                                   const vk::AttachmentReference2KHR* pDepthStencilResolveAttachment_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassDescriptionDepthStencilResolveKHR( depthResolveMode_, stencilResolveMode_, pDepthStencilResolveAttachment_ )
    {}

    SubpassDescriptionDepthStencilResolveKHR( VkSubpassDescriptionDepthStencilResolveKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassDescriptionDepthStencilResolveKHR( rhs )
    {}

    SubpassDescriptionDepthStencilResolveKHR& operator=( VkSubpassDescriptionDepthStencilResolveKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SubpassDescriptionDepthStencilResolveKHR::operator=(rhs);
      return *this;
    }

    SubpassDescriptionDepthStencilResolveKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SubpassDescriptionDepthStencilResolveKHR & setDepthResolveMode( vk::ResolveModeFlagBitsKHR depthResolveMode_ ) VULKAN_HPP_NOEXCEPT
    {
      depthResolveMode = depthResolveMode_;
      return *this;
    }

    SubpassDescriptionDepthStencilResolveKHR & setStencilResolveMode( vk::ResolveModeFlagBitsKHR stencilResolveMode_ ) VULKAN_HPP_NOEXCEPT
    {
      stencilResolveMode = stencilResolveMode_;
      return *this;
    }

    SubpassDescriptionDepthStencilResolveKHR & setPDepthStencilResolveAttachment( const vk::AttachmentReference2KHR* pDepthStencilResolveAttachment_ ) VULKAN_HPP_NOEXCEPT
    {
      pDepthStencilResolveAttachment = pDepthStencilResolveAttachment_;
      return *this;
    }

    operator VkSubpassDescriptionDepthStencilResolveKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassDescriptionDepthStencilResolveKHR*>( this );
    }

    operator VkSubpassDescriptionDepthStencilResolveKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassDescriptionDepthStencilResolveKHR*>( this );
    }

    bool operator==( SubpassDescriptionDepthStencilResolveKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && vk::operator==( depthResolveMode, rhs.depthResolveMode )
          && vk::operator==( stencilResolveMode, rhs.stencilResolveMode )
          && ( pDepthStencilResolveAttachment == rhs.pDepthStencilResolveAttachment );
    }

    bool operator!=( SubpassDescriptionDepthStencilResolveKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SubpassDescriptionDepthStencilResolveKHR::sType;
  };
  static_assert( sizeof( SubpassDescriptionDepthStencilResolveKHR ) == sizeof( VkSubpassDescriptionDepthStencilResolveKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassDescriptionDepthStencilResolveKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SubpassEndInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SubpassEndInfoKHR() VULKAN_HPP_NOEXCEPT
      {}

      SubpassEndInfoKHR( VkSubpassEndInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassEndInfoKHR*>(this) = rhs;
      }

      SubpassEndInfoKHR& operator=( VkSubpassEndInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSubpassEndInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSubpassEndInfoKHR;
      const void* pNext = nullptr;
    };
    static_assert( sizeof( SubpassEndInfoKHR ) == sizeof( VkSubpassEndInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SubpassEndInfoKHR : public layout::SubpassEndInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SubpassEndInfoKHR() VULKAN_HPP_NOEXCEPT
      : layout::SubpassEndInfoKHR()
    {}

    SubpassEndInfoKHR( VkSubpassEndInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SubpassEndInfoKHR( rhs )
    {}

    SubpassEndInfoKHR& operator=( VkSubpassEndInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SubpassEndInfoKHR::operator=(rhs);
      return *this;
    }

    SubpassEndInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    operator VkSubpassEndInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSubpassEndInfoKHR*>( this );
    }

    operator VkSubpassEndInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSubpassEndInfoKHR*>( this );
    }

    bool operator==( SubpassEndInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext );
    }

    bool operator!=( SubpassEndInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SubpassEndInfoKHR::sType;
  };
  static_assert( sizeof( SubpassEndInfoKHR ) == sizeof( VkSubpassEndInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SubpassEndInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SurfaceCapabilities2EXT
    {
    protected:
      SurfaceCapabilities2EXT() VULKAN_HPP_NOEXCEPT
      {}

      SurfaceCapabilities2EXT( VkSurfaceCapabilities2EXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceCapabilities2EXT*>(this) = rhs;
      }

      SurfaceCapabilities2EXT& operator=( VkSurfaceCapabilities2EXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceCapabilities2EXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSurfaceCapabilities2EXT;
      void* pNext = nullptr;
      uint32_t minImageCount;
      uint32_t maxImageCount;
      vk::Extent2D currentExtent;
      vk::Extent2D minImageExtent;
      vk::Extent2D maxImageExtent;
      uint32_t maxImageArrayLayers;
      vk::SurfaceTransformFlagsKHR supportedTransforms;
      vk::SurfaceTransformFlagBitsKHR currentTransform;
      vk::CompositeAlphaFlagsKHR supportedCompositeAlpha;
      vk::ImageUsageFlags supportedUsageFlags;
      vk::SurfaceCounterFlagsEXT supportedSurfaceCounters;
    };
    static_assert( sizeof( SurfaceCapabilities2EXT ) == sizeof( VkSurfaceCapabilities2EXT ), "layout struct and wrapper have different size!" );
  }

  struct SurfaceCapabilities2EXT : public layout::SurfaceCapabilities2EXT
  {
    SurfaceCapabilities2EXT() VULKAN_HPP_NOEXCEPT
      : layout::SurfaceCapabilities2EXT()
    {}

    SurfaceCapabilities2EXT( VkSurfaceCapabilities2EXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceCapabilities2EXT( rhs )
    {}

    SurfaceCapabilities2EXT& operator=( VkSurfaceCapabilities2EXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SurfaceCapabilities2EXT::operator=(rhs);
      return *this;
    }

    operator VkSurfaceCapabilities2EXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceCapabilities2EXT*>( this );
    }

    operator VkSurfaceCapabilities2EXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceCapabilities2EXT*>( this );
    }

    bool operator==( SurfaceCapabilities2EXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( minImageCount == rhs.minImageCount )
          && ( maxImageCount == rhs.maxImageCount )
          && ( currentExtent == rhs.currentExtent )
          && ( minImageExtent == rhs.minImageExtent )
          && ( maxImageExtent == rhs.maxImageExtent )
          && ( maxImageArrayLayers == rhs.maxImageArrayLayers )
          && ( supportedTransforms == rhs.supportedTransforms )
          && vk::operator==( currentTransform, rhs.currentTransform )
          && ( supportedCompositeAlpha == rhs.supportedCompositeAlpha )
          && ( supportedUsageFlags == rhs.supportedUsageFlags )
          && ( supportedSurfaceCounters == rhs.supportedSurfaceCounters );
    }

    bool operator!=( SurfaceCapabilities2EXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SurfaceCapabilities2EXT::sType;
  };
  static_assert( sizeof( SurfaceCapabilities2EXT ) == sizeof( VkSurfaceCapabilities2EXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceCapabilities2EXT>::value, "struct wrapper is not a standard layout!" );

  struct SurfaceCapabilitiesKHR
  {
    SurfaceCapabilitiesKHR() VULKAN_HPP_NOEXCEPT
    {}

    SurfaceCapabilitiesKHR( VkSurfaceCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSurfaceCapabilitiesKHR*>(this) = rhs;
    }

    SurfaceCapabilitiesKHR& operator=( VkSurfaceCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSurfaceCapabilitiesKHR*>(this) = rhs;
      return *this;
    }

    operator VkSurfaceCapabilitiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceCapabilitiesKHR*>( this );
    }

    operator VkSurfaceCapabilitiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceCapabilitiesKHR*>( this );
    }

    bool operator==( SurfaceCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( minImageCount == rhs.minImageCount )
          && ( maxImageCount == rhs.maxImageCount )
          && ( currentExtent == rhs.currentExtent )
          && ( minImageExtent == rhs.minImageExtent )
          && ( maxImageExtent == rhs.maxImageExtent )
          && ( maxImageArrayLayers == rhs.maxImageArrayLayers )
          && ( supportedTransforms == rhs.supportedTransforms )
          && vk::operator==( currentTransform, rhs.currentTransform )
          && ( supportedCompositeAlpha == rhs.supportedCompositeAlpha )
          && ( supportedUsageFlags == rhs.supportedUsageFlags );
    }

    bool operator!=( SurfaceCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    uint32_t minImageCount;
    uint32_t maxImageCount;
    vk::Extent2D currentExtent;
    vk::Extent2D minImageExtent;
    vk::Extent2D maxImageExtent;
    uint32_t maxImageArrayLayers;
    vk::SurfaceTransformFlagsKHR supportedTransforms;
    vk::SurfaceTransformFlagBitsKHR currentTransform;
    vk::CompositeAlphaFlagsKHR supportedCompositeAlpha;
    vk::ImageUsageFlags supportedUsageFlags;
  };
  static_assert( sizeof( SurfaceCapabilitiesKHR ) == sizeof( VkSurfaceCapabilitiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceCapabilitiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SurfaceCapabilities2KHR
    {
    protected:
      SurfaceCapabilities2KHR() VULKAN_HPP_NOEXCEPT
      {}

      SurfaceCapabilities2KHR( VkSurfaceCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceCapabilities2KHR*>(this) = rhs;
      }

      SurfaceCapabilities2KHR& operator=( VkSurfaceCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceCapabilities2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSurfaceCapabilities2KHR;
      void* pNext = nullptr;
      vk::SurfaceCapabilitiesKHR surfaceCapabilities;
    };
    static_assert( sizeof( SurfaceCapabilities2KHR ) == sizeof( VkSurfaceCapabilities2KHR ), "layout struct and wrapper have different size!" );
  }

  struct SurfaceCapabilities2KHR : public layout::SurfaceCapabilities2KHR
  {
    SurfaceCapabilities2KHR() VULKAN_HPP_NOEXCEPT
      : layout::SurfaceCapabilities2KHR()
    {}

    SurfaceCapabilities2KHR( VkSurfaceCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceCapabilities2KHR( rhs )
    {}

    SurfaceCapabilities2KHR& operator=( VkSurfaceCapabilities2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SurfaceCapabilities2KHR::operator=(rhs);
      return *this;
    }

    operator VkSurfaceCapabilities2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceCapabilities2KHR*>( this );
    }

    operator VkSurfaceCapabilities2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceCapabilities2KHR*>( this );
    }

    bool operator==( SurfaceCapabilities2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( surfaceCapabilities == rhs.surfaceCapabilities );
    }

    bool operator!=( SurfaceCapabilities2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SurfaceCapabilities2KHR::sType;
  };
  static_assert( sizeof( SurfaceCapabilities2KHR ) == sizeof( VkSurfaceCapabilities2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceCapabilities2KHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct SurfaceCapabilitiesFullScreenExclusiveEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR SurfaceCapabilitiesFullScreenExclusiveEXT( vk::Bool32 fullScreenExclusiveSupported_ = 0 ) VULKAN_HPP_NOEXCEPT
        : fullScreenExclusiveSupported( fullScreenExclusiveSupported_ )
      {}

      SurfaceCapabilitiesFullScreenExclusiveEXT( VkSurfaceCapabilitiesFullScreenExclusiveEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceCapabilitiesFullScreenExclusiveEXT*>(this) = rhs;
      }

      SurfaceCapabilitiesFullScreenExclusiveEXT& operator=( VkSurfaceCapabilitiesFullScreenExclusiveEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceCapabilitiesFullScreenExclusiveEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSurfaceCapabilitiesFullScreenExclusiveEXT;
      void* pNext = nullptr;
      vk::Bool32 fullScreenExclusiveSupported;
    };
    static_assert( sizeof( SurfaceCapabilitiesFullScreenExclusiveEXT ) == sizeof( VkSurfaceCapabilitiesFullScreenExclusiveEXT ), "layout struct and wrapper have different size!" );
  }

  struct SurfaceCapabilitiesFullScreenExclusiveEXT : public layout::SurfaceCapabilitiesFullScreenExclusiveEXT
  {
    VULKAN_HPP_CONSTEXPR SurfaceCapabilitiesFullScreenExclusiveEXT( vk::Bool32 fullScreenExclusiveSupported_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceCapabilitiesFullScreenExclusiveEXT( fullScreenExclusiveSupported_ )
    {}

    SurfaceCapabilitiesFullScreenExclusiveEXT( VkSurfaceCapabilitiesFullScreenExclusiveEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceCapabilitiesFullScreenExclusiveEXT( rhs )
    {}

    SurfaceCapabilitiesFullScreenExclusiveEXT& operator=( VkSurfaceCapabilitiesFullScreenExclusiveEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SurfaceCapabilitiesFullScreenExclusiveEXT::operator=(rhs);
      return *this;
    }

    SurfaceCapabilitiesFullScreenExclusiveEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SurfaceCapabilitiesFullScreenExclusiveEXT & setFullScreenExclusiveSupported( vk::Bool32 fullScreenExclusiveSupported_ ) VULKAN_HPP_NOEXCEPT
    {
      fullScreenExclusiveSupported = fullScreenExclusiveSupported_;
      return *this;
    }

    operator VkSurfaceCapabilitiesFullScreenExclusiveEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceCapabilitiesFullScreenExclusiveEXT*>( this );
    }

    operator VkSurfaceCapabilitiesFullScreenExclusiveEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceCapabilitiesFullScreenExclusiveEXT*>( this );
    }

    bool operator==( SurfaceCapabilitiesFullScreenExclusiveEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fullScreenExclusiveSupported == rhs.fullScreenExclusiveSupported );
    }

    bool operator!=( SurfaceCapabilitiesFullScreenExclusiveEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SurfaceCapabilitiesFullScreenExclusiveEXT::sType;
  };
  static_assert( sizeof( SurfaceCapabilitiesFullScreenExclusiveEXT ) == sizeof( VkSurfaceCapabilitiesFullScreenExclusiveEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceCapabilitiesFullScreenExclusiveEXT>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  struct SurfaceFormatKHR
  {
    SurfaceFormatKHR() VULKAN_HPP_NOEXCEPT
    {}

    SurfaceFormatKHR( VkSurfaceFormatKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSurfaceFormatKHR*>(this) = rhs;
    }

    SurfaceFormatKHR& operator=( VkSurfaceFormatKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      *reinterpret_cast<VkSurfaceFormatKHR*>(this) = rhs;
      return *this;
    }

    operator VkSurfaceFormatKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceFormatKHR*>( this );
    }

    operator VkSurfaceFormatKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceFormatKHR*>( this );
    }

    bool operator==( SurfaceFormatKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( format == rhs.format )
          && ( colorSpace == rhs.colorSpace );
    }

    bool operator!=( SurfaceFormatKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  public:
    vk::Format format;
    vk::ColorSpaceKHR colorSpace;
  };
  static_assert( sizeof( SurfaceFormatKHR ) == sizeof( VkSurfaceFormatKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceFormatKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SurfaceFormat2KHR
    {
    protected:
      SurfaceFormat2KHR() VULKAN_HPP_NOEXCEPT
      {}

      SurfaceFormat2KHR( VkSurfaceFormat2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceFormat2KHR*>(this) = rhs;
      }

      SurfaceFormat2KHR& operator=( VkSurfaceFormat2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceFormat2KHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSurfaceFormat2KHR;
      void* pNext = nullptr;
      vk::SurfaceFormatKHR surfaceFormat;
    };
    static_assert( sizeof( SurfaceFormat2KHR ) == sizeof( VkSurfaceFormat2KHR ), "layout struct and wrapper have different size!" );
  }

  struct SurfaceFormat2KHR : public layout::SurfaceFormat2KHR
  {
    SurfaceFormat2KHR() VULKAN_HPP_NOEXCEPT
      : layout::SurfaceFormat2KHR()
    {}

    SurfaceFormat2KHR( VkSurfaceFormat2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceFormat2KHR( rhs )
    {}

    SurfaceFormat2KHR& operator=( VkSurfaceFormat2KHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SurfaceFormat2KHR::operator=(rhs);
      return *this;
    }

    operator VkSurfaceFormat2KHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceFormat2KHR*>( this );
    }

    operator VkSurfaceFormat2KHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceFormat2KHR*>( this );
    }

    bool operator==( SurfaceFormat2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( surfaceFormat == rhs.surfaceFormat );
    }

    bool operator!=( SurfaceFormat2KHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SurfaceFormat2KHR::sType;
  };
  static_assert( sizeof( SurfaceFormat2KHR ) == sizeof( VkSurfaceFormat2KHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceFormat2KHR>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct SurfaceFullScreenExclusiveInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR SurfaceFullScreenExclusiveInfoEXT( vk::FullScreenExclusiveEXT fullScreenExclusive_ = vk::FullScreenExclusiveEXT::eDefault ) VULKAN_HPP_NOEXCEPT
        : fullScreenExclusive( fullScreenExclusive_ )
      {}

      SurfaceFullScreenExclusiveInfoEXT( VkSurfaceFullScreenExclusiveInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceFullScreenExclusiveInfoEXT*>(this) = rhs;
      }

      SurfaceFullScreenExclusiveInfoEXT& operator=( VkSurfaceFullScreenExclusiveInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceFullScreenExclusiveInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSurfaceFullScreenExclusiveInfoEXT;
      void* pNext = nullptr;
      vk::FullScreenExclusiveEXT fullScreenExclusive;
    };
    static_assert( sizeof( SurfaceFullScreenExclusiveInfoEXT ) == sizeof( VkSurfaceFullScreenExclusiveInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct SurfaceFullScreenExclusiveInfoEXT : public layout::SurfaceFullScreenExclusiveInfoEXT
  {
    VULKAN_HPP_CONSTEXPR SurfaceFullScreenExclusiveInfoEXT( vk::FullScreenExclusiveEXT fullScreenExclusive_ = vk::FullScreenExclusiveEXT::eDefault ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceFullScreenExclusiveInfoEXT( fullScreenExclusive_ )
    {}

    SurfaceFullScreenExclusiveInfoEXT( VkSurfaceFullScreenExclusiveInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceFullScreenExclusiveInfoEXT( rhs )
    {}

    SurfaceFullScreenExclusiveInfoEXT& operator=( VkSurfaceFullScreenExclusiveInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SurfaceFullScreenExclusiveInfoEXT::operator=(rhs);
      return *this;
    }

    SurfaceFullScreenExclusiveInfoEXT & setPNext( void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SurfaceFullScreenExclusiveInfoEXT & setFullScreenExclusive( vk::FullScreenExclusiveEXT fullScreenExclusive_ ) VULKAN_HPP_NOEXCEPT
    {
      fullScreenExclusive = fullScreenExclusive_;
      return *this;
    }

    operator VkSurfaceFullScreenExclusiveInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceFullScreenExclusiveInfoEXT*>( this );
    }

    operator VkSurfaceFullScreenExclusiveInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceFullScreenExclusiveInfoEXT*>( this );
    }

    bool operator==( SurfaceFullScreenExclusiveInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( fullScreenExclusive == rhs.fullScreenExclusive );
    }

    bool operator!=( SurfaceFullScreenExclusiveInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SurfaceFullScreenExclusiveInfoEXT::sType;
  };
  static_assert( sizeof( SurfaceFullScreenExclusiveInfoEXT ) == sizeof( VkSurfaceFullScreenExclusiveInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceFullScreenExclusiveInfoEXT>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct SurfaceFullScreenExclusiveWin32InfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR SurfaceFullScreenExclusiveWin32InfoEXT( HMONITOR hmonitor_ = 0 ) VULKAN_HPP_NOEXCEPT
        : hmonitor( hmonitor_ )
      {}

      SurfaceFullScreenExclusiveWin32InfoEXT( VkSurfaceFullScreenExclusiveWin32InfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceFullScreenExclusiveWin32InfoEXT*>(this) = rhs;
      }

      SurfaceFullScreenExclusiveWin32InfoEXT& operator=( VkSurfaceFullScreenExclusiveWin32InfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceFullScreenExclusiveWin32InfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSurfaceFullScreenExclusiveWin32InfoEXT;
      const void* pNext = nullptr;
      HMONITOR hmonitor;
    };
    static_assert( sizeof( SurfaceFullScreenExclusiveWin32InfoEXT ) == sizeof( VkSurfaceFullScreenExclusiveWin32InfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct SurfaceFullScreenExclusiveWin32InfoEXT : public layout::SurfaceFullScreenExclusiveWin32InfoEXT
  {
    VULKAN_HPP_CONSTEXPR SurfaceFullScreenExclusiveWin32InfoEXT( HMONITOR hmonitor_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceFullScreenExclusiveWin32InfoEXT( hmonitor_ )
    {}

    SurfaceFullScreenExclusiveWin32InfoEXT( VkSurfaceFullScreenExclusiveWin32InfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceFullScreenExclusiveWin32InfoEXT( rhs )
    {}

    SurfaceFullScreenExclusiveWin32InfoEXT& operator=( VkSurfaceFullScreenExclusiveWin32InfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SurfaceFullScreenExclusiveWin32InfoEXT::operator=(rhs);
      return *this;
    }

    SurfaceFullScreenExclusiveWin32InfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SurfaceFullScreenExclusiveWin32InfoEXT & setHmonitor( HMONITOR hmonitor_ ) VULKAN_HPP_NOEXCEPT
    {
      hmonitor = hmonitor_;
      return *this;
    }

    operator VkSurfaceFullScreenExclusiveWin32InfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceFullScreenExclusiveWin32InfoEXT*>( this );
    }

    operator VkSurfaceFullScreenExclusiveWin32InfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceFullScreenExclusiveWin32InfoEXT*>( this );
    }

    bool operator==( SurfaceFullScreenExclusiveWin32InfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( hmonitor == rhs.hmonitor );
    }

    bool operator!=( SurfaceFullScreenExclusiveWin32InfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SurfaceFullScreenExclusiveWin32InfoEXT::sType;
  };
  static_assert( sizeof( SurfaceFullScreenExclusiveWin32InfoEXT ) == sizeof( VkSurfaceFullScreenExclusiveWin32InfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceFullScreenExclusiveWin32InfoEXT>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct SurfaceProtectedCapabilitiesKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SurfaceProtectedCapabilitiesKHR( vk::Bool32 supportsProtected_ = 0 ) VULKAN_HPP_NOEXCEPT
        : supportsProtected( supportsProtected_ )
      {}

      SurfaceProtectedCapabilitiesKHR( VkSurfaceProtectedCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceProtectedCapabilitiesKHR*>(this) = rhs;
      }

      SurfaceProtectedCapabilitiesKHR& operator=( VkSurfaceProtectedCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSurfaceProtectedCapabilitiesKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSurfaceProtectedCapabilitiesKHR;
      const void* pNext = nullptr;
      vk::Bool32 supportsProtected;
    };
    static_assert( sizeof( SurfaceProtectedCapabilitiesKHR ) == sizeof( VkSurfaceProtectedCapabilitiesKHR ), "layout struct and wrapper have different size!" );
  }

  struct SurfaceProtectedCapabilitiesKHR : public layout::SurfaceProtectedCapabilitiesKHR
  {
    VULKAN_HPP_CONSTEXPR SurfaceProtectedCapabilitiesKHR( vk::Bool32 supportsProtected_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceProtectedCapabilitiesKHR( supportsProtected_ )
    {}

    SurfaceProtectedCapabilitiesKHR( VkSurfaceProtectedCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SurfaceProtectedCapabilitiesKHR( rhs )
    {}

    SurfaceProtectedCapabilitiesKHR& operator=( VkSurfaceProtectedCapabilitiesKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SurfaceProtectedCapabilitiesKHR::operator=(rhs);
      return *this;
    }

    SurfaceProtectedCapabilitiesKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SurfaceProtectedCapabilitiesKHR & setSupportsProtected( vk::Bool32 supportsProtected_ ) VULKAN_HPP_NOEXCEPT
    {
      supportsProtected = supportsProtected_;
      return *this;
    }

    operator VkSurfaceProtectedCapabilitiesKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSurfaceProtectedCapabilitiesKHR*>( this );
    }

    operator VkSurfaceProtectedCapabilitiesKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSurfaceProtectedCapabilitiesKHR*>( this );
    }

    bool operator==( SurfaceProtectedCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( supportsProtected == rhs.supportsProtected );
    }

    bool operator!=( SurfaceProtectedCapabilitiesKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SurfaceProtectedCapabilitiesKHR::sType;
  };
  static_assert( sizeof( SurfaceProtectedCapabilitiesKHR ) == sizeof( VkSurfaceProtectedCapabilitiesKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SurfaceProtectedCapabilitiesKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SwapchainCounterCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR SwapchainCounterCreateInfoEXT( vk::SurfaceCounterFlagsEXT surfaceCounters_ = vk::SurfaceCounterFlagsEXT() ) VULKAN_HPP_NOEXCEPT
        : surfaceCounters( surfaceCounters_ )
      {}

      SwapchainCounterCreateInfoEXT( VkSwapchainCounterCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSwapchainCounterCreateInfoEXT*>(this) = rhs;
      }

      SwapchainCounterCreateInfoEXT& operator=( VkSwapchainCounterCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSwapchainCounterCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSwapchainCounterCreateInfoEXT;
      const void* pNext = nullptr;
      vk::SurfaceCounterFlagsEXT surfaceCounters;
    };
    static_assert( sizeof( SwapchainCounterCreateInfoEXT ) == sizeof( VkSwapchainCounterCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct SwapchainCounterCreateInfoEXT : public layout::SwapchainCounterCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR SwapchainCounterCreateInfoEXT( vk::SurfaceCounterFlagsEXT surfaceCounters_ = vk::SurfaceCounterFlagsEXT() ) VULKAN_HPP_NOEXCEPT
      : layout::SwapchainCounterCreateInfoEXT( surfaceCounters_ )
    {}

    SwapchainCounterCreateInfoEXT( VkSwapchainCounterCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SwapchainCounterCreateInfoEXT( rhs )
    {}

    SwapchainCounterCreateInfoEXT& operator=( VkSwapchainCounterCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SwapchainCounterCreateInfoEXT::operator=(rhs);
      return *this;
    }

    SwapchainCounterCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SwapchainCounterCreateInfoEXT & setSurfaceCounters( vk::SurfaceCounterFlagsEXT surfaceCounters_ ) VULKAN_HPP_NOEXCEPT
    {
      surfaceCounters = surfaceCounters_;
      return *this;
    }

    operator VkSwapchainCounterCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSwapchainCounterCreateInfoEXT*>( this );
    }

    operator VkSwapchainCounterCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSwapchainCounterCreateInfoEXT*>( this );
    }

    bool operator==( SwapchainCounterCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( surfaceCounters == rhs.surfaceCounters );
    }

    bool operator!=( SwapchainCounterCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SwapchainCounterCreateInfoEXT::sType;
  };
  static_assert( sizeof( SwapchainCounterCreateInfoEXT ) == sizeof( VkSwapchainCounterCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SwapchainCounterCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SwapchainCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR SwapchainCreateInfoKHR( vk::SwapchainCreateFlagsKHR flags_ = vk::SwapchainCreateFlagsKHR(),
                                                   vk::SurfaceKHR surface_ = vk::SurfaceKHR(),
                                                   uint32_t minImageCount_ = 0,
                                                   vk::Format imageFormat_ = vk::Format::eUndefined,
                                                   vk::ColorSpaceKHR imageColorSpace_ = vk::ColorSpaceKHR::eSrgbNonlinear,
                                                   vk::Extent2D imageExtent_ = vk::Extent2D(),
                                                   uint32_t imageArrayLayers_ = 0,
                                                   vk::ImageUsageFlags imageUsage_ = vk::ImageUsageFlags(),
                                                   vk::SharingMode imageSharingMode_ = vk::SharingMode::eExclusive,
                                                   uint32_t queueFamilyIndexCount_ = 0,
                                                   const uint32_t* pQueueFamilyIndices_ = nullptr,
                                                   vk::SurfaceTransformFlagBitsKHR preTransform_ = vk::SurfaceTransformFlagBitsKHR::eIdentity,
                                                   vk::CompositeAlphaFlagBitsKHR compositeAlpha_ = vk::CompositeAlphaFlagBitsKHR::eOpaque,
                                                   vk::PresentModeKHR presentMode_ = vk::PresentModeKHR::eImmediate,
                                                   vk::Bool32 clipped_ = 0,
                                                   vk::SwapchainKHR oldSwapchain_ = vk::SwapchainKHR() ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , surface( surface_ )
        , minImageCount( minImageCount_ )
        , imageFormat( imageFormat_ )
        , imageColorSpace( imageColorSpace_ )
        , imageExtent( imageExtent_ )
        , imageArrayLayers( imageArrayLayers_ )
        , imageUsage( imageUsage_ )
        , imageSharingMode( imageSharingMode_ )
        , queueFamilyIndexCount( queueFamilyIndexCount_ )
        , pQueueFamilyIndices( pQueueFamilyIndices_ )
        , preTransform( preTransform_ )
        , compositeAlpha( compositeAlpha_ )
        , presentMode( presentMode_ )
        , clipped( clipped_ )
        , oldSwapchain( oldSwapchain_ )
      {}

      SwapchainCreateInfoKHR( VkSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSwapchainCreateInfoKHR*>(this) = rhs;
      }

      SwapchainCreateInfoKHR& operator=( VkSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSwapchainCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSwapchainCreateInfoKHR;
      const void* pNext = nullptr;
      vk::SwapchainCreateFlagsKHR flags;
      vk::SurfaceKHR surface;
      uint32_t minImageCount;
      vk::Format imageFormat;
      vk::ColorSpaceKHR imageColorSpace;
      vk::Extent2D imageExtent;
      uint32_t imageArrayLayers;
      vk::ImageUsageFlags imageUsage;
      vk::SharingMode imageSharingMode;
      uint32_t queueFamilyIndexCount;
      const uint32_t* pQueueFamilyIndices;
      vk::SurfaceTransformFlagBitsKHR preTransform;
      vk::CompositeAlphaFlagBitsKHR compositeAlpha;
      vk::PresentModeKHR presentMode;
      vk::Bool32 clipped;
      vk::SwapchainKHR oldSwapchain;
    };
    static_assert( sizeof( SwapchainCreateInfoKHR ) == sizeof( VkSwapchainCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct SwapchainCreateInfoKHR : public layout::SwapchainCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR SwapchainCreateInfoKHR( vk::SwapchainCreateFlagsKHR flags_ = vk::SwapchainCreateFlagsKHR(),
                                                 vk::SurfaceKHR surface_ = vk::SurfaceKHR(),
                                                 uint32_t minImageCount_ = 0,
                                                 vk::Format imageFormat_ = vk::Format::eUndefined,
                                                 vk::ColorSpaceKHR imageColorSpace_ = vk::ColorSpaceKHR::eSrgbNonlinear,
                                                 vk::Extent2D imageExtent_ = vk::Extent2D(),
                                                 uint32_t imageArrayLayers_ = 0,
                                                 vk::ImageUsageFlags imageUsage_ = vk::ImageUsageFlags(),
                                                 vk::SharingMode imageSharingMode_ = vk::SharingMode::eExclusive,
                                                 uint32_t queueFamilyIndexCount_ = 0,
                                                 const uint32_t* pQueueFamilyIndices_ = nullptr,
                                                 vk::SurfaceTransformFlagBitsKHR preTransform_ = vk::SurfaceTransformFlagBitsKHR::eIdentity,
                                                 vk::CompositeAlphaFlagBitsKHR compositeAlpha_ = vk::CompositeAlphaFlagBitsKHR::eOpaque,
                                                 vk::PresentModeKHR presentMode_ = vk::PresentModeKHR::eImmediate,
                                                 vk::Bool32 clipped_ = 0,
                                                 vk::SwapchainKHR oldSwapchain_ = vk::SwapchainKHR() ) VULKAN_HPP_NOEXCEPT
      : layout::SwapchainCreateInfoKHR( flags_, surface_, minImageCount_, imageFormat_, imageColorSpace_, imageExtent_, imageArrayLayers_, imageUsage_, imageSharingMode_, queueFamilyIndexCount_, pQueueFamilyIndices_, preTransform_, compositeAlpha_, presentMode_, clipped_, oldSwapchain_ )
    {}

    SwapchainCreateInfoKHR( VkSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SwapchainCreateInfoKHR( rhs )
    {}

    SwapchainCreateInfoKHR& operator=( VkSwapchainCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SwapchainCreateInfoKHR::operator=(rhs);
      return *this;
    }

    SwapchainCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SwapchainCreateInfoKHR & setFlags( vk::SwapchainCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    SwapchainCreateInfoKHR & setSurface( vk::SurfaceKHR surface_ ) VULKAN_HPP_NOEXCEPT
    {
      surface = surface_;
      return *this;
    }

    SwapchainCreateInfoKHR & setMinImageCount( uint32_t minImageCount_ ) VULKAN_HPP_NOEXCEPT
    {
      minImageCount = minImageCount_;
      return *this;
    }

    SwapchainCreateInfoKHR & setImageFormat( vk::Format imageFormat_ ) VULKAN_HPP_NOEXCEPT
    {
      imageFormat = imageFormat_;
      return *this;
    }

    SwapchainCreateInfoKHR & setImageColorSpace( vk::ColorSpaceKHR imageColorSpace_ ) VULKAN_HPP_NOEXCEPT
    {
      imageColorSpace = imageColorSpace_;
      return *this;
    }

    SwapchainCreateInfoKHR & setImageExtent( vk::Extent2D imageExtent_ ) VULKAN_HPP_NOEXCEPT
    {
      imageExtent = imageExtent_;
      return *this;
    }

    SwapchainCreateInfoKHR & setImageArrayLayers( uint32_t imageArrayLayers_ ) VULKAN_HPP_NOEXCEPT
    {
      imageArrayLayers = imageArrayLayers_;
      return *this;
    }

    SwapchainCreateInfoKHR & setImageUsage( vk::ImageUsageFlags imageUsage_ ) VULKAN_HPP_NOEXCEPT
    {
      imageUsage = imageUsage_;
      return *this;
    }

    SwapchainCreateInfoKHR & setImageSharingMode( vk::SharingMode imageSharingMode_ ) VULKAN_HPP_NOEXCEPT
    {
      imageSharingMode = imageSharingMode_;
      return *this;
    }

    SwapchainCreateInfoKHR & setQueueFamilyIndexCount( uint32_t queueFamilyIndexCount_ ) VULKAN_HPP_NOEXCEPT
    {
      queueFamilyIndexCount = queueFamilyIndexCount_;
      return *this;
    }

    SwapchainCreateInfoKHR & setPQueueFamilyIndices( const uint32_t* pQueueFamilyIndices_ ) VULKAN_HPP_NOEXCEPT
    {
      pQueueFamilyIndices = pQueueFamilyIndices_;
      return *this;
    }

    SwapchainCreateInfoKHR & setPreTransform( vk::SurfaceTransformFlagBitsKHR preTransform_ ) VULKAN_HPP_NOEXCEPT
    {
      preTransform = preTransform_;
      return *this;
    }

    SwapchainCreateInfoKHR & setCompositeAlpha( vk::CompositeAlphaFlagBitsKHR compositeAlpha_ ) VULKAN_HPP_NOEXCEPT
    {
      compositeAlpha = compositeAlpha_;
      return *this;
    }

    SwapchainCreateInfoKHR & setPresentMode( vk::PresentModeKHR presentMode_ ) VULKAN_HPP_NOEXCEPT
    {
      presentMode = presentMode_;
      return *this;
    }

    SwapchainCreateInfoKHR & setClipped( vk::Bool32 clipped_ ) VULKAN_HPP_NOEXCEPT
    {
      clipped = clipped_;
      return *this;
    }

    SwapchainCreateInfoKHR & setOldSwapchain( vk::SwapchainKHR oldSwapchain_ ) VULKAN_HPP_NOEXCEPT
    {
      oldSwapchain = oldSwapchain_;
      return *this;
    }

    operator VkSwapchainCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSwapchainCreateInfoKHR*>( this );
    }

    operator VkSwapchainCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSwapchainCreateInfoKHR*>( this );
    }

    bool operator==( SwapchainCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( surface == rhs.surface )
          && ( minImageCount == rhs.minImageCount )
          && ( imageFormat == rhs.imageFormat )
          && ( imageColorSpace == rhs.imageColorSpace )
          && ( imageExtent == rhs.imageExtent )
          && ( imageArrayLayers == rhs.imageArrayLayers )
          && ( imageUsage == rhs.imageUsage )
          && ( imageSharingMode == rhs.imageSharingMode )
          && ( queueFamilyIndexCount == rhs.queueFamilyIndexCount )
          && ( pQueueFamilyIndices == rhs.pQueueFamilyIndices )
          && vk::operator==( preTransform, rhs.preTransform )
          && vk::operator==( compositeAlpha, rhs.compositeAlpha )
          && ( presentMode == rhs.presentMode )
          && ( clipped == rhs.clipped )
          && ( oldSwapchain == rhs.oldSwapchain );
    }

    bool operator!=( SwapchainCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SwapchainCreateInfoKHR::sType;
  };
  static_assert( sizeof( SwapchainCreateInfoKHR ) == sizeof( VkSwapchainCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SwapchainCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct SwapchainDisplayNativeHdrCreateInfoAMD
    {
    protected:
      VULKAN_HPP_CONSTEXPR SwapchainDisplayNativeHdrCreateInfoAMD( vk::Bool32 localDimmingEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
        : localDimmingEnable( localDimmingEnable_ )
      {}

      SwapchainDisplayNativeHdrCreateInfoAMD( VkSwapchainDisplayNativeHdrCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSwapchainDisplayNativeHdrCreateInfoAMD*>(this) = rhs;
      }

      SwapchainDisplayNativeHdrCreateInfoAMD& operator=( VkSwapchainDisplayNativeHdrCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkSwapchainDisplayNativeHdrCreateInfoAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eSwapchainDisplayNativeHdrCreateInfoAMD;
      const void* pNext = nullptr;
      vk::Bool32 localDimmingEnable;
    };
    static_assert( sizeof( SwapchainDisplayNativeHdrCreateInfoAMD ) == sizeof( VkSwapchainDisplayNativeHdrCreateInfoAMD ), "layout struct and wrapper have different size!" );
  }

  struct SwapchainDisplayNativeHdrCreateInfoAMD : public layout::SwapchainDisplayNativeHdrCreateInfoAMD
  {
    VULKAN_HPP_CONSTEXPR SwapchainDisplayNativeHdrCreateInfoAMD( vk::Bool32 localDimmingEnable_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::SwapchainDisplayNativeHdrCreateInfoAMD( localDimmingEnable_ )
    {}

    SwapchainDisplayNativeHdrCreateInfoAMD( VkSwapchainDisplayNativeHdrCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::SwapchainDisplayNativeHdrCreateInfoAMD( rhs )
    {}

    SwapchainDisplayNativeHdrCreateInfoAMD& operator=( VkSwapchainDisplayNativeHdrCreateInfoAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::SwapchainDisplayNativeHdrCreateInfoAMD::operator=(rhs);
      return *this;
    }

    SwapchainDisplayNativeHdrCreateInfoAMD & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    SwapchainDisplayNativeHdrCreateInfoAMD & setLocalDimmingEnable( vk::Bool32 localDimmingEnable_ ) VULKAN_HPP_NOEXCEPT
    {
      localDimmingEnable = localDimmingEnable_;
      return *this;
    }

    operator VkSwapchainDisplayNativeHdrCreateInfoAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkSwapchainDisplayNativeHdrCreateInfoAMD*>( this );
    }

    operator VkSwapchainDisplayNativeHdrCreateInfoAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkSwapchainDisplayNativeHdrCreateInfoAMD*>( this );
    }

    bool operator==( SwapchainDisplayNativeHdrCreateInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( localDimmingEnable == rhs.localDimmingEnable );
    }

    bool operator!=( SwapchainDisplayNativeHdrCreateInfoAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::SwapchainDisplayNativeHdrCreateInfoAMD::sType;
  };
  static_assert( sizeof( SwapchainDisplayNativeHdrCreateInfoAMD ) == sizeof( VkSwapchainDisplayNativeHdrCreateInfoAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<SwapchainDisplayNativeHdrCreateInfoAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct TextureLODGatherFormatPropertiesAMD
    {
    protected:
      TextureLODGatherFormatPropertiesAMD() VULKAN_HPP_NOEXCEPT
      {}

      TextureLODGatherFormatPropertiesAMD( VkTextureLODGatherFormatPropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkTextureLODGatherFormatPropertiesAMD*>(this) = rhs;
      }

      TextureLODGatherFormatPropertiesAMD& operator=( VkTextureLODGatherFormatPropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkTextureLODGatherFormatPropertiesAMD*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eTextureLodGatherFormatPropertiesAMD;
      void* pNext = nullptr;
      vk::Bool32 supportsTextureGatherLODBiasAMD;
    };
    static_assert( sizeof( TextureLODGatherFormatPropertiesAMD ) == sizeof( VkTextureLODGatherFormatPropertiesAMD ), "layout struct and wrapper have different size!" );
  }

  struct TextureLODGatherFormatPropertiesAMD : public layout::TextureLODGatherFormatPropertiesAMD
  {
    TextureLODGatherFormatPropertiesAMD() VULKAN_HPP_NOEXCEPT
      : layout::TextureLODGatherFormatPropertiesAMD()
    {}

    TextureLODGatherFormatPropertiesAMD( VkTextureLODGatherFormatPropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::TextureLODGatherFormatPropertiesAMD( rhs )
    {}

    TextureLODGatherFormatPropertiesAMD& operator=( VkTextureLODGatherFormatPropertiesAMD const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::TextureLODGatherFormatPropertiesAMD::operator=(rhs);
      return *this;
    }

    operator VkTextureLODGatherFormatPropertiesAMD const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkTextureLODGatherFormatPropertiesAMD*>( this );
    }

    operator VkTextureLODGatherFormatPropertiesAMD &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkTextureLODGatherFormatPropertiesAMD*>( this );
    }

    bool operator==( TextureLODGatherFormatPropertiesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( supportsTextureGatherLODBiasAMD == rhs.supportsTextureGatherLODBiasAMD );
    }

    bool operator!=( TextureLODGatherFormatPropertiesAMD const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::TextureLODGatherFormatPropertiesAMD::sType;
  };
  static_assert( sizeof( TextureLODGatherFormatPropertiesAMD ) == sizeof( VkTextureLODGatherFormatPropertiesAMD ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<TextureLODGatherFormatPropertiesAMD>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct TimelineSemaphoreSubmitInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR TimelineSemaphoreSubmitInfoKHR( uint32_t waitSemaphoreValueCount_ = 0,
                                                           const uint64_t* pWaitSemaphoreValues_ = nullptr,
                                                           uint32_t signalSemaphoreValueCount_ = 0,
                                                           const uint64_t* pSignalSemaphoreValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : waitSemaphoreValueCount( waitSemaphoreValueCount_ )
        , pWaitSemaphoreValues( pWaitSemaphoreValues_ )
        , signalSemaphoreValueCount( signalSemaphoreValueCount_ )
        , pSignalSemaphoreValues( pSignalSemaphoreValues_ )
      {}

      TimelineSemaphoreSubmitInfoKHR( VkTimelineSemaphoreSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkTimelineSemaphoreSubmitInfoKHR*>(this) = rhs;
      }

      TimelineSemaphoreSubmitInfoKHR& operator=( VkTimelineSemaphoreSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkTimelineSemaphoreSubmitInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eTimelineSemaphoreSubmitInfoKHR;
      const void* pNext = nullptr;
      uint32_t waitSemaphoreValueCount;
      const uint64_t* pWaitSemaphoreValues;
      uint32_t signalSemaphoreValueCount;
      const uint64_t* pSignalSemaphoreValues;
    };
    static_assert( sizeof( TimelineSemaphoreSubmitInfoKHR ) == sizeof( VkTimelineSemaphoreSubmitInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct TimelineSemaphoreSubmitInfoKHR : public layout::TimelineSemaphoreSubmitInfoKHR
  {
    VULKAN_HPP_CONSTEXPR TimelineSemaphoreSubmitInfoKHR( uint32_t waitSemaphoreValueCount_ = 0,
                                                         const uint64_t* pWaitSemaphoreValues_ = nullptr,
                                                         uint32_t signalSemaphoreValueCount_ = 0,
                                                         const uint64_t* pSignalSemaphoreValues_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::TimelineSemaphoreSubmitInfoKHR( waitSemaphoreValueCount_, pWaitSemaphoreValues_, signalSemaphoreValueCount_, pSignalSemaphoreValues_ )
    {}

    TimelineSemaphoreSubmitInfoKHR( VkTimelineSemaphoreSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::TimelineSemaphoreSubmitInfoKHR( rhs )
    {}

    TimelineSemaphoreSubmitInfoKHR& operator=( VkTimelineSemaphoreSubmitInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::TimelineSemaphoreSubmitInfoKHR::operator=(rhs);
      return *this;
    }

    TimelineSemaphoreSubmitInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    TimelineSemaphoreSubmitInfoKHR & setWaitSemaphoreValueCount( uint32_t waitSemaphoreValueCount_ ) VULKAN_HPP_NOEXCEPT
    {
      waitSemaphoreValueCount = waitSemaphoreValueCount_;
      return *this;
    }

    TimelineSemaphoreSubmitInfoKHR & setPWaitSemaphoreValues( const uint64_t* pWaitSemaphoreValues_ ) VULKAN_HPP_NOEXCEPT
    {
      pWaitSemaphoreValues = pWaitSemaphoreValues_;
      return *this;
    }

    TimelineSemaphoreSubmitInfoKHR & setSignalSemaphoreValueCount( uint32_t signalSemaphoreValueCount_ ) VULKAN_HPP_NOEXCEPT
    {
      signalSemaphoreValueCount = signalSemaphoreValueCount_;
      return *this;
    }

    TimelineSemaphoreSubmitInfoKHR & setPSignalSemaphoreValues( const uint64_t* pSignalSemaphoreValues_ ) VULKAN_HPP_NOEXCEPT
    {
      pSignalSemaphoreValues = pSignalSemaphoreValues_;
      return *this;
    }

    operator VkTimelineSemaphoreSubmitInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkTimelineSemaphoreSubmitInfoKHR*>( this );
    }

    operator VkTimelineSemaphoreSubmitInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkTimelineSemaphoreSubmitInfoKHR*>( this );
    }

    bool operator==( TimelineSemaphoreSubmitInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( waitSemaphoreValueCount == rhs.waitSemaphoreValueCount )
          && ( pWaitSemaphoreValues == rhs.pWaitSemaphoreValues )
          && ( signalSemaphoreValueCount == rhs.signalSemaphoreValueCount )
          && ( pSignalSemaphoreValues == rhs.pSignalSemaphoreValues );
    }

    bool operator!=( TimelineSemaphoreSubmitInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::TimelineSemaphoreSubmitInfoKHR::sType;
  };
  static_assert( sizeof( TimelineSemaphoreSubmitInfoKHR ) == sizeof( VkTimelineSemaphoreSubmitInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<TimelineSemaphoreSubmitInfoKHR>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ValidationCacheCreateInfoEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ValidationCacheCreateInfoEXT( vk::ValidationCacheCreateFlagsEXT flags_ = vk::ValidationCacheCreateFlagsEXT(),
                                                         size_t initialDataSize_ = 0,
                                                         const void* pInitialData_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , initialDataSize( initialDataSize_ )
        , pInitialData( pInitialData_ )
      {}

      ValidationCacheCreateInfoEXT( VkValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkValidationCacheCreateInfoEXT*>(this) = rhs;
      }

      ValidationCacheCreateInfoEXT& operator=( VkValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkValidationCacheCreateInfoEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eValidationCacheCreateInfoEXT;
      const void* pNext = nullptr;
      vk::ValidationCacheCreateFlagsEXT flags;
      size_t initialDataSize;
      const void* pInitialData;
    };
    static_assert( sizeof( ValidationCacheCreateInfoEXT ) == sizeof( VkValidationCacheCreateInfoEXT ), "layout struct and wrapper have different size!" );
  }

  struct ValidationCacheCreateInfoEXT : public layout::ValidationCacheCreateInfoEXT
  {
    VULKAN_HPP_CONSTEXPR ValidationCacheCreateInfoEXT( vk::ValidationCacheCreateFlagsEXT flags_ = vk::ValidationCacheCreateFlagsEXT(),
                                                       size_t initialDataSize_ = 0,
                                                       const void* pInitialData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ValidationCacheCreateInfoEXT( flags_, initialDataSize_, pInitialData_ )
    {}

    ValidationCacheCreateInfoEXT( VkValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ValidationCacheCreateInfoEXT( rhs )
    {}

    ValidationCacheCreateInfoEXT& operator=( VkValidationCacheCreateInfoEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ValidationCacheCreateInfoEXT::operator=(rhs);
      return *this;
    }

    ValidationCacheCreateInfoEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ValidationCacheCreateInfoEXT & setFlags( vk::ValidationCacheCreateFlagsEXT flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ValidationCacheCreateInfoEXT & setInitialDataSize( size_t initialDataSize_ ) VULKAN_HPP_NOEXCEPT
    {
      initialDataSize = initialDataSize_;
      return *this;
    }

    ValidationCacheCreateInfoEXT & setPInitialData( const void* pInitialData_ ) VULKAN_HPP_NOEXCEPT
    {
      pInitialData = pInitialData_;
      return *this;
    }

    operator VkValidationCacheCreateInfoEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkValidationCacheCreateInfoEXT*>( this );
    }

    operator VkValidationCacheCreateInfoEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkValidationCacheCreateInfoEXT*>( this );
    }

    bool operator==( ValidationCacheCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( initialDataSize == rhs.initialDataSize )
          && ( pInitialData == rhs.pInitialData );
    }

    bool operator!=( ValidationCacheCreateInfoEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ValidationCacheCreateInfoEXT::sType;
  };
  static_assert( sizeof( ValidationCacheCreateInfoEXT ) == sizeof( VkValidationCacheCreateInfoEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ValidationCacheCreateInfoEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ValidationFeaturesEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ValidationFeaturesEXT( uint32_t enabledValidationFeatureCount_ = 0,
                                                  const vk::ValidationFeatureEnableEXT* pEnabledValidationFeatures_ = nullptr,
                                                  uint32_t disabledValidationFeatureCount_ = 0,
                                                  const vk::ValidationFeatureDisableEXT* pDisabledValidationFeatures_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : enabledValidationFeatureCount( enabledValidationFeatureCount_ )
        , pEnabledValidationFeatures( pEnabledValidationFeatures_ )
        , disabledValidationFeatureCount( disabledValidationFeatureCount_ )
        , pDisabledValidationFeatures( pDisabledValidationFeatures_ )
      {}

      ValidationFeaturesEXT( VkValidationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkValidationFeaturesEXT*>(this) = rhs;
      }

      ValidationFeaturesEXT& operator=( VkValidationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkValidationFeaturesEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eValidationFeaturesEXT;
      const void* pNext = nullptr;
      uint32_t enabledValidationFeatureCount;
      const vk::ValidationFeatureEnableEXT* pEnabledValidationFeatures;
      uint32_t disabledValidationFeatureCount;
      const vk::ValidationFeatureDisableEXT* pDisabledValidationFeatures;
    };
    static_assert( sizeof( ValidationFeaturesEXT ) == sizeof( VkValidationFeaturesEXT ), "layout struct and wrapper have different size!" );
  }

  struct ValidationFeaturesEXT : public layout::ValidationFeaturesEXT
  {
    VULKAN_HPP_CONSTEXPR ValidationFeaturesEXT( uint32_t enabledValidationFeatureCount_ = 0,
                                                const vk::ValidationFeatureEnableEXT* pEnabledValidationFeatures_ = nullptr,
                                                uint32_t disabledValidationFeatureCount_ = 0,
                                                const vk::ValidationFeatureDisableEXT* pDisabledValidationFeatures_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ValidationFeaturesEXT( enabledValidationFeatureCount_, pEnabledValidationFeatures_, disabledValidationFeatureCount_, pDisabledValidationFeatures_ )
    {}

    ValidationFeaturesEXT( VkValidationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ValidationFeaturesEXT( rhs )
    {}

    ValidationFeaturesEXT& operator=( VkValidationFeaturesEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ValidationFeaturesEXT::operator=(rhs);
      return *this;
    }

    ValidationFeaturesEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ValidationFeaturesEXT & setEnabledValidationFeatureCount( uint32_t enabledValidationFeatureCount_ ) VULKAN_HPP_NOEXCEPT
    {
      enabledValidationFeatureCount = enabledValidationFeatureCount_;
      return *this;
    }

    ValidationFeaturesEXT & setPEnabledValidationFeatures( const vk::ValidationFeatureEnableEXT* pEnabledValidationFeatures_ ) VULKAN_HPP_NOEXCEPT
    {
      pEnabledValidationFeatures = pEnabledValidationFeatures_;
      return *this;
    }

    ValidationFeaturesEXT & setDisabledValidationFeatureCount( uint32_t disabledValidationFeatureCount_ ) VULKAN_HPP_NOEXCEPT
    {
      disabledValidationFeatureCount = disabledValidationFeatureCount_;
      return *this;
    }

    ValidationFeaturesEXT & setPDisabledValidationFeatures( const vk::ValidationFeatureDisableEXT* pDisabledValidationFeatures_ ) VULKAN_HPP_NOEXCEPT
    {
      pDisabledValidationFeatures = pDisabledValidationFeatures_;
      return *this;
    }

    operator VkValidationFeaturesEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkValidationFeaturesEXT*>( this );
    }

    operator VkValidationFeaturesEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkValidationFeaturesEXT*>( this );
    }

    bool operator==( ValidationFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( enabledValidationFeatureCount == rhs.enabledValidationFeatureCount )
          && ( pEnabledValidationFeatures == rhs.pEnabledValidationFeatures )
          && ( disabledValidationFeatureCount == rhs.disabledValidationFeatureCount )
          && ( pDisabledValidationFeatures == rhs.pDisabledValidationFeatures );
    }

    bool operator!=( ValidationFeaturesEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ValidationFeaturesEXT::sType;
  };
  static_assert( sizeof( ValidationFeaturesEXT ) == sizeof( VkValidationFeaturesEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ValidationFeaturesEXT>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct ValidationFlagsEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR ValidationFlagsEXT( uint32_t disabledValidationCheckCount_ = 0,
                                               const vk::ValidationCheckEXT* pDisabledValidationChecks_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : disabledValidationCheckCount( disabledValidationCheckCount_ )
        , pDisabledValidationChecks( pDisabledValidationChecks_ )
      {}

      ValidationFlagsEXT( VkValidationFlagsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkValidationFlagsEXT*>(this) = rhs;
      }

      ValidationFlagsEXT& operator=( VkValidationFlagsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkValidationFlagsEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eValidationFlagsEXT;
      const void* pNext = nullptr;
      uint32_t disabledValidationCheckCount;
      const vk::ValidationCheckEXT* pDisabledValidationChecks;
    };
    static_assert( sizeof( ValidationFlagsEXT ) == sizeof( VkValidationFlagsEXT ), "layout struct and wrapper have different size!" );
  }

  struct ValidationFlagsEXT : public layout::ValidationFlagsEXT
  {
    VULKAN_HPP_CONSTEXPR ValidationFlagsEXT( uint32_t disabledValidationCheckCount_ = 0,
                                             const vk::ValidationCheckEXT* pDisabledValidationChecks_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ValidationFlagsEXT( disabledValidationCheckCount_, pDisabledValidationChecks_ )
    {}

    ValidationFlagsEXT( VkValidationFlagsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ValidationFlagsEXT( rhs )
    {}

    ValidationFlagsEXT& operator=( VkValidationFlagsEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ValidationFlagsEXT::operator=(rhs);
      return *this;
    }

    ValidationFlagsEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ValidationFlagsEXT & setDisabledValidationCheckCount( uint32_t disabledValidationCheckCount_ ) VULKAN_HPP_NOEXCEPT
    {
      disabledValidationCheckCount = disabledValidationCheckCount_;
      return *this;
    }

    ValidationFlagsEXT & setPDisabledValidationChecks( const vk::ValidationCheckEXT* pDisabledValidationChecks_ ) VULKAN_HPP_NOEXCEPT
    {
      pDisabledValidationChecks = pDisabledValidationChecks_;
      return *this;
    }

    operator VkValidationFlagsEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkValidationFlagsEXT*>( this );
    }

    operator VkValidationFlagsEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkValidationFlagsEXT*>( this );
    }

    bool operator==( ValidationFlagsEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( disabledValidationCheckCount == rhs.disabledValidationCheckCount )
          && ( pDisabledValidationChecks == rhs.pDisabledValidationChecks );
    }

    bool operator!=( ValidationFlagsEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ValidationFlagsEXT::sType;
  };
  static_assert( sizeof( ValidationFlagsEXT ) == sizeof( VkValidationFlagsEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ValidationFlagsEXT>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_VI_NN

  namespace layout
  {
    struct ViSurfaceCreateInfoNN
    {
    protected:
      VULKAN_HPP_CONSTEXPR ViSurfaceCreateInfoNN( vk::ViSurfaceCreateFlagsNN flags_ = vk::ViSurfaceCreateFlagsNN(),
                                                  void* window_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , window( window_ )
      {}

      ViSurfaceCreateInfoNN( VkViSurfaceCreateInfoNN const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkViSurfaceCreateInfoNN*>(this) = rhs;
      }

      ViSurfaceCreateInfoNN& operator=( VkViSurfaceCreateInfoNN const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkViSurfaceCreateInfoNN*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eViSurfaceCreateInfoNN;
      const void* pNext = nullptr;
      vk::ViSurfaceCreateFlagsNN flags;
      void* window;
    };
    static_assert( sizeof( ViSurfaceCreateInfoNN ) == sizeof( VkViSurfaceCreateInfoNN ), "layout struct and wrapper have different size!" );
  }

  struct ViSurfaceCreateInfoNN : public layout::ViSurfaceCreateInfoNN
  {
    VULKAN_HPP_CONSTEXPR ViSurfaceCreateInfoNN( vk::ViSurfaceCreateFlagsNN flags_ = vk::ViSurfaceCreateFlagsNN(),
                                                void* window_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::ViSurfaceCreateInfoNN( flags_, window_ )
    {}

    ViSurfaceCreateInfoNN( VkViSurfaceCreateInfoNN const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::ViSurfaceCreateInfoNN( rhs )
    {}

    ViSurfaceCreateInfoNN& operator=( VkViSurfaceCreateInfoNN const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::ViSurfaceCreateInfoNN::operator=(rhs);
      return *this;
    }

    ViSurfaceCreateInfoNN & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    ViSurfaceCreateInfoNN & setFlags( vk::ViSurfaceCreateFlagsNN flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    ViSurfaceCreateInfoNN & setWindow( void* window_ ) VULKAN_HPP_NOEXCEPT
    {
      window = window_;
      return *this;
    }

    operator VkViSurfaceCreateInfoNN const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkViSurfaceCreateInfoNN*>( this );
    }

    operator VkViSurfaceCreateInfoNN &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkViSurfaceCreateInfoNN*>( this );
    }

    bool operator==( ViSurfaceCreateInfoNN const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( window == rhs.window );
    }

    bool operator!=( ViSurfaceCreateInfoNN const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::ViSurfaceCreateInfoNN::sType;
  };
  static_assert( sizeof( ViSurfaceCreateInfoNN ) == sizeof( VkViSurfaceCreateInfoNN ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<ViSurfaceCreateInfoNN>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_VI_NN*/

#ifdef VK_USE_PLATFORM_WAYLAND_KHR

  namespace layout
  {
    struct WaylandSurfaceCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR WaylandSurfaceCreateInfoKHR( vk::WaylandSurfaceCreateFlagsKHR flags_ = vk::WaylandSurfaceCreateFlagsKHR(),
                                                        struct wl_display* display_ = nullptr,
                                                        struct wl_surface* surface_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , display( display_ )
        , surface( surface_ )
      {}

      WaylandSurfaceCreateInfoKHR( VkWaylandSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWaylandSurfaceCreateInfoKHR*>(this) = rhs;
      }

      WaylandSurfaceCreateInfoKHR& operator=( VkWaylandSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWaylandSurfaceCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eWaylandSurfaceCreateInfoKHR;
      const void* pNext = nullptr;
      vk::WaylandSurfaceCreateFlagsKHR flags;
      struct wl_display* display;
      struct wl_surface* surface;
    };
    static_assert( sizeof( WaylandSurfaceCreateInfoKHR ) == sizeof( VkWaylandSurfaceCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct WaylandSurfaceCreateInfoKHR : public layout::WaylandSurfaceCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR WaylandSurfaceCreateInfoKHR( vk::WaylandSurfaceCreateFlagsKHR flags_ = vk::WaylandSurfaceCreateFlagsKHR(),
                                                      struct wl_display* display_ = nullptr,
                                                      struct wl_surface* surface_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::WaylandSurfaceCreateInfoKHR( flags_, display_, surface_ )
    {}

    WaylandSurfaceCreateInfoKHR( VkWaylandSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::WaylandSurfaceCreateInfoKHR( rhs )
    {}

    WaylandSurfaceCreateInfoKHR& operator=( VkWaylandSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::WaylandSurfaceCreateInfoKHR::operator=(rhs);
      return *this;
    }

    WaylandSurfaceCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    WaylandSurfaceCreateInfoKHR & setFlags( vk::WaylandSurfaceCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    WaylandSurfaceCreateInfoKHR & setDisplay( struct wl_display* display_ ) VULKAN_HPP_NOEXCEPT
    {
      display = display_;
      return *this;
    }

    WaylandSurfaceCreateInfoKHR & setSurface( struct wl_surface* surface_ ) VULKAN_HPP_NOEXCEPT
    {
      surface = surface_;
      return *this;
    }

    operator VkWaylandSurfaceCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkWaylandSurfaceCreateInfoKHR*>( this );
    }

    operator VkWaylandSurfaceCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkWaylandSurfaceCreateInfoKHR*>( this );
    }

    bool operator==( WaylandSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( display == rhs.display )
          && ( surface == rhs.surface );
    }

    bool operator!=( WaylandSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::WaylandSurfaceCreateInfoKHR::sType;
  };
  static_assert( sizeof( WaylandSurfaceCreateInfoKHR ) == sizeof( VkWaylandSurfaceCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<WaylandSurfaceCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct Win32KeyedMutexAcquireReleaseInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR Win32KeyedMutexAcquireReleaseInfoKHR( uint32_t acquireCount_ = 0,
                                                                 const vk::DeviceMemory* pAcquireSyncs_ = nullptr,
                                                                 const uint64_t* pAcquireKeys_ = nullptr,
                                                                 const uint32_t* pAcquireTimeouts_ = nullptr,
                                                                 uint32_t releaseCount_ = 0,
                                                                 const vk::DeviceMemory* pReleaseSyncs_ = nullptr,
                                                                 const uint64_t* pReleaseKeys_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : acquireCount( acquireCount_ )
        , pAcquireSyncs( pAcquireSyncs_ )
        , pAcquireKeys( pAcquireKeys_ )
        , pAcquireTimeouts( pAcquireTimeouts_ )
        , releaseCount( releaseCount_ )
        , pReleaseSyncs( pReleaseSyncs_ )
        , pReleaseKeys( pReleaseKeys_ )
      {}

      Win32KeyedMutexAcquireReleaseInfoKHR( VkWin32KeyedMutexAcquireReleaseInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWin32KeyedMutexAcquireReleaseInfoKHR*>(this) = rhs;
      }

      Win32KeyedMutexAcquireReleaseInfoKHR& operator=( VkWin32KeyedMutexAcquireReleaseInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWin32KeyedMutexAcquireReleaseInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eWin32KeyedMutexAcquireReleaseInfoKHR;
      const void* pNext = nullptr;
      uint32_t acquireCount;
      const vk::DeviceMemory* pAcquireSyncs;
      const uint64_t* pAcquireKeys;
      const uint32_t* pAcquireTimeouts;
      uint32_t releaseCount;
      const vk::DeviceMemory* pReleaseSyncs;
      const uint64_t* pReleaseKeys;
    };
    static_assert( sizeof( Win32KeyedMutexAcquireReleaseInfoKHR ) == sizeof( VkWin32KeyedMutexAcquireReleaseInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct Win32KeyedMutexAcquireReleaseInfoKHR : public layout::Win32KeyedMutexAcquireReleaseInfoKHR
  {
    VULKAN_HPP_CONSTEXPR Win32KeyedMutexAcquireReleaseInfoKHR( uint32_t acquireCount_ = 0,
                                                               const vk::DeviceMemory* pAcquireSyncs_ = nullptr,
                                                               const uint64_t* pAcquireKeys_ = nullptr,
                                                               const uint32_t* pAcquireTimeouts_ = nullptr,
                                                               uint32_t releaseCount_ = 0,
                                                               const vk::DeviceMemory* pReleaseSyncs_ = nullptr,
                                                               const uint64_t* pReleaseKeys_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::Win32KeyedMutexAcquireReleaseInfoKHR( acquireCount_, pAcquireSyncs_, pAcquireKeys_, pAcquireTimeouts_, releaseCount_, pReleaseSyncs_, pReleaseKeys_ )
    {}

    Win32KeyedMutexAcquireReleaseInfoKHR( VkWin32KeyedMutexAcquireReleaseInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::Win32KeyedMutexAcquireReleaseInfoKHR( rhs )
    {}

    Win32KeyedMutexAcquireReleaseInfoKHR& operator=( VkWin32KeyedMutexAcquireReleaseInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::Win32KeyedMutexAcquireReleaseInfoKHR::operator=(rhs);
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setAcquireCount( uint32_t acquireCount_ ) VULKAN_HPP_NOEXCEPT
    {
      acquireCount = acquireCount_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setPAcquireSyncs( const vk::DeviceMemory* pAcquireSyncs_ ) VULKAN_HPP_NOEXCEPT
    {
      pAcquireSyncs = pAcquireSyncs_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setPAcquireKeys( const uint64_t* pAcquireKeys_ ) VULKAN_HPP_NOEXCEPT
    {
      pAcquireKeys = pAcquireKeys_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setPAcquireTimeouts( const uint32_t* pAcquireTimeouts_ ) VULKAN_HPP_NOEXCEPT
    {
      pAcquireTimeouts = pAcquireTimeouts_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setReleaseCount( uint32_t releaseCount_ ) VULKAN_HPP_NOEXCEPT
    {
      releaseCount = releaseCount_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setPReleaseSyncs( const vk::DeviceMemory* pReleaseSyncs_ ) VULKAN_HPP_NOEXCEPT
    {
      pReleaseSyncs = pReleaseSyncs_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoKHR & setPReleaseKeys( const uint64_t* pReleaseKeys_ ) VULKAN_HPP_NOEXCEPT
    {
      pReleaseKeys = pReleaseKeys_;
      return *this;
    }

    operator VkWin32KeyedMutexAcquireReleaseInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkWin32KeyedMutexAcquireReleaseInfoKHR*>( this );
    }

    operator VkWin32KeyedMutexAcquireReleaseInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkWin32KeyedMutexAcquireReleaseInfoKHR*>( this );
    }

    bool operator==( Win32KeyedMutexAcquireReleaseInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( acquireCount == rhs.acquireCount )
          && ( pAcquireSyncs == rhs.pAcquireSyncs )
          && ( pAcquireKeys == rhs.pAcquireKeys )
          && ( pAcquireTimeouts == rhs.pAcquireTimeouts )
          && ( releaseCount == rhs.releaseCount )
          && ( pReleaseSyncs == rhs.pReleaseSyncs )
          && ( pReleaseKeys == rhs.pReleaseKeys );
    }

    bool operator!=( Win32KeyedMutexAcquireReleaseInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::Win32KeyedMutexAcquireReleaseInfoKHR::sType;
  };
  static_assert( sizeof( Win32KeyedMutexAcquireReleaseInfoKHR ) == sizeof( VkWin32KeyedMutexAcquireReleaseInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Win32KeyedMutexAcquireReleaseInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct Win32KeyedMutexAcquireReleaseInfoNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR Win32KeyedMutexAcquireReleaseInfoNV( uint32_t acquireCount_ = 0,
                                                                const vk::DeviceMemory* pAcquireSyncs_ = nullptr,
                                                                const uint64_t* pAcquireKeys_ = nullptr,
                                                                const uint32_t* pAcquireTimeoutMilliseconds_ = nullptr,
                                                                uint32_t releaseCount_ = 0,
                                                                const vk::DeviceMemory* pReleaseSyncs_ = nullptr,
                                                                const uint64_t* pReleaseKeys_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : acquireCount( acquireCount_ )
        , pAcquireSyncs( pAcquireSyncs_ )
        , pAcquireKeys( pAcquireKeys_ )
        , pAcquireTimeoutMilliseconds( pAcquireTimeoutMilliseconds_ )
        , releaseCount( releaseCount_ )
        , pReleaseSyncs( pReleaseSyncs_ )
        , pReleaseKeys( pReleaseKeys_ )
      {}

      Win32KeyedMutexAcquireReleaseInfoNV( VkWin32KeyedMutexAcquireReleaseInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWin32KeyedMutexAcquireReleaseInfoNV*>(this) = rhs;
      }

      Win32KeyedMutexAcquireReleaseInfoNV& operator=( VkWin32KeyedMutexAcquireReleaseInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWin32KeyedMutexAcquireReleaseInfoNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eWin32KeyedMutexAcquireReleaseInfoNV;
      const void* pNext = nullptr;
      uint32_t acquireCount;
      const vk::DeviceMemory* pAcquireSyncs;
      const uint64_t* pAcquireKeys;
      const uint32_t* pAcquireTimeoutMilliseconds;
      uint32_t releaseCount;
      const vk::DeviceMemory* pReleaseSyncs;
      const uint64_t* pReleaseKeys;
    };
    static_assert( sizeof( Win32KeyedMutexAcquireReleaseInfoNV ) == sizeof( VkWin32KeyedMutexAcquireReleaseInfoNV ), "layout struct and wrapper have different size!" );
  }

  struct Win32KeyedMutexAcquireReleaseInfoNV : public layout::Win32KeyedMutexAcquireReleaseInfoNV
  {
    VULKAN_HPP_CONSTEXPR Win32KeyedMutexAcquireReleaseInfoNV( uint32_t acquireCount_ = 0,
                                                              const vk::DeviceMemory* pAcquireSyncs_ = nullptr,
                                                              const uint64_t* pAcquireKeys_ = nullptr,
                                                              const uint32_t* pAcquireTimeoutMilliseconds_ = nullptr,
                                                              uint32_t releaseCount_ = 0,
                                                              const vk::DeviceMemory* pReleaseSyncs_ = nullptr,
                                                              const uint64_t* pReleaseKeys_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::Win32KeyedMutexAcquireReleaseInfoNV( acquireCount_, pAcquireSyncs_, pAcquireKeys_, pAcquireTimeoutMilliseconds_, releaseCount_, pReleaseSyncs_, pReleaseKeys_ )
    {}

    Win32KeyedMutexAcquireReleaseInfoNV( VkWin32KeyedMutexAcquireReleaseInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::Win32KeyedMutexAcquireReleaseInfoNV( rhs )
    {}

    Win32KeyedMutexAcquireReleaseInfoNV& operator=( VkWin32KeyedMutexAcquireReleaseInfoNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::Win32KeyedMutexAcquireReleaseInfoNV::operator=(rhs);
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setAcquireCount( uint32_t acquireCount_ ) VULKAN_HPP_NOEXCEPT
    {
      acquireCount = acquireCount_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setPAcquireSyncs( const vk::DeviceMemory* pAcquireSyncs_ ) VULKAN_HPP_NOEXCEPT
    {
      pAcquireSyncs = pAcquireSyncs_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setPAcquireKeys( const uint64_t* pAcquireKeys_ ) VULKAN_HPP_NOEXCEPT
    {
      pAcquireKeys = pAcquireKeys_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setPAcquireTimeoutMilliseconds( const uint32_t* pAcquireTimeoutMilliseconds_ ) VULKAN_HPP_NOEXCEPT
    {
      pAcquireTimeoutMilliseconds = pAcquireTimeoutMilliseconds_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setReleaseCount( uint32_t releaseCount_ ) VULKAN_HPP_NOEXCEPT
    {
      releaseCount = releaseCount_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setPReleaseSyncs( const vk::DeviceMemory* pReleaseSyncs_ ) VULKAN_HPP_NOEXCEPT
    {
      pReleaseSyncs = pReleaseSyncs_;
      return *this;
    }

    Win32KeyedMutexAcquireReleaseInfoNV & setPReleaseKeys( const uint64_t* pReleaseKeys_ ) VULKAN_HPP_NOEXCEPT
    {
      pReleaseKeys = pReleaseKeys_;
      return *this;
    }

    operator VkWin32KeyedMutexAcquireReleaseInfoNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkWin32KeyedMutexAcquireReleaseInfoNV*>( this );
    }

    operator VkWin32KeyedMutexAcquireReleaseInfoNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkWin32KeyedMutexAcquireReleaseInfoNV*>( this );
    }

    bool operator==( Win32KeyedMutexAcquireReleaseInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( acquireCount == rhs.acquireCount )
          && ( pAcquireSyncs == rhs.pAcquireSyncs )
          && ( pAcquireKeys == rhs.pAcquireKeys )
          && ( pAcquireTimeoutMilliseconds == rhs.pAcquireTimeoutMilliseconds )
          && ( releaseCount == rhs.releaseCount )
          && ( pReleaseSyncs == rhs.pReleaseSyncs )
          && ( pReleaseKeys == rhs.pReleaseKeys );
    }

    bool operator!=( Win32KeyedMutexAcquireReleaseInfoNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::Win32KeyedMutexAcquireReleaseInfoNV::sType;
  };
  static_assert( sizeof( Win32KeyedMutexAcquireReleaseInfoNV ) == sizeof( VkWin32KeyedMutexAcquireReleaseInfoNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Win32KeyedMutexAcquireReleaseInfoNV>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR

  namespace layout
  {
    struct Win32SurfaceCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR Win32SurfaceCreateInfoKHR( vk::Win32SurfaceCreateFlagsKHR flags_ = vk::Win32SurfaceCreateFlagsKHR(),
                                                      HINSTANCE hinstance_ = 0,
                                                      HWND hwnd_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , hinstance( hinstance_ )
        , hwnd( hwnd_ )
      {}

      Win32SurfaceCreateInfoKHR( VkWin32SurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWin32SurfaceCreateInfoKHR*>(this) = rhs;
      }

      Win32SurfaceCreateInfoKHR& operator=( VkWin32SurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWin32SurfaceCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eWin32SurfaceCreateInfoKHR;
      const void* pNext = nullptr;
      vk::Win32SurfaceCreateFlagsKHR flags;
      HINSTANCE hinstance;
      HWND hwnd;
    };
    static_assert( sizeof( Win32SurfaceCreateInfoKHR ) == sizeof( VkWin32SurfaceCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct Win32SurfaceCreateInfoKHR : public layout::Win32SurfaceCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR Win32SurfaceCreateInfoKHR( vk::Win32SurfaceCreateFlagsKHR flags_ = vk::Win32SurfaceCreateFlagsKHR(),
                                                    HINSTANCE hinstance_ = 0,
                                                    HWND hwnd_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::Win32SurfaceCreateInfoKHR( flags_, hinstance_, hwnd_ )
    {}

    Win32SurfaceCreateInfoKHR( VkWin32SurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::Win32SurfaceCreateInfoKHR( rhs )
    {}

    Win32SurfaceCreateInfoKHR& operator=( VkWin32SurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::Win32SurfaceCreateInfoKHR::operator=(rhs);
      return *this;
    }

    Win32SurfaceCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    Win32SurfaceCreateInfoKHR & setFlags( vk::Win32SurfaceCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    Win32SurfaceCreateInfoKHR & setHinstance( HINSTANCE hinstance_ ) VULKAN_HPP_NOEXCEPT
    {
      hinstance = hinstance_;
      return *this;
    }

    Win32SurfaceCreateInfoKHR & setHwnd( HWND hwnd_ ) VULKAN_HPP_NOEXCEPT
    {
      hwnd = hwnd_;
      return *this;
    }

    operator VkWin32SurfaceCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkWin32SurfaceCreateInfoKHR*>( this );
    }

    operator VkWin32SurfaceCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkWin32SurfaceCreateInfoKHR*>( this );
    }

    bool operator==( Win32SurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( hinstance == rhs.hinstance )
          && ( hwnd == rhs.hwnd );
    }

    bool operator!=( Win32SurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::Win32SurfaceCreateInfoKHR::sType;
  };
  static_assert( sizeof( Win32SurfaceCreateInfoKHR ) == sizeof( VkWin32SurfaceCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<Win32SurfaceCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  namespace layout
  {
    struct WriteDescriptorSet
    {
    protected:
      VULKAN_HPP_CONSTEXPR WriteDescriptorSet( vk::DescriptorSet dstSet_ = vk::DescriptorSet(),
                                               uint32_t dstBinding_ = 0,
                                               uint32_t dstArrayElement_ = 0,
                                               uint32_t descriptorCount_ = 0,
                                               vk::DescriptorType descriptorType_ = vk::DescriptorType::eSampler,
                                               const vk::DescriptorImageInfo* pImageInfo_ = nullptr,
                                               const vk::DescriptorBufferInfo* pBufferInfo_ = nullptr,
                                               const vk::BufferView* pTexelBufferView_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : dstSet( dstSet_ )
        , dstBinding( dstBinding_ )
        , dstArrayElement( dstArrayElement_ )
        , descriptorCount( descriptorCount_ )
        , descriptorType( descriptorType_ )
        , pImageInfo( pImageInfo_ )
        , pBufferInfo( pBufferInfo_ )
        , pTexelBufferView( pTexelBufferView_ )
      {}

      WriteDescriptorSet( VkWriteDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWriteDescriptorSet*>(this) = rhs;
      }

      WriteDescriptorSet& operator=( VkWriteDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWriteDescriptorSet*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eWriteDescriptorSet;
      const void* pNext = nullptr;
      vk::DescriptorSet dstSet;
      uint32_t dstBinding;
      uint32_t dstArrayElement;
      uint32_t descriptorCount;
      vk::DescriptorType descriptorType;
      const vk::DescriptorImageInfo* pImageInfo;
      const vk::DescriptorBufferInfo* pBufferInfo;
      const vk::BufferView* pTexelBufferView;
    };
    static_assert( sizeof( WriteDescriptorSet ) == sizeof( VkWriteDescriptorSet ), "layout struct and wrapper have different size!" );
  }

  struct WriteDescriptorSet : public layout::WriteDescriptorSet
  {
    VULKAN_HPP_CONSTEXPR WriteDescriptorSet( vk::DescriptorSet dstSet_ = vk::DescriptorSet(),
                                             uint32_t dstBinding_ = 0,
                                             uint32_t dstArrayElement_ = 0,
                                             uint32_t descriptorCount_ = 0,
                                             vk::DescriptorType descriptorType_ = vk::DescriptorType::eSampler,
                                             const vk::DescriptorImageInfo* pImageInfo_ = nullptr,
                                             const vk::DescriptorBufferInfo* pBufferInfo_ = nullptr,
                                             const vk::BufferView* pTexelBufferView_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::WriteDescriptorSet( dstSet_, dstBinding_, dstArrayElement_, descriptorCount_, descriptorType_, pImageInfo_, pBufferInfo_, pTexelBufferView_ )
    {}

    WriteDescriptorSet( VkWriteDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::WriteDescriptorSet( rhs )
    {}

    WriteDescriptorSet& operator=( VkWriteDescriptorSet const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::WriteDescriptorSet::operator=(rhs);
      return *this;
    }

    WriteDescriptorSet & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    WriteDescriptorSet & setDstSet( vk::DescriptorSet dstSet_ ) VULKAN_HPP_NOEXCEPT
    {
      dstSet = dstSet_;
      return *this;
    }

    WriteDescriptorSet & setDstBinding( uint32_t dstBinding_ ) VULKAN_HPP_NOEXCEPT
    {
      dstBinding = dstBinding_;
      return *this;
    }

    WriteDescriptorSet & setDstArrayElement( uint32_t dstArrayElement_ ) VULKAN_HPP_NOEXCEPT
    {
      dstArrayElement = dstArrayElement_;
      return *this;
    }

    WriteDescriptorSet & setDescriptorCount( uint32_t descriptorCount_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorCount = descriptorCount_;
      return *this;
    }

    WriteDescriptorSet & setDescriptorType( vk::DescriptorType descriptorType_ ) VULKAN_HPP_NOEXCEPT
    {
      descriptorType = descriptorType_;
      return *this;
    }

    WriteDescriptorSet & setPImageInfo( const vk::DescriptorImageInfo* pImageInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      pImageInfo = pImageInfo_;
      return *this;
    }

    WriteDescriptorSet & setPBufferInfo( const vk::DescriptorBufferInfo* pBufferInfo_ ) VULKAN_HPP_NOEXCEPT
    {
      pBufferInfo = pBufferInfo_;
      return *this;
    }

    WriteDescriptorSet & setPTexelBufferView( const vk::BufferView* pTexelBufferView_ ) VULKAN_HPP_NOEXCEPT
    {
      pTexelBufferView = pTexelBufferView_;
      return *this;
    }

    operator VkWriteDescriptorSet const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkWriteDescriptorSet*>( this );
    }

    operator VkWriteDescriptorSet &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkWriteDescriptorSet*>( this );
    }

    bool operator==( WriteDescriptorSet const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( dstSet == rhs.dstSet )
          && ( dstBinding == rhs.dstBinding )
          && ( dstArrayElement == rhs.dstArrayElement )
          && ( descriptorCount == rhs.descriptorCount )
          && ( descriptorType == rhs.descriptorType )
          && ( pImageInfo == rhs.pImageInfo )
          && ( pBufferInfo == rhs.pBufferInfo )
          && ( pTexelBufferView == rhs.pTexelBufferView );
    }

    bool operator!=( WriteDescriptorSet const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::WriteDescriptorSet::sType;
  };
  static_assert( sizeof( WriteDescriptorSet ) == sizeof( VkWriteDescriptorSet ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<WriteDescriptorSet>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct WriteDescriptorSetAccelerationStructureNV
    {
    protected:
      VULKAN_HPP_CONSTEXPR WriteDescriptorSetAccelerationStructureNV( uint32_t accelerationStructureCount_ = 0,
                                                                      const vk::AccelerationStructureNV* pAccelerationStructures_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : accelerationStructureCount( accelerationStructureCount_ )
        , pAccelerationStructures( pAccelerationStructures_ )
      {}

      WriteDescriptorSetAccelerationStructureNV( VkWriteDescriptorSetAccelerationStructureNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWriteDescriptorSetAccelerationStructureNV*>(this) = rhs;
      }

      WriteDescriptorSetAccelerationStructureNV& operator=( VkWriteDescriptorSetAccelerationStructureNV const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWriteDescriptorSetAccelerationStructureNV*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eWriteDescriptorSetAccelerationStructureNV;
      const void* pNext = nullptr;
      uint32_t accelerationStructureCount;
      const vk::AccelerationStructureNV* pAccelerationStructures;
    };
    static_assert( sizeof( WriteDescriptorSetAccelerationStructureNV ) == sizeof( VkWriteDescriptorSetAccelerationStructureNV ), "layout struct and wrapper have different size!" );
  }

  struct WriteDescriptorSetAccelerationStructureNV : public layout::WriteDescriptorSetAccelerationStructureNV
  {
    VULKAN_HPP_CONSTEXPR WriteDescriptorSetAccelerationStructureNV( uint32_t accelerationStructureCount_ = 0,
                                                                    const vk::AccelerationStructureNV* pAccelerationStructures_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::WriteDescriptorSetAccelerationStructureNV( accelerationStructureCount_, pAccelerationStructures_ )
    {}

    WriteDescriptorSetAccelerationStructureNV( VkWriteDescriptorSetAccelerationStructureNV const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::WriteDescriptorSetAccelerationStructureNV( rhs )
    {}

    WriteDescriptorSetAccelerationStructureNV& operator=( VkWriteDescriptorSetAccelerationStructureNV const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::WriteDescriptorSetAccelerationStructureNV::operator=(rhs);
      return *this;
    }

    WriteDescriptorSetAccelerationStructureNV & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    WriteDescriptorSetAccelerationStructureNV & setAccelerationStructureCount( uint32_t accelerationStructureCount_ ) VULKAN_HPP_NOEXCEPT
    {
      accelerationStructureCount = accelerationStructureCount_;
      return *this;
    }

    WriteDescriptorSetAccelerationStructureNV & setPAccelerationStructures( const vk::AccelerationStructureNV* pAccelerationStructures_ ) VULKAN_HPP_NOEXCEPT
    {
      pAccelerationStructures = pAccelerationStructures_;
      return *this;
    }

    operator VkWriteDescriptorSetAccelerationStructureNV const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkWriteDescriptorSetAccelerationStructureNV*>( this );
    }

    operator VkWriteDescriptorSetAccelerationStructureNV &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkWriteDescriptorSetAccelerationStructureNV*>( this );
    }

    bool operator==( WriteDescriptorSetAccelerationStructureNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( accelerationStructureCount == rhs.accelerationStructureCount )
          && ( pAccelerationStructures == rhs.pAccelerationStructures );
    }

    bool operator!=( WriteDescriptorSetAccelerationStructureNV const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::WriteDescriptorSetAccelerationStructureNV::sType;
  };
  static_assert( sizeof( WriteDescriptorSetAccelerationStructureNV ) == sizeof( VkWriteDescriptorSetAccelerationStructureNV ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<WriteDescriptorSetAccelerationStructureNV>::value, "struct wrapper is not a standard layout!" );

  namespace layout
  {
    struct WriteDescriptorSetInlineUniformBlockEXT
    {
    protected:
      VULKAN_HPP_CONSTEXPR WriteDescriptorSetInlineUniformBlockEXT( uint32_t dataSize_ = 0,
                                                                    const void* pData_ = nullptr ) VULKAN_HPP_NOEXCEPT
        : dataSize( dataSize_ )
        , pData( pData_ )
      {}

      WriteDescriptorSetInlineUniformBlockEXT( VkWriteDescriptorSetInlineUniformBlockEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWriteDescriptorSetInlineUniformBlockEXT*>(this) = rhs;
      }

      WriteDescriptorSetInlineUniformBlockEXT& operator=( VkWriteDescriptorSetInlineUniformBlockEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkWriteDescriptorSetInlineUniformBlockEXT*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eWriteDescriptorSetInlineUniformBlockEXT;
      const void* pNext = nullptr;
      uint32_t dataSize;
      const void* pData;
    };
    static_assert( sizeof( WriteDescriptorSetInlineUniformBlockEXT ) == sizeof( VkWriteDescriptorSetInlineUniformBlockEXT ), "layout struct and wrapper have different size!" );
  }

  struct WriteDescriptorSetInlineUniformBlockEXT : public layout::WriteDescriptorSetInlineUniformBlockEXT
  {
    VULKAN_HPP_CONSTEXPR WriteDescriptorSetInlineUniformBlockEXT( uint32_t dataSize_ = 0,
                                                                  const void* pData_ = nullptr ) VULKAN_HPP_NOEXCEPT
      : layout::WriteDescriptorSetInlineUniformBlockEXT( dataSize_, pData_ )
    {}

    WriteDescriptorSetInlineUniformBlockEXT( VkWriteDescriptorSetInlineUniformBlockEXT const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::WriteDescriptorSetInlineUniformBlockEXT( rhs )
    {}

    WriteDescriptorSetInlineUniformBlockEXT& operator=( VkWriteDescriptorSetInlineUniformBlockEXT const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::WriteDescriptorSetInlineUniformBlockEXT::operator=(rhs);
      return *this;
    }

    WriteDescriptorSetInlineUniformBlockEXT & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    WriteDescriptorSetInlineUniformBlockEXT & setDataSize( uint32_t dataSize_ ) VULKAN_HPP_NOEXCEPT
    {
      dataSize = dataSize_;
      return *this;
    }

    WriteDescriptorSetInlineUniformBlockEXT & setPData( const void* pData_ ) VULKAN_HPP_NOEXCEPT
    {
      pData = pData_;
      return *this;
    }

    operator VkWriteDescriptorSetInlineUniformBlockEXT const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkWriteDescriptorSetInlineUniformBlockEXT*>( this );
    }

    operator VkWriteDescriptorSetInlineUniformBlockEXT &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkWriteDescriptorSetInlineUniformBlockEXT*>( this );
    }

    bool operator==( WriteDescriptorSetInlineUniformBlockEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( dataSize == rhs.dataSize )
          && ( pData == rhs.pData );
    }

    bool operator!=( WriteDescriptorSetInlineUniformBlockEXT const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::WriteDescriptorSetInlineUniformBlockEXT::sType;
  };
  static_assert( sizeof( WriteDescriptorSetInlineUniformBlockEXT ) == sizeof( VkWriteDescriptorSetInlineUniformBlockEXT ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<WriteDescriptorSetInlineUniformBlockEXT>::value, "struct wrapper is not a standard layout!" );

#ifdef VK_USE_PLATFORM_XCB_KHR

  namespace layout
  {
    struct XcbSurfaceCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR XcbSurfaceCreateInfoKHR( vk::XcbSurfaceCreateFlagsKHR flags_ = vk::XcbSurfaceCreateFlagsKHR(),
                                                    xcb_connection_t* connection_ = nullptr,
                                                    xcb_window_t window_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , connection( connection_ )
        , window( window_ )
      {}

      XcbSurfaceCreateInfoKHR( VkXcbSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkXcbSurfaceCreateInfoKHR*>(this) = rhs;
      }

      XcbSurfaceCreateInfoKHR& operator=( VkXcbSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkXcbSurfaceCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eXcbSurfaceCreateInfoKHR;
      const void* pNext = nullptr;
      vk::XcbSurfaceCreateFlagsKHR flags;
      xcb_connection_t* connection;
      xcb_window_t window;
    };
    static_assert( sizeof( XcbSurfaceCreateInfoKHR ) == sizeof( VkXcbSurfaceCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct XcbSurfaceCreateInfoKHR : public layout::XcbSurfaceCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR XcbSurfaceCreateInfoKHR( vk::XcbSurfaceCreateFlagsKHR flags_ = vk::XcbSurfaceCreateFlagsKHR(),
                                                  xcb_connection_t* connection_ = nullptr,
                                                  xcb_window_t window_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::XcbSurfaceCreateInfoKHR( flags_, connection_, window_ )
    {}

    XcbSurfaceCreateInfoKHR( VkXcbSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::XcbSurfaceCreateInfoKHR( rhs )
    {}

    XcbSurfaceCreateInfoKHR& operator=( VkXcbSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::XcbSurfaceCreateInfoKHR::operator=(rhs);
      return *this;
    }

    XcbSurfaceCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    XcbSurfaceCreateInfoKHR & setFlags( vk::XcbSurfaceCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    XcbSurfaceCreateInfoKHR & setConnection( xcb_connection_t* connection_ ) VULKAN_HPP_NOEXCEPT
    {
      connection = connection_;
      return *this;
    }

    XcbSurfaceCreateInfoKHR & setWindow( xcb_window_t window_ ) VULKAN_HPP_NOEXCEPT
    {
      window = window_;
      return *this;
    }

    operator VkXcbSurfaceCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkXcbSurfaceCreateInfoKHR*>( this );
    }

    operator VkXcbSurfaceCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkXcbSurfaceCreateInfoKHR*>( this );
    }

    bool operator==( XcbSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( connection == rhs.connection )
          && ( window == rhs.window );
    }

    bool operator!=( XcbSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::XcbSurfaceCreateInfoKHR::sType;
  };
  static_assert( sizeof( XcbSurfaceCreateInfoKHR ) == sizeof( VkXcbSurfaceCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<XcbSurfaceCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR

  namespace layout
  {
    struct XlibSurfaceCreateInfoKHR
    {
    protected:
      VULKAN_HPP_CONSTEXPR XlibSurfaceCreateInfoKHR( vk::XlibSurfaceCreateFlagsKHR flags_ = vk::XlibSurfaceCreateFlagsKHR(),
                                                     Display* dpy_ = nullptr,
                                                     Window window_ = 0 ) VULKAN_HPP_NOEXCEPT
        : flags( flags_ )
        , dpy( dpy_ )
        , window( window_ )
      {}

      XlibSurfaceCreateInfoKHR( VkXlibSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkXlibSurfaceCreateInfoKHR*>(this) = rhs;
      }

      XlibSurfaceCreateInfoKHR& operator=( VkXlibSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      {
        *reinterpret_cast<VkXlibSurfaceCreateInfoKHR*>(this) = rhs;
        return *this;
      }

    public:
      vk::StructureType sType = StructureType::eXlibSurfaceCreateInfoKHR;
      const void* pNext = nullptr;
      vk::XlibSurfaceCreateFlagsKHR flags;
      Display* dpy;
      Window window;
    };
    static_assert( sizeof( XlibSurfaceCreateInfoKHR ) == sizeof( VkXlibSurfaceCreateInfoKHR ), "layout struct and wrapper have different size!" );
  }

  struct XlibSurfaceCreateInfoKHR : public layout::XlibSurfaceCreateInfoKHR
  {
    VULKAN_HPP_CONSTEXPR XlibSurfaceCreateInfoKHR( vk::XlibSurfaceCreateFlagsKHR flags_ = vk::XlibSurfaceCreateFlagsKHR(),
                                                   Display* dpy_ = nullptr,
                                                   Window window_ = 0 ) VULKAN_HPP_NOEXCEPT
      : layout::XlibSurfaceCreateInfoKHR( flags_, dpy_, window_ )
    {}

    XlibSurfaceCreateInfoKHR( VkXlibSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
      : layout::XlibSurfaceCreateInfoKHR( rhs )
    {}

    XlibSurfaceCreateInfoKHR& operator=( VkXlibSurfaceCreateInfoKHR const & rhs ) VULKAN_HPP_NOEXCEPT
    {
      layout::XlibSurfaceCreateInfoKHR::operator=(rhs);
      return *this;
    }

    XlibSurfaceCreateInfoKHR & setPNext( const void* pNext_ ) VULKAN_HPP_NOEXCEPT
    {
      pNext = pNext_;
      return *this;
    }

    XlibSurfaceCreateInfoKHR & setFlags( vk::XlibSurfaceCreateFlagsKHR flags_ ) VULKAN_HPP_NOEXCEPT
    {
      flags = flags_;
      return *this;
    }

    XlibSurfaceCreateInfoKHR & setDpy( Display* dpy_ ) VULKAN_HPP_NOEXCEPT
    {
      dpy = dpy_;
      return *this;
    }

    XlibSurfaceCreateInfoKHR & setWindow( Window window_ ) VULKAN_HPP_NOEXCEPT
    {
      window = window_;
      return *this;
    }

    operator VkXlibSurfaceCreateInfoKHR const&() const VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<const VkXlibSurfaceCreateInfoKHR*>( this );
    }

    operator VkXlibSurfaceCreateInfoKHR &() VULKAN_HPP_NOEXCEPT
    {
      return *reinterpret_cast<VkXlibSurfaceCreateInfoKHR*>( this );
    }

    bool operator==( XlibSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return ( sType == rhs.sType )
          && ( pNext == rhs.pNext )
          && ( flags == rhs.flags )
          && ( dpy == rhs.dpy )
          && ( window == rhs.window );
    }

    bool operator!=( XlibSurfaceCreateInfoKHR const& rhs ) const VULKAN_HPP_NOEXCEPT
    {
      return !operator==( rhs );
    }

  private:
    using layout::XlibSurfaceCreateInfoKHR::sType;
  };
  static_assert( sizeof( XlibSurfaceCreateInfoKHR ) == sizeof( VkXlibSurfaceCreateInfoKHR ), "struct and wrapper have different size!" );
  static_assert( std::is_standard_layout<XlibSurfaceCreateInfoKHR>::value, "struct wrapper is not a standard layout!" );
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result createInstance( const vk::InstanceCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Instance* pInstance, Dispatch const &d)
  {
    return static_cast<Result>( d.vkCreateInstance( reinterpret_cast<const VkInstanceCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkInstance*>( pInstance ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Instance>::type createInstance( const InstanceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d )
  {
    vk::Instance instance;
    Result result = static_cast<Result>( d.vkCreateInstance( reinterpret_cast<const VkInstanceCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkInstance*>( &instance ) ) );
    return createResultValue( result, instance, VULKAN_HPP_NAMESPACE_STRING"::createInstance" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Instance,Dispatch>>::type createInstanceUnique( const InstanceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d )
  {
    vk::Instance instance;
    Result result = static_cast<Result>( d.vkCreateInstance( reinterpret_cast<const VkInstanceCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkInstance*>( &instance ) ) );

    ObjectDestroy<NoParent,Dispatch> deleter( allocator, d );
    return createResultValue<Instance,Dispatch>( result, instance, VULKAN_HPP_NAMESPACE_STRING"::createInstanceUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result enumerateInstanceExtensionProperties( const char* pLayerName, uint32_t* pPropertyCount, vk::ExtensionProperties* pProperties, Dispatch const &d)
  {
    return static_cast<Result>( d.vkEnumerateInstanceExtensionProperties( pLayerName, pPropertyCount, reinterpret_cast<VkExtensionProperties*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type enumerateInstanceExtensionProperties( Optional<const std::string> layerName, Dispatch const &d )
  {
    std::vector<ExtensionProperties,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateInstanceExtensionProperties( layerName ? layerName->c_str() : nullptr, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateInstanceExtensionProperties( layerName ? layerName->c_str() : nullptr, &propertyCount, reinterpret_cast<VkExtensionProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::enumerateInstanceExtensionProperties" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type enumerateInstanceExtensionProperties( Optional<const std::string> layerName, Allocator const& vectorAllocator, Dispatch const &d )
  {
    std::vector<ExtensionProperties,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateInstanceExtensionProperties( layerName ? layerName->c_str() : nullptr, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateInstanceExtensionProperties( layerName ? layerName->c_str() : nullptr, &propertyCount, reinterpret_cast<VkExtensionProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::enumerateInstanceExtensionProperties" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result enumerateInstanceLayerProperties( uint32_t* pPropertyCount, vk::LayerProperties* pProperties, Dispatch const &d)
  {
    return static_cast<Result>( d.vkEnumerateInstanceLayerProperties( pPropertyCount, reinterpret_cast<VkLayerProperties*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<LayerProperties,Allocator>>::type enumerateInstanceLayerProperties(Dispatch const &d )
  {
    std::vector<LayerProperties,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateInstanceLayerProperties( &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateInstanceLayerProperties( &propertyCount, reinterpret_cast<VkLayerProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::enumerateInstanceLayerProperties" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<LayerProperties,Allocator>>::type enumerateInstanceLayerProperties(Allocator const& vectorAllocator, Dispatch const &d )
  {
    std::vector<LayerProperties,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateInstanceLayerProperties( &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateInstanceLayerProperties( &propertyCount, reinterpret_cast<VkLayerProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::enumerateInstanceLayerProperties" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result enumerateInstanceVersion( uint32_t* pApiVersion, Dispatch const &d)
  {
    return static_cast<Result>( d.vkEnumerateInstanceVersion( pApiVersion ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<uint32_t>::type enumerateInstanceVersion(Dispatch const &d )
  {
    uint32_t apiVersion;
    Result result = static_cast<Result>( d.vkEnumerateInstanceVersion( &apiVersion ) );
    return createResultValue( result, apiVersion, VULKAN_HPP_NAMESPACE_STRING"::enumerateInstanceVersion" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result CommandBuffer::begin( const vk::CommandBufferBeginInfo* pBeginInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBeginCommandBuffer( m_commandBuffer, reinterpret_cast<const VkCommandBufferBeginInfo*>( pBeginInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type CommandBuffer::begin( const CommandBufferBeginInfo & beginInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBeginCommandBuffer( m_commandBuffer, reinterpret_cast<const VkCommandBufferBeginInfo*>( &beginInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::CommandBuffer::begin" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginConditionalRenderingEXT( const vk::ConditionalRenderingBeginInfoEXT* pConditionalRenderingBegin, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginConditionalRenderingEXT( m_commandBuffer, reinterpret_cast<const VkConditionalRenderingBeginInfoEXT*>( pConditionalRenderingBegin ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginConditionalRenderingEXT( const ConditionalRenderingBeginInfoEXT & conditionalRenderingBegin, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginConditionalRenderingEXT( m_commandBuffer, reinterpret_cast<const VkConditionalRenderingBeginInfoEXT*>( &conditionalRenderingBegin ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginDebugUtilsLabelEXT( m_commandBuffer, reinterpret_cast<const VkDebugUtilsLabelEXT*>( pLabelInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginDebugUtilsLabelEXT( m_commandBuffer, reinterpret_cast<const VkDebugUtilsLabelEXT*>( &labelInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginQuery( vk::QueryPool queryPool, uint32_t query, vk::QueryControlFlags flags, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginQuery( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query, static_cast<VkQueryControlFlags>( flags ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginQuery( vk::QueryPool queryPool, uint32_t query, vk::QueryControlFlags flags, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginQuery( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query, static_cast<VkQueryControlFlags>( flags ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginQueryIndexedEXT( vk::QueryPool queryPool, uint32_t query, vk::QueryControlFlags flags, uint32_t index, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginQueryIndexedEXT( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query, static_cast<VkQueryControlFlags>( flags ), index );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginQueryIndexedEXT( vk::QueryPool queryPool, uint32_t query, vk::QueryControlFlags flags, uint32_t index, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginQueryIndexedEXT( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query, static_cast<VkQueryControlFlags>( flags ), index );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginRenderPass( const vk::RenderPassBeginInfo* pRenderPassBegin, vk::SubpassContents contents, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginRenderPass( m_commandBuffer, reinterpret_cast<const VkRenderPassBeginInfo*>( pRenderPassBegin ), static_cast<VkSubpassContents>( contents ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginRenderPass( const RenderPassBeginInfo & renderPassBegin, vk::SubpassContents contents, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginRenderPass( m_commandBuffer, reinterpret_cast<const VkRenderPassBeginInfo*>( &renderPassBegin ), static_cast<VkSubpassContents>( contents ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginRenderPass2KHR( const vk::RenderPassBeginInfo* pRenderPassBegin, const vk::SubpassBeginInfoKHR* pSubpassBeginInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginRenderPass2KHR( m_commandBuffer, reinterpret_cast<const VkRenderPassBeginInfo*>( pRenderPassBegin ), reinterpret_cast<const VkSubpassBeginInfoKHR*>( pSubpassBeginInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginRenderPass2KHR( const RenderPassBeginInfo & renderPassBegin, const SubpassBeginInfoKHR & subpassBeginInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginRenderPass2KHR( m_commandBuffer, reinterpret_cast<const VkRenderPassBeginInfo*>( &renderPassBegin ), reinterpret_cast<const VkSubpassBeginInfoKHR*>( &subpassBeginInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginTransformFeedbackEXT( uint32_t firstCounterBuffer, uint32_t counterBufferCount, const vk::Buffer* pCounterBuffers, const vk::DeviceSize* pCounterBufferOffsets, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBeginTransformFeedbackEXT( m_commandBuffer, firstCounterBuffer, counterBufferCount, reinterpret_cast<const VkBuffer*>( pCounterBuffers ), reinterpret_cast<const VkDeviceSize*>( pCounterBufferOffsets ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::beginTransformFeedbackEXT( uint32_t firstCounterBuffer, ArrayProxy<const vk::Buffer> counterBuffers, ArrayProxy<const vk::DeviceSize> counterBufferOffsets, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( counterBuffers.size() == counterBufferOffsets.size() );
#else
    if ( counterBuffers.size() != counterBufferOffsets.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkCommandBuffer::beginTransformFeedbackEXT: counterBuffers.size() != counterBufferOffsets.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    d.vkCmdBeginTransformFeedbackEXT( m_commandBuffer, firstCounterBuffer, counterBuffers.size() , reinterpret_cast<const VkBuffer*>( counterBuffers.data() ), reinterpret_cast<const VkDeviceSize*>( counterBufferOffsets.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindDescriptorSets( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t firstSet, uint32_t descriptorSetCount, const vk::DescriptorSet* pDescriptorSets, uint32_t dynamicOffsetCount, const uint32_t* pDynamicOffsets, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindDescriptorSets( m_commandBuffer, static_cast<VkPipelineBindPoint>( pipelineBindPoint ), static_cast<VkPipelineLayout>( layout ), firstSet, descriptorSetCount, reinterpret_cast<const VkDescriptorSet*>( pDescriptorSets ), dynamicOffsetCount, pDynamicOffsets );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindDescriptorSets( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t firstSet, ArrayProxy<const vk::DescriptorSet> descriptorSets, ArrayProxy<const uint32_t> dynamicOffsets, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindDescriptorSets( m_commandBuffer, static_cast<VkPipelineBindPoint>( pipelineBindPoint ), static_cast<VkPipelineLayout>( layout ), firstSet, descriptorSets.size() , reinterpret_cast<const VkDescriptorSet*>( descriptorSets.data() ), dynamicOffsets.size() , dynamicOffsets.data() );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindIndexBuffer( vk::Buffer buffer, vk::DeviceSize offset, vk::IndexType indexType, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindIndexBuffer( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkIndexType>( indexType ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindIndexBuffer( vk::Buffer buffer, vk::DeviceSize offset, vk::IndexType indexType, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindIndexBuffer( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkIndexType>( indexType ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindPipeline( vk::PipelineBindPoint pipelineBindPoint, vk::Pipeline pipeline, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindPipeline( m_commandBuffer, static_cast<VkPipelineBindPoint>( pipelineBindPoint ), static_cast<VkPipeline>( pipeline ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindPipeline( vk::PipelineBindPoint pipelineBindPoint, vk::Pipeline pipeline, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindPipeline( m_commandBuffer, static_cast<VkPipelineBindPoint>( pipelineBindPoint ), static_cast<VkPipeline>( pipeline ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindShadingRateImageNV( vk::ImageView imageView, vk::ImageLayout imageLayout, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindShadingRateImageNV( m_commandBuffer, static_cast<VkImageView>( imageView ), static_cast<VkImageLayout>( imageLayout ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindShadingRateImageNV( vk::ImageView imageView, vk::ImageLayout imageLayout, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindShadingRateImageNV( m_commandBuffer, static_cast<VkImageView>( imageView ), static_cast<VkImageLayout>( imageLayout ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindTransformFeedbackBuffersEXT( uint32_t firstBinding, uint32_t bindingCount, const vk::Buffer* pBuffers, const vk::DeviceSize* pOffsets, const vk::DeviceSize* pSizes, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindTransformFeedbackBuffersEXT( m_commandBuffer, firstBinding, bindingCount, reinterpret_cast<const VkBuffer*>( pBuffers ), reinterpret_cast<const VkDeviceSize*>( pOffsets ), reinterpret_cast<const VkDeviceSize*>( pSizes ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindTransformFeedbackBuffersEXT( uint32_t firstBinding, ArrayProxy<const vk::Buffer> buffers, ArrayProxy<const vk::DeviceSize> offsets, ArrayProxy<const vk::DeviceSize> sizes, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( buffers.size() == offsets.size() );
#else
    if ( buffers.size() != offsets.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkCommandBuffer::bindTransformFeedbackBuffersEXT: buffers.size() != offsets.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( buffers.size() == sizes.size() );
#else
    if ( buffers.size() != sizes.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkCommandBuffer::bindTransformFeedbackBuffersEXT: buffers.size() != sizes.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( offsets.size() == sizes.size() );
#else
    if ( offsets.size() != sizes.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkCommandBuffer::bindTransformFeedbackBuffersEXT: offsets.size() != sizes.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    d.vkCmdBindTransformFeedbackBuffersEXT( m_commandBuffer, firstBinding, buffers.size() , reinterpret_cast<const VkBuffer*>( buffers.data() ), reinterpret_cast<const VkDeviceSize*>( offsets.data() ), reinterpret_cast<const VkDeviceSize*>( sizes.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindVertexBuffers( uint32_t firstBinding, uint32_t bindingCount, const vk::Buffer* pBuffers, const vk::DeviceSize* pOffsets, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBindVertexBuffers( m_commandBuffer, firstBinding, bindingCount, reinterpret_cast<const VkBuffer*>( pBuffers ), reinterpret_cast<const VkDeviceSize*>( pOffsets ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::bindVertexBuffers( uint32_t firstBinding, ArrayProxy<const vk::Buffer> buffers, ArrayProxy<const vk::DeviceSize> offsets, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( buffers.size() == offsets.size() );
#else
    if ( buffers.size() != offsets.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkCommandBuffer::bindVertexBuffers: buffers.size() != offsets.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    d.vkCmdBindVertexBuffers( m_commandBuffer, firstBinding, buffers.size() , reinterpret_cast<const VkBuffer*>( buffers.data() ), reinterpret_cast<const VkDeviceSize*>( offsets.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::blitImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::ImageBlit* pRegions, vk::Filter filter, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBlitImage( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regionCount, reinterpret_cast<const VkImageBlit*>( pRegions ), static_cast<VkFilter>( filter ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::blitImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::ImageBlit> regions, vk::Filter filter, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBlitImage( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regions.size() , reinterpret_cast<const VkImageBlit*>( regions.data() ), static_cast<VkFilter>( filter ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::buildAccelerationStructureNV( const vk::AccelerationStructureInfoNV* pInfo, vk::Buffer instanceData, vk::DeviceSize instanceOffset, vk::Bool32 update, vk::AccelerationStructureNV dst, vk::AccelerationStructureNV src, vk::Buffer scratch, vk::DeviceSize scratchOffset, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBuildAccelerationStructureNV( m_commandBuffer, reinterpret_cast<const VkAccelerationStructureInfoNV*>( pInfo ), static_cast<VkBuffer>( instanceData ), static_cast<VkDeviceSize>( instanceOffset ), static_cast<VkBool32>( update ), static_cast<VkAccelerationStructureNV>( dst ), static_cast<VkAccelerationStructureNV>( src ), static_cast<VkBuffer>( scratch ), static_cast<VkDeviceSize>( scratchOffset ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::buildAccelerationStructureNV( const AccelerationStructureInfoNV & info, vk::Buffer instanceData, vk::DeviceSize instanceOffset, vk::Bool32 update, vk::AccelerationStructureNV dst, vk::AccelerationStructureNV src, vk::Buffer scratch, vk::DeviceSize scratchOffset, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdBuildAccelerationStructureNV( m_commandBuffer, reinterpret_cast<const VkAccelerationStructureInfoNV*>( &info ), static_cast<VkBuffer>( instanceData ), static_cast<VkDeviceSize>( instanceOffset ), static_cast<VkBool32>( update ), static_cast<VkAccelerationStructureNV>( dst ), static_cast<VkAccelerationStructureNV>( src ), static_cast<VkBuffer>( scratch ), static_cast<VkDeviceSize>( scratchOffset ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::clearAttachments( uint32_t attachmentCount, const vk::ClearAttachment* pAttachments, uint32_t rectCount, const vk::ClearRect* pRects, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdClearAttachments( m_commandBuffer, attachmentCount, reinterpret_cast<const VkClearAttachment*>( pAttachments ), rectCount, reinterpret_cast<const VkClearRect*>( pRects ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::clearAttachments( ArrayProxy<const vk::ClearAttachment> attachments, ArrayProxy<const vk::ClearRect> rects, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdClearAttachments( m_commandBuffer, attachments.size() , reinterpret_cast<const VkClearAttachment*>( attachments.data() ), rects.size() , reinterpret_cast<const VkClearRect*>( rects.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::clearColorImage( vk::Image image, vk::ImageLayout imageLayout, const vk::ClearColorValue* pColor, uint32_t rangeCount, const vk::ImageSubresourceRange* pRanges, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdClearColorImage( m_commandBuffer, static_cast<VkImage>( image ), static_cast<VkImageLayout>( imageLayout ), reinterpret_cast<const VkClearColorValue*>( pColor ), rangeCount, reinterpret_cast<const VkImageSubresourceRange*>( pRanges ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::clearColorImage( vk::Image image, vk::ImageLayout imageLayout, const ClearColorValue & color, ArrayProxy<const vk::ImageSubresourceRange> ranges, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdClearColorImage( m_commandBuffer, static_cast<VkImage>( image ), static_cast<VkImageLayout>( imageLayout ), reinterpret_cast<const VkClearColorValue*>( &color ), ranges.size() , reinterpret_cast<const VkImageSubresourceRange*>( ranges.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::clearDepthStencilImage( vk::Image image, vk::ImageLayout imageLayout, const vk::ClearDepthStencilValue* pDepthStencil, uint32_t rangeCount, const vk::ImageSubresourceRange* pRanges, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdClearDepthStencilImage( m_commandBuffer, static_cast<VkImage>( image ), static_cast<VkImageLayout>( imageLayout ), reinterpret_cast<const VkClearDepthStencilValue*>( pDepthStencil ), rangeCount, reinterpret_cast<const VkImageSubresourceRange*>( pRanges ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::clearDepthStencilImage( vk::Image image, vk::ImageLayout imageLayout, const ClearDepthStencilValue & depthStencil, ArrayProxy<const vk::ImageSubresourceRange> ranges, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdClearDepthStencilImage( m_commandBuffer, static_cast<VkImage>( image ), static_cast<VkImageLayout>( imageLayout ), reinterpret_cast<const VkClearDepthStencilValue*>( &depthStencil ), ranges.size() , reinterpret_cast<const VkImageSubresourceRange*>( ranges.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyAccelerationStructureNV( vk::AccelerationStructureNV dst, vk::AccelerationStructureNV src, vk::CopyAccelerationStructureModeNV mode, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyAccelerationStructureNV( m_commandBuffer, static_cast<VkAccelerationStructureNV>( dst ), static_cast<VkAccelerationStructureNV>( src ), static_cast<VkCopyAccelerationStructureModeNV>( mode ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyAccelerationStructureNV( vk::AccelerationStructureNV dst, vk::AccelerationStructureNV src, vk::CopyAccelerationStructureModeNV mode, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyAccelerationStructureNV( m_commandBuffer, static_cast<VkAccelerationStructureNV>( dst ), static_cast<VkAccelerationStructureNV>( src ), static_cast<VkCopyAccelerationStructureModeNV>( mode ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyBuffer( vk::Buffer srcBuffer, vk::Buffer dstBuffer, uint32_t regionCount, const vk::BufferCopy* pRegions, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyBuffer( m_commandBuffer, static_cast<VkBuffer>( srcBuffer ), static_cast<VkBuffer>( dstBuffer ), regionCount, reinterpret_cast<const VkBufferCopy*>( pRegions ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyBuffer( vk::Buffer srcBuffer, vk::Buffer dstBuffer, ArrayProxy<const vk::BufferCopy> regions, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyBuffer( m_commandBuffer, static_cast<VkBuffer>( srcBuffer ), static_cast<VkBuffer>( dstBuffer ), regions.size() , reinterpret_cast<const VkBufferCopy*>( regions.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyBufferToImage( vk::Buffer srcBuffer, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::BufferImageCopy* pRegions, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyBufferToImage( m_commandBuffer, static_cast<VkBuffer>( srcBuffer ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regionCount, reinterpret_cast<const VkBufferImageCopy*>( pRegions ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyBufferToImage( vk::Buffer srcBuffer, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::BufferImageCopy> regions, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyBufferToImage( m_commandBuffer, static_cast<VkBuffer>( srcBuffer ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regions.size() , reinterpret_cast<const VkBufferImageCopy*>( regions.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::ImageCopy* pRegions, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyImage( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regionCount, reinterpret_cast<const VkImageCopy*>( pRegions ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::ImageCopy> regions, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyImage( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regions.size() , reinterpret_cast<const VkImageCopy*>( regions.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyImageToBuffer( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Buffer dstBuffer, uint32_t regionCount, const vk::BufferImageCopy* pRegions, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyImageToBuffer( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkBuffer>( dstBuffer ), regionCount, reinterpret_cast<const VkBufferImageCopy*>( pRegions ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyImageToBuffer( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Buffer dstBuffer, ArrayProxy<const vk::BufferImageCopy> regions, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyImageToBuffer( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkBuffer>( dstBuffer ), regions.size() , reinterpret_cast<const VkBufferImageCopy*>( regions.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyQueryPoolResults( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize stride, vk::QueryResultFlags flags, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyQueryPoolResults( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount, static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), static_cast<VkDeviceSize>( stride ), static_cast<VkQueryResultFlags>( flags ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::copyQueryPoolResults( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize stride, vk::QueryResultFlags flags, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdCopyQueryPoolResults( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount, static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), static_cast<VkDeviceSize>( stride ), static_cast<VkQueryResultFlags>( flags ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::debugMarkerBeginEXT( const vk::DebugMarkerMarkerInfoEXT* pMarkerInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDebugMarkerBeginEXT( m_commandBuffer, reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>( pMarkerInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::debugMarkerBeginEXT( const DebugMarkerMarkerInfoEXT & markerInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDebugMarkerBeginEXT( m_commandBuffer, reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>( &markerInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::debugMarkerEndEXT(Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDebugMarkerEndEXT( m_commandBuffer );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::debugMarkerEndEXT(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDebugMarkerEndEXT( m_commandBuffer );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::debugMarkerInsertEXT( const vk::DebugMarkerMarkerInfoEXT* pMarkerInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDebugMarkerInsertEXT( m_commandBuffer, reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>( pMarkerInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::debugMarkerInsertEXT( const DebugMarkerMarkerInfoEXT & markerInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDebugMarkerInsertEXT( m_commandBuffer, reinterpret_cast<const VkDebugMarkerMarkerInfoEXT*>( &markerInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatch( uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatch( m_commandBuffer, groupCountX, groupCountY, groupCountZ );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatch( uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatch( m_commandBuffer, groupCountX, groupCountY, groupCountZ );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatchBase( uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatchBase( m_commandBuffer, baseGroupX, baseGroupY, baseGroupZ, groupCountX, groupCountY, groupCountZ );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatchBase( uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatchBase( m_commandBuffer, baseGroupX, baseGroupY, baseGroupZ, groupCountX, groupCountY, groupCountZ );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatchBaseKHR( uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatchBaseKHR( m_commandBuffer, baseGroupX, baseGroupY, baseGroupZ, groupCountX, groupCountY, groupCountZ );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatchBaseKHR( uint32_t baseGroupX, uint32_t baseGroupY, uint32_t baseGroupZ, uint32_t groupCountX, uint32_t groupCountY, uint32_t groupCountZ, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatchBaseKHR( m_commandBuffer, baseGroupX, baseGroupY, baseGroupZ, groupCountX, groupCountY, groupCountZ );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatchIndirect( vk::Buffer buffer, vk::DeviceSize offset, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatchIndirect( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::dispatchIndirect( vk::Buffer buffer, vk::DeviceSize offset, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDispatchIndirect( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::draw( uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDraw( m_commandBuffer, vertexCount, instanceCount, firstVertex, firstInstance );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::draw( uint32_t vertexCount, uint32_t instanceCount, uint32_t firstVertex, uint32_t firstInstance, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDraw( m_commandBuffer, vertexCount, instanceCount, firstVertex, firstInstance );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexed( uint32_t indexCount, uint32_t instanceCount, uint32_t firstIndex, int32_t vertexOffset, uint32_t firstInstance, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexed( m_commandBuffer, indexCount, instanceCount, firstIndex, vertexOffset, firstInstance );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexed( uint32_t indexCount, uint32_t instanceCount, uint32_t firstIndex, int32_t vertexOffset, uint32_t firstInstance, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexed( m_commandBuffer, indexCount, instanceCount, firstIndex, vertexOffset, firstInstance );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexedIndirect( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexedIndirect( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), drawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexedIndirect( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexedIndirect( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), drawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexedIndirectCountAMD( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexedIndirectCountAMD( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexedIndirectCountAMD( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexedIndirectCountAMD( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexedIndirectCountKHR( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexedIndirectCountKHR( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndexedIndirectCountKHR( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndexedIndirectCountKHR( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirect( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirect( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), drawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirect( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirect( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), drawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirectByteCountEXT( uint32_t instanceCount, uint32_t firstInstance, vk::Buffer counterBuffer, vk::DeviceSize counterBufferOffset, uint32_t counterOffset, uint32_t vertexStride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirectByteCountEXT( m_commandBuffer, instanceCount, firstInstance, static_cast<VkBuffer>( counterBuffer ), static_cast<VkDeviceSize>( counterBufferOffset ), counterOffset, vertexStride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirectByteCountEXT( uint32_t instanceCount, uint32_t firstInstance, vk::Buffer counterBuffer, vk::DeviceSize counterBufferOffset, uint32_t counterOffset, uint32_t vertexStride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirectByteCountEXT( m_commandBuffer, instanceCount, firstInstance, static_cast<VkBuffer>( counterBuffer ), static_cast<VkDeviceSize>( counterBufferOffset ), counterOffset, vertexStride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirectCountAMD( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirectCountAMD( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirectCountAMD( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirectCountAMD( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirectCountKHR( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirectCountKHR( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawIndirectCountKHR( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawIndirectCountKHR( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawMeshTasksIndirectCountNV( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawMeshTasksIndirectCountNV( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawMeshTasksIndirectCountNV( vk::Buffer buffer, vk::DeviceSize offset, vk::Buffer countBuffer, vk::DeviceSize countBufferOffset, uint32_t maxDrawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawMeshTasksIndirectCountNV( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), static_cast<VkBuffer>( countBuffer ), static_cast<VkDeviceSize>( countBufferOffset ), maxDrawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawMeshTasksIndirectNV( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawMeshTasksIndirectNV( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), drawCount, stride );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawMeshTasksIndirectNV( vk::Buffer buffer, vk::DeviceSize offset, uint32_t drawCount, uint32_t stride, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawMeshTasksIndirectNV( m_commandBuffer, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceSize>( offset ), drawCount, stride );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawMeshTasksNV( uint32_t taskCount, uint32_t firstTask, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawMeshTasksNV( m_commandBuffer, taskCount, firstTask );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::drawMeshTasksNV( uint32_t taskCount, uint32_t firstTask, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdDrawMeshTasksNV( m_commandBuffer, taskCount, firstTask );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endConditionalRenderingEXT(Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndConditionalRenderingEXT( m_commandBuffer );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endConditionalRenderingEXT(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndConditionalRenderingEXT( m_commandBuffer );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endDebugUtilsLabelEXT(Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndDebugUtilsLabelEXT( m_commandBuffer );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endDebugUtilsLabelEXT(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndDebugUtilsLabelEXT( m_commandBuffer );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endQuery( vk::QueryPool queryPool, uint32_t query, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndQuery( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endQuery( vk::QueryPool queryPool, uint32_t query, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndQuery( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endQueryIndexedEXT( vk::QueryPool queryPool, uint32_t query, uint32_t index, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndQueryIndexedEXT( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query, index );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endQueryIndexedEXT( vk::QueryPool queryPool, uint32_t query, uint32_t index, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndQueryIndexedEXT( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), query, index );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endRenderPass(Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndRenderPass( m_commandBuffer );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endRenderPass(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndRenderPass( m_commandBuffer );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endRenderPass2KHR( const vk::SubpassEndInfoKHR* pSubpassEndInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndRenderPass2KHR( m_commandBuffer, reinterpret_cast<const VkSubpassEndInfoKHR*>( pSubpassEndInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endRenderPass2KHR( const SubpassEndInfoKHR & subpassEndInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndRenderPass2KHR( m_commandBuffer, reinterpret_cast<const VkSubpassEndInfoKHR*>( &subpassEndInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endTransformFeedbackEXT( uint32_t firstCounterBuffer, uint32_t counterBufferCount, const vk::Buffer* pCounterBuffers, const vk::DeviceSize* pCounterBufferOffsets, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdEndTransformFeedbackEXT( m_commandBuffer, firstCounterBuffer, counterBufferCount, reinterpret_cast<const VkBuffer*>( pCounterBuffers ), reinterpret_cast<const VkDeviceSize*>( pCounterBufferOffsets ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::endTransformFeedbackEXT( uint32_t firstCounterBuffer, ArrayProxy<const vk::Buffer> counterBuffers, ArrayProxy<const vk::DeviceSize> counterBufferOffsets, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( counterBuffers.size() == counterBufferOffsets.size() );
#else
    if ( counterBuffers.size() != counterBufferOffsets.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkCommandBuffer::endTransformFeedbackEXT: counterBuffers.size() != counterBufferOffsets.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    d.vkCmdEndTransformFeedbackEXT( m_commandBuffer, firstCounterBuffer, counterBuffers.size() , reinterpret_cast<const VkBuffer*>( counterBuffers.data() ), reinterpret_cast<const VkDeviceSize*>( counterBufferOffsets.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::executeCommands( uint32_t commandBufferCount, const vk::CommandBuffer* pCommandBuffers, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdExecuteCommands( m_commandBuffer, commandBufferCount, reinterpret_cast<const VkCommandBuffer*>( pCommandBuffers ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::executeCommands( ArrayProxy<const vk::CommandBuffer> commandBuffers, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdExecuteCommands( m_commandBuffer, commandBuffers.size() , reinterpret_cast<const VkCommandBuffer*>( commandBuffers.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::fillBuffer( vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize size, uint32_t data, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdFillBuffer( m_commandBuffer, static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), static_cast<VkDeviceSize>( size ), data );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::fillBuffer( vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize size, uint32_t data, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdFillBuffer( m_commandBuffer, static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), static_cast<VkDeviceSize>( size ), data );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::insertDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdInsertDebugUtilsLabelEXT( m_commandBuffer, reinterpret_cast<const VkDebugUtilsLabelEXT*>( pLabelInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::insertDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdInsertDebugUtilsLabelEXT( m_commandBuffer, reinterpret_cast<const VkDebugUtilsLabelEXT*>( &labelInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::nextSubpass( vk::SubpassContents contents, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdNextSubpass( m_commandBuffer, static_cast<VkSubpassContents>( contents ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::nextSubpass( vk::SubpassContents contents, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdNextSubpass( m_commandBuffer, static_cast<VkSubpassContents>( contents ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::nextSubpass2KHR( const vk::SubpassBeginInfoKHR* pSubpassBeginInfo, const vk::SubpassEndInfoKHR* pSubpassEndInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdNextSubpass2KHR( m_commandBuffer, reinterpret_cast<const VkSubpassBeginInfoKHR*>( pSubpassBeginInfo ), reinterpret_cast<const VkSubpassEndInfoKHR*>( pSubpassEndInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::nextSubpass2KHR( const SubpassBeginInfoKHR & subpassBeginInfo, const SubpassEndInfoKHR & subpassEndInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdNextSubpass2KHR( m_commandBuffer, reinterpret_cast<const VkSubpassBeginInfoKHR*>( &subpassBeginInfo ), reinterpret_cast<const VkSubpassEndInfoKHR*>( &subpassEndInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pipelineBarrier( vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, vk::DependencyFlags dependencyFlags, uint32_t memoryBarrierCount, const vk::MemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const vk::BufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const vk::ImageMemoryBarrier* pImageMemoryBarriers, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPipelineBarrier( m_commandBuffer, static_cast<VkPipelineStageFlags>( srcStageMask ), static_cast<VkPipelineStageFlags>( dstStageMask ), static_cast<VkDependencyFlags>( dependencyFlags ), memoryBarrierCount, reinterpret_cast<const VkMemoryBarrier*>( pMemoryBarriers ), bufferMemoryBarrierCount, reinterpret_cast<const VkBufferMemoryBarrier*>( pBufferMemoryBarriers ), imageMemoryBarrierCount, reinterpret_cast<const VkImageMemoryBarrier*>( pImageMemoryBarriers ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pipelineBarrier( vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, vk::DependencyFlags dependencyFlags, ArrayProxy<const vk::MemoryBarrier> memoryBarriers, ArrayProxy<const vk::BufferMemoryBarrier> bufferMemoryBarriers, ArrayProxy<const vk::ImageMemoryBarrier> imageMemoryBarriers, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPipelineBarrier( m_commandBuffer, static_cast<VkPipelineStageFlags>( srcStageMask ), static_cast<VkPipelineStageFlags>( dstStageMask ), static_cast<VkDependencyFlags>( dependencyFlags ), memoryBarriers.size() , reinterpret_cast<const VkMemoryBarrier*>( memoryBarriers.data() ), bufferMemoryBarriers.size() , reinterpret_cast<const VkBufferMemoryBarrier*>( bufferMemoryBarriers.data() ), imageMemoryBarriers.size() , reinterpret_cast<const VkImageMemoryBarrier*>( imageMemoryBarriers.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::processCommandsNVX( const vk::CmdProcessCommandsInfoNVX* pProcessCommandsInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdProcessCommandsNVX( m_commandBuffer, reinterpret_cast<const VkCmdProcessCommandsInfoNVX*>( pProcessCommandsInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::processCommandsNVX( const CmdProcessCommandsInfoNVX & processCommandsInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdProcessCommandsNVX( m_commandBuffer, reinterpret_cast<const VkCmdProcessCommandsInfoNVX*>( &processCommandsInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pushConstants( vk::PipelineLayout layout, vk::ShaderStageFlags stageFlags, uint32_t offset, uint32_t size, const void* pValues, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPushConstants( m_commandBuffer, static_cast<VkPipelineLayout>( layout ), static_cast<VkShaderStageFlags>( stageFlags ), offset, size, pValues );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename T, typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pushConstants( vk::PipelineLayout layout, vk::ShaderStageFlags stageFlags, uint32_t offset, ArrayProxy<const T> values, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPushConstants( m_commandBuffer, static_cast<VkPipelineLayout>( layout ), static_cast<VkShaderStageFlags>( stageFlags ), offset, values.size() * sizeof( T ) , reinterpret_cast<const void*>( values.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pushDescriptorSetKHR( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t set, uint32_t descriptorWriteCount, const vk::WriteDescriptorSet* pDescriptorWrites, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPushDescriptorSetKHR( m_commandBuffer, static_cast<VkPipelineBindPoint>( pipelineBindPoint ), static_cast<VkPipelineLayout>( layout ), set, descriptorWriteCount, reinterpret_cast<const VkWriteDescriptorSet*>( pDescriptorWrites ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pushDescriptorSetKHR( vk::PipelineBindPoint pipelineBindPoint, vk::PipelineLayout layout, uint32_t set, ArrayProxy<const vk::WriteDescriptorSet> descriptorWrites, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPushDescriptorSetKHR( m_commandBuffer, static_cast<VkPipelineBindPoint>( pipelineBindPoint ), static_cast<VkPipelineLayout>( layout ), set, descriptorWrites.size() , reinterpret_cast<const VkWriteDescriptorSet*>( descriptorWrites.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pushDescriptorSetWithTemplateKHR( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, vk::PipelineLayout layout, uint32_t set, const void* pData, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPushDescriptorSetWithTemplateKHR( m_commandBuffer, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), static_cast<VkPipelineLayout>( layout ), set, pData );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::pushDescriptorSetWithTemplateKHR( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, vk::PipelineLayout layout, uint32_t set, const void* pData, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdPushDescriptorSetWithTemplateKHR( m_commandBuffer, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), static_cast<VkPipelineLayout>( layout ), set, pData );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::reserveSpaceForCommandsNVX( const vk::CmdReserveSpaceForCommandsInfoNVX* pReserveSpaceInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdReserveSpaceForCommandsNVX( m_commandBuffer, reinterpret_cast<const VkCmdReserveSpaceForCommandsInfoNVX*>( pReserveSpaceInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::reserveSpaceForCommandsNVX( const CmdReserveSpaceForCommandsInfoNVX & reserveSpaceInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdReserveSpaceForCommandsNVX( m_commandBuffer, reinterpret_cast<const VkCmdReserveSpaceForCommandsInfoNVX*>( &reserveSpaceInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::resetEvent( vk::Event event, vk::PipelineStageFlags stageMask, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdResetEvent( m_commandBuffer, static_cast<VkEvent>( event ), static_cast<VkPipelineStageFlags>( stageMask ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::resetEvent( vk::Event event, vk::PipelineStageFlags stageMask, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdResetEvent( m_commandBuffer, static_cast<VkEvent>( event ), static_cast<VkPipelineStageFlags>( stageMask ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::resetQueryPool( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdResetQueryPool( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::resetQueryPool( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdResetQueryPool( m_commandBuffer, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::resolveImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, uint32_t regionCount, const vk::ImageResolve* pRegions, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdResolveImage( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regionCount, reinterpret_cast<const VkImageResolve*>( pRegions ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::resolveImage( vk::Image srcImage, vk::ImageLayout srcImageLayout, vk::Image dstImage, vk::ImageLayout dstImageLayout, ArrayProxy<const vk::ImageResolve> regions, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdResolveImage( m_commandBuffer, static_cast<VkImage>( srcImage ), static_cast<VkImageLayout>( srcImageLayout ), static_cast<VkImage>( dstImage ), static_cast<VkImageLayout>( dstImageLayout ), regions.size() , reinterpret_cast<const VkImageResolve*>( regions.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setBlendConstants( const float blendConstants[4], Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetBlendConstants( m_commandBuffer, blendConstants );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setBlendConstants( const float blendConstants[4], Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetBlendConstants( m_commandBuffer, blendConstants );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setCheckpointNV( const void* pCheckpointMarker, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetCheckpointNV( m_commandBuffer, pCheckpointMarker );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setCheckpointNV( const void* pCheckpointMarker, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetCheckpointNV( m_commandBuffer, pCheckpointMarker );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setCoarseSampleOrderNV( vk::CoarseSampleOrderTypeNV sampleOrderType, uint32_t customSampleOrderCount, const vk::CoarseSampleOrderCustomNV* pCustomSampleOrders, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetCoarseSampleOrderNV( m_commandBuffer, static_cast<VkCoarseSampleOrderTypeNV>( sampleOrderType ), customSampleOrderCount, reinterpret_cast<const VkCoarseSampleOrderCustomNV*>( pCustomSampleOrders ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setCoarseSampleOrderNV( vk::CoarseSampleOrderTypeNV sampleOrderType, ArrayProxy<const vk::CoarseSampleOrderCustomNV> customSampleOrders, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetCoarseSampleOrderNV( m_commandBuffer, static_cast<VkCoarseSampleOrderTypeNV>( sampleOrderType ), customSampleOrders.size() , reinterpret_cast<const VkCoarseSampleOrderCustomNV*>( customSampleOrders.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDepthBias( float depthBiasConstantFactor, float depthBiasClamp, float depthBiasSlopeFactor, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDepthBias( m_commandBuffer, depthBiasConstantFactor, depthBiasClamp, depthBiasSlopeFactor );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDepthBias( float depthBiasConstantFactor, float depthBiasClamp, float depthBiasSlopeFactor, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDepthBias( m_commandBuffer, depthBiasConstantFactor, depthBiasClamp, depthBiasSlopeFactor );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDepthBounds( float minDepthBounds, float maxDepthBounds, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDepthBounds( m_commandBuffer, minDepthBounds, maxDepthBounds );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDepthBounds( float minDepthBounds, float maxDepthBounds, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDepthBounds( m_commandBuffer, minDepthBounds, maxDepthBounds );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDeviceMask( uint32_t deviceMask, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDeviceMask( m_commandBuffer, deviceMask );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDeviceMask( uint32_t deviceMask, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDeviceMask( m_commandBuffer, deviceMask );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDeviceMaskKHR( uint32_t deviceMask, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDeviceMaskKHR( m_commandBuffer, deviceMask );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDeviceMaskKHR( uint32_t deviceMask, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDeviceMaskKHR( m_commandBuffer, deviceMask );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDiscardRectangleEXT( uint32_t firstDiscardRectangle, uint32_t discardRectangleCount, const vk::Rect2D* pDiscardRectangles, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDiscardRectangleEXT( m_commandBuffer, firstDiscardRectangle, discardRectangleCount, reinterpret_cast<const VkRect2D*>( pDiscardRectangles ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setDiscardRectangleEXT( uint32_t firstDiscardRectangle, ArrayProxy<const vk::Rect2D> discardRectangles, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetDiscardRectangleEXT( m_commandBuffer, firstDiscardRectangle, discardRectangles.size() , reinterpret_cast<const VkRect2D*>( discardRectangles.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setEvent( vk::Event event, vk::PipelineStageFlags stageMask, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetEvent( m_commandBuffer, static_cast<VkEvent>( event ), static_cast<VkPipelineStageFlags>( stageMask ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setEvent( vk::Event event, vk::PipelineStageFlags stageMask, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetEvent( m_commandBuffer, static_cast<VkEvent>( event ), static_cast<VkPipelineStageFlags>( stageMask ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setExclusiveScissorNV( uint32_t firstExclusiveScissor, uint32_t exclusiveScissorCount, const vk::Rect2D* pExclusiveScissors, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetExclusiveScissorNV( m_commandBuffer, firstExclusiveScissor, exclusiveScissorCount, reinterpret_cast<const VkRect2D*>( pExclusiveScissors ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setExclusiveScissorNV( uint32_t firstExclusiveScissor, ArrayProxy<const vk::Rect2D> exclusiveScissors, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetExclusiveScissorNV( m_commandBuffer, firstExclusiveScissor, exclusiveScissors.size() , reinterpret_cast<const VkRect2D*>( exclusiveScissors.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setLineStippleEXT( uint32_t lineStippleFactor, uint16_t lineStipplePattern, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetLineStippleEXT( m_commandBuffer, lineStippleFactor, lineStipplePattern );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setLineStippleEXT( uint32_t lineStippleFactor, uint16_t lineStipplePattern, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetLineStippleEXT( m_commandBuffer, lineStippleFactor, lineStipplePattern );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setLineWidth( float lineWidth, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetLineWidth( m_commandBuffer, lineWidth );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setLineWidth( float lineWidth, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetLineWidth( m_commandBuffer, lineWidth );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result CommandBuffer::setPerformanceMarkerINTEL( const vk::PerformanceMarkerInfoINTEL* pMarkerInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCmdSetPerformanceMarkerINTEL( m_commandBuffer, reinterpret_cast<const VkPerformanceMarkerInfoINTEL*>( pMarkerInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type CommandBuffer::setPerformanceMarkerINTEL( const PerformanceMarkerInfoINTEL & markerInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkCmdSetPerformanceMarkerINTEL( m_commandBuffer, reinterpret_cast<const VkPerformanceMarkerInfoINTEL*>( &markerInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::CommandBuffer::setPerformanceMarkerINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result CommandBuffer::setPerformanceOverrideINTEL( const vk::PerformanceOverrideInfoINTEL* pOverrideInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCmdSetPerformanceOverrideINTEL( m_commandBuffer, reinterpret_cast<const VkPerformanceOverrideInfoINTEL*>( pOverrideInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type CommandBuffer::setPerformanceOverrideINTEL( const PerformanceOverrideInfoINTEL & overrideInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkCmdSetPerformanceOverrideINTEL( m_commandBuffer, reinterpret_cast<const VkPerformanceOverrideInfoINTEL*>( &overrideInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::CommandBuffer::setPerformanceOverrideINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result CommandBuffer::setPerformanceStreamMarkerINTEL( const vk::PerformanceStreamMarkerInfoINTEL* pMarkerInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCmdSetPerformanceStreamMarkerINTEL( m_commandBuffer, reinterpret_cast<const VkPerformanceStreamMarkerInfoINTEL*>( pMarkerInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type CommandBuffer::setPerformanceStreamMarkerINTEL( const PerformanceStreamMarkerInfoINTEL & markerInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkCmdSetPerformanceStreamMarkerINTEL( m_commandBuffer, reinterpret_cast<const VkPerformanceStreamMarkerInfoINTEL*>( &markerInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::CommandBuffer::setPerformanceStreamMarkerINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setSampleLocationsEXT( const vk::SampleLocationsInfoEXT* pSampleLocationsInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetSampleLocationsEXT( m_commandBuffer, reinterpret_cast<const VkSampleLocationsInfoEXT*>( pSampleLocationsInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setSampleLocationsEXT( const SampleLocationsInfoEXT & sampleLocationsInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetSampleLocationsEXT( m_commandBuffer, reinterpret_cast<const VkSampleLocationsInfoEXT*>( &sampleLocationsInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setScissor( uint32_t firstScissor, uint32_t scissorCount, const vk::Rect2D* pScissors, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetScissor( m_commandBuffer, firstScissor, scissorCount, reinterpret_cast<const VkRect2D*>( pScissors ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setScissor( uint32_t firstScissor, ArrayProxy<const vk::Rect2D> scissors, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetScissor( m_commandBuffer, firstScissor, scissors.size() , reinterpret_cast<const VkRect2D*>( scissors.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setStencilCompareMask( vk::StencilFaceFlags faceMask, uint32_t compareMask, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetStencilCompareMask( m_commandBuffer, static_cast<VkStencilFaceFlags>( faceMask ), compareMask );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setStencilCompareMask( vk::StencilFaceFlags faceMask, uint32_t compareMask, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetStencilCompareMask( m_commandBuffer, static_cast<VkStencilFaceFlags>( faceMask ), compareMask );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setStencilReference( vk::StencilFaceFlags faceMask, uint32_t reference, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetStencilReference( m_commandBuffer, static_cast<VkStencilFaceFlags>( faceMask ), reference );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setStencilReference( vk::StencilFaceFlags faceMask, uint32_t reference, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetStencilReference( m_commandBuffer, static_cast<VkStencilFaceFlags>( faceMask ), reference );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setStencilWriteMask( vk::StencilFaceFlags faceMask, uint32_t writeMask, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetStencilWriteMask( m_commandBuffer, static_cast<VkStencilFaceFlags>( faceMask ), writeMask );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setStencilWriteMask( vk::StencilFaceFlags faceMask, uint32_t writeMask, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetStencilWriteMask( m_commandBuffer, static_cast<VkStencilFaceFlags>( faceMask ), writeMask );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setViewport( uint32_t firstViewport, uint32_t viewportCount, const vk::Viewport* pViewports, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetViewport( m_commandBuffer, firstViewport, viewportCount, reinterpret_cast<const VkViewport*>( pViewports ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setViewport( uint32_t firstViewport, ArrayProxy<const vk::Viewport> viewports, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetViewport( m_commandBuffer, firstViewport, viewports.size() , reinterpret_cast<const VkViewport*>( viewports.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setViewportShadingRatePaletteNV( uint32_t firstViewport, uint32_t viewportCount, const vk::ShadingRatePaletteNV* pShadingRatePalettes, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetViewportShadingRatePaletteNV( m_commandBuffer, firstViewport, viewportCount, reinterpret_cast<const VkShadingRatePaletteNV*>( pShadingRatePalettes ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setViewportShadingRatePaletteNV( uint32_t firstViewport, ArrayProxy<const vk::ShadingRatePaletteNV> shadingRatePalettes, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetViewportShadingRatePaletteNV( m_commandBuffer, firstViewport, shadingRatePalettes.size() , reinterpret_cast<const VkShadingRatePaletteNV*>( shadingRatePalettes.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setViewportWScalingNV( uint32_t firstViewport, uint32_t viewportCount, const vk::ViewportWScalingNV* pViewportWScalings, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetViewportWScalingNV( m_commandBuffer, firstViewport, viewportCount, reinterpret_cast<const VkViewportWScalingNV*>( pViewportWScalings ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::setViewportWScalingNV( uint32_t firstViewport, ArrayProxy<const vk::ViewportWScalingNV> viewportWScalings, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdSetViewportWScalingNV( m_commandBuffer, firstViewport, viewportWScalings.size() , reinterpret_cast<const VkViewportWScalingNV*>( viewportWScalings.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::traceRaysNV( vk::Buffer raygenShaderBindingTableBuffer, vk::DeviceSize raygenShaderBindingOffset, vk::Buffer missShaderBindingTableBuffer, vk::DeviceSize missShaderBindingOffset, vk::DeviceSize missShaderBindingStride, vk::Buffer hitShaderBindingTableBuffer, vk::DeviceSize hitShaderBindingOffset, vk::DeviceSize hitShaderBindingStride, vk::Buffer callableShaderBindingTableBuffer, vk::DeviceSize callableShaderBindingOffset, vk::DeviceSize callableShaderBindingStride, uint32_t width, uint32_t height, uint32_t depth, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdTraceRaysNV( m_commandBuffer, static_cast<VkBuffer>( raygenShaderBindingTableBuffer ), static_cast<VkDeviceSize>( raygenShaderBindingOffset ), static_cast<VkBuffer>( missShaderBindingTableBuffer ), static_cast<VkDeviceSize>( missShaderBindingOffset ), static_cast<VkDeviceSize>( missShaderBindingStride ), static_cast<VkBuffer>( hitShaderBindingTableBuffer ), static_cast<VkDeviceSize>( hitShaderBindingOffset ), static_cast<VkDeviceSize>( hitShaderBindingStride ), static_cast<VkBuffer>( callableShaderBindingTableBuffer ), static_cast<VkDeviceSize>( callableShaderBindingOffset ), static_cast<VkDeviceSize>( callableShaderBindingStride ), width, height, depth );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::traceRaysNV( vk::Buffer raygenShaderBindingTableBuffer, vk::DeviceSize raygenShaderBindingOffset, vk::Buffer missShaderBindingTableBuffer, vk::DeviceSize missShaderBindingOffset, vk::DeviceSize missShaderBindingStride, vk::Buffer hitShaderBindingTableBuffer, vk::DeviceSize hitShaderBindingOffset, vk::DeviceSize hitShaderBindingStride, vk::Buffer callableShaderBindingTableBuffer, vk::DeviceSize callableShaderBindingOffset, vk::DeviceSize callableShaderBindingStride, uint32_t width, uint32_t height, uint32_t depth, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdTraceRaysNV( m_commandBuffer, static_cast<VkBuffer>( raygenShaderBindingTableBuffer ), static_cast<VkDeviceSize>( raygenShaderBindingOffset ), static_cast<VkBuffer>( missShaderBindingTableBuffer ), static_cast<VkDeviceSize>( missShaderBindingOffset ), static_cast<VkDeviceSize>( missShaderBindingStride ), static_cast<VkBuffer>( hitShaderBindingTableBuffer ), static_cast<VkDeviceSize>( hitShaderBindingOffset ), static_cast<VkDeviceSize>( hitShaderBindingStride ), static_cast<VkBuffer>( callableShaderBindingTableBuffer ), static_cast<VkDeviceSize>( callableShaderBindingOffset ), static_cast<VkDeviceSize>( callableShaderBindingStride ), width, height, depth );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::updateBuffer( vk::Buffer dstBuffer, vk::DeviceSize dstOffset, vk::DeviceSize dataSize, const void* pData, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdUpdateBuffer( m_commandBuffer, static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), static_cast<VkDeviceSize>( dataSize ), pData );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename T, typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::updateBuffer( vk::Buffer dstBuffer, vk::DeviceSize dstOffset, ArrayProxy<const T> data, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdUpdateBuffer( m_commandBuffer, static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), data.size() * sizeof( T ) , reinterpret_cast<const void*>( data.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::waitEvents( uint32_t eventCount, const vk::Event* pEvents, vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, uint32_t memoryBarrierCount, const vk::MemoryBarrier* pMemoryBarriers, uint32_t bufferMemoryBarrierCount, const vk::BufferMemoryBarrier* pBufferMemoryBarriers, uint32_t imageMemoryBarrierCount, const vk::ImageMemoryBarrier* pImageMemoryBarriers, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWaitEvents( m_commandBuffer, eventCount, reinterpret_cast<const VkEvent*>( pEvents ), static_cast<VkPipelineStageFlags>( srcStageMask ), static_cast<VkPipelineStageFlags>( dstStageMask ), memoryBarrierCount, reinterpret_cast<const VkMemoryBarrier*>( pMemoryBarriers ), bufferMemoryBarrierCount, reinterpret_cast<const VkBufferMemoryBarrier*>( pBufferMemoryBarriers ), imageMemoryBarrierCount, reinterpret_cast<const VkImageMemoryBarrier*>( pImageMemoryBarriers ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::waitEvents( ArrayProxy<const vk::Event> events, vk::PipelineStageFlags srcStageMask, vk::PipelineStageFlags dstStageMask, ArrayProxy<const vk::MemoryBarrier> memoryBarriers, ArrayProxy<const vk::BufferMemoryBarrier> bufferMemoryBarriers, ArrayProxy<const vk::ImageMemoryBarrier> imageMemoryBarriers, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWaitEvents( m_commandBuffer, events.size() , reinterpret_cast<const VkEvent*>( events.data() ), static_cast<VkPipelineStageFlags>( srcStageMask ), static_cast<VkPipelineStageFlags>( dstStageMask ), memoryBarriers.size() , reinterpret_cast<const VkMemoryBarrier*>( memoryBarriers.data() ), bufferMemoryBarriers.size() , reinterpret_cast<const VkBufferMemoryBarrier*>( bufferMemoryBarriers.data() ), imageMemoryBarriers.size() , reinterpret_cast<const VkImageMemoryBarrier*>( imageMemoryBarriers.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::writeAccelerationStructuresPropertiesNV( uint32_t accelerationStructureCount, const vk::AccelerationStructureNV* pAccelerationStructures, vk::QueryType queryType, vk::QueryPool queryPool, uint32_t firstQuery, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWriteAccelerationStructuresPropertiesNV( m_commandBuffer, accelerationStructureCount, reinterpret_cast<const VkAccelerationStructureNV*>( pAccelerationStructures ), static_cast<VkQueryType>( queryType ), static_cast<VkQueryPool>( queryPool ), firstQuery );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::writeAccelerationStructuresPropertiesNV( ArrayProxy<const vk::AccelerationStructureNV> accelerationStructures, vk::QueryType queryType, vk::QueryPool queryPool, uint32_t firstQuery, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWriteAccelerationStructuresPropertiesNV( m_commandBuffer, accelerationStructures.size() , reinterpret_cast<const VkAccelerationStructureNV*>( accelerationStructures.data() ), static_cast<VkQueryType>( queryType ), static_cast<VkQueryPool>( queryPool ), firstQuery );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::writeBufferMarkerAMD( vk::PipelineStageFlagBits pipelineStage, vk::Buffer dstBuffer, vk::DeviceSize dstOffset, uint32_t marker, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWriteBufferMarkerAMD( m_commandBuffer, static_cast<VkPipelineStageFlagBits>( pipelineStage ), static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), marker );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::writeBufferMarkerAMD( vk::PipelineStageFlagBits pipelineStage, vk::Buffer dstBuffer, vk::DeviceSize dstOffset, uint32_t marker, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWriteBufferMarkerAMD( m_commandBuffer, static_cast<VkPipelineStageFlagBits>( pipelineStage ), static_cast<VkBuffer>( dstBuffer ), static_cast<VkDeviceSize>( dstOffset ), marker );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::writeTimestamp( vk::PipelineStageFlagBits pipelineStage, vk::QueryPool queryPool, uint32_t query, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWriteTimestamp( m_commandBuffer, static_cast<VkPipelineStageFlagBits>( pipelineStage ), static_cast<VkQueryPool>( queryPool ), query );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void CommandBuffer::writeTimestamp( vk::PipelineStageFlagBits pipelineStage, vk::QueryPool queryPool, uint32_t query, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkCmdWriteTimestamp( m_commandBuffer, static_cast<VkPipelineStageFlagBits>( pipelineStage ), static_cast<VkQueryPool>( queryPool ), query );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result CommandBuffer::end(Dispatch const &d) const
  {
    return static_cast<Result>( d.vkEndCommandBuffer( m_commandBuffer ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type CommandBuffer::end(Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkEndCommandBuffer( m_commandBuffer ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::CommandBuffer::end" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result CommandBuffer::reset( vk::CommandBufferResetFlags flags, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkResetCommandBuffer( m_commandBuffer, static_cast<VkCommandBufferResetFlags>( flags ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type CommandBuffer::reset( vk::CommandBufferResetFlags flags, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkResetCommandBuffer( m_commandBuffer, static_cast<VkCommandBufferResetFlags>( flags ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::CommandBuffer::reset" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::acquireFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAcquireFullScreenExclusiveModeEXT( m_device, static_cast<VkSwapchainKHR>( swapchain ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::acquireFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkAcquireFullScreenExclusiveModeEXT( m_device, static_cast<VkSwapchainKHR>( swapchain ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::acquireFullScreenExclusiveModeEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::acquireNextImage2KHR( const vk::AcquireNextImageInfoKHR* pAcquireInfo, uint32_t* pImageIndex, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAcquireNextImage2KHR( m_device, reinterpret_cast<const VkAcquireNextImageInfoKHR*>( pAcquireInfo ), pImageIndex ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValue<uint32_t> Device::acquireNextImage2KHR( const AcquireNextImageInfoKHR & acquireInfo, Dispatch const &d ) const
  {
    uint32_t imageIndex;
    Result result = static_cast<Result>( d.vkAcquireNextImage2KHR( m_device, reinterpret_cast<const VkAcquireNextImageInfoKHR*>( &acquireInfo ), &imageIndex ) );
    return createResultValue( result, imageIndex, VULKAN_HPP_NAMESPACE_STRING"::Device::acquireNextImage2KHR", { Result::eSuccess, Result::eTimeout, Result::eNotReady, Result::eSuboptimalKHR } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::acquireNextImageKHR( vk::SwapchainKHR swapchain, uint64_t timeout, vk::Semaphore semaphore, vk::Fence fence, uint32_t* pImageIndex, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAcquireNextImageKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), timeout, static_cast<VkSemaphore>( semaphore ), static_cast<VkFence>( fence ), pImageIndex ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValue<uint32_t> Device::acquireNextImageKHR( vk::SwapchainKHR swapchain, uint64_t timeout, vk::Semaphore semaphore, vk::Fence fence, Dispatch const &d ) const
  {
    uint32_t imageIndex;
    Result result = static_cast<Result>( d.vkAcquireNextImageKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), timeout, static_cast<VkSemaphore>( semaphore ), static_cast<VkFence>( fence ), &imageIndex ) );
    return createResultValue( result, imageIndex, VULKAN_HPP_NAMESPACE_STRING"::Device::acquireNextImageKHR", { Result::eSuccess, Result::eTimeout, Result::eNotReady, Result::eSuboptimalKHR } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::acquirePerformanceConfigurationINTEL( const vk::PerformanceConfigurationAcquireInfoINTEL* pAcquireInfo, vk::PerformanceConfigurationINTEL* pConfiguration, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAcquirePerformanceConfigurationINTEL( m_device, reinterpret_cast<const VkPerformanceConfigurationAcquireInfoINTEL*>( pAcquireInfo ), reinterpret_cast<VkPerformanceConfigurationINTEL*>( pConfiguration ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::PerformanceConfigurationINTEL>::type Device::acquirePerformanceConfigurationINTEL( const PerformanceConfigurationAcquireInfoINTEL & acquireInfo, Dispatch const &d ) const
  {
    vk::PerformanceConfigurationINTEL configuration;
    Result result = static_cast<Result>( d.vkAcquirePerformanceConfigurationINTEL( m_device, reinterpret_cast<const VkPerformanceConfigurationAcquireInfoINTEL*>( &acquireInfo ), reinterpret_cast<VkPerformanceConfigurationINTEL*>( &configuration ) ) );
    return createResultValue( result, configuration, VULKAN_HPP_NAMESPACE_STRING"::Device::acquirePerformanceConfigurationINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::allocateCommandBuffers( const vk::CommandBufferAllocateInfo* pAllocateInfo, vk::CommandBuffer* pCommandBuffers, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAllocateCommandBuffers( m_device, reinterpret_cast<const VkCommandBufferAllocateInfo*>( pAllocateInfo ), reinterpret_cast<VkCommandBuffer*>( pCommandBuffers ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<CommandBuffer,Allocator>>::type Device::allocateCommandBuffers( const CommandBufferAllocateInfo & allocateInfo, Dispatch const &d ) const
  {
    std::vector<CommandBuffer,Allocator> commandBuffers( allocateInfo.commandBufferCount );
    Result result = static_cast<Result>( d.vkAllocateCommandBuffers( m_device, reinterpret_cast<const VkCommandBufferAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkCommandBuffer*>( commandBuffers.data() ) ) );
    return createResultValue( result, commandBuffers, VULKAN_HPP_NAMESPACE_STRING"::Device::allocateCommandBuffers" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<CommandBuffer,Allocator>>::type Device::allocateCommandBuffers( const CommandBufferAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<CommandBuffer,Allocator> commandBuffers( allocateInfo.commandBufferCount, vectorAllocator );
    Result result = static_cast<Result>( d.vkAllocateCommandBuffers( m_device, reinterpret_cast<const VkCommandBufferAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkCommandBuffer*>( commandBuffers.data() ) ) );
    return createResultValue( result, commandBuffers, VULKAN_HPP_NAMESPACE_STRING"::Device::allocateCommandBuffers" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<CommandBuffer,Dispatch>,Allocator>>::type Device::allocateCommandBuffersUnique( const CommandBufferAllocateInfo & allocateInfo, Dispatch const &d ) const
  {
    static_assert( sizeof( CommandBuffer ) <= sizeof( UniqueHandle<CommandBuffer, Dispatch> ), "CommandBuffer is greater than UniqueHandle<CommandBuffer, Dispatch>!" );
    std::vector<UniqueHandle<CommandBuffer, Dispatch>, Allocator> commandBuffers;
    commandBuffers.reserve( allocateInfo.commandBufferCount );
    CommandBuffer* buffer = reinterpret_cast<CommandBuffer*>( reinterpret_cast<char*>( commandBuffers.data() ) + allocateInfo.commandBufferCount * ( sizeof( UniqueHandle<CommandBuffer, Dispatch> ) - sizeof( CommandBuffer ) ) );
    Result result = static_cast<Result>(d.vkAllocateCommandBuffers( m_device, reinterpret_cast<const VkCommandBufferAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkCommandBuffer*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      PoolFree<Device,CommandPool,Dispatch> deleter( *this, allocateInfo.commandPool, d );
      for ( size_t i=0 ; i<allocateInfo.commandBufferCount ; i++ )
      {
        commandBuffers.push_back( UniqueHandle<CommandBuffer, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, commandBuffers, VULKAN_HPP_NAMESPACE_STRING "::Device::allocateCommandBuffersUnique" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<CommandBuffer,Dispatch>,Allocator>>::type Device::allocateCommandBuffersUnique( const CommandBufferAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    static_assert( sizeof( CommandBuffer ) <= sizeof( UniqueHandle<CommandBuffer, Dispatch> ), "CommandBuffer is greater than UniqueHandle<CommandBuffer, Dispatch>!" );
    std::vector<UniqueHandle<CommandBuffer, Dispatch>, Allocator> commandBuffers( vectorAllocator );
    commandBuffers.reserve( allocateInfo.commandBufferCount );
    CommandBuffer* buffer = reinterpret_cast<CommandBuffer*>( reinterpret_cast<char*>( commandBuffers.data() ) + allocateInfo.commandBufferCount * ( sizeof( UniqueHandle<CommandBuffer, Dispatch> ) - sizeof( CommandBuffer ) ) );
    Result result = static_cast<Result>(d.vkAllocateCommandBuffers( m_device, reinterpret_cast<const VkCommandBufferAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkCommandBuffer*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      PoolFree<Device,CommandPool,Dispatch> deleter( *this, allocateInfo.commandPool, d );
      for ( size_t i=0 ; i<allocateInfo.commandBufferCount ; i++ )
      {
        commandBuffers.push_back( UniqueHandle<CommandBuffer, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, commandBuffers, VULKAN_HPP_NAMESPACE_STRING "::Device::allocateCommandBuffersUnique" );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::allocateDescriptorSets( const vk::DescriptorSetAllocateInfo* pAllocateInfo, vk::DescriptorSet* pDescriptorSets, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAllocateDescriptorSets( m_device, reinterpret_cast<const VkDescriptorSetAllocateInfo*>( pAllocateInfo ), reinterpret_cast<VkDescriptorSet*>( pDescriptorSets ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DescriptorSet,Allocator>>::type Device::allocateDescriptorSets( const DescriptorSetAllocateInfo & allocateInfo, Dispatch const &d ) const
  {
    std::vector<DescriptorSet,Allocator> descriptorSets( allocateInfo.descriptorSetCount );
    Result result = static_cast<Result>( d.vkAllocateDescriptorSets( m_device, reinterpret_cast<const VkDescriptorSetAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkDescriptorSet*>( descriptorSets.data() ) ) );
    return createResultValue( result, descriptorSets, VULKAN_HPP_NAMESPACE_STRING"::Device::allocateDescriptorSets" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DescriptorSet,Allocator>>::type Device::allocateDescriptorSets( const DescriptorSetAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DescriptorSet,Allocator> descriptorSets( allocateInfo.descriptorSetCount, vectorAllocator );
    Result result = static_cast<Result>( d.vkAllocateDescriptorSets( m_device, reinterpret_cast<const VkDescriptorSetAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkDescriptorSet*>( descriptorSets.data() ) ) );
    return createResultValue( result, descriptorSets, VULKAN_HPP_NAMESPACE_STRING"::Device::allocateDescriptorSets" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<DescriptorSet,Dispatch>,Allocator>>::type Device::allocateDescriptorSetsUnique( const DescriptorSetAllocateInfo & allocateInfo, Dispatch const &d ) const
  {
    static_assert( sizeof( DescriptorSet ) <= sizeof( UniqueHandle<DescriptorSet, Dispatch> ), "DescriptorSet is greater than UniqueHandle<DescriptorSet, Dispatch>!" );
    std::vector<UniqueHandle<DescriptorSet, Dispatch>, Allocator> descriptorSets;
    descriptorSets.reserve( allocateInfo.descriptorSetCount );
    DescriptorSet* buffer = reinterpret_cast<DescriptorSet*>( reinterpret_cast<char*>( descriptorSets.data() ) + allocateInfo.descriptorSetCount * ( sizeof( UniqueHandle<DescriptorSet, Dispatch> ) - sizeof( DescriptorSet ) ) );
    Result result = static_cast<Result>(d.vkAllocateDescriptorSets( m_device, reinterpret_cast<const VkDescriptorSetAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkDescriptorSet*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      PoolFree<Device,DescriptorPool,Dispatch> deleter( *this, allocateInfo.descriptorPool, d );
      for ( size_t i=0 ; i<allocateInfo.descriptorSetCount ; i++ )
      {
        descriptorSets.push_back( UniqueHandle<DescriptorSet, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, descriptorSets, VULKAN_HPP_NAMESPACE_STRING "::Device::allocateDescriptorSetsUnique" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<DescriptorSet,Dispatch>,Allocator>>::type Device::allocateDescriptorSetsUnique( const DescriptorSetAllocateInfo & allocateInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    static_assert( sizeof( DescriptorSet ) <= sizeof( UniqueHandle<DescriptorSet, Dispatch> ), "DescriptorSet is greater than UniqueHandle<DescriptorSet, Dispatch>!" );
    std::vector<UniqueHandle<DescriptorSet, Dispatch>, Allocator> descriptorSets( vectorAllocator );
    descriptorSets.reserve( allocateInfo.descriptorSetCount );
    DescriptorSet* buffer = reinterpret_cast<DescriptorSet*>( reinterpret_cast<char*>( descriptorSets.data() ) + allocateInfo.descriptorSetCount * ( sizeof( UniqueHandle<DescriptorSet, Dispatch> ) - sizeof( DescriptorSet ) ) );
    Result result = static_cast<Result>(d.vkAllocateDescriptorSets( m_device, reinterpret_cast<const VkDescriptorSetAllocateInfo*>( &allocateInfo ), reinterpret_cast<VkDescriptorSet*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      PoolFree<Device,DescriptorPool,Dispatch> deleter( *this, allocateInfo.descriptorPool, d );
      for ( size_t i=0 ; i<allocateInfo.descriptorSetCount ; i++ )
      {
        descriptorSets.push_back( UniqueHandle<DescriptorSet, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, descriptorSets, VULKAN_HPP_NAMESPACE_STRING "::Device::allocateDescriptorSetsUnique" );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::allocateMemory( const vk::MemoryAllocateInfo* pAllocateInfo, const vk::AllocationCallbacks* pAllocator, vk::DeviceMemory* pMemory, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAllocateMemory( m_device, reinterpret_cast<const VkMemoryAllocateInfo*>( pAllocateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDeviceMemory*>( pMemory ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DeviceMemory>::type Device::allocateMemory( const MemoryAllocateInfo & allocateInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DeviceMemory memory;
    Result result = static_cast<Result>( d.vkAllocateMemory( m_device, reinterpret_cast<const VkMemoryAllocateInfo*>( &allocateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDeviceMemory*>( &memory ) ) );
    return createResultValue( result, memory, VULKAN_HPP_NAMESPACE_STRING"::Device::allocateMemory" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<DeviceMemory,Dispatch>>::type Device::allocateMemoryUnique( const MemoryAllocateInfo & allocateInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DeviceMemory memory;
    Result result = static_cast<Result>( d.vkAllocateMemory( m_device, reinterpret_cast<const VkMemoryAllocateInfo*>( &allocateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDeviceMemory*>( &memory ) ) );

    ObjectFree<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<DeviceMemory,Dispatch>( result, memory, VULKAN_HPP_NAMESPACE_STRING"::Device::allocateMemoryUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::bindAccelerationStructureMemoryNV( uint32_t bindInfoCount, const vk::BindAccelerationStructureMemoryInfoNV* pBindInfos, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBindAccelerationStructureMemoryNV( m_device, bindInfoCount, reinterpret_cast<const VkBindAccelerationStructureMemoryInfoNV*>( pBindInfos ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::bindAccelerationStructureMemoryNV( ArrayProxy<const vk::BindAccelerationStructureMemoryInfoNV> bindInfos, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBindAccelerationStructureMemoryNV( m_device, bindInfos.size() , reinterpret_cast<const VkBindAccelerationStructureMemoryInfoNV*>( bindInfos.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::bindAccelerationStructureMemoryNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::bindBufferMemory( vk::Buffer buffer, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBindBufferMemory( m_device, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceMemory>( memory ), static_cast<VkDeviceSize>( memoryOffset ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::bindBufferMemory( vk::Buffer buffer, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBindBufferMemory( m_device, static_cast<VkBuffer>( buffer ), static_cast<VkDeviceMemory>( memory ), static_cast<VkDeviceSize>( memoryOffset ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::bindBufferMemory" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::bindBufferMemory2( uint32_t bindInfoCount, const vk::BindBufferMemoryInfo* pBindInfos, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBindBufferMemory2( m_device, bindInfoCount, reinterpret_cast<const VkBindBufferMemoryInfo*>( pBindInfos ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::bindBufferMemory2( ArrayProxy<const vk::BindBufferMemoryInfo> bindInfos, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBindBufferMemory2( m_device, bindInfos.size() , reinterpret_cast<const VkBindBufferMemoryInfo*>( bindInfos.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::bindBufferMemory2" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::bindBufferMemory2KHR( uint32_t bindInfoCount, const vk::BindBufferMemoryInfo* pBindInfos, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBindBufferMemory2KHR( m_device, bindInfoCount, reinterpret_cast<const VkBindBufferMemoryInfo*>( pBindInfos ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::bindBufferMemory2KHR( ArrayProxy<const vk::BindBufferMemoryInfo> bindInfos, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBindBufferMemory2KHR( m_device, bindInfos.size() , reinterpret_cast<const VkBindBufferMemoryInfo*>( bindInfos.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::bindBufferMemory2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::bindImageMemory( vk::Image image, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBindImageMemory( m_device, static_cast<VkImage>( image ), static_cast<VkDeviceMemory>( memory ), static_cast<VkDeviceSize>( memoryOffset ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::bindImageMemory( vk::Image image, vk::DeviceMemory memory, vk::DeviceSize memoryOffset, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBindImageMemory( m_device, static_cast<VkImage>( image ), static_cast<VkDeviceMemory>( memory ), static_cast<VkDeviceSize>( memoryOffset ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::bindImageMemory" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::bindImageMemory2( uint32_t bindInfoCount, const vk::BindImageMemoryInfo* pBindInfos, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBindImageMemory2( m_device, bindInfoCount, reinterpret_cast<const VkBindImageMemoryInfo*>( pBindInfos ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::bindImageMemory2( ArrayProxy<const vk::BindImageMemoryInfo> bindInfos, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBindImageMemory2( m_device, bindInfos.size() , reinterpret_cast<const VkBindImageMemoryInfo*>( bindInfos.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::bindImageMemory2" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::bindImageMemory2KHR( uint32_t bindInfoCount, const vk::BindImageMemoryInfo* pBindInfos, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkBindImageMemory2KHR( m_device, bindInfoCount, reinterpret_cast<const VkBindImageMemoryInfo*>( pBindInfos ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::bindImageMemory2KHR( ArrayProxy<const vk::BindImageMemoryInfo> bindInfos, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkBindImageMemory2KHR( m_device, bindInfos.size() , reinterpret_cast<const VkBindImageMemoryInfo*>( bindInfos.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::bindImageMemory2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::compileDeferredNV( vk::Pipeline pipeline, uint32_t shader, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCompileDeferredNV( m_device, static_cast<VkPipeline>( pipeline ), shader ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::compileDeferredNV( vk::Pipeline pipeline, uint32_t shader, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkCompileDeferredNV( m_device, static_cast<VkPipeline>( pipeline ), shader ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::compileDeferredNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createAccelerationStructureNV( const vk::AccelerationStructureCreateInfoNV* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::AccelerationStructureNV* pAccelerationStructure, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateAccelerationStructureNV( m_device, reinterpret_cast<const VkAccelerationStructureCreateInfoNV*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkAccelerationStructureNV*>( pAccelerationStructure ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::AccelerationStructureNV>::type Device::createAccelerationStructureNV( const AccelerationStructureCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::AccelerationStructureNV accelerationStructure;
    Result result = static_cast<Result>( d.vkCreateAccelerationStructureNV( m_device, reinterpret_cast<const VkAccelerationStructureCreateInfoNV*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkAccelerationStructureNV*>( &accelerationStructure ) ) );
    return createResultValue( result, accelerationStructure, VULKAN_HPP_NAMESPACE_STRING"::Device::createAccelerationStructureNV" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<AccelerationStructureNV,Dispatch>>::type Device::createAccelerationStructureNVUnique( const AccelerationStructureCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::AccelerationStructureNV accelerationStructure;
    Result result = static_cast<Result>( d.vkCreateAccelerationStructureNV( m_device, reinterpret_cast<const VkAccelerationStructureCreateInfoNV*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkAccelerationStructureNV*>( &accelerationStructure ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<AccelerationStructureNV,Dispatch>( result, accelerationStructure, VULKAN_HPP_NAMESPACE_STRING"::Device::createAccelerationStructureNVUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createBuffer( const vk::BufferCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Buffer* pBuffer, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateBuffer( m_device, reinterpret_cast<const VkBufferCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkBuffer*>( pBuffer ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Buffer>::type Device::createBuffer( const BufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Buffer buffer;
    Result result = static_cast<Result>( d.vkCreateBuffer( m_device, reinterpret_cast<const VkBufferCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkBuffer*>( &buffer ) ) );
    return createResultValue( result, buffer, VULKAN_HPP_NAMESPACE_STRING"::Device::createBuffer" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Buffer,Dispatch>>::type Device::createBufferUnique( const BufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Buffer buffer;
    Result result = static_cast<Result>( d.vkCreateBuffer( m_device, reinterpret_cast<const VkBufferCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkBuffer*>( &buffer ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Buffer,Dispatch>( result, buffer, VULKAN_HPP_NAMESPACE_STRING"::Device::createBufferUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createBufferView( const vk::BufferViewCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::BufferView* pView, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateBufferView( m_device, reinterpret_cast<const VkBufferViewCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkBufferView*>( pView ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::BufferView>::type Device::createBufferView( const BufferViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::BufferView view;
    Result result = static_cast<Result>( d.vkCreateBufferView( m_device, reinterpret_cast<const VkBufferViewCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkBufferView*>( &view ) ) );
    return createResultValue( result, view, VULKAN_HPP_NAMESPACE_STRING"::Device::createBufferView" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<BufferView,Dispatch>>::type Device::createBufferViewUnique( const BufferViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::BufferView view;
    Result result = static_cast<Result>( d.vkCreateBufferView( m_device, reinterpret_cast<const VkBufferViewCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkBufferView*>( &view ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<BufferView,Dispatch>( result, view, VULKAN_HPP_NAMESPACE_STRING"::Device::createBufferViewUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createCommandPool( const vk::CommandPoolCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::CommandPool* pCommandPool, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateCommandPool( m_device, reinterpret_cast<const VkCommandPoolCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkCommandPool*>( pCommandPool ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::CommandPool>::type Device::createCommandPool( const CommandPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::CommandPool commandPool;
    Result result = static_cast<Result>( d.vkCreateCommandPool( m_device, reinterpret_cast<const VkCommandPoolCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkCommandPool*>( &commandPool ) ) );
    return createResultValue( result, commandPool, VULKAN_HPP_NAMESPACE_STRING"::Device::createCommandPool" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<CommandPool,Dispatch>>::type Device::createCommandPoolUnique( const CommandPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::CommandPool commandPool;
    Result result = static_cast<Result>( d.vkCreateCommandPool( m_device, reinterpret_cast<const VkCommandPoolCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkCommandPool*>( &commandPool ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<CommandPool,Dispatch>( result, commandPool, VULKAN_HPP_NAMESPACE_STRING"::Device::createCommandPoolUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createComputePipelines( vk::PipelineCache pipelineCache, uint32_t createInfoCount, const vk::ComputePipelineCreateInfo* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::Pipeline* pPipelines, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateComputePipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfoCount, reinterpret_cast<const VkComputePipelineCreateInfo*>( pCreateInfos ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkPipeline*>( pPipelines ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Pipeline,Allocator>>::type Device::createComputePipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    std::vector<Pipeline,Allocator> pipelines( createInfos.size() );
    Result result = static_cast<Result>( d.vkCreateComputePipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkComputePipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( pipelines.data() ) ) );
    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING"::Device::createComputePipelines" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Pipeline,Allocator>>::type Device::createComputePipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<Pipeline,Allocator> pipelines( createInfos.size(), vectorAllocator );
    Result result = static_cast<Result>( d.vkCreateComputePipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkComputePipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( pipelines.data() ) ) );
    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING"::Device::createComputePipelines" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<Pipeline>::type Device::createComputePipeline( vk::PipelineCache pipelineCache, const ComputePipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    Pipeline pipeline;
    Result result = static_cast<Result>( d.vkCreateComputePipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), 1 , reinterpret_cast<const VkComputePipelineCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( &pipeline ) ) );
    return createResultValue( result, pipeline, VULKAN_HPP_NAMESPACE_STRING"::Device::createComputePipeline" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type Device::createComputePipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    static_assert( sizeof( Pipeline ) <= sizeof( UniqueHandle<Pipeline, Dispatch> ), "Pipeline is greater than UniqueHandle<Pipeline, Dispatch>!" );
    std::vector<UniqueHandle<Pipeline, Dispatch>, Allocator> pipelines;
    pipelines.reserve( createInfos.size() );
    Pipeline* buffer = reinterpret_cast<Pipeline*>( reinterpret_cast<char*>( pipelines.data() ) + createInfos.size() * ( sizeof( UniqueHandle<Pipeline, Dispatch> ) - sizeof( Pipeline ) ) );
    Result result = static_cast<Result>(d.vkCreateComputePipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkComputePipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        pipelines.push_back( UniqueHandle<Pipeline, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING "::Device::createComputePipelinesUnique" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type Device::createComputePipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::ComputePipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    static_assert( sizeof( Pipeline ) <= sizeof( UniqueHandle<Pipeline, Dispatch> ), "Pipeline is greater than UniqueHandle<Pipeline, Dispatch>!" );
    std::vector<UniqueHandle<Pipeline, Dispatch>, Allocator> pipelines( vectorAllocator );
    pipelines.reserve( createInfos.size() );
    Pipeline* buffer = reinterpret_cast<Pipeline*>( reinterpret_cast<char*>( pipelines.data() ) + createInfos.size() * ( sizeof( UniqueHandle<Pipeline, Dispatch> ) - sizeof( Pipeline ) ) );
    Result result = static_cast<Result>(d.vkCreateComputePipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkComputePipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        pipelines.push_back( UniqueHandle<Pipeline, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING "::Device::createComputePipelinesUnique" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Pipeline,Dispatch>>::type Device::createComputePipelineUnique( vk::PipelineCache pipelineCache, const ComputePipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    Pipeline pipeline;
    Result result = static_cast<Result>( d.vkCreateComputePipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), 1 , reinterpret_cast<const VkComputePipelineCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( &pipeline ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Pipeline,Dispatch>( result, pipeline, VULKAN_HPP_NAMESPACE_STRING"::Device::createComputePipelineUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createDescriptorPool( const vk::DescriptorPoolCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorPool* pDescriptorPool, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDescriptorPool( m_device, reinterpret_cast<const VkDescriptorPoolCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDescriptorPool*>( pDescriptorPool ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DescriptorPool>::type Device::createDescriptorPool( const DescriptorPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorPool descriptorPool;
    Result result = static_cast<Result>( d.vkCreateDescriptorPool( m_device, reinterpret_cast<const VkDescriptorPoolCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorPool*>( &descriptorPool ) ) );
    return createResultValue( result, descriptorPool, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorPool" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<DescriptorPool,Dispatch>>::type Device::createDescriptorPoolUnique( const DescriptorPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorPool descriptorPool;
    Result result = static_cast<Result>( d.vkCreateDescriptorPool( m_device, reinterpret_cast<const VkDescriptorPoolCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorPool*>( &descriptorPool ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<DescriptorPool,Dispatch>( result, descriptorPool, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorPoolUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createDescriptorSetLayout( const vk::DescriptorSetLayoutCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorSetLayout* pSetLayout, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDescriptorSetLayout( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDescriptorSetLayout*>( pSetLayout ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DescriptorSetLayout>::type Device::createDescriptorSetLayout( const DescriptorSetLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorSetLayout setLayout;
    Result result = static_cast<Result>( d.vkCreateDescriptorSetLayout( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorSetLayout*>( &setLayout ) ) );
    return createResultValue( result, setLayout, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorSetLayout" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<DescriptorSetLayout,Dispatch>>::type Device::createDescriptorSetLayoutUnique( const DescriptorSetLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorSetLayout setLayout;
    Result result = static_cast<Result>( d.vkCreateDescriptorSetLayout( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorSetLayout*>( &setLayout ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<DescriptorSetLayout,Dispatch>( result, setLayout, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorSetLayoutUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createDescriptorUpdateTemplate( const vk::DescriptorUpdateTemplateCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorUpdateTemplate* pDescriptorUpdateTemplate, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDescriptorUpdateTemplate( m_device, reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDescriptorUpdateTemplate*>( pDescriptorUpdateTemplate ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DescriptorUpdateTemplate>::type Device::createDescriptorUpdateTemplate( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorUpdateTemplate descriptorUpdateTemplate;
    Result result = static_cast<Result>( d.vkCreateDescriptorUpdateTemplate( m_device, reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorUpdateTemplate*>( &descriptorUpdateTemplate ) ) );
    return createResultValue( result, descriptorUpdateTemplate, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorUpdateTemplate" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<DescriptorUpdateTemplate,Dispatch>>::type Device::createDescriptorUpdateTemplateUnique( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorUpdateTemplate descriptorUpdateTemplate;
    Result result = static_cast<Result>( d.vkCreateDescriptorUpdateTemplate( m_device, reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorUpdateTemplate*>( &descriptorUpdateTemplate ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<DescriptorUpdateTemplate,Dispatch>( result, descriptorUpdateTemplate, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorUpdateTemplateUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createDescriptorUpdateTemplateKHR( const vk::DescriptorUpdateTemplateCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DescriptorUpdateTemplate* pDescriptorUpdateTemplate, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDescriptorUpdateTemplateKHR( m_device, reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDescriptorUpdateTemplate*>( pDescriptorUpdateTemplate ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DescriptorUpdateTemplate>::type Device::createDescriptorUpdateTemplateKHR( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorUpdateTemplate descriptorUpdateTemplate;
    Result result = static_cast<Result>( d.vkCreateDescriptorUpdateTemplateKHR( m_device, reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorUpdateTemplate*>( &descriptorUpdateTemplate ) ) );
    return createResultValue( result, descriptorUpdateTemplate, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorUpdateTemplateKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<DescriptorUpdateTemplate,Dispatch>>::type Device::createDescriptorUpdateTemplateKHRUnique( const DescriptorUpdateTemplateCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DescriptorUpdateTemplate descriptorUpdateTemplate;
    Result result = static_cast<Result>( d.vkCreateDescriptorUpdateTemplateKHR( m_device, reinterpret_cast<const VkDescriptorUpdateTemplateCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDescriptorUpdateTemplate*>( &descriptorUpdateTemplate ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<DescriptorUpdateTemplate,Dispatch>( result, descriptorUpdateTemplate, VULKAN_HPP_NAMESPACE_STRING"::Device::createDescriptorUpdateTemplateKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createEvent( const vk::EventCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Event* pEvent, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateEvent( m_device, reinterpret_cast<const VkEventCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkEvent*>( pEvent ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Event>::type Device::createEvent( const EventCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Event event;
    Result result = static_cast<Result>( d.vkCreateEvent( m_device, reinterpret_cast<const VkEventCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkEvent*>( &event ) ) );
    return createResultValue( result, event, VULKAN_HPP_NAMESPACE_STRING"::Device::createEvent" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Event,Dispatch>>::type Device::createEventUnique( const EventCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Event event;
    Result result = static_cast<Result>( d.vkCreateEvent( m_device, reinterpret_cast<const VkEventCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkEvent*>( &event ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Event,Dispatch>( result, event, VULKAN_HPP_NAMESPACE_STRING"::Device::createEventUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createFence( const vk::FenceCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Fence* pFence, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateFence( m_device, reinterpret_cast<const VkFenceCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkFence*>( pFence ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Fence>::type Device::createFence( const FenceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Fence fence;
    Result result = static_cast<Result>( d.vkCreateFence( m_device, reinterpret_cast<const VkFenceCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkFence*>( &fence ) ) );
    return createResultValue( result, fence, VULKAN_HPP_NAMESPACE_STRING"::Device::createFence" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Fence,Dispatch>>::type Device::createFenceUnique( const FenceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Fence fence;
    Result result = static_cast<Result>( d.vkCreateFence( m_device, reinterpret_cast<const VkFenceCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkFence*>( &fence ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Fence,Dispatch>( result, fence, VULKAN_HPP_NAMESPACE_STRING"::Device::createFenceUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createFramebuffer( const vk::FramebufferCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Framebuffer* pFramebuffer, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateFramebuffer( m_device, reinterpret_cast<const VkFramebufferCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkFramebuffer*>( pFramebuffer ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Framebuffer>::type Device::createFramebuffer( const FramebufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Framebuffer framebuffer;
    Result result = static_cast<Result>( d.vkCreateFramebuffer( m_device, reinterpret_cast<const VkFramebufferCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkFramebuffer*>( &framebuffer ) ) );
    return createResultValue( result, framebuffer, VULKAN_HPP_NAMESPACE_STRING"::Device::createFramebuffer" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Framebuffer,Dispatch>>::type Device::createFramebufferUnique( const FramebufferCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Framebuffer framebuffer;
    Result result = static_cast<Result>( d.vkCreateFramebuffer( m_device, reinterpret_cast<const VkFramebufferCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkFramebuffer*>( &framebuffer ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Framebuffer,Dispatch>( result, framebuffer, VULKAN_HPP_NAMESPACE_STRING"::Device::createFramebufferUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createGraphicsPipelines( vk::PipelineCache pipelineCache, uint32_t createInfoCount, const vk::GraphicsPipelineCreateInfo* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::Pipeline* pPipelines, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateGraphicsPipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfoCount, reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( pCreateInfos ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkPipeline*>( pPipelines ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Pipeline,Allocator>>::type Device::createGraphicsPipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    std::vector<Pipeline,Allocator> pipelines( createInfos.size() );
    Result result = static_cast<Result>( d.vkCreateGraphicsPipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( pipelines.data() ) ) );
    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING"::Device::createGraphicsPipelines" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Pipeline,Allocator>>::type Device::createGraphicsPipelines( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<Pipeline,Allocator> pipelines( createInfos.size(), vectorAllocator );
    Result result = static_cast<Result>( d.vkCreateGraphicsPipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( pipelines.data() ) ) );
    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING"::Device::createGraphicsPipelines" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<Pipeline>::type Device::createGraphicsPipeline( vk::PipelineCache pipelineCache, const GraphicsPipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    Pipeline pipeline;
    Result result = static_cast<Result>( d.vkCreateGraphicsPipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), 1 , reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( &pipeline ) ) );
    return createResultValue( result, pipeline, VULKAN_HPP_NAMESPACE_STRING"::Device::createGraphicsPipeline" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type Device::createGraphicsPipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    static_assert( sizeof( Pipeline ) <= sizeof( UniqueHandle<Pipeline, Dispatch> ), "Pipeline is greater than UniqueHandle<Pipeline, Dispatch>!" );
    std::vector<UniqueHandle<Pipeline, Dispatch>, Allocator> pipelines;
    pipelines.reserve( createInfos.size() );
    Pipeline* buffer = reinterpret_cast<Pipeline*>( reinterpret_cast<char*>( pipelines.data() ) + createInfos.size() * ( sizeof( UniqueHandle<Pipeline, Dispatch> ) - sizeof( Pipeline ) ) );
    Result result = static_cast<Result>(d.vkCreateGraphicsPipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        pipelines.push_back( UniqueHandle<Pipeline, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING "::Device::createGraphicsPipelinesUnique" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type Device::createGraphicsPipelinesUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::GraphicsPipelineCreateInfo> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    static_assert( sizeof( Pipeline ) <= sizeof( UniqueHandle<Pipeline, Dispatch> ), "Pipeline is greater than UniqueHandle<Pipeline, Dispatch>!" );
    std::vector<UniqueHandle<Pipeline, Dispatch>, Allocator> pipelines( vectorAllocator );
    pipelines.reserve( createInfos.size() );
    Pipeline* buffer = reinterpret_cast<Pipeline*>( reinterpret_cast<char*>( pipelines.data() ) + createInfos.size() * ( sizeof( UniqueHandle<Pipeline, Dispatch> ) - sizeof( Pipeline ) ) );
    Result result = static_cast<Result>(d.vkCreateGraphicsPipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        pipelines.push_back( UniqueHandle<Pipeline, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING "::Device::createGraphicsPipelinesUnique" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Pipeline,Dispatch>>::type Device::createGraphicsPipelineUnique( vk::PipelineCache pipelineCache, const GraphicsPipelineCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    Pipeline pipeline;
    Result result = static_cast<Result>( d.vkCreateGraphicsPipelines( m_device, static_cast<VkPipelineCache>( pipelineCache ), 1 , reinterpret_cast<const VkGraphicsPipelineCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( &pipeline ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Pipeline,Dispatch>( result, pipeline, VULKAN_HPP_NAMESPACE_STRING"::Device::createGraphicsPipelineUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createImage( const vk::ImageCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Image* pImage, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateImage( m_device, reinterpret_cast<const VkImageCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkImage*>( pImage ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Image>::type Device::createImage( const ImageCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Image image;
    Result result = static_cast<Result>( d.vkCreateImage( m_device, reinterpret_cast<const VkImageCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkImage*>( &image ) ) );
    return createResultValue( result, image, VULKAN_HPP_NAMESPACE_STRING"::Device::createImage" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Image,Dispatch>>::type Device::createImageUnique( const ImageCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Image image;
    Result result = static_cast<Result>( d.vkCreateImage( m_device, reinterpret_cast<const VkImageCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkImage*>( &image ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Image,Dispatch>( result, image, VULKAN_HPP_NAMESPACE_STRING"::Device::createImageUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createImageView( const vk::ImageViewCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ImageView* pView, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateImageView( m_device, reinterpret_cast<const VkImageViewCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkImageView*>( pView ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ImageView>::type Device::createImageView( const ImageViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ImageView view;
    Result result = static_cast<Result>( d.vkCreateImageView( m_device, reinterpret_cast<const VkImageViewCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkImageView*>( &view ) ) );
    return createResultValue( result, view, VULKAN_HPP_NAMESPACE_STRING"::Device::createImageView" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<ImageView,Dispatch>>::type Device::createImageViewUnique( const ImageViewCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ImageView view;
    Result result = static_cast<Result>( d.vkCreateImageView( m_device, reinterpret_cast<const VkImageViewCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkImageView*>( &view ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<ImageView,Dispatch>( result, view, VULKAN_HPP_NAMESPACE_STRING"::Device::createImageViewUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createIndirectCommandsLayoutNVX( const vk::IndirectCommandsLayoutCreateInfoNVX* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::IndirectCommandsLayoutNVX* pIndirectCommandsLayout, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateIndirectCommandsLayoutNVX( m_device, reinterpret_cast<const VkIndirectCommandsLayoutCreateInfoNVX*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkIndirectCommandsLayoutNVX*>( pIndirectCommandsLayout ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::IndirectCommandsLayoutNVX>::type Device::createIndirectCommandsLayoutNVX( const IndirectCommandsLayoutCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::IndirectCommandsLayoutNVX indirectCommandsLayout;
    Result result = static_cast<Result>( d.vkCreateIndirectCommandsLayoutNVX( m_device, reinterpret_cast<const VkIndirectCommandsLayoutCreateInfoNVX*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkIndirectCommandsLayoutNVX*>( &indirectCommandsLayout ) ) );
    return createResultValue( result, indirectCommandsLayout, VULKAN_HPP_NAMESPACE_STRING"::Device::createIndirectCommandsLayoutNVX" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<IndirectCommandsLayoutNVX,Dispatch>>::type Device::createIndirectCommandsLayoutNVXUnique( const IndirectCommandsLayoutCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::IndirectCommandsLayoutNVX indirectCommandsLayout;
    Result result = static_cast<Result>( d.vkCreateIndirectCommandsLayoutNVX( m_device, reinterpret_cast<const VkIndirectCommandsLayoutCreateInfoNVX*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkIndirectCommandsLayoutNVX*>( &indirectCommandsLayout ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<IndirectCommandsLayoutNVX,Dispatch>( result, indirectCommandsLayout, VULKAN_HPP_NAMESPACE_STRING"::Device::createIndirectCommandsLayoutNVXUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createObjectTableNVX( const vk::ObjectTableCreateInfoNVX* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ObjectTableNVX* pObjectTable, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateObjectTableNVX( m_device, reinterpret_cast<const VkObjectTableCreateInfoNVX*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkObjectTableNVX*>( pObjectTable ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ObjectTableNVX>::type Device::createObjectTableNVX( const ObjectTableCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ObjectTableNVX objectTable;
    Result result = static_cast<Result>( d.vkCreateObjectTableNVX( m_device, reinterpret_cast<const VkObjectTableCreateInfoNVX*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkObjectTableNVX*>( &objectTable ) ) );
    return createResultValue( result, objectTable, VULKAN_HPP_NAMESPACE_STRING"::Device::createObjectTableNVX" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<ObjectTableNVX,Dispatch>>::type Device::createObjectTableNVXUnique( const ObjectTableCreateInfoNVX & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ObjectTableNVX objectTable;
    Result result = static_cast<Result>( d.vkCreateObjectTableNVX( m_device, reinterpret_cast<const VkObjectTableCreateInfoNVX*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkObjectTableNVX*>( &objectTable ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<ObjectTableNVX,Dispatch>( result, objectTable, VULKAN_HPP_NAMESPACE_STRING"::Device::createObjectTableNVXUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createPipelineCache( const vk::PipelineCacheCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::PipelineCache* pPipelineCache, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreatePipelineCache( m_device, reinterpret_cast<const VkPipelineCacheCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkPipelineCache*>( pPipelineCache ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::PipelineCache>::type Device::createPipelineCache( const PipelineCacheCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::PipelineCache pipelineCache;
    Result result = static_cast<Result>( d.vkCreatePipelineCache( m_device, reinterpret_cast<const VkPipelineCacheCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipelineCache*>( &pipelineCache ) ) );
    return createResultValue( result, pipelineCache, VULKAN_HPP_NAMESPACE_STRING"::Device::createPipelineCache" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<PipelineCache,Dispatch>>::type Device::createPipelineCacheUnique( const PipelineCacheCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::PipelineCache pipelineCache;
    Result result = static_cast<Result>( d.vkCreatePipelineCache( m_device, reinterpret_cast<const VkPipelineCacheCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipelineCache*>( &pipelineCache ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<PipelineCache,Dispatch>( result, pipelineCache, VULKAN_HPP_NAMESPACE_STRING"::Device::createPipelineCacheUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createPipelineLayout( const vk::PipelineLayoutCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::PipelineLayout* pPipelineLayout, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreatePipelineLayout( m_device, reinterpret_cast<const VkPipelineLayoutCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkPipelineLayout*>( pPipelineLayout ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::PipelineLayout>::type Device::createPipelineLayout( const PipelineLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::PipelineLayout pipelineLayout;
    Result result = static_cast<Result>( d.vkCreatePipelineLayout( m_device, reinterpret_cast<const VkPipelineLayoutCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipelineLayout*>( &pipelineLayout ) ) );
    return createResultValue( result, pipelineLayout, VULKAN_HPP_NAMESPACE_STRING"::Device::createPipelineLayout" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<PipelineLayout,Dispatch>>::type Device::createPipelineLayoutUnique( const PipelineLayoutCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::PipelineLayout pipelineLayout;
    Result result = static_cast<Result>( d.vkCreatePipelineLayout( m_device, reinterpret_cast<const VkPipelineLayoutCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipelineLayout*>( &pipelineLayout ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<PipelineLayout,Dispatch>( result, pipelineLayout, VULKAN_HPP_NAMESPACE_STRING"::Device::createPipelineLayoutUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createQueryPool( const vk::QueryPoolCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::QueryPool* pQueryPool, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateQueryPool( m_device, reinterpret_cast<const VkQueryPoolCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkQueryPool*>( pQueryPool ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::QueryPool>::type Device::createQueryPool( const QueryPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::QueryPool queryPool;
    Result result = static_cast<Result>( d.vkCreateQueryPool( m_device, reinterpret_cast<const VkQueryPoolCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkQueryPool*>( &queryPool ) ) );
    return createResultValue( result, queryPool, VULKAN_HPP_NAMESPACE_STRING"::Device::createQueryPool" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<QueryPool,Dispatch>>::type Device::createQueryPoolUnique( const QueryPoolCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::QueryPool queryPool;
    Result result = static_cast<Result>( d.vkCreateQueryPool( m_device, reinterpret_cast<const VkQueryPoolCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkQueryPool*>( &queryPool ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<QueryPool,Dispatch>( result, queryPool, VULKAN_HPP_NAMESPACE_STRING"::Device::createQueryPoolUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createRayTracingPipelinesNV( vk::PipelineCache pipelineCache, uint32_t createInfoCount, const vk::RayTracingPipelineCreateInfoNV* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::Pipeline* pPipelines, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateRayTracingPipelinesNV( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfoCount, reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( pCreateInfos ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkPipeline*>( pPipelines ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Pipeline,Allocator>>::type Device::createRayTracingPipelinesNV( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    std::vector<Pipeline,Allocator> pipelines( createInfos.size() );
    Result result = static_cast<Result>( d.vkCreateRayTracingPipelinesNV( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( pipelines.data() ) ) );
    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING"::Device::createRayTracingPipelinesNV" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Pipeline,Allocator>>::type Device::createRayTracingPipelinesNV( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<Pipeline,Allocator> pipelines( createInfos.size(), vectorAllocator );
    Result result = static_cast<Result>( d.vkCreateRayTracingPipelinesNV( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( pipelines.data() ) ) );
    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING"::Device::createRayTracingPipelinesNV" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<Pipeline>::type Device::createRayTracingPipelineNV( vk::PipelineCache pipelineCache, const RayTracingPipelineCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    Pipeline pipeline;
    Result result = static_cast<Result>( d.vkCreateRayTracingPipelinesNV( m_device, static_cast<VkPipelineCache>( pipelineCache ), 1 , reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( &pipeline ) ) );
    return createResultValue( result, pipeline, VULKAN_HPP_NAMESPACE_STRING"::Device::createRayTracingPipelineNV" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type Device::createRayTracingPipelinesNVUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    static_assert( sizeof( Pipeline ) <= sizeof( UniqueHandle<Pipeline, Dispatch> ), "Pipeline is greater than UniqueHandle<Pipeline, Dispatch>!" );
    std::vector<UniqueHandle<Pipeline, Dispatch>, Allocator> pipelines;
    pipelines.reserve( createInfos.size() );
    Pipeline* buffer = reinterpret_cast<Pipeline*>( reinterpret_cast<char*>( pipelines.data() ) + createInfos.size() * ( sizeof( UniqueHandle<Pipeline, Dispatch> ) - sizeof( Pipeline ) ) );
    Result result = static_cast<Result>(d.vkCreateRayTracingPipelinesNV( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        pipelines.push_back( UniqueHandle<Pipeline, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING "::Device::createRayTracingPipelinesNVUnique" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<Pipeline,Dispatch>,Allocator>>::type Device::createRayTracingPipelinesNVUnique( vk::PipelineCache pipelineCache, ArrayProxy<const vk::RayTracingPipelineCreateInfoNV> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    static_assert( sizeof( Pipeline ) <= sizeof( UniqueHandle<Pipeline, Dispatch> ), "Pipeline is greater than UniqueHandle<Pipeline, Dispatch>!" );
    std::vector<UniqueHandle<Pipeline, Dispatch>, Allocator> pipelines( vectorAllocator );
    pipelines.reserve( createInfos.size() );
    Pipeline* buffer = reinterpret_cast<Pipeline*>( reinterpret_cast<char*>( pipelines.data() ) + createInfos.size() * ( sizeof( UniqueHandle<Pipeline, Dispatch> ) - sizeof( Pipeline ) ) );
    Result result = static_cast<Result>(d.vkCreateRayTracingPipelinesNV( m_device, static_cast<VkPipelineCache>( pipelineCache ), createInfos.size() , reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        pipelines.push_back( UniqueHandle<Pipeline, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, pipelines, VULKAN_HPP_NAMESPACE_STRING "::Device::createRayTracingPipelinesNVUnique" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Pipeline,Dispatch>>::type Device::createRayTracingPipelineNVUnique( vk::PipelineCache pipelineCache, const RayTracingPipelineCreateInfoNV & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    Pipeline pipeline;
    Result result = static_cast<Result>( d.vkCreateRayTracingPipelinesNV( m_device, static_cast<VkPipelineCache>( pipelineCache ), 1 , reinterpret_cast<const VkRayTracingPipelineCreateInfoNV*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkPipeline*>( &pipeline ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Pipeline,Dispatch>( result, pipeline, VULKAN_HPP_NAMESPACE_STRING"::Device::createRayTracingPipelineNVUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createRenderPass( const vk::RenderPassCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::RenderPass* pRenderPass, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateRenderPass( m_device, reinterpret_cast<const VkRenderPassCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkRenderPass*>( pRenderPass ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::RenderPass>::type Device::createRenderPass( const RenderPassCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::RenderPass renderPass;
    Result result = static_cast<Result>( d.vkCreateRenderPass( m_device, reinterpret_cast<const VkRenderPassCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkRenderPass*>( &renderPass ) ) );
    return createResultValue( result, renderPass, VULKAN_HPP_NAMESPACE_STRING"::Device::createRenderPass" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<RenderPass,Dispatch>>::type Device::createRenderPassUnique( const RenderPassCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::RenderPass renderPass;
    Result result = static_cast<Result>( d.vkCreateRenderPass( m_device, reinterpret_cast<const VkRenderPassCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkRenderPass*>( &renderPass ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<RenderPass,Dispatch>( result, renderPass, VULKAN_HPP_NAMESPACE_STRING"::Device::createRenderPassUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createRenderPass2KHR( const vk::RenderPassCreateInfo2KHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::RenderPass* pRenderPass, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateRenderPass2KHR( m_device, reinterpret_cast<const VkRenderPassCreateInfo2KHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkRenderPass*>( pRenderPass ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::RenderPass>::type Device::createRenderPass2KHR( const RenderPassCreateInfo2KHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::RenderPass renderPass;
    Result result = static_cast<Result>( d.vkCreateRenderPass2KHR( m_device, reinterpret_cast<const VkRenderPassCreateInfo2KHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkRenderPass*>( &renderPass ) ) );
    return createResultValue( result, renderPass, VULKAN_HPP_NAMESPACE_STRING"::Device::createRenderPass2KHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<RenderPass,Dispatch>>::type Device::createRenderPass2KHRUnique( const RenderPassCreateInfo2KHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::RenderPass renderPass;
    Result result = static_cast<Result>( d.vkCreateRenderPass2KHR( m_device, reinterpret_cast<const VkRenderPassCreateInfo2KHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkRenderPass*>( &renderPass ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<RenderPass,Dispatch>( result, renderPass, VULKAN_HPP_NAMESPACE_STRING"::Device::createRenderPass2KHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createSampler( const vk::SamplerCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Sampler* pSampler, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateSampler( m_device, reinterpret_cast<const VkSamplerCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSampler*>( pSampler ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Sampler>::type Device::createSampler( const SamplerCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Sampler sampler;
    Result result = static_cast<Result>( d.vkCreateSampler( m_device, reinterpret_cast<const VkSamplerCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSampler*>( &sampler ) ) );
    return createResultValue( result, sampler, VULKAN_HPP_NAMESPACE_STRING"::Device::createSampler" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Sampler,Dispatch>>::type Device::createSamplerUnique( const SamplerCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Sampler sampler;
    Result result = static_cast<Result>( d.vkCreateSampler( m_device, reinterpret_cast<const VkSamplerCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSampler*>( &sampler ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Sampler,Dispatch>( result, sampler, VULKAN_HPP_NAMESPACE_STRING"::Device::createSamplerUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createSamplerYcbcrConversion( const vk::SamplerYcbcrConversionCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SamplerYcbcrConversion* pYcbcrConversion, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateSamplerYcbcrConversion( m_device, reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSamplerYcbcrConversion*>( pYcbcrConversion ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SamplerYcbcrConversion>::type Device::createSamplerYcbcrConversion( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SamplerYcbcrConversion ycbcrConversion;
    Result result = static_cast<Result>( d.vkCreateSamplerYcbcrConversion( m_device, reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSamplerYcbcrConversion*>( &ycbcrConversion ) ) );
    return createResultValue( result, ycbcrConversion, VULKAN_HPP_NAMESPACE_STRING"::Device::createSamplerYcbcrConversion" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SamplerYcbcrConversion,Dispatch>>::type Device::createSamplerYcbcrConversionUnique( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SamplerYcbcrConversion ycbcrConversion;
    Result result = static_cast<Result>( d.vkCreateSamplerYcbcrConversion( m_device, reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSamplerYcbcrConversion*>( &ycbcrConversion ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SamplerYcbcrConversion,Dispatch>( result, ycbcrConversion, VULKAN_HPP_NAMESPACE_STRING"::Device::createSamplerYcbcrConversionUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createSamplerYcbcrConversionKHR( const vk::SamplerYcbcrConversionCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SamplerYcbcrConversion* pYcbcrConversion, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateSamplerYcbcrConversionKHR( m_device, reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSamplerYcbcrConversion*>( pYcbcrConversion ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SamplerYcbcrConversion>::type Device::createSamplerYcbcrConversionKHR( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SamplerYcbcrConversion ycbcrConversion;
    Result result = static_cast<Result>( d.vkCreateSamplerYcbcrConversionKHR( m_device, reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSamplerYcbcrConversion*>( &ycbcrConversion ) ) );
    return createResultValue( result, ycbcrConversion, VULKAN_HPP_NAMESPACE_STRING"::Device::createSamplerYcbcrConversionKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SamplerYcbcrConversion,Dispatch>>::type Device::createSamplerYcbcrConversionKHRUnique( const SamplerYcbcrConversionCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SamplerYcbcrConversion ycbcrConversion;
    Result result = static_cast<Result>( d.vkCreateSamplerYcbcrConversionKHR( m_device, reinterpret_cast<const VkSamplerYcbcrConversionCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSamplerYcbcrConversion*>( &ycbcrConversion ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SamplerYcbcrConversion,Dispatch>( result, ycbcrConversion, VULKAN_HPP_NAMESPACE_STRING"::Device::createSamplerYcbcrConversionKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createSemaphore( const vk::SemaphoreCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Semaphore* pSemaphore, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateSemaphore( m_device, reinterpret_cast<const VkSemaphoreCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSemaphore*>( pSemaphore ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Semaphore>::type Device::createSemaphore( const SemaphoreCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Semaphore semaphore;
    Result result = static_cast<Result>( d.vkCreateSemaphore( m_device, reinterpret_cast<const VkSemaphoreCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSemaphore*>( &semaphore ) ) );
    return createResultValue( result, semaphore, VULKAN_HPP_NAMESPACE_STRING"::Device::createSemaphore" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Semaphore,Dispatch>>::type Device::createSemaphoreUnique( const SemaphoreCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Semaphore semaphore;
    Result result = static_cast<Result>( d.vkCreateSemaphore( m_device, reinterpret_cast<const VkSemaphoreCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSemaphore*>( &semaphore ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<Semaphore,Dispatch>( result, semaphore, VULKAN_HPP_NAMESPACE_STRING"::Device::createSemaphoreUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createShaderModule( const vk::ShaderModuleCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ShaderModule* pShaderModule, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateShaderModule( m_device, reinterpret_cast<const VkShaderModuleCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkShaderModule*>( pShaderModule ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ShaderModule>::type Device::createShaderModule( const ShaderModuleCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ShaderModule shaderModule;
    Result result = static_cast<Result>( d.vkCreateShaderModule( m_device, reinterpret_cast<const VkShaderModuleCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkShaderModule*>( &shaderModule ) ) );
    return createResultValue( result, shaderModule, VULKAN_HPP_NAMESPACE_STRING"::Device::createShaderModule" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<ShaderModule,Dispatch>>::type Device::createShaderModuleUnique( const ShaderModuleCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ShaderModule shaderModule;
    Result result = static_cast<Result>( d.vkCreateShaderModule( m_device, reinterpret_cast<const VkShaderModuleCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkShaderModule*>( &shaderModule ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<ShaderModule,Dispatch>( result, shaderModule, VULKAN_HPP_NAMESPACE_STRING"::Device::createShaderModuleUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createSharedSwapchainsKHR( uint32_t swapchainCount, const vk::SwapchainCreateInfoKHR* pCreateInfos, const vk::AllocationCallbacks* pAllocator, vk::SwapchainKHR* pSwapchains, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateSharedSwapchainsKHR( m_device, swapchainCount, reinterpret_cast<const VkSwapchainCreateInfoKHR*>( pCreateInfos ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSwapchainKHR*>( pSwapchains ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<SwapchainKHR,Allocator>>::type Device::createSharedSwapchainsKHR( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    std::vector<SwapchainKHR,Allocator> swapchains( createInfos.size() );
    Result result = static_cast<Result>( d.vkCreateSharedSwapchainsKHR( m_device, createInfos.size() , reinterpret_cast<const VkSwapchainCreateInfoKHR*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( swapchains.data() ) ) );
    return createResultValue( result, swapchains, VULKAN_HPP_NAMESPACE_STRING"::Device::createSharedSwapchainsKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<SwapchainKHR,Allocator>>::type Device::createSharedSwapchainsKHR( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SwapchainKHR,Allocator> swapchains( createInfos.size(), vectorAllocator );
    Result result = static_cast<Result>( d.vkCreateSharedSwapchainsKHR( m_device, createInfos.size() , reinterpret_cast<const VkSwapchainCreateInfoKHR*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( swapchains.data() ) ) );
    return createResultValue( result, swapchains, VULKAN_HPP_NAMESPACE_STRING"::Device::createSharedSwapchainsKHR" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<SwapchainKHR>::type Device::createSharedSwapchainKHR( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    SwapchainKHR swapchain;
    Result result = static_cast<Result>( d.vkCreateSharedSwapchainsKHR( m_device, 1 , reinterpret_cast<const VkSwapchainCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( &swapchain ) ) );
    return createResultValue( result, swapchain, VULKAN_HPP_NAMESPACE_STRING"::Device::createSharedSwapchainKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<SwapchainKHR,Dispatch>,Allocator>>::type Device::createSharedSwapchainsKHRUnique( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    static_assert( sizeof( SwapchainKHR ) <= sizeof( UniqueHandle<SwapchainKHR, Dispatch> ), "SwapchainKHR is greater than UniqueHandle<SwapchainKHR, Dispatch>!" );
    std::vector<UniqueHandle<SwapchainKHR, Dispatch>, Allocator> swapchainKHRs;
    swapchainKHRs.reserve( createInfos.size() );
    SwapchainKHR* buffer = reinterpret_cast<SwapchainKHR*>( reinterpret_cast<char*>( swapchainKHRs.data() ) + createInfos.size() * ( sizeof( UniqueHandle<SwapchainKHR, Dispatch> ) - sizeof( SwapchainKHR ) ) );
    Result result = static_cast<Result>(d.vkCreateSharedSwapchainsKHR( m_device, createInfos.size() , reinterpret_cast<const VkSwapchainCreateInfoKHR*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        swapchainKHRs.push_back( UniqueHandle<SwapchainKHR, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, swapchainKHRs, VULKAN_HPP_NAMESPACE_STRING "::Device::createSharedSwapchainsKHRUnique" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<UniqueHandle<SwapchainKHR,Dispatch>,Allocator>>::type Device::createSharedSwapchainsKHRUnique( ArrayProxy<const vk::SwapchainCreateInfoKHR> createInfos, Optional<const AllocationCallbacks> allocator, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    static_assert( sizeof( SwapchainKHR ) <= sizeof( UniqueHandle<SwapchainKHR, Dispatch> ), "SwapchainKHR is greater than UniqueHandle<SwapchainKHR, Dispatch>!" );
    std::vector<UniqueHandle<SwapchainKHR, Dispatch>, Allocator> swapchainKHRs( vectorAllocator );
    swapchainKHRs.reserve( createInfos.size() );
    SwapchainKHR* buffer = reinterpret_cast<SwapchainKHR*>( reinterpret_cast<char*>( swapchainKHRs.data() ) + createInfos.size() * ( sizeof( UniqueHandle<SwapchainKHR, Dispatch> ) - sizeof( SwapchainKHR ) ) );
    Result result = static_cast<Result>(d.vkCreateSharedSwapchainsKHR( m_device, createInfos.size() , reinterpret_cast<const VkSwapchainCreateInfoKHR*>( createInfos.data() ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( buffer ) ) );
    if (result == vk::Result::eSuccess)
    {
      ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
      for ( size_t i=0 ; i<createInfos.size() ; i++ )
      {
        swapchainKHRs.push_back( UniqueHandle<SwapchainKHR, Dispatch>( buffer[i], deleter ) );
      }
    }

    return createResultValue( result, swapchainKHRs, VULKAN_HPP_NAMESPACE_STRING "::Device::createSharedSwapchainsKHRUnique" );
  }
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SwapchainKHR,Dispatch>>::type Device::createSharedSwapchainKHRUnique( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    SwapchainKHR swapchain;
    Result result = static_cast<Result>( d.vkCreateSharedSwapchainsKHR( m_device, 1 , reinterpret_cast<const VkSwapchainCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( &swapchain ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SwapchainKHR,Dispatch>( result, swapchain, VULKAN_HPP_NAMESPACE_STRING"::Device::createSharedSwapchainKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createSwapchainKHR( const vk::SwapchainCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SwapchainKHR* pSwapchain, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateSwapchainKHR( m_device, reinterpret_cast<const VkSwapchainCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSwapchainKHR*>( pSwapchain ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SwapchainKHR>::type Device::createSwapchainKHR( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SwapchainKHR swapchain;
    Result result = static_cast<Result>( d.vkCreateSwapchainKHR( m_device, reinterpret_cast<const VkSwapchainCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( &swapchain ) ) );
    return createResultValue( result, swapchain, VULKAN_HPP_NAMESPACE_STRING"::Device::createSwapchainKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SwapchainKHR,Dispatch>>::type Device::createSwapchainKHRUnique( const SwapchainCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SwapchainKHR swapchain;
    Result result = static_cast<Result>( d.vkCreateSwapchainKHR( m_device, reinterpret_cast<const VkSwapchainCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSwapchainKHR*>( &swapchain ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SwapchainKHR,Dispatch>( result, swapchain, VULKAN_HPP_NAMESPACE_STRING"::Device::createSwapchainKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::createValidationCacheEXT( const vk::ValidationCacheCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::ValidationCacheEXT* pValidationCache, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateValidationCacheEXT( m_device, reinterpret_cast<const VkValidationCacheCreateInfoEXT*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkValidationCacheEXT*>( pValidationCache ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ValidationCacheEXT>::type Device::createValidationCacheEXT( const ValidationCacheCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ValidationCacheEXT validationCache;
    Result result = static_cast<Result>( d.vkCreateValidationCacheEXT( m_device, reinterpret_cast<const VkValidationCacheCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkValidationCacheEXT*>( &validationCache ) ) );
    return createResultValue( result, validationCache, VULKAN_HPP_NAMESPACE_STRING"::Device::createValidationCacheEXT" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<ValidationCacheEXT,Dispatch>>::type Device::createValidationCacheEXTUnique( const ValidationCacheCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::ValidationCacheEXT validationCache;
    Result result = static_cast<Result>( d.vkCreateValidationCacheEXT( m_device, reinterpret_cast<const VkValidationCacheCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkValidationCacheEXT*>( &validationCache ) ) );

    ObjectDestroy<Device,Dispatch> deleter( *this, allocator, d );
    return createResultValue<ValidationCacheEXT,Dispatch>( result, validationCache, VULKAN_HPP_NAMESPACE_STRING"::Device::createValidationCacheEXTUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::debugMarkerSetObjectNameEXT( const vk::DebugMarkerObjectNameInfoEXT* pNameInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkDebugMarkerSetObjectNameEXT( m_device, reinterpret_cast<const VkDebugMarkerObjectNameInfoEXT*>( pNameInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::debugMarkerSetObjectNameEXT( const DebugMarkerObjectNameInfoEXT & nameInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkDebugMarkerSetObjectNameEXT( m_device, reinterpret_cast<const VkDebugMarkerObjectNameInfoEXT*>( &nameInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::debugMarkerSetObjectNameEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::debugMarkerSetObjectTagEXT( const vk::DebugMarkerObjectTagInfoEXT* pTagInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkDebugMarkerSetObjectTagEXT( m_device, reinterpret_cast<const VkDebugMarkerObjectTagInfoEXT*>( pTagInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::debugMarkerSetObjectTagEXT( const DebugMarkerObjectTagInfoEXT & tagInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkDebugMarkerSetObjectTagEXT( m_device, reinterpret_cast<const VkDebugMarkerObjectTagInfoEXT*>( &tagInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::debugMarkerSetObjectTagEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyAccelerationStructureNV( vk::AccelerationStructureNV accelerationStructure, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyAccelerationStructureNV( m_device, static_cast<VkAccelerationStructureNV>( accelerationStructure ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyAccelerationStructureNV( vk::AccelerationStructureNV accelerationStructure, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyAccelerationStructureNV( m_device, static_cast<VkAccelerationStructureNV>( accelerationStructure ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::AccelerationStructureNV accelerationStructure, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyAccelerationStructureNV( m_device, static_cast<VkAccelerationStructureNV>( accelerationStructure ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::AccelerationStructureNV accelerationStructure, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyAccelerationStructureNV( m_device, static_cast<VkAccelerationStructureNV>( accelerationStructure ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyBuffer( vk::Buffer buffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBuffer( m_device, static_cast<VkBuffer>( buffer ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyBuffer( vk::Buffer buffer, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBuffer( m_device, static_cast<VkBuffer>( buffer ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Buffer buffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBuffer( m_device, static_cast<VkBuffer>( buffer ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Buffer buffer, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBuffer( m_device, static_cast<VkBuffer>( buffer ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyBufferView( vk::BufferView bufferView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBufferView( m_device, static_cast<VkBufferView>( bufferView ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyBufferView( vk::BufferView bufferView, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBufferView( m_device, static_cast<VkBufferView>( bufferView ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::BufferView bufferView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBufferView( m_device, static_cast<VkBufferView>( bufferView ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::BufferView bufferView, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyBufferView( m_device, static_cast<VkBufferView>( bufferView ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyCommandPool( vk::CommandPool commandPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyCommandPool( vk::CommandPool commandPool, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::CommandPool commandPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::CommandPool commandPool, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorPool( vk::DescriptorPool descriptorPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorPool( m_device, static_cast<VkDescriptorPool>( descriptorPool ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorPool( vk::DescriptorPool descriptorPool, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorPool( m_device, static_cast<VkDescriptorPool>( descriptorPool ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::DescriptorPool descriptorPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorPool( m_device, static_cast<VkDescriptorPool>( descriptorPool ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::DescriptorPool descriptorPool, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorPool( m_device, static_cast<VkDescriptorPool>( descriptorPool ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorSetLayout( vk::DescriptorSetLayout descriptorSetLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorSetLayout( m_device, static_cast<VkDescriptorSetLayout>( descriptorSetLayout ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorSetLayout( vk::DescriptorSetLayout descriptorSetLayout, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorSetLayout( m_device, static_cast<VkDescriptorSetLayout>( descriptorSetLayout ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::DescriptorSetLayout descriptorSetLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorSetLayout( m_device, static_cast<VkDescriptorSetLayout>( descriptorSetLayout ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::DescriptorSetLayout descriptorSetLayout, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorSetLayout( m_device, static_cast<VkDescriptorSetLayout>( descriptorSetLayout ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorUpdateTemplate( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorUpdateTemplate( m_device, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorUpdateTemplate( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorUpdateTemplate( m_device, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorUpdateTemplate( m_device, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorUpdateTemplate( m_device, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorUpdateTemplateKHR( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorUpdateTemplateKHR( m_device, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyDescriptorUpdateTemplateKHR( vk::DescriptorUpdateTemplate descriptorUpdateTemplate, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDescriptorUpdateTemplateKHR( m_device, static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDevice( m_device, reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDevice( m_device, reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyEvent( vk::Event event, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyEvent( m_device, static_cast<VkEvent>( event ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyEvent( vk::Event event, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyEvent( m_device, static_cast<VkEvent>( event ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Event event, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyEvent( m_device, static_cast<VkEvent>( event ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Event event, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyEvent( m_device, static_cast<VkEvent>( event ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyFence( vk::Fence fence, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFence( m_device, static_cast<VkFence>( fence ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyFence( vk::Fence fence, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFence( m_device, static_cast<VkFence>( fence ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Fence fence, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFence( m_device, static_cast<VkFence>( fence ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Fence fence, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFence( m_device, static_cast<VkFence>( fence ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyFramebuffer( vk::Framebuffer framebuffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFramebuffer( m_device, static_cast<VkFramebuffer>( framebuffer ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyFramebuffer( vk::Framebuffer framebuffer, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFramebuffer( m_device, static_cast<VkFramebuffer>( framebuffer ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Framebuffer framebuffer, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFramebuffer( m_device, static_cast<VkFramebuffer>( framebuffer ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Framebuffer framebuffer, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyFramebuffer( m_device, static_cast<VkFramebuffer>( framebuffer ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyImage( vk::Image image, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImage( m_device, static_cast<VkImage>( image ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyImage( vk::Image image, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImage( m_device, static_cast<VkImage>( image ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Image image, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImage( m_device, static_cast<VkImage>( image ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Image image, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImage( m_device, static_cast<VkImage>( image ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyImageView( vk::ImageView imageView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImageView( m_device, static_cast<VkImageView>( imageView ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyImageView( vk::ImageView imageView, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImageView( m_device, static_cast<VkImageView>( imageView ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ImageView imageView, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImageView( m_device, static_cast<VkImageView>( imageView ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ImageView imageView, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyImageView( m_device, static_cast<VkImageView>( imageView ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyIndirectCommandsLayoutNVX( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyIndirectCommandsLayoutNVX( m_device, static_cast<VkIndirectCommandsLayoutNVX>( indirectCommandsLayout ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyIndirectCommandsLayoutNVX( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyIndirectCommandsLayoutNVX( m_device, static_cast<VkIndirectCommandsLayoutNVX>( indirectCommandsLayout ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyIndirectCommandsLayoutNVX( m_device, static_cast<VkIndirectCommandsLayoutNVX>( indirectCommandsLayout ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::IndirectCommandsLayoutNVX indirectCommandsLayout, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyIndirectCommandsLayoutNVX( m_device, static_cast<VkIndirectCommandsLayoutNVX>( indirectCommandsLayout ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyObjectTableNVX( vk::ObjectTableNVX objectTable, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyObjectTableNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyObjectTableNVX( vk::ObjectTableNVX objectTable, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyObjectTableNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ObjectTableNVX objectTable, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyObjectTableNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ObjectTableNVX objectTable, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyObjectTableNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyPipeline( vk::Pipeline pipeline, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipeline( m_device, static_cast<VkPipeline>( pipeline ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyPipeline( vk::Pipeline pipeline, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipeline( m_device, static_cast<VkPipeline>( pipeline ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Pipeline pipeline, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipeline( m_device, static_cast<VkPipeline>( pipeline ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Pipeline pipeline, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipeline( m_device, static_cast<VkPipeline>( pipeline ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyPipelineCache( vk::PipelineCache pipelineCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineCache( m_device, static_cast<VkPipelineCache>( pipelineCache ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyPipelineCache( vk::PipelineCache pipelineCache, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineCache( m_device, static_cast<VkPipelineCache>( pipelineCache ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::PipelineCache pipelineCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineCache( m_device, static_cast<VkPipelineCache>( pipelineCache ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::PipelineCache pipelineCache, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineCache( m_device, static_cast<VkPipelineCache>( pipelineCache ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyPipelineLayout( vk::PipelineLayout pipelineLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineLayout( m_device, static_cast<VkPipelineLayout>( pipelineLayout ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyPipelineLayout( vk::PipelineLayout pipelineLayout, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineLayout( m_device, static_cast<VkPipelineLayout>( pipelineLayout ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::PipelineLayout pipelineLayout, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineLayout( m_device, static_cast<VkPipelineLayout>( pipelineLayout ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::PipelineLayout pipelineLayout, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyPipelineLayout( m_device, static_cast<VkPipelineLayout>( pipelineLayout ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyQueryPool( vk::QueryPool queryPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyQueryPool( m_device, static_cast<VkQueryPool>( queryPool ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyQueryPool( vk::QueryPool queryPool, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyQueryPool( m_device, static_cast<VkQueryPool>( queryPool ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::QueryPool queryPool, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyQueryPool( m_device, static_cast<VkQueryPool>( queryPool ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::QueryPool queryPool, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyQueryPool( m_device, static_cast<VkQueryPool>( queryPool ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyRenderPass( vk::RenderPass renderPass, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyRenderPass( m_device, static_cast<VkRenderPass>( renderPass ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyRenderPass( vk::RenderPass renderPass, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyRenderPass( m_device, static_cast<VkRenderPass>( renderPass ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::RenderPass renderPass, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyRenderPass( m_device, static_cast<VkRenderPass>( renderPass ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::RenderPass renderPass, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyRenderPass( m_device, static_cast<VkRenderPass>( renderPass ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySampler( vk::Sampler sampler, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySampler( m_device, static_cast<VkSampler>( sampler ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySampler( vk::Sampler sampler, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySampler( m_device, static_cast<VkSampler>( sampler ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Sampler sampler, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySampler( m_device, static_cast<VkSampler>( sampler ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Sampler sampler, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySampler( m_device, static_cast<VkSampler>( sampler ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySamplerYcbcrConversion( vk::SamplerYcbcrConversion ycbcrConversion, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySamplerYcbcrConversion( m_device, static_cast<VkSamplerYcbcrConversion>( ycbcrConversion ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySamplerYcbcrConversion( vk::SamplerYcbcrConversion ycbcrConversion, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySamplerYcbcrConversion( m_device, static_cast<VkSamplerYcbcrConversion>( ycbcrConversion ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::SamplerYcbcrConversion ycbcrConversion, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySamplerYcbcrConversion( m_device, static_cast<VkSamplerYcbcrConversion>( ycbcrConversion ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::SamplerYcbcrConversion ycbcrConversion, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySamplerYcbcrConversion( m_device, static_cast<VkSamplerYcbcrConversion>( ycbcrConversion ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySamplerYcbcrConversionKHR( vk::SamplerYcbcrConversion ycbcrConversion, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySamplerYcbcrConversionKHR( m_device, static_cast<VkSamplerYcbcrConversion>( ycbcrConversion ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySamplerYcbcrConversionKHR( vk::SamplerYcbcrConversion ycbcrConversion, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySamplerYcbcrConversionKHR( m_device, static_cast<VkSamplerYcbcrConversion>( ycbcrConversion ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySemaphore( vk::Semaphore semaphore, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySemaphore( m_device, static_cast<VkSemaphore>( semaphore ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySemaphore( vk::Semaphore semaphore, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySemaphore( m_device, static_cast<VkSemaphore>( semaphore ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Semaphore semaphore, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySemaphore( m_device, static_cast<VkSemaphore>( semaphore ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::Semaphore semaphore, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySemaphore( m_device, static_cast<VkSemaphore>( semaphore ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyShaderModule( vk::ShaderModule shaderModule, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyShaderModule( m_device, static_cast<VkShaderModule>( shaderModule ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyShaderModule( vk::ShaderModule shaderModule, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyShaderModule( m_device, static_cast<VkShaderModule>( shaderModule ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ShaderModule shaderModule, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyShaderModule( m_device, static_cast<VkShaderModule>( shaderModule ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ShaderModule shaderModule, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyShaderModule( m_device, static_cast<VkShaderModule>( shaderModule ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySwapchainKHR( vk::SwapchainKHR swapchain, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySwapchainKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroySwapchainKHR( vk::SwapchainKHR swapchain, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySwapchainKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::SwapchainKHR swapchain, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySwapchainKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::SwapchainKHR swapchain, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySwapchainKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyValidationCacheEXT( vk::ValidationCacheEXT validationCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyValidationCacheEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroyValidationCacheEXT( vk::ValidationCacheEXT validationCache, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyValidationCacheEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ValidationCacheEXT validationCache, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyValidationCacheEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::destroy( vk::ValidationCacheEXT validationCache, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyValidationCacheEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::waitIdle(Dispatch const &d) const
  {
    return static_cast<Result>( d.vkDeviceWaitIdle( m_device ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::waitIdle(Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkDeviceWaitIdle( m_device ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::waitIdle" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::displayPowerControlEXT( vk::DisplayKHR display, const vk::DisplayPowerInfoEXT* pDisplayPowerInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkDisplayPowerControlEXT( m_device, static_cast<VkDisplayKHR>( display ), reinterpret_cast<const VkDisplayPowerInfoEXT*>( pDisplayPowerInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::displayPowerControlEXT( vk::DisplayKHR display, const DisplayPowerInfoEXT & displayPowerInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkDisplayPowerControlEXT( m_device, static_cast<VkDisplayKHR>( display ), reinterpret_cast<const VkDisplayPowerInfoEXT*>( &displayPowerInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::displayPowerControlEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::flushMappedMemoryRanges( uint32_t memoryRangeCount, const vk::MappedMemoryRange* pMemoryRanges, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkFlushMappedMemoryRanges( m_device, memoryRangeCount, reinterpret_cast<const VkMappedMemoryRange*>( pMemoryRanges ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::flushMappedMemoryRanges( ArrayProxy<const vk::MappedMemoryRange> memoryRanges, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkFlushMappedMemoryRanges( m_device, memoryRanges.size() , reinterpret_cast<const VkMappedMemoryRange*>( memoryRanges.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::flushMappedMemoryRanges" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::freeCommandBuffers( vk::CommandPool commandPool, uint32_t commandBufferCount, const vk::CommandBuffer* pCommandBuffers, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeCommandBuffers( m_device, static_cast<VkCommandPool>( commandPool ), commandBufferCount, reinterpret_cast<const VkCommandBuffer*>( pCommandBuffers ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::freeCommandBuffers( vk::CommandPool commandPool, ArrayProxy<const vk::CommandBuffer> commandBuffers, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeCommandBuffers( m_device, static_cast<VkCommandPool>( commandPool ), commandBuffers.size() , reinterpret_cast<const VkCommandBuffer*>( commandBuffers.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::free( vk::CommandPool commandPool, uint32_t commandBufferCount, const vk::CommandBuffer* pCommandBuffers, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeCommandBuffers( m_device, static_cast<VkCommandPool>( commandPool ), commandBufferCount, reinterpret_cast<const VkCommandBuffer*>( pCommandBuffers ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::free( vk::CommandPool commandPool, ArrayProxy<const vk::CommandBuffer> commandBuffers, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeCommandBuffers( m_device, static_cast<VkCommandPool>( commandPool ), commandBuffers.size() , reinterpret_cast<const VkCommandBuffer*>( commandBuffers.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::freeDescriptorSets( vk::DescriptorPool descriptorPool, uint32_t descriptorSetCount, const vk::DescriptorSet* pDescriptorSets, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkFreeDescriptorSets( m_device, static_cast<VkDescriptorPool>( descriptorPool ), descriptorSetCount, reinterpret_cast<const VkDescriptorSet*>( pDescriptorSets ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::freeDescriptorSets( vk::DescriptorPool descriptorPool, ArrayProxy<const vk::DescriptorSet> descriptorSets, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkFreeDescriptorSets( m_device, static_cast<VkDescriptorPool>( descriptorPool ), descriptorSets.size() , reinterpret_cast<const VkDescriptorSet*>( descriptorSets.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::freeDescriptorSets" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::free( vk::DescriptorPool descriptorPool, uint32_t descriptorSetCount, const vk::DescriptorSet* pDescriptorSets, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkFreeDescriptorSets( m_device, static_cast<VkDescriptorPool>( descriptorPool ), descriptorSetCount, reinterpret_cast<const VkDescriptorSet*>( pDescriptorSets ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::free( vk::DescriptorPool descriptorPool, ArrayProxy<const vk::DescriptorSet> descriptorSets, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkFreeDescriptorSets( m_device, static_cast<VkDescriptorPool>( descriptorPool ), descriptorSets.size() , reinterpret_cast<const VkDescriptorSet*>( descriptorSets.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::free" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::freeMemory( vk::DeviceMemory memory, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeMemory( m_device, static_cast<VkDeviceMemory>( memory ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::freeMemory( vk::DeviceMemory memory, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeMemory( m_device, static_cast<VkDeviceMemory>( memory ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::free( vk::DeviceMemory memory, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeMemory( m_device, static_cast<VkDeviceMemory>( memory ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::free( vk::DeviceMemory memory, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkFreeMemory( m_device, static_cast<VkDeviceMemory>( memory ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getAccelerationStructureHandleNV( vk::AccelerationStructureNV accelerationStructure, size_t dataSize, void* pData, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetAccelerationStructureHandleNV( m_device, static_cast<VkAccelerationStructureNV>( accelerationStructure ), dataSize, pData ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename T, typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::getAccelerationStructureHandleNV( vk::AccelerationStructureNV accelerationStructure, ArrayProxy<T> data, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkGetAccelerationStructureHandleNV( m_device, static_cast<VkAccelerationStructureNV>( accelerationStructure ), data.size() * sizeof( T ) , reinterpret_cast<void*>( data.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::getAccelerationStructureHandleNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getAccelerationStructureMemoryRequirementsNV( const vk::AccelerationStructureMemoryRequirementsInfoNV* pInfo, vk::MemoryRequirements2KHR* pMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetAccelerationStructureMemoryRequirementsNV( m_device, reinterpret_cast<const VkAccelerationStructureMemoryRequirementsInfoNV*>( pInfo ), reinterpret_cast<VkMemoryRequirements2KHR*>( pMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MemoryRequirements2KHR Device::getAccelerationStructureMemoryRequirementsNV( const AccelerationStructureMemoryRequirementsInfoNV & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MemoryRequirements2KHR memoryRequirements;
    d.vkGetAccelerationStructureMemoryRequirementsNV( m_device, reinterpret_cast<const VkAccelerationStructureMemoryRequirementsInfoNV*>( &info ), reinterpret_cast<VkMemoryRequirements2KHR*>( &memoryRequirements ) );
    return memoryRequirements;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> Device::getAccelerationStructureMemoryRequirementsNV( const AccelerationStructureMemoryRequirementsInfoNV & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::MemoryRequirements2KHR& memoryRequirements = structureChain.template get<vk::MemoryRequirements2KHR>();
    d.vkGetAccelerationStructureMemoryRequirementsNV( m_device, reinterpret_cast<const VkAccelerationStructureMemoryRequirementsInfoNV*>( &info ), reinterpret_cast<VkMemoryRequirements2KHR*>( &memoryRequirements ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getAndroidHardwareBufferPropertiesANDROID( const struct AHardwareBuffer* buffer, vk::AndroidHardwareBufferPropertiesANDROID* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetAndroidHardwareBufferPropertiesANDROID( m_device, buffer, reinterpret_cast<VkAndroidHardwareBufferPropertiesANDROID*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::AndroidHardwareBufferPropertiesANDROID>::type Device::getAndroidHardwareBufferPropertiesANDROID( const struct AHardwareBuffer & buffer, Dispatch const &d ) const
  {
    vk::AndroidHardwareBufferPropertiesANDROID properties;
    Result result = static_cast<Result>( d.vkGetAndroidHardwareBufferPropertiesANDROID( m_device, buffer, reinterpret_cast<VkAndroidHardwareBufferPropertiesANDROID*>( &properties ) ) );
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::Device::getAndroidHardwareBufferPropertiesANDROID" );
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<StructureChain<X, Y, Z...>>::type Device::getAndroidHardwareBufferPropertiesANDROID( const struct AHardwareBuffer & buffer, Dispatch const &d ) const
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::AndroidHardwareBufferPropertiesANDROID& properties = structureChain.template get<vk::AndroidHardwareBufferPropertiesANDROID>();
    Result result = static_cast<Result>( d.vkGetAndroidHardwareBufferPropertiesANDROID( m_device, buffer, reinterpret_cast<VkAndroidHardwareBufferPropertiesANDROID*>( &properties ) ) );
    return createResultValue( result, structureChain, VULKAN_HPP_NAMESPACE_STRING"::Device::getAndroidHardwareBufferPropertiesANDROID" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE DeviceAddress Device::getBufferAddressEXT( const vk::BufferDeviceAddressInfoEXT* pInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return static_cast<DeviceAddress>( d.vkGetBufferDeviceAddressEXT( m_device, reinterpret_cast<const VkBufferDeviceAddressInfoEXT*>( pInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE DeviceAddress Device::getBufferAddressEXT( const BufferDeviceAddressInfoEXT & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetBufferDeviceAddressEXT( m_device, reinterpret_cast<const VkBufferDeviceAddressInfoEXT*>( &info ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getBufferMemoryRequirements( vk::Buffer buffer, vk::MemoryRequirements* pMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetBufferMemoryRequirements( m_device, static_cast<VkBuffer>( buffer ), reinterpret_cast<VkMemoryRequirements*>( pMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MemoryRequirements Device::getBufferMemoryRequirements( vk::Buffer buffer, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MemoryRequirements memoryRequirements;
    d.vkGetBufferMemoryRequirements( m_device, static_cast<VkBuffer>( buffer ), reinterpret_cast<VkMemoryRequirements*>( &memoryRequirements ) );
    return memoryRequirements;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getBufferMemoryRequirements2( const vk::BufferMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetBufferMemoryRequirements2( m_device, reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>( pInfo ), reinterpret_cast<VkMemoryRequirements2*>( pMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MemoryRequirements2 Device::getBufferMemoryRequirements2( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MemoryRequirements2 memoryRequirements;
    d.vkGetBufferMemoryRequirements2( m_device, reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return memoryRequirements;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> Device::getBufferMemoryRequirements2( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::MemoryRequirements2& memoryRequirements = structureChain.template get<vk::MemoryRequirements2>();
    d.vkGetBufferMemoryRequirements2( m_device, reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getBufferMemoryRequirements2KHR( const vk::BufferMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetBufferMemoryRequirements2KHR( m_device, reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>( pInfo ), reinterpret_cast<VkMemoryRequirements2*>( pMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MemoryRequirements2 Device::getBufferMemoryRequirements2KHR( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MemoryRequirements2 memoryRequirements;
    d.vkGetBufferMemoryRequirements2KHR( m_device, reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return memoryRequirements;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> Device::getBufferMemoryRequirements2KHR( const BufferMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::MemoryRequirements2& memoryRequirements = structureChain.template get<vk::MemoryRequirements2>();
    d.vkGetBufferMemoryRequirements2KHR( m_device, reinterpret_cast<const VkBufferMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getCalibratedTimestampsEXT( uint32_t timestampCount, const vk::CalibratedTimestampInfoEXT* pTimestampInfos, uint64_t* pTimestamps, uint64_t* pMaxDeviation, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetCalibratedTimestampsEXT( m_device, timestampCount, reinterpret_cast<const VkCalibratedTimestampInfoEXT*>( pTimestampInfos ), pTimestamps, pMaxDeviation ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<uint64_t>::type Device::getCalibratedTimestampsEXT( ArrayProxy<const vk::CalibratedTimestampInfoEXT> timestampInfos, ArrayProxy<uint64_t> timestamps, Dispatch const &d ) const
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( timestampInfos.size() == timestamps.size() );
#else
    if ( timestampInfos.size() != timestamps.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkDevice::getCalibratedTimestampsEXT: timestampInfos.size() != timestamps.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    uint64_t maxDeviation;
    Result result = static_cast<Result>( d.vkGetCalibratedTimestampsEXT( m_device, timestampInfos.size() , reinterpret_cast<const VkCalibratedTimestampInfoEXT*>( timestampInfos.data() ), timestamps.data(), &maxDeviation ) );
    return createResultValue( result, maxDeviation, VULKAN_HPP_NAMESPACE_STRING"::Device::getCalibratedTimestampsEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getDescriptorSetLayoutSupport( const vk::DescriptorSetLayoutCreateInfo* pCreateInfo, vk::DescriptorSetLayoutSupport* pSupport, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetDescriptorSetLayoutSupport( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( pCreateInfo ), reinterpret_cast<VkDescriptorSetLayoutSupport*>( pSupport ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::DescriptorSetLayoutSupport Device::getDescriptorSetLayoutSupport( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::DescriptorSetLayoutSupport support;
    d.vkGetDescriptorSetLayoutSupport( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( &createInfo ), reinterpret_cast<VkDescriptorSetLayoutSupport*>( &support ) );
    return support;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> Device::getDescriptorSetLayoutSupport( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::DescriptorSetLayoutSupport& support = structureChain.template get<vk::DescriptorSetLayoutSupport>();
    d.vkGetDescriptorSetLayoutSupport( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( &createInfo ), reinterpret_cast<VkDescriptorSetLayoutSupport*>( &support ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getDescriptorSetLayoutSupportKHR( const vk::DescriptorSetLayoutCreateInfo* pCreateInfo, vk::DescriptorSetLayoutSupport* pSupport, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetDescriptorSetLayoutSupportKHR( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( pCreateInfo ), reinterpret_cast<VkDescriptorSetLayoutSupport*>( pSupport ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::DescriptorSetLayoutSupport Device::getDescriptorSetLayoutSupportKHR( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::DescriptorSetLayoutSupport support;
    d.vkGetDescriptorSetLayoutSupportKHR( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( &createInfo ), reinterpret_cast<VkDescriptorSetLayoutSupport*>( &support ) );
    return support;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> Device::getDescriptorSetLayoutSupportKHR( const DescriptorSetLayoutCreateInfo & createInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::DescriptorSetLayoutSupport& support = structureChain.template get<vk::DescriptorSetLayoutSupport>();
    d.vkGetDescriptorSetLayoutSupportKHR( m_device, reinterpret_cast<const VkDescriptorSetLayoutCreateInfo*>( &createInfo ), reinterpret_cast<VkDescriptorSetLayoutSupport*>( &support ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getGroupPeerMemoryFeatures( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, vk::PeerMemoryFeatureFlags* pPeerMemoryFeatures, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetDeviceGroupPeerMemoryFeatures( m_device, heapIndex, localDeviceIndex, remoteDeviceIndex, reinterpret_cast<VkPeerMemoryFeatureFlags*>( pPeerMemoryFeatures ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PeerMemoryFeatureFlags Device::getGroupPeerMemoryFeatures( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PeerMemoryFeatureFlags peerMemoryFeatures;
    d.vkGetDeviceGroupPeerMemoryFeatures( m_device, heapIndex, localDeviceIndex, remoteDeviceIndex, reinterpret_cast<VkPeerMemoryFeatureFlags*>( &peerMemoryFeatures ) );
    return peerMemoryFeatures;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getGroupPeerMemoryFeaturesKHR( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, vk::PeerMemoryFeatureFlags* pPeerMemoryFeatures, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetDeviceGroupPeerMemoryFeaturesKHR( m_device, heapIndex, localDeviceIndex, remoteDeviceIndex, reinterpret_cast<VkPeerMemoryFeatureFlags*>( pPeerMemoryFeatures ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PeerMemoryFeatureFlags Device::getGroupPeerMemoryFeaturesKHR( uint32_t heapIndex, uint32_t localDeviceIndex, uint32_t remoteDeviceIndex, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PeerMemoryFeatureFlags peerMemoryFeatures;
    d.vkGetDeviceGroupPeerMemoryFeaturesKHR( m_device, heapIndex, localDeviceIndex, remoteDeviceIndex, reinterpret_cast<VkPeerMemoryFeatureFlags*>( &peerMemoryFeatures ) );
    return peerMemoryFeatures;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getGroupPresentCapabilitiesKHR( vk::DeviceGroupPresentCapabilitiesKHR* pDeviceGroupPresentCapabilities, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDeviceGroupPresentCapabilitiesKHR( m_device, reinterpret_cast<VkDeviceGroupPresentCapabilitiesKHR*>( pDeviceGroupPresentCapabilities ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DeviceGroupPresentCapabilitiesKHR>::type Device::getGroupPresentCapabilitiesKHR(Dispatch const &d ) const
  {
    vk::DeviceGroupPresentCapabilitiesKHR deviceGroupPresentCapabilities;
    Result result = static_cast<Result>( d.vkGetDeviceGroupPresentCapabilitiesKHR( m_device, reinterpret_cast<VkDeviceGroupPresentCapabilitiesKHR*>( &deviceGroupPresentCapabilities ) ) );
    return createResultValue( result, deviceGroupPresentCapabilities, VULKAN_HPP_NAMESPACE_STRING"::Device::getGroupPresentCapabilitiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getGroupSurfacePresentModes2EXT( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, vk::DeviceGroupPresentModeFlagsKHR* pModes, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDeviceGroupSurfacePresentModes2EXT( m_device, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( pSurfaceInfo ), reinterpret_cast<VkDeviceGroupPresentModeFlagsKHR*>( pModes ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DeviceGroupPresentModeFlagsKHR>::type Device::getGroupSurfacePresentModes2EXT( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d ) const
  {
    vk::DeviceGroupPresentModeFlagsKHR modes;
    Result result = static_cast<Result>( d.vkGetDeviceGroupSurfacePresentModes2EXT( m_device, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), reinterpret_cast<VkDeviceGroupPresentModeFlagsKHR*>( &modes ) ) );
    return createResultValue( result, modes, VULKAN_HPP_NAMESPACE_STRING"::Device::getGroupSurfacePresentModes2EXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getGroupSurfacePresentModesKHR( vk::SurfaceKHR surface, vk::DeviceGroupPresentModeFlagsKHR* pModes, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDeviceGroupSurfacePresentModesKHR( m_device, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkDeviceGroupPresentModeFlagsKHR*>( pModes ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DeviceGroupPresentModeFlagsKHR>::type Device::getGroupSurfacePresentModesKHR( vk::SurfaceKHR surface, Dispatch const &d ) const
  {
    vk::DeviceGroupPresentModeFlagsKHR modes;
    Result result = static_cast<Result>( d.vkGetDeviceGroupSurfacePresentModesKHR( m_device, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkDeviceGroupPresentModeFlagsKHR*>( &modes ) ) );
    return createResultValue( result, modes, VULKAN_HPP_NAMESPACE_STRING"::Device::getGroupSurfacePresentModesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getMemoryCommitment( vk::DeviceMemory memory, vk::DeviceSize* pCommittedMemoryInBytes, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetDeviceMemoryCommitment( m_device, static_cast<VkDeviceMemory>( memory ), reinterpret_cast<VkDeviceSize*>( pCommittedMemoryInBytes ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::DeviceSize Device::getMemoryCommitment( vk::DeviceMemory memory, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::DeviceSize committedMemoryInBytes;
    d.vkGetDeviceMemoryCommitment( m_device, static_cast<VkDeviceMemory>( memory ), reinterpret_cast<VkDeviceSize*>( &committedMemoryInBytes ) );
    return committedMemoryInBytes;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE PFN_vkVoidFunction Device::getProcAddr( const char* pName, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetDeviceProcAddr( m_device, pName );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE PFN_vkVoidFunction Device::getProcAddr( const std::string & name, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetDeviceProcAddr( m_device, name.c_str() );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getQueue( uint32_t queueFamilyIndex, uint32_t queueIndex, vk::Queue* pQueue, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetDeviceQueue( m_device, queueFamilyIndex, queueIndex, reinterpret_cast<VkQueue*>( pQueue ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::Queue Device::getQueue( uint32_t queueFamilyIndex, uint32_t queueIndex, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::Queue queue;
    d.vkGetDeviceQueue( m_device, queueFamilyIndex, queueIndex, reinterpret_cast<VkQueue*>( &queue ) );
    return queue;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getQueue2( const vk::DeviceQueueInfo2* pQueueInfo, vk::Queue* pQueue, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetDeviceQueue2( m_device, reinterpret_cast<const VkDeviceQueueInfo2*>( pQueueInfo ), reinterpret_cast<VkQueue*>( pQueue ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::Queue Device::getQueue2( const DeviceQueueInfo2 & queueInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::Queue queue;
    d.vkGetDeviceQueue2( m_device, reinterpret_cast<const VkDeviceQueueInfo2*>( &queueInfo ), reinterpret_cast<VkQueue*>( &queue ) );
    return queue;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getEventStatus( vk::Event event, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetEventStatus( m_device, static_cast<VkEvent>( event ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getEventStatus( vk::Event event, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkGetEventStatus( m_device, static_cast<VkEvent>( event ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::getEventStatus", { Result::eEventSet, Result::eEventReset } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getFenceFdKHR( const vk::FenceGetFdInfoKHR* pGetFdInfo, int* pFd, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetFenceFdKHR( m_device, reinterpret_cast<const VkFenceGetFdInfoKHR*>( pGetFdInfo ), pFd ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<int>::type Device::getFenceFdKHR( const FenceGetFdInfoKHR & getFdInfo, Dispatch const &d ) const
  {
    int fd;
    Result result = static_cast<Result>( d.vkGetFenceFdKHR( m_device, reinterpret_cast<const VkFenceGetFdInfoKHR*>( &getFdInfo ), &fd ) );
    return createResultValue( result, fd, VULKAN_HPP_NAMESPACE_STRING"::Device::getFenceFdKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getFenceStatus( vk::Fence fence, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetFenceStatus( m_device, static_cast<VkFence>( fence ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getFenceStatus( vk::Fence fence, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkGetFenceStatus( m_device, static_cast<VkFence>( fence ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::getFenceStatus", { Result::eSuccess, Result::eNotReady } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getFenceWin32HandleKHR( const vk::FenceGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetFenceWin32HandleKHR( m_device, reinterpret_cast<const VkFenceGetWin32HandleInfoKHR*>( pGetWin32HandleInfo ), pHandle ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<HANDLE>::type Device::getFenceWin32HandleKHR( const FenceGetWin32HandleInfoKHR & getWin32HandleInfo, Dispatch const &d ) const
  {
    HANDLE handle;
    Result result = static_cast<Result>( d.vkGetFenceWin32HandleKHR( m_device, reinterpret_cast<const VkFenceGetWin32HandleInfoKHR*>( &getWin32HandleInfo ), &handle ) );
    return createResultValue( result, handle, VULKAN_HPP_NAMESPACE_STRING"::Device::getFenceWin32HandleKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getImageDrmFormatModifierPropertiesEXT( vk::Image image, vk::ImageDrmFormatModifierPropertiesEXT* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetImageDrmFormatModifierPropertiesEXT( m_device, static_cast<VkImage>( image ), reinterpret_cast<VkImageDrmFormatModifierPropertiesEXT*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ImageDrmFormatModifierPropertiesEXT>::type Device::getImageDrmFormatModifierPropertiesEXT( vk::Image image, Dispatch const &d ) const
  {
    vk::ImageDrmFormatModifierPropertiesEXT properties;
    Result result = static_cast<Result>( d.vkGetImageDrmFormatModifierPropertiesEXT( m_device, static_cast<VkImage>( image ), reinterpret_cast<VkImageDrmFormatModifierPropertiesEXT*>( &properties ) ) );
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::Device::getImageDrmFormatModifierPropertiesEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getImageMemoryRequirements( vk::Image image, vk::MemoryRequirements* pMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetImageMemoryRequirements( m_device, static_cast<VkImage>( image ), reinterpret_cast<VkMemoryRequirements*>( pMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MemoryRequirements Device::getImageMemoryRequirements( vk::Image image, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MemoryRequirements memoryRequirements;
    d.vkGetImageMemoryRequirements( m_device, static_cast<VkImage>( image ), reinterpret_cast<VkMemoryRequirements*>( &memoryRequirements ) );
    return memoryRequirements;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getImageMemoryRequirements2( const vk::ImageMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetImageMemoryRequirements2( m_device, reinterpret_cast<const VkImageMemoryRequirementsInfo2*>( pInfo ), reinterpret_cast<VkMemoryRequirements2*>( pMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MemoryRequirements2 Device::getImageMemoryRequirements2( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MemoryRequirements2 memoryRequirements;
    d.vkGetImageMemoryRequirements2( m_device, reinterpret_cast<const VkImageMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return memoryRequirements;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> Device::getImageMemoryRequirements2( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::MemoryRequirements2& memoryRequirements = structureChain.template get<vk::MemoryRequirements2>();
    d.vkGetImageMemoryRequirements2( m_device, reinterpret_cast<const VkImageMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getImageMemoryRequirements2KHR( const vk::ImageMemoryRequirementsInfo2* pInfo, vk::MemoryRequirements2* pMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetImageMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageMemoryRequirementsInfo2*>( pInfo ), reinterpret_cast<VkMemoryRequirements2*>( pMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MemoryRequirements2 Device::getImageMemoryRequirements2KHR( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MemoryRequirements2 memoryRequirements;
    d.vkGetImageMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return memoryRequirements;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> Device::getImageMemoryRequirements2KHR( const ImageMemoryRequirementsInfo2 & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::MemoryRequirements2& memoryRequirements = structureChain.template get<vk::MemoryRequirements2>();
    d.vkGetImageMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageMemoryRequirementsInfo2*>( &info ), reinterpret_cast<VkMemoryRequirements2*>( &memoryRequirements ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getImageSparseMemoryRequirements( vk::Image image, uint32_t* pSparseMemoryRequirementCount, vk::SparseImageMemoryRequirements* pSparseMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetImageSparseMemoryRequirements( m_device, static_cast<VkImage>( image ), pSparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements*>( pSparseMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageMemoryRequirements,Allocator> Device::getImageSparseMemoryRequirements( vk::Image image, Dispatch const &d ) const
  {
    std::vector<SparseImageMemoryRequirements,Allocator> sparseMemoryRequirements;
    uint32_t sparseMemoryRequirementCount;
    d.vkGetImageSparseMemoryRequirements( m_device, static_cast<VkImage>( image ), &sparseMemoryRequirementCount, nullptr );
    sparseMemoryRequirements.resize( sparseMemoryRequirementCount );
    d.vkGetImageSparseMemoryRequirements( m_device, static_cast<VkImage>( image ), &sparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements*>( sparseMemoryRequirements.data() ) );
    return sparseMemoryRequirements;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageMemoryRequirements,Allocator> Device::getImageSparseMemoryRequirements( vk::Image image, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SparseImageMemoryRequirements,Allocator> sparseMemoryRequirements( vectorAllocator );
    uint32_t sparseMemoryRequirementCount;
    d.vkGetImageSparseMemoryRequirements( m_device, static_cast<VkImage>( image ), &sparseMemoryRequirementCount, nullptr );
    sparseMemoryRequirements.resize( sparseMemoryRequirementCount );
    d.vkGetImageSparseMemoryRequirements( m_device, static_cast<VkImage>( image ), &sparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements*>( sparseMemoryRequirements.data() ) );
    return sparseMemoryRequirements;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getImageSparseMemoryRequirements2( const vk::ImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, vk::SparseImageMemoryRequirements2* pSparseMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetImageSparseMemoryRequirements2( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( pInfo ), pSparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements2*>( pSparseMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageMemoryRequirements2,Allocator> Device::getImageSparseMemoryRequirements2( const ImageSparseMemoryRequirementsInfo2 & info, Dispatch const &d ) const
  {
    std::vector<SparseImageMemoryRequirements2,Allocator> sparseMemoryRequirements;
    uint32_t sparseMemoryRequirementCount;
    d.vkGetImageSparseMemoryRequirements2( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, nullptr );
    sparseMemoryRequirements.resize( sparseMemoryRequirementCount );
    d.vkGetImageSparseMemoryRequirements2( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements2*>( sparseMemoryRequirements.data() ) );
    return sparseMemoryRequirements;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageMemoryRequirements2,Allocator> Device::getImageSparseMemoryRequirements2( const ImageSparseMemoryRequirementsInfo2 & info, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SparseImageMemoryRequirements2,Allocator> sparseMemoryRequirements( vectorAllocator );
    uint32_t sparseMemoryRequirementCount;
    d.vkGetImageSparseMemoryRequirements2( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, nullptr );
    sparseMemoryRequirements.resize( sparseMemoryRequirementCount );
    d.vkGetImageSparseMemoryRequirements2( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements2*>( sparseMemoryRequirements.data() ) );
    return sparseMemoryRequirements;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getImageSparseMemoryRequirements2KHR( const vk::ImageSparseMemoryRequirementsInfo2* pInfo, uint32_t* pSparseMemoryRequirementCount, vk::SparseImageMemoryRequirements2* pSparseMemoryRequirements, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetImageSparseMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( pInfo ), pSparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements2*>( pSparseMemoryRequirements ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageMemoryRequirements2,Allocator> Device::getImageSparseMemoryRequirements2KHR( const ImageSparseMemoryRequirementsInfo2 & info, Dispatch const &d ) const
  {
    std::vector<SparseImageMemoryRequirements2,Allocator> sparseMemoryRequirements;
    uint32_t sparseMemoryRequirementCount;
    d.vkGetImageSparseMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, nullptr );
    sparseMemoryRequirements.resize( sparseMemoryRequirementCount );
    d.vkGetImageSparseMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements2*>( sparseMemoryRequirements.data() ) );
    return sparseMemoryRequirements;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageMemoryRequirements2,Allocator> Device::getImageSparseMemoryRequirements2KHR( const ImageSparseMemoryRequirementsInfo2 & info, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SparseImageMemoryRequirements2,Allocator> sparseMemoryRequirements( vectorAllocator );
    uint32_t sparseMemoryRequirementCount;
    d.vkGetImageSparseMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, nullptr );
    sparseMemoryRequirements.resize( sparseMemoryRequirementCount );
    d.vkGetImageSparseMemoryRequirements2KHR( m_device, reinterpret_cast<const VkImageSparseMemoryRequirementsInfo2*>( &info ), &sparseMemoryRequirementCount, reinterpret_cast<VkSparseImageMemoryRequirements2*>( sparseMemoryRequirements.data() ) );
    return sparseMemoryRequirements;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getImageSubresourceLayout( vk::Image image, const vk::ImageSubresource* pSubresource, vk::SubresourceLayout* pLayout, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetImageSubresourceLayout( m_device, static_cast<VkImage>( image ), reinterpret_cast<const VkImageSubresource*>( pSubresource ), reinterpret_cast<VkSubresourceLayout*>( pLayout ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::SubresourceLayout Device::getImageSubresourceLayout( vk::Image image, const ImageSubresource & subresource, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::SubresourceLayout layout;
    d.vkGetImageSubresourceLayout( m_device, static_cast<VkImage>( image ), reinterpret_cast<const VkImageSubresource*>( &subresource ), reinterpret_cast<VkSubresourceLayout*>( &layout ) );
    return layout;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE uint32_t Device::getImageViewHandleNVX( const vk::ImageViewHandleInfoNVX* pInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetImageViewHandleNVX( m_device, reinterpret_cast<const VkImageViewHandleInfoNVX*>( pInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE uint32_t Device::getImageViewHandleNVX( const ImageViewHandleInfoNVX & info, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetImageViewHandleNVX( m_device, reinterpret_cast<const VkImageViewHandleInfoNVX*>( &info ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getMemoryAndroidHardwareBufferANDROID( const vk::MemoryGetAndroidHardwareBufferInfoANDROID* pInfo, struct AHardwareBuffer** pBuffer, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetMemoryAndroidHardwareBufferANDROID( m_device, reinterpret_cast<const VkMemoryGetAndroidHardwareBufferInfoANDROID*>( pInfo ), pBuffer ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<struct AHardwareBuffer*>::type Device::getMemoryAndroidHardwareBufferANDROID( const MemoryGetAndroidHardwareBufferInfoANDROID & info, Dispatch const &d ) const
  {
    struct AHardwareBuffer* buffer;
    Result result = static_cast<Result>( d.vkGetMemoryAndroidHardwareBufferANDROID( m_device, reinterpret_cast<const VkMemoryGetAndroidHardwareBufferInfoANDROID*>( &info ), &buffer ) );
    return createResultValue( result, buffer, VULKAN_HPP_NAMESPACE_STRING"::Device::getMemoryAndroidHardwareBufferANDROID" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getMemoryFdKHR( const vk::MemoryGetFdInfoKHR* pGetFdInfo, int* pFd, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetMemoryFdKHR( m_device, reinterpret_cast<const VkMemoryGetFdInfoKHR*>( pGetFdInfo ), pFd ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<int>::type Device::getMemoryFdKHR( const MemoryGetFdInfoKHR & getFdInfo, Dispatch const &d ) const
  {
    int fd;
    Result result = static_cast<Result>( d.vkGetMemoryFdKHR( m_device, reinterpret_cast<const VkMemoryGetFdInfoKHR*>( &getFdInfo ), &fd ) );
    return createResultValue( result, fd, VULKAN_HPP_NAMESPACE_STRING"::Device::getMemoryFdKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getMemoryFdPropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, int fd, vk::MemoryFdPropertiesKHR* pMemoryFdProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetMemoryFdPropertiesKHR( m_device, static_cast<VkExternalMemoryHandleTypeFlagBits>( handleType ), fd, reinterpret_cast<VkMemoryFdPropertiesKHR*>( pMemoryFdProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::MemoryFdPropertiesKHR>::type Device::getMemoryFdPropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, int fd, Dispatch const &d ) const
  {
    vk::MemoryFdPropertiesKHR memoryFdProperties;
    Result result = static_cast<Result>( d.vkGetMemoryFdPropertiesKHR( m_device, static_cast<VkExternalMemoryHandleTypeFlagBits>( handleType ), fd, reinterpret_cast<VkMemoryFdPropertiesKHR*>( &memoryFdProperties ) ) );
    return createResultValue( result, memoryFdProperties, VULKAN_HPP_NAMESPACE_STRING"::Device::getMemoryFdPropertiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getMemoryHostPointerPropertiesEXT( vk::ExternalMemoryHandleTypeFlagBits handleType, const void* pHostPointer, vk::MemoryHostPointerPropertiesEXT* pMemoryHostPointerProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetMemoryHostPointerPropertiesEXT( m_device, static_cast<VkExternalMemoryHandleTypeFlagBits>( handleType ), pHostPointer, reinterpret_cast<VkMemoryHostPointerPropertiesEXT*>( pMemoryHostPointerProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::MemoryHostPointerPropertiesEXT>::type Device::getMemoryHostPointerPropertiesEXT( vk::ExternalMemoryHandleTypeFlagBits handleType, const void* pHostPointer, Dispatch const &d ) const
  {
    vk::MemoryHostPointerPropertiesEXT memoryHostPointerProperties;
    Result result = static_cast<Result>( d.vkGetMemoryHostPointerPropertiesEXT( m_device, static_cast<VkExternalMemoryHandleTypeFlagBits>( handleType ), pHostPointer, reinterpret_cast<VkMemoryHostPointerPropertiesEXT*>( &memoryHostPointerProperties ) ) );
    return createResultValue( result, memoryHostPointerProperties, VULKAN_HPP_NAMESPACE_STRING"::Device::getMemoryHostPointerPropertiesEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getMemoryWin32HandleKHR( const vk::MemoryGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetMemoryWin32HandleKHR( m_device, reinterpret_cast<const VkMemoryGetWin32HandleInfoKHR*>( pGetWin32HandleInfo ), pHandle ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<HANDLE>::type Device::getMemoryWin32HandleKHR( const MemoryGetWin32HandleInfoKHR & getWin32HandleInfo, Dispatch const &d ) const
  {
    HANDLE handle;
    Result result = static_cast<Result>( d.vkGetMemoryWin32HandleKHR( m_device, reinterpret_cast<const VkMemoryGetWin32HandleInfoKHR*>( &getWin32HandleInfo ), &handle ) );
    return createResultValue( result, handle, VULKAN_HPP_NAMESPACE_STRING"::Device::getMemoryWin32HandleKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getMemoryWin32HandleNV( vk::DeviceMemory memory, vk::ExternalMemoryHandleTypeFlagsNV handleType, HANDLE* pHandle, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetMemoryWin32HandleNV( m_device, static_cast<VkDeviceMemory>( memory ), static_cast<VkExternalMemoryHandleTypeFlagsNV>( handleType ), pHandle ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<HANDLE>::type Device::getMemoryWin32HandleNV( vk::DeviceMemory memory, vk::ExternalMemoryHandleTypeFlagsNV handleType, Dispatch const &d ) const
  {
    HANDLE handle;
    Result result = static_cast<Result>( d.vkGetMemoryWin32HandleNV( m_device, static_cast<VkDeviceMemory>( memory ), static_cast<VkExternalMemoryHandleTypeFlagsNV>( handleType ), &handle ) );
    return createResultValue( result, handle, VULKAN_HPP_NAMESPACE_STRING"::Device::getMemoryWin32HandleNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getMemoryWin32HandlePropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, HANDLE handle, vk::MemoryWin32HandlePropertiesKHR* pMemoryWin32HandleProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetMemoryWin32HandlePropertiesKHR( m_device, static_cast<VkExternalMemoryHandleTypeFlagBits>( handleType ), handle, reinterpret_cast<VkMemoryWin32HandlePropertiesKHR*>( pMemoryWin32HandleProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::MemoryWin32HandlePropertiesKHR>::type Device::getMemoryWin32HandlePropertiesKHR( vk::ExternalMemoryHandleTypeFlagBits handleType, HANDLE handle, Dispatch const &d ) const
  {
    vk::MemoryWin32HandlePropertiesKHR memoryWin32HandleProperties;
    Result result = static_cast<Result>( d.vkGetMemoryWin32HandlePropertiesKHR( m_device, static_cast<VkExternalMemoryHandleTypeFlagBits>( handleType ), handle, reinterpret_cast<VkMemoryWin32HandlePropertiesKHR*>( &memoryWin32HandleProperties ) ) );
    return createResultValue( result, memoryWin32HandleProperties, VULKAN_HPP_NAMESPACE_STRING"::Device::getMemoryWin32HandlePropertiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getPastPresentationTimingGOOGLE( vk::SwapchainKHR swapchain, uint32_t* pPresentationTimingCount, vk::PastPresentationTimingGOOGLE* pPresentationTimings, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPastPresentationTimingGOOGLE( m_device, static_cast<VkSwapchainKHR>( swapchain ), pPresentationTimingCount, reinterpret_cast<VkPastPresentationTimingGOOGLE*>( pPresentationTimings ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PastPresentationTimingGOOGLE,Allocator>>::type Device::getPastPresentationTimingGOOGLE( vk::SwapchainKHR swapchain, Dispatch const &d ) const
  {
    std::vector<PastPresentationTimingGOOGLE,Allocator> presentationTimings;
    uint32_t presentationTimingCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPastPresentationTimingGOOGLE( m_device, static_cast<VkSwapchainKHR>( swapchain ), &presentationTimingCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && presentationTimingCount )
      {
        presentationTimings.resize( presentationTimingCount );
        result = static_cast<Result>( d.vkGetPastPresentationTimingGOOGLE( m_device, static_cast<VkSwapchainKHR>( swapchain ), &presentationTimingCount, reinterpret_cast<VkPastPresentationTimingGOOGLE*>( presentationTimings.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( presentationTimingCount <= presentationTimings.size() );
      presentationTimings.resize( presentationTimingCount );
    }
    return createResultValue( result, presentationTimings, VULKAN_HPP_NAMESPACE_STRING"::Device::getPastPresentationTimingGOOGLE" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PastPresentationTimingGOOGLE,Allocator>>::type Device::getPastPresentationTimingGOOGLE( vk::SwapchainKHR swapchain, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PastPresentationTimingGOOGLE,Allocator> presentationTimings( vectorAllocator );
    uint32_t presentationTimingCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPastPresentationTimingGOOGLE( m_device, static_cast<VkSwapchainKHR>( swapchain ), &presentationTimingCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && presentationTimingCount )
      {
        presentationTimings.resize( presentationTimingCount );
        result = static_cast<Result>( d.vkGetPastPresentationTimingGOOGLE( m_device, static_cast<VkSwapchainKHR>( swapchain ), &presentationTimingCount, reinterpret_cast<VkPastPresentationTimingGOOGLE*>( presentationTimings.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( presentationTimingCount <= presentationTimings.size() );
      presentationTimings.resize( presentationTimingCount );
    }
    return createResultValue( result, presentationTimings, VULKAN_HPP_NAMESPACE_STRING"::Device::getPastPresentationTimingGOOGLE" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getPerformanceParameterINTEL( vk::PerformanceParameterTypeINTEL parameter, vk::PerformanceValueINTEL* pValue, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPerformanceParameterINTEL( m_device, static_cast<VkPerformanceParameterTypeINTEL>( parameter ), reinterpret_cast<VkPerformanceValueINTEL*>( pValue ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::PerformanceValueINTEL>::type Device::getPerformanceParameterINTEL( vk::PerformanceParameterTypeINTEL parameter, Dispatch const &d ) const
  {
    vk::PerformanceValueINTEL value;
    Result result = static_cast<Result>( d.vkGetPerformanceParameterINTEL( m_device, static_cast<VkPerformanceParameterTypeINTEL>( parameter ), reinterpret_cast<VkPerformanceValueINTEL*>( &value ) ) );
    return createResultValue( result, value, VULKAN_HPP_NAMESPACE_STRING"::Device::getPerformanceParameterINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getPipelineCacheData( vk::PipelineCache pipelineCache, size_t* pDataSize, void* pData, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPipelineCacheData( m_device, static_cast<VkPipelineCache>( pipelineCache ), pDataSize, pData ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<uint8_t,Allocator>>::type Device::getPipelineCacheData( vk::PipelineCache pipelineCache, Dispatch const &d ) const
  {
    std::vector<uint8_t,Allocator> data;
    size_t dataSize;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineCacheData( m_device, static_cast<VkPipelineCache>( pipelineCache ), &dataSize, nullptr ) );
      if ( ( result == Result::eSuccess ) && dataSize )
      {
        data.resize( dataSize );
        result = static_cast<Result>( d.vkGetPipelineCacheData( m_device, static_cast<VkPipelineCache>( pipelineCache ), &dataSize, reinterpret_cast<void*>( data.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( dataSize <= data.size() );
      data.resize( dataSize );
    }
    return createResultValue( result, data, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineCacheData" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<uint8_t,Allocator>>::type Device::getPipelineCacheData( vk::PipelineCache pipelineCache, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<uint8_t,Allocator> data( vectorAllocator );
    size_t dataSize;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineCacheData( m_device, static_cast<VkPipelineCache>( pipelineCache ), &dataSize, nullptr ) );
      if ( ( result == Result::eSuccess ) && dataSize )
      {
        data.resize( dataSize );
        result = static_cast<Result>( d.vkGetPipelineCacheData( m_device, static_cast<VkPipelineCache>( pipelineCache ), &dataSize, reinterpret_cast<void*>( data.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( dataSize <= data.size() );
      data.resize( dataSize );
    }
    return createResultValue( result, data, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineCacheData" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getPipelineExecutableInternalRepresentationsKHR( const vk::PipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pInternalRepresentationCount, vk::PipelineExecutableInternalRepresentationKHR* pInternalRepresentations, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPipelineExecutableInternalRepresentationsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( pExecutableInfo ), pInternalRepresentationCount, reinterpret_cast<VkPipelineExecutableInternalRepresentationKHR*>( pInternalRepresentations ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PipelineExecutableInternalRepresentationKHR,Allocator>>::type Device::getPipelineExecutableInternalRepresentationsKHR( const PipelineExecutableInfoKHR & executableInfo, Dispatch const &d ) const
  {
    std::vector<PipelineExecutableInternalRepresentationKHR,Allocator> internalRepresentations;
    uint32_t internalRepresentationCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineExecutableInternalRepresentationsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &internalRepresentationCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && internalRepresentationCount )
      {
        internalRepresentations.resize( internalRepresentationCount );
        result = static_cast<Result>( d.vkGetPipelineExecutableInternalRepresentationsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &internalRepresentationCount, reinterpret_cast<VkPipelineExecutableInternalRepresentationKHR*>( internalRepresentations.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( internalRepresentationCount <= internalRepresentations.size() );
      internalRepresentations.resize( internalRepresentationCount );
    }
    return createResultValue( result, internalRepresentations, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineExecutableInternalRepresentationsKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PipelineExecutableInternalRepresentationKHR,Allocator>>::type Device::getPipelineExecutableInternalRepresentationsKHR( const PipelineExecutableInfoKHR & executableInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PipelineExecutableInternalRepresentationKHR,Allocator> internalRepresentations( vectorAllocator );
    uint32_t internalRepresentationCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineExecutableInternalRepresentationsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &internalRepresentationCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && internalRepresentationCount )
      {
        internalRepresentations.resize( internalRepresentationCount );
        result = static_cast<Result>( d.vkGetPipelineExecutableInternalRepresentationsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &internalRepresentationCount, reinterpret_cast<VkPipelineExecutableInternalRepresentationKHR*>( internalRepresentations.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( internalRepresentationCount <= internalRepresentations.size() );
      internalRepresentations.resize( internalRepresentationCount );
    }
    return createResultValue( result, internalRepresentations, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineExecutableInternalRepresentationsKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getPipelineExecutablePropertiesKHR( const vk::PipelineInfoKHR* pPipelineInfo, uint32_t* pExecutableCount, vk::PipelineExecutablePropertiesKHR* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPipelineExecutablePropertiesKHR( m_device, reinterpret_cast<const VkPipelineInfoKHR*>( pPipelineInfo ), pExecutableCount, reinterpret_cast<VkPipelineExecutablePropertiesKHR*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PipelineExecutablePropertiesKHR,Allocator>>::type Device::getPipelineExecutablePropertiesKHR( const PipelineInfoKHR & pipelineInfo, Dispatch const &d ) const
  {
    std::vector<PipelineExecutablePropertiesKHR,Allocator> properties;
    uint32_t executableCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineExecutablePropertiesKHR( m_device, reinterpret_cast<const VkPipelineInfoKHR*>( &pipelineInfo ), &executableCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && executableCount )
      {
        properties.resize( executableCount );
        result = static_cast<Result>( d.vkGetPipelineExecutablePropertiesKHR( m_device, reinterpret_cast<const VkPipelineInfoKHR*>( &pipelineInfo ), &executableCount, reinterpret_cast<VkPipelineExecutablePropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( executableCount <= properties.size() );
      properties.resize( executableCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineExecutablePropertiesKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PipelineExecutablePropertiesKHR,Allocator>>::type Device::getPipelineExecutablePropertiesKHR( const PipelineInfoKHR & pipelineInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PipelineExecutablePropertiesKHR,Allocator> properties( vectorAllocator );
    uint32_t executableCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineExecutablePropertiesKHR( m_device, reinterpret_cast<const VkPipelineInfoKHR*>( &pipelineInfo ), &executableCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && executableCount )
      {
        properties.resize( executableCount );
        result = static_cast<Result>( d.vkGetPipelineExecutablePropertiesKHR( m_device, reinterpret_cast<const VkPipelineInfoKHR*>( &pipelineInfo ), &executableCount, reinterpret_cast<VkPipelineExecutablePropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( executableCount <= properties.size() );
      properties.resize( executableCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineExecutablePropertiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getPipelineExecutableStatisticsKHR( const vk::PipelineExecutableInfoKHR* pExecutableInfo, uint32_t* pStatisticCount, vk::PipelineExecutableStatisticKHR* pStatistics, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPipelineExecutableStatisticsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( pExecutableInfo ), pStatisticCount, reinterpret_cast<VkPipelineExecutableStatisticKHR*>( pStatistics ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PipelineExecutableStatisticKHR,Allocator>>::type Device::getPipelineExecutableStatisticsKHR( const PipelineExecutableInfoKHR & executableInfo, Dispatch const &d ) const
  {
    std::vector<PipelineExecutableStatisticKHR,Allocator> statistics;
    uint32_t statisticCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineExecutableStatisticsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &statisticCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && statisticCount )
      {
        statistics.resize( statisticCount );
        result = static_cast<Result>( d.vkGetPipelineExecutableStatisticsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &statisticCount, reinterpret_cast<VkPipelineExecutableStatisticKHR*>( statistics.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( statisticCount <= statistics.size() );
      statistics.resize( statisticCount );
    }
    return createResultValue( result, statistics, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineExecutableStatisticsKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PipelineExecutableStatisticKHR,Allocator>>::type Device::getPipelineExecutableStatisticsKHR( const PipelineExecutableInfoKHR & executableInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PipelineExecutableStatisticKHR,Allocator> statistics( vectorAllocator );
    uint32_t statisticCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPipelineExecutableStatisticsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &statisticCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && statisticCount )
      {
        statistics.resize( statisticCount );
        result = static_cast<Result>( d.vkGetPipelineExecutableStatisticsKHR( m_device, reinterpret_cast<const VkPipelineExecutableInfoKHR*>( &executableInfo ), &statisticCount, reinterpret_cast<VkPipelineExecutableStatisticKHR*>( statistics.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( statisticCount <= statistics.size() );
      statistics.resize( statisticCount );
    }
    return createResultValue( result, statistics, VULKAN_HPP_NAMESPACE_STRING"::Device::getPipelineExecutableStatisticsKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getQueryPoolResults( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, size_t dataSize, void* pData, vk::DeviceSize stride, vk::QueryResultFlags flags, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetQueryPoolResults( m_device, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount, dataSize, pData, static_cast<VkDeviceSize>( stride ), static_cast<VkQueryResultFlags>( flags ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename T, typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getQueryPoolResults( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, ArrayProxy<T> data, vk::DeviceSize stride, vk::QueryResultFlags flags, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkGetQueryPoolResults( m_device, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount, data.size() * sizeof( T ) , reinterpret_cast<void*>( data.data() ), static_cast<VkDeviceSize>( stride ), static_cast<VkQueryResultFlags>( flags ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::getQueryPoolResults", { Result::eSuccess, Result::eNotReady } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getRayTracingShaderGroupHandlesNV( vk::Pipeline pipeline, uint32_t firstGroup, uint32_t groupCount, size_t dataSize, void* pData, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetRayTracingShaderGroupHandlesNV( m_device, static_cast<VkPipeline>( pipeline ), firstGroup, groupCount, dataSize, pData ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename T, typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::getRayTracingShaderGroupHandlesNV( vk::Pipeline pipeline, uint32_t firstGroup, uint32_t groupCount, ArrayProxy<T> data, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkGetRayTracingShaderGroupHandlesNV( m_device, static_cast<VkPipeline>( pipeline ), firstGroup, groupCount, data.size() * sizeof( T ) , reinterpret_cast<void*>( data.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::getRayTracingShaderGroupHandlesNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getRefreshCycleDurationGOOGLE( vk::SwapchainKHR swapchain, vk::RefreshCycleDurationGOOGLE* pDisplayTimingProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetRefreshCycleDurationGOOGLE( m_device, static_cast<VkSwapchainKHR>( swapchain ), reinterpret_cast<VkRefreshCycleDurationGOOGLE*>( pDisplayTimingProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::RefreshCycleDurationGOOGLE>::type Device::getRefreshCycleDurationGOOGLE( vk::SwapchainKHR swapchain, Dispatch const &d ) const
  {
    vk::RefreshCycleDurationGOOGLE displayTimingProperties;
    Result result = static_cast<Result>( d.vkGetRefreshCycleDurationGOOGLE( m_device, static_cast<VkSwapchainKHR>( swapchain ), reinterpret_cast<VkRefreshCycleDurationGOOGLE*>( &displayTimingProperties ) ) );
    return createResultValue( result, displayTimingProperties, VULKAN_HPP_NAMESPACE_STRING"::Device::getRefreshCycleDurationGOOGLE" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::getRenderAreaGranularity( vk::RenderPass renderPass, vk::Extent2D* pGranularity, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetRenderAreaGranularity( m_device, static_cast<VkRenderPass>( renderPass ), reinterpret_cast<VkExtent2D*>( pGranularity ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::Extent2D Device::getRenderAreaGranularity( vk::RenderPass renderPass, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::Extent2D granularity;
    d.vkGetRenderAreaGranularity( m_device, static_cast<VkRenderPass>( renderPass ), reinterpret_cast<VkExtent2D*>( &granularity ) );
    return granularity;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getSemaphoreCounterValueKHR( vk::Semaphore semaphore, uint64_t* pValue, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetSemaphoreCounterValueKHR( m_device, static_cast<VkSemaphore>( semaphore ), pValue ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<uint64_t>::type Device::getSemaphoreCounterValueKHR( vk::Semaphore semaphore, Dispatch const &d ) const
  {
    uint64_t value;
    Result result = static_cast<Result>( d.vkGetSemaphoreCounterValueKHR( m_device, static_cast<VkSemaphore>( semaphore ), &value ) );
    return createResultValue( result, value, VULKAN_HPP_NAMESPACE_STRING"::Device::getSemaphoreCounterValueKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getSemaphoreFdKHR( const vk::SemaphoreGetFdInfoKHR* pGetFdInfo, int* pFd, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetSemaphoreFdKHR( m_device, reinterpret_cast<const VkSemaphoreGetFdInfoKHR*>( pGetFdInfo ), pFd ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<int>::type Device::getSemaphoreFdKHR( const SemaphoreGetFdInfoKHR & getFdInfo, Dispatch const &d ) const
  {
    int fd;
    Result result = static_cast<Result>( d.vkGetSemaphoreFdKHR( m_device, reinterpret_cast<const VkSemaphoreGetFdInfoKHR*>( &getFdInfo ), &fd ) );
    return createResultValue( result, fd, VULKAN_HPP_NAMESPACE_STRING"::Device::getSemaphoreFdKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getSemaphoreWin32HandleKHR( const vk::SemaphoreGetWin32HandleInfoKHR* pGetWin32HandleInfo, HANDLE* pHandle, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetSemaphoreWin32HandleKHR( m_device, reinterpret_cast<const VkSemaphoreGetWin32HandleInfoKHR*>( pGetWin32HandleInfo ), pHandle ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<HANDLE>::type Device::getSemaphoreWin32HandleKHR( const SemaphoreGetWin32HandleInfoKHR & getWin32HandleInfo, Dispatch const &d ) const
  {
    HANDLE handle;
    Result result = static_cast<Result>( d.vkGetSemaphoreWin32HandleKHR( m_device, reinterpret_cast<const VkSemaphoreGetWin32HandleInfoKHR*>( &getWin32HandleInfo ), &handle ) );
    return createResultValue( result, handle, VULKAN_HPP_NAMESPACE_STRING"::Device::getSemaphoreWin32HandleKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getShaderInfoAMD( vk::Pipeline pipeline, vk::ShaderStageFlagBits shaderStage, vk::ShaderInfoTypeAMD infoType, size_t* pInfoSize, void* pInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetShaderInfoAMD( m_device, static_cast<VkPipeline>( pipeline ), static_cast<VkShaderStageFlagBits>( shaderStage ), static_cast<VkShaderInfoTypeAMD>( infoType ), pInfoSize, pInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<uint8_t,Allocator>>::type Device::getShaderInfoAMD( vk::Pipeline pipeline, vk::ShaderStageFlagBits shaderStage, vk::ShaderInfoTypeAMD infoType, Dispatch const &d ) const
  {
    std::vector<uint8_t,Allocator> info;
    size_t infoSize;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetShaderInfoAMD( m_device, static_cast<VkPipeline>( pipeline ), static_cast<VkShaderStageFlagBits>( shaderStage ), static_cast<VkShaderInfoTypeAMD>( infoType ), &infoSize, nullptr ) );
      if ( ( result == Result::eSuccess ) && infoSize )
      {
        info.resize( infoSize );
        result = static_cast<Result>( d.vkGetShaderInfoAMD( m_device, static_cast<VkPipeline>( pipeline ), static_cast<VkShaderStageFlagBits>( shaderStage ), static_cast<VkShaderInfoTypeAMD>( infoType ), &infoSize, reinterpret_cast<void*>( info.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( infoSize <= info.size() );
      info.resize( infoSize );
    }
    return createResultValue( result, info, VULKAN_HPP_NAMESPACE_STRING"::Device::getShaderInfoAMD" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<uint8_t,Allocator>>::type Device::getShaderInfoAMD( vk::Pipeline pipeline, vk::ShaderStageFlagBits shaderStage, vk::ShaderInfoTypeAMD infoType, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<uint8_t,Allocator> info( vectorAllocator );
    size_t infoSize;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetShaderInfoAMD( m_device, static_cast<VkPipeline>( pipeline ), static_cast<VkShaderStageFlagBits>( shaderStage ), static_cast<VkShaderInfoTypeAMD>( infoType ), &infoSize, nullptr ) );
      if ( ( result == Result::eSuccess ) && infoSize )
      {
        info.resize( infoSize );
        result = static_cast<Result>( d.vkGetShaderInfoAMD( m_device, static_cast<VkPipeline>( pipeline ), static_cast<VkShaderStageFlagBits>( shaderStage ), static_cast<VkShaderInfoTypeAMD>( infoType ), &infoSize, reinterpret_cast<void*>( info.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( infoSize <= info.size() );
      info.resize( infoSize );
    }
    return createResultValue( result, info, VULKAN_HPP_NAMESPACE_STRING"::Device::getShaderInfoAMD" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getSwapchainCounterEXT( vk::SwapchainKHR swapchain, vk::SurfaceCounterFlagBitsEXT counter, uint64_t* pCounterValue, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetSwapchainCounterEXT( m_device, static_cast<VkSwapchainKHR>( swapchain ), static_cast<VkSurfaceCounterFlagBitsEXT>( counter ), pCounterValue ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<uint64_t>::type Device::getSwapchainCounterEXT( vk::SwapchainKHR swapchain, vk::SurfaceCounterFlagBitsEXT counter, Dispatch const &d ) const
  {
    uint64_t counterValue;
    Result result = static_cast<Result>( d.vkGetSwapchainCounterEXT( m_device, static_cast<VkSwapchainKHR>( swapchain ), static_cast<VkSurfaceCounterFlagBitsEXT>( counter ), &counterValue ) );
    return createResultValue( result, counterValue, VULKAN_HPP_NAMESPACE_STRING"::Device::getSwapchainCounterEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getSwapchainImagesKHR( vk::SwapchainKHR swapchain, uint32_t* pSwapchainImageCount, vk::Image* pSwapchainImages, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetSwapchainImagesKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), pSwapchainImageCount, reinterpret_cast<VkImage*>( pSwapchainImages ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Image,Allocator>>::type Device::getSwapchainImagesKHR( vk::SwapchainKHR swapchain, Dispatch const &d ) const
  {
    std::vector<Image,Allocator> swapchainImages;
    uint32_t swapchainImageCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetSwapchainImagesKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), &swapchainImageCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && swapchainImageCount )
      {
        swapchainImages.resize( swapchainImageCount );
        result = static_cast<Result>( d.vkGetSwapchainImagesKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), &swapchainImageCount, reinterpret_cast<VkImage*>( swapchainImages.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( swapchainImageCount <= swapchainImages.size() );
      swapchainImages.resize( swapchainImageCount );
    }
    return createResultValue( result, swapchainImages, VULKAN_HPP_NAMESPACE_STRING"::Device::getSwapchainImagesKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Image,Allocator>>::type Device::getSwapchainImagesKHR( vk::SwapchainKHR swapchain, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<Image,Allocator> swapchainImages( vectorAllocator );
    uint32_t swapchainImageCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetSwapchainImagesKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), &swapchainImageCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && swapchainImageCount )
      {
        swapchainImages.resize( swapchainImageCount );
        result = static_cast<Result>( d.vkGetSwapchainImagesKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ), &swapchainImageCount, reinterpret_cast<VkImage*>( swapchainImages.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( swapchainImageCount <= swapchainImages.size() );
      swapchainImages.resize( swapchainImageCount );
    }
    return createResultValue( result, swapchainImages, VULKAN_HPP_NAMESPACE_STRING"::Device::getSwapchainImagesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getSwapchainStatusKHR( vk::SwapchainKHR swapchain, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetSwapchainStatusKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getSwapchainStatusKHR( vk::SwapchainKHR swapchain, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkGetSwapchainStatusKHR( m_device, static_cast<VkSwapchainKHR>( swapchain ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::getSwapchainStatusKHR", { Result::eSuccess, Result::eSuboptimalKHR } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::getValidationCacheDataEXT( vk::ValidationCacheEXT validationCache, size_t* pDataSize, void* pData, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetValidationCacheDataEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), pDataSize, pData ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<uint8_t,Allocator>>::type Device::getValidationCacheDataEXT( vk::ValidationCacheEXT validationCache, Dispatch const &d ) const
  {
    std::vector<uint8_t,Allocator> data;
    size_t dataSize;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetValidationCacheDataEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), &dataSize, nullptr ) );
      if ( ( result == Result::eSuccess ) && dataSize )
      {
        data.resize( dataSize );
        result = static_cast<Result>( d.vkGetValidationCacheDataEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), &dataSize, reinterpret_cast<void*>( data.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( dataSize <= data.size() );
      data.resize( dataSize );
    }
    return createResultValue( result, data, VULKAN_HPP_NAMESPACE_STRING"::Device::getValidationCacheDataEXT" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<uint8_t,Allocator>>::type Device::getValidationCacheDataEXT( vk::ValidationCacheEXT validationCache, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<uint8_t,Allocator> data( vectorAllocator );
    size_t dataSize;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetValidationCacheDataEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), &dataSize, nullptr ) );
      if ( ( result == Result::eSuccess ) && dataSize )
      {
        data.resize( dataSize );
        result = static_cast<Result>( d.vkGetValidationCacheDataEXT( m_device, static_cast<VkValidationCacheEXT>( validationCache ), &dataSize, reinterpret_cast<void*>( data.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( dataSize <= data.size() );
      data.resize( dataSize );
    }
    return createResultValue( result, data, VULKAN_HPP_NAMESPACE_STRING"::Device::getValidationCacheDataEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::importFenceFdKHR( const vk::ImportFenceFdInfoKHR* pImportFenceFdInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkImportFenceFdKHR( m_device, reinterpret_cast<const VkImportFenceFdInfoKHR*>( pImportFenceFdInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::importFenceFdKHR( const ImportFenceFdInfoKHR & importFenceFdInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkImportFenceFdKHR( m_device, reinterpret_cast<const VkImportFenceFdInfoKHR*>( &importFenceFdInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::importFenceFdKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::importFenceWin32HandleKHR( const vk::ImportFenceWin32HandleInfoKHR* pImportFenceWin32HandleInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkImportFenceWin32HandleKHR( m_device, reinterpret_cast<const VkImportFenceWin32HandleInfoKHR*>( pImportFenceWin32HandleInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::importFenceWin32HandleKHR( const ImportFenceWin32HandleInfoKHR & importFenceWin32HandleInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkImportFenceWin32HandleKHR( m_device, reinterpret_cast<const VkImportFenceWin32HandleInfoKHR*>( &importFenceWin32HandleInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::importFenceWin32HandleKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::importSemaphoreFdKHR( const vk::ImportSemaphoreFdInfoKHR* pImportSemaphoreFdInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkImportSemaphoreFdKHR( m_device, reinterpret_cast<const VkImportSemaphoreFdInfoKHR*>( pImportSemaphoreFdInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::importSemaphoreFdKHR( const ImportSemaphoreFdInfoKHR & importSemaphoreFdInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkImportSemaphoreFdKHR( m_device, reinterpret_cast<const VkImportSemaphoreFdInfoKHR*>( &importSemaphoreFdInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::importSemaphoreFdKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::importSemaphoreWin32HandleKHR( const vk::ImportSemaphoreWin32HandleInfoKHR* pImportSemaphoreWin32HandleInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkImportSemaphoreWin32HandleKHR( m_device, reinterpret_cast<const VkImportSemaphoreWin32HandleInfoKHR*>( pImportSemaphoreWin32HandleInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::importSemaphoreWin32HandleKHR( const ImportSemaphoreWin32HandleInfoKHR & importSemaphoreWin32HandleInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkImportSemaphoreWin32HandleKHR( m_device, reinterpret_cast<const VkImportSemaphoreWin32HandleInfoKHR*>( &importSemaphoreWin32HandleInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::importSemaphoreWin32HandleKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::initializePerformanceApiINTEL( const vk::InitializePerformanceApiInfoINTEL* pInitializeInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkInitializePerformanceApiINTEL( m_device, reinterpret_cast<const VkInitializePerformanceApiInfoINTEL*>( pInitializeInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::initializePerformanceApiINTEL( const InitializePerformanceApiInfoINTEL & initializeInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkInitializePerformanceApiINTEL( m_device, reinterpret_cast<const VkInitializePerformanceApiInfoINTEL*>( &initializeInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::initializePerformanceApiINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::invalidateMappedMemoryRanges( uint32_t memoryRangeCount, const vk::MappedMemoryRange* pMemoryRanges, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkInvalidateMappedMemoryRanges( m_device, memoryRangeCount, reinterpret_cast<const VkMappedMemoryRange*>( pMemoryRanges ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::invalidateMappedMemoryRanges( ArrayProxy<const vk::MappedMemoryRange> memoryRanges, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkInvalidateMappedMemoryRanges( m_device, memoryRanges.size() , reinterpret_cast<const VkMappedMemoryRange*>( memoryRanges.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::invalidateMappedMemoryRanges" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::mapMemory( vk::DeviceMemory memory, vk::DeviceSize offset, vk::DeviceSize size, vk::MemoryMapFlags flags, void** ppData, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkMapMemory( m_device, static_cast<VkDeviceMemory>( memory ), static_cast<VkDeviceSize>( offset ), static_cast<VkDeviceSize>( size ), static_cast<VkMemoryMapFlags>( flags ), ppData ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void*>::type Device::mapMemory( vk::DeviceMemory memory, vk::DeviceSize offset, vk::DeviceSize size, vk::MemoryMapFlags flags, Dispatch const &d ) const
  {
    void* pData;
    Result result = static_cast<Result>( d.vkMapMemory( m_device, static_cast<VkDeviceMemory>( memory ), static_cast<VkDeviceSize>( offset ), static_cast<VkDeviceSize>( size ), static_cast<VkMemoryMapFlags>( flags ), &pData ) );
    return createResultValue( result, pData, VULKAN_HPP_NAMESPACE_STRING"::Device::mapMemory" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::mergePipelineCaches( vk::PipelineCache dstCache, uint32_t srcCacheCount, const vk::PipelineCache* pSrcCaches, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkMergePipelineCaches( m_device, static_cast<VkPipelineCache>( dstCache ), srcCacheCount, reinterpret_cast<const VkPipelineCache*>( pSrcCaches ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::mergePipelineCaches( vk::PipelineCache dstCache, ArrayProxy<const vk::PipelineCache> srcCaches, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkMergePipelineCaches( m_device, static_cast<VkPipelineCache>( dstCache ), srcCaches.size() , reinterpret_cast<const VkPipelineCache*>( srcCaches.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::mergePipelineCaches" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::mergeValidationCachesEXT( vk::ValidationCacheEXT dstCache, uint32_t srcCacheCount, const vk::ValidationCacheEXT* pSrcCaches, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkMergeValidationCachesEXT( m_device, static_cast<VkValidationCacheEXT>( dstCache ), srcCacheCount, reinterpret_cast<const VkValidationCacheEXT*>( pSrcCaches ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::mergeValidationCachesEXT( vk::ValidationCacheEXT dstCache, ArrayProxy<const vk::ValidationCacheEXT> srcCaches, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkMergeValidationCachesEXT( m_device, static_cast<VkValidationCacheEXT>( dstCache ), srcCaches.size() , reinterpret_cast<const VkValidationCacheEXT*>( srcCaches.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::mergeValidationCachesEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::registerEventEXT( const vk::DeviceEventInfoEXT* pDeviceEventInfo, const vk::AllocationCallbacks* pAllocator, vk::Fence* pFence, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkRegisterDeviceEventEXT( m_device, reinterpret_cast<const VkDeviceEventInfoEXT*>( pDeviceEventInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkFence*>( pFence ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Fence>::type Device::registerEventEXT( const DeviceEventInfoEXT & deviceEventInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Fence fence;
    Result result = static_cast<Result>( d.vkRegisterDeviceEventEXT( m_device, reinterpret_cast<const VkDeviceEventInfoEXT*>( &deviceEventInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkFence*>( &fence ) ) );
    return createResultValue( result, fence, VULKAN_HPP_NAMESPACE_STRING"::Device::registerEventEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::registerDisplayEventEXT( vk::DisplayKHR display, const vk::DisplayEventInfoEXT* pDisplayEventInfo, const vk::AllocationCallbacks* pAllocator, vk::Fence* pFence, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkRegisterDisplayEventEXT( m_device, static_cast<VkDisplayKHR>( display ), reinterpret_cast<const VkDisplayEventInfoEXT*>( pDisplayEventInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkFence*>( pFence ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Fence>::type Device::registerDisplayEventEXT( vk::DisplayKHR display, const DisplayEventInfoEXT & displayEventInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Fence fence;
    Result result = static_cast<Result>( d.vkRegisterDisplayEventEXT( m_device, static_cast<VkDisplayKHR>( display ), reinterpret_cast<const VkDisplayEventInfoEXT*>( &displayEventInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkFence*>( &fence ) ) );
    return createResultValue( result, fence, VULKAN_HPP_NAMESPACE_STRING"::Device::registerDisplayEventEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::registerObjectsNVX( vk::ObjectTableNVX objectTable, uint32_t objectCount, const vk::ObjectTableEntryNVX* const* ppObjectTableEntries, const uint32_t* pObjectIndices, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkRegisterObjectsNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), objectCount, reinterpret_cast<const VkObjectTableEntryNVX* const*>( ppObjectTableEntries ), pObjectIndices ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::registerObjectsNVX( vk::ObjectTableNVX objectTable, ArrayProxy<const vk::ObjectTableEntryNVX* const> pObjectTableEntries, ArrayProxy<const uint32_t> objectIndices, Dispatch const &d ) const
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( pObjectTableEntries.size() == objectIndices.size() );
#else
    if ( pObjectTableEntries.size() != objectIndices.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkDevice::registerObjectsNVX: pObjectTableEntries.size() != objectIndices.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    Result result = static_cast<Result>( d.vkRegisterObjectsNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), pObjectTableEntries.size() , reinterpret_cast<const VkObjectTableEntryNVX* const*>( pObjectTableEntries.data() ), objectIndices.data() ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::registerObjectsNVX" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::releaseFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkReleaseFullScreenExclusiveModeEXT( m_device, static_cast<VkSwapchainKHR>( swapchain ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::releaseFullScreenExclusiveModeEXT( vk::SwapchainKHR swapchain, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkReleaseFullScreenExclusiveModeEXT( m_device, static_cast<VkSwapchainKHR>( swapchain ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::releaseFullScreenExclusiveModeEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::releasePerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkReleasePerformanceConfigurationINTEL( m_device, static_cast<VkPerformanceConfigurationINTEL>( configuration ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::releasePerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkReleasePerformanceConfigurationINTEL( m_device, static_cast<VkPerformanceConfigurationINTEL>( configuration ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::releasePerformanceConfigurationINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::resetCommandPool( vk::CommandPool commandPool, vk::CommandPoolResetFlags flags, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkResetCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), static_cast<VkCommandPoolResetFlags>( flags ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::resetCommandPool( vk::CommandPool commandPool, vk::CommandPoolResetFlags flags, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkResetCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), static_cast<VkCommandPoolResetFlags>( flags ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::resetCommandPool" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::resetDescriptorPool( vk::DescriptorPool descriptorPool, vk::DescriptorPoolResetFlags flags, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkResetDescriptorPool( m_device, static_cast<VkDescriptorPool>( descriptorPool ), static_cast<VkDescriptorPoolResetFlags>( flags ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::resetDescriptorPool( vk::DescriptorPool descriptorPool, vk::DescriptorPoolResetFlags flags, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkResetDescriptorPool( m_device, static_cast<VkDescriptorPool>( descriptorPool ), static_cast<VkDescriptorPoolResetFlags>( flags ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::resetDescriptorPool" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::resetEvent( vk::Event event, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkResetEvent( m_device, static_cast<VkEvent>( event ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::resetEvent( vk::Event event, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkResetEvent( m_device, static_cast<VkEvent>( event ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::resetEvent" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::resetFences( uint32_t fenceCount, const vk::Fence* pFences, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkResetFences( m_device, fenceCount, reinterpret_cast<const VkFence*>( pFences ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::resetFences( ArrayProxy<const vk::Fence> fences, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkResetFences( m_device, fences.size() , reinterpret_cast<const VkFence*>( fences.data() ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::resetFences" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::resetQueryPoolEXT( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkResetQueryPoolEXT( m_device, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::resetQueryPoolEXT( vk::QueryPool queryPool, uint32_t firstQuery, uint32_t queryCount, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkResetQueryPoolEXT( m_device, static_cast<VkQueryPool>( queryPool ), firstQuery, queryCount );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::setDebugUtilsObjectNameEXT( const vk::DebugUtilsObjectNameInfoEXT* pNameInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkSetDebugUtilsObjectNameEXT( m_device, reinterpret_cast<const VkDebugUtilsObjectNameInfoEXT*>( pNameInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::setDebugUtilsObjectNameEXT( const DebugUtilsObjectNameInfoEXT & nameInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkSetDebugUtilsObjectNameEXT( m_device, reinterpret_cast<const VkDebugUtilsObjectNameInfoEXT*>( &nameInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::setDebugUtilsObjectNameEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::setDebugUtilsObjectTagEXT( const vk::DebugUtilsObjectTagInfoEXT* pTagInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkSetDebugUtilsObjectTagEXT( m_device, reinterpret_cast<const VkDebugUtilsObjectTagInfoEXT*>( pTagInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::setDebugUtilsObjectTagEXT( const DebugUtilsObjectTagInfoEXT & tagInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkSetDebugUtilsObjectTagEXT( m_device, reinterpret_cast<const VkDebugUtilsObjectTagInfoEXT*>( &tagInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::setDebugUtilsObjectTagEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::setEvent( vk::Event event, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkSetEvent( m_device, static_cast<VkEvent>( event ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::setEvent( vk::Event event, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkSetEvent( m_device, static_cast<VkEvent>( event ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::setEvent" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::setHdrMetadataEXT( uint32_t swapchainCount, const vk::SwapchainKHR* pSwapchains, const vk::HdrMetadataEXT* pMetadata, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkSetHdrMetadataEXT( m_device, swapchainCount, reinterpret_cast<const VkSwapchainKHR*>( pSwapchains ), reinterpret_cast<const VkHdrMetadataEXT*>( pMetadata ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::setHdrMetadataEXT( ArrayProxy<const vk::SwapchainKHR> swapchains, ArrayProxy<const vk::HdrMetadataEXT> metadata, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( swapchains.size() == metadata.size() );
#else
    if ( swapchains.size() != metadata.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkDevice::setHdrMetadataEXT: swapchains.size() != metadata.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    d.vkSetHdrMetadataEXT( m_device, swapchains.size() , reinterpret_cast<const VkSwapchainKHR*>( swapchains.data() ), reinterpret_cast<const VkHdrMetadataEXT*>( metadata.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::setLocalDimmingAMD( vk::SwapchainKHR swapChain, vk::Bool32 localDimmingEnable, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkSetLocalDimmingAMD( m_device, static_cast<VkSwapchainKHR>( swapChain ), static_cast<VkBool32>( localDimmingEnable ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::setLocalDimmingAMD( vk::SwapchainKHR swapChain, vk::Bool32 localDimmingEnable, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkSetLocalDimmingAMD( m_device, static_cast<VkSwapchainKHR>( swapChain ), static_cast<VkBool32>( localDimmingEnable ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::signalSemaphoreKHR( const vk::SemaphoreSignalInfoKHR* pSignalInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkSignalSemaphoreKHR( m_device, reinterpret_cast<const VkSemaphoreSignalInfoKHR*>( pSignalInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::signalSemaphoreKHR( const SemaphoreSignalInfoKHR & signalInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkSignalSemaphoreKHR( m_device, reinterpret_cast<const VkSemaphoreSignalInfoKHR*>( &signalInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::signalSemaphoreKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::trimCommandPool( vk::CommandPool commandPool, vk::CommandPoolTrimFlags flags, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkTrimCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), static_cast<VkCommandPoolTrimFlags>( flags ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::trimCommandPool( vk::CommandPool commandPool, vk::CommandPoolTrimFlags flags, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkTrimCommandPool( m_device, static_cast<VkCommandPool>( commandPool ), static_cast<VkCommandPoolTrimFlags>( flags ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::trimCommandPoolKHR( vk::CommandPool commandPool, vk::CommandPoolTrimFlags flags, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkTrimCommandPoolKHR( m_device, static_cast<VkCommandPool>( commandPool ), static_cast<VkCommandPoolTrimFlags>( flags ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::trimCommandPoolKHR( vk::CommandPool commandPool, vk::CommandPoolTrimFlags flags, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkTrimCommandPoolKHR( m_device, static_cast<VkCommandPool>( commandPool ), static_cast<VkCommandPoolTrimFlags>( flags ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::uninitializePerformanceApiINTEL(Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUninitializePerformanceApiINTEL( m_device );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::uninitializePerformanceApiINTEL(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUninitializePerformanceApiINTEL( m_device );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::unmapMemory( vk::DeviceMemory memory, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUnmapMemory( m_device, static_cast<VkDeviceMemory>( memory ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::unmapMemory( vk::DeviceMemory memory, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUnmapMemory( m_device, static_cast<VkDeviceMemory>( memory ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::unregisterObjectsNVX( vk::ObjectTableNVX objectTable, uint32_t objectCount, const vk::ObjectEntryTypeNVX* pObjectEntryTypes, const uint32_t* pObjectIndices, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkUnregisterObjectsNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), objectCount, reinterpret_cast<const VkObjectEntryTypeNVX*>( pObjectEntryTypes ), pObjectIndices ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Device::unregisterObjectsNVX( vk::ObjectTableNVX objectTable, ArrayProxy<const vk::ObjectEntryTypeNVX> objectEntryTypes, ArrayProxy<const uint32_t> objectIndices, Dispatch const &d ) const
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( objectEntryTypes.size() == objectIndices.size() );
#else
    if ( objectEntryTypes.size() != objectIndices.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkDevice::unregisterObjectsNVX: objectEntryTypes.size() != objectIndices.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    Result result = static_cast<Result>( d.vkUnregisterObjectsNVX( m_device, static_cast<VkObjectTableNVX>( objectTable ), objectEntryTypes.size() , reinterpret_cast<const VkObjectEntryTypeNVX*>( objectEntryTypes.data() ), objectIndices.data() ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::unregisterObjectsNVX" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::updateDescriptorSetWithTemplate( vk::DescriptorSet descriptorSet, vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUpdateDescriptorSetWithTemplate( m_device, static_cast<VkDescriptorSet>( descriptorSet ), static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), pData );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::updateDescriptorSetWithTemplate( vk::DescriptorSet descriptorSet, vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUpdateDescriptorSetWithTemplate( m_device, static_cast<VkDescriptorSet>( descriptorSet ), static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), pData );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::updateDescriptorSetWithTemplateKHR( vk::DescriptorSet descriptorSet, vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUpdateDescriptorSetWithTemplateKHR( m_device, static_cast<VkDescriptorSet>( descriptorSet ), static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), pData );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::updateDescriptorSetWithTemplateKHR( vk::DescriptorSet descriptorSet, vk::DescriptorUpdateTemplate descriptorUpdateTemplate, const void* pData, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUpdateDescriptorSetWithTemplateKHR( m_device, static_cast<VkDescriptorSet>( descriptorSet ), static_cast<VkDescriptorUpdateTemplate>( descriptorUpdateTemplate ), pData );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::updateDescriptorSets( uint32_t descriptorWriteCount, const vk::WriteDescriptorSet* pDescriptorWrites, uint32_t descriptorCopyCount, const vk::CopyDescriptorSet* pDescriptorCopies, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUpdateDescriptorSets( m_device, descriptorWriteCount, reinterpret_cast<const VkWriteDescriptorSet*>( pDescriptorWrites ), descriptorCopyCount, reinterpret_cast<const VkCopyDescriptorSet*>( pDescriptorCopies ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Device::updateDescriptorSets( ArrayProxy<const vk::WriteDescriptorSet> descriptorWrites, ArrayProxy<const vk::CopyDescriptorSet> descriptorCopies, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkUpdateDescriptorSets( m_device, descriptorWrites.size() , reinterpret_cast<const VkWriteDescriptorSet*>( descriptorWrites.data() ), descriptorCopies.size() , reinterpret_cast<const VkCopyDescriptorSet*>( descriptorCopies.data() ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::waitForFences( uint32_t fenceCount, const vk::Fence* pFences, vk::Bool32 waitAll, uint64_t timeout, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkWaitForFences( m_device, fenceCount, reinterpret_cast<const VkFence*>( pFences ), static_cast<VkBool32>( waitAll ), timeout ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::waitForFences( ArrayProxy<const vk::Fence> fences, vk::Bool32 waitAll, uint64_t timeout, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkWaitForFences( m_device, fences.size() , reinterpret_cast<const VkFence*>( fences.data() ), static_cast<VkBool32>( waitAll ), timeout ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::waitForFences", { Result::eSuccess, Result::eTimeout } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::waitSemaphoresKHR( const vk::SemaphoreWaitInfoKHR* pWaitInfo, uint64_t timeout, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkWaitSemaphoresKHR( m_device, reinterpret_cast<const VkSemaphoreWaitInfoKHR*>( pWaitInfo ), timeout ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Device::waitSemaphoresKHR( const SemaphoreWaitInfoKHR & waitInfo, uint64_t timeout, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkWaitSemaphoresKHR( m_device, reinterpret_cast<const VkSemaphoreWaitInfoKHR*>( &waitInfo ), timeout ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Device::waitSemaphoresKHR", { Result::eSuccess, Result::eTimeout } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createAndroidSurfaceKHR( const vk::AndroidSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateAndroidSurfaceKHR( m_instance, reinterpret_cast<const VkAndroidSurfaceCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createAndroidSurfaceKHR( const AndroidSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateAndroidSurfaceKHR( m_instance, reinterpret_cast<const VkAndroidSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createAndroidSurfaceKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createAndroidSurfaceKHRUnique( const AndroidSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateAndroidSurfaceKHR( m_instance, reinterpret_cast<const VkAndroidSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createAndroidSurfaceKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createDebugReportCallbackEXT( const vk::DebugReportCallbackCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DebugReportCallbackEXT* pCallback, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDebugReportCallbackEXT( m_instance, reinterpret_cast<const VkDebugReportCallbackCreateInfoEXT*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDebugReportCallbackEXT*>( pCallback ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DebugReportCallbackEXT>::type Instance::createDebugReportCallbackEXT( const DebugReportCallbackCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DebugReportCallbackEXT callback;
    Result result = static_cast<Result>( d.vkCreateDebugReportCallbackEXT( m_instance, reinterpret_cast<const VkDebugReportCallbackCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDebugReportCallbackEXT*>( &callback ) ) );
    return createResultValue( result, callback, VULKAN_HPP_NAMESPACE_STRING"::Instance::createDebugReportCallbackEXT" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<DebugReportCallbackEXT,Dispatch>>::type Instance::createDebugReportCallbackEXTUnique( const DebugReportCallbackCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DebugReportCallbackEXT callback;
    Result result = static_cast<Result>( d.vkCreateDebugReportCallbackEXT( m_instance, reinterpret_cast<const VkDebugReportCallbackCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDebugReportCallbackEXT*>( &callback ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<DebugReportCallbackEXT,Dispatch>( result, callback, VULKAN_HPP_NAMESPACE_STRING"::Instance::createDebugReportCallbackEXTUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createDebugUtilsMessengerEXT( const vk::DebugUtilsMessengerCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DebugUtilsMessengerEXT* pMessenger, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDebugUtilsMessengerEXT( m_instance, reinterpret_cast<const VkDebugUtilsMessengerCreateInfoEXT*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDebugUtilsMessengerEXT*>( pMessenger ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DebugUtilsMessengerEXT>::type Instance::createDebugUtilsMessengerEXT( const DebugUtilsMessengerCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DebugUtilsMessengerEXT messenger;
    Result result = static_cast<Result>( d.vkCreateDebugUtilsMessengerEXT( m_instance, reinterpret_cast<const VkDebugUtilsMessengerCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDebugUtilsMessengerEXT*>( &messenger ) ) );
    return createResultValue( result, messenger, VULKAN_HPP_NAMESPACE_STRING"::Instance::createDebugUtilsMessengerEXT" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<DebugUtilsMessengerEXT,Dispatch>>::type Instance::createDebugUtilsMessengerEXTUnique( const DebugUtilsMessengerCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DebugUtilsMessengerEXT messenger;
    Result result = static_cast<Result>( d.vkCreateDebugUtilsMessengerEXT( m_instance, reinterpret_cast<const VkDebugUtilsMessengerCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDebugUtilsMessengerEXT*>( &messenger ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<DebugUtilsMessengerEXT,Dispatch>( result, messenger, VULKAN_HPP_NAMESPACE_STRING"::Instance::createDebugUtilsMessengerEXTUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createDisplayPlaneSurfaceKHR( const vk::DisplaySurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDisplayPlaneSurfaceKHR( m_instance, reinterpret_cast<const VkDisplaySurfaceCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createDisplayPlaneSurfaceKHR( const DisplaySurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateDisplayPlaneSurfaceKHR( m_instance, reinterpret_cast<const VkDisplaySurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createDisplayPlaneSurfaceKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createDisplayPlaneSurfaceKHRUnique( const DisplaySurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateDisplayPlaneSurfaceKHR( m_instance, reinterpret_cast<const VkDisplaySurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createDisplayPlaneSurfaceKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createHeadlessSurfaceEXT( const vk::HeadlessSurfaceCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateHeadlessSurfaceEXT( m_instance, reinterpret_cast<const VkHeadlessSurfaceCreateInfoEXT*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createHeadlessSurfaceEXT( const HeadlessSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateHeadlessSurfaceEXT( m_instance, reinterpret_cast<const VkHeadlessSurfaceCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createHeadlessSurfaceEXT" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createHeadlessSurfaceEXTUnique( const HeadlessSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateHeadlessSurfaceEXT( m_instance, reinterpret_cast<const VkHeadlessSurfaceCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createHeadlessSurfaceEXTUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_IOS_MVK
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createIOSSurfaceMVK( const vk::IOSSurfaceCreateInfoMVK* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateIOSSurfaceMVK( m_instance, reinterpret_cast<const VkIOSSurfaceCreateInfoMVK*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createIOSSurfaceMVK( const IOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateIOSSurfaceMVK( m_instance, reinterpret_cast<const VkIOSSurfaceCreateInfoMVK*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createIOSSurfaceMVK" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createIOSSurfaceMVKUnique( const IOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateIOSSurfaceMVK( m_instance, reinterpret_cast<const VkIOSSurfaceCreateInfoMVK*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createIOSSurfaceMVKUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_IOS_MVK*/

#ifdef VK_USE_PLATFORM_FUCHSIA
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createImagePipeSurfaceFUCHSIA( const vk::ImagePipeSurfaceCreateInfoFUCHSIA* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateImagePipeSurfaceFUCHSIA( m_instance, reinterpret_cast<const VkImagePipeSurfaceCreateInfoFUCHSIA*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createImagePipeSurfaceFUCHSIA( const ImagePipeSurfaceCreateInfoFUCHSIA & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateImagePipeSurfaceFUCHSIA( m_instance, reinterpret_cast<const VkImagePipeSurfaceCreateInfoFUCHSIA*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createImagePipeSurfaceFUCHSIA" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createImagePipeSurfaceFUCHSIAUnique( const ImagePipeSurfaceCreateInfoFUCHSIA & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateImagePipeSurfaceFUCHSIA( m_instance, reinterpret_cast<const VkImagePipeSurfaceCreateInfoFUCHSIA*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createImagePipeSurfaceFUCHSIAUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_FUCHSIA*/

#ifdef VK_USE_PLATFORM_MACOS_MVK
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createMacOSSurfaceMVK( const vk::MacOSSurfaceCreateInfoMVK* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateMacOSSurfaceMVK( m_instance, reinterpret_cast<const VkMacOSSurfaceCreateInfoMVK*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createMacOSSurfaceMVK( const MacOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateMacOSSurfaceMVK( m_instance, reinterpret_cast<const VkMacOSSurfaceCreateInfoMVK*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createMacOSSurfaceMVK" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createMacOSSurfaceMVKUnique( const MacOSSurfaceCreateInfoMVK & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateMacOSSurfaceMVK( m_instance, reinterpret_cast<const VkMacOSSurfaceCreateInfoMVK*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createMacOSSurfaceMVKUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_MACOS_MVK*/

#ifdef VK_USE_PLATFORM_METAL_EXT
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createMetalSurfaceEXT( const vk::MetalSurfaceCreateInfoEXT* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateMetalSurfaceEXT( m_instance, reinterpret_cast<const VkMetalSurfaceCreateInfoEXT*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createMetalSurfaceEXT( const MetalSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateMetalSurfaceEXT( m_instance, reinterpret_cast<const VkMetalSurfaceCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createMetalSurfaceEXT" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createMetalSurfaceEXTUnique( const MetalSurfaceCreateInfoEXT & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateMetalSurfaceEXT( m_instance, reinterpret_cast<const VkMetalSurfaceCreateInfoEXT*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createMetalSurfaceEXTUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_METAL_EXT*/

#ifdef VK_USE_PLATFORM_GGP
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createStreamDescriptorSurfaceGGP( const vk::StreamDescriptorSurfaceCreateInfoGGP* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateStreamDescriptorSurfaceGGP( m_instance, reinterpret_cast<const VkStreamDescriptorSurfaceCreateInfoGGP*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createStreamDescriptorSurfaceGGP( const StreamDescriptorSurfaceCreateInfoGGP & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateStreamDescriptorSurfaceGGP( m_instance, reinterpret_cast<const VkStreamDescriptorSurfaceCreateInfoGGP*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createStreamDescriptorSurfaceGGP" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createStreamDescriptorSurfaceGGPUnique( const StreamDescriptorSurfaceCreateInfoGGP & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateStreamDescriptorSurfaceGGP( m_instance, reinterpret_cast<const VkStreamDescriptorSurfaceCreateInfoGGP*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createStreamDescriptorSurfaceGGPUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_GGP*/

#ifdef VK_USE_PLATFORM_VI_NN
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createViSurfaceNN( const vk::ViSurfaceCreateInfoNN* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateViSurfaceNN( m_instance, reinterpret_cast<const VkViSurfaceCreateInfoNN*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createViSurfaceNN( const ViSurfaceCreateInfoNN & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateViSurfaceNN( m_instance, reinterpret_cast<const VkViSurfaceCreateInfoNN*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createViSurfaceNN" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createViSurfaceNNUnique( const ViSurfaceCreateInfoNN & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateViSurfaceNN( m_instance, reinterpret_cast<const VkViSurfaceCreateInfoNN*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createViSurfaceNNUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_VI_NN*/

#ifdef VK_USE_PLATFORM_WAYLAND_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createWaylandSurfaceKHR( const vk::WaylandSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateWaylandSurfaceKHR( m_instance, reinterpret_cast<const VkWaylandSurfaceCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createWaylandSurfaceKHR( const WaylandSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateWaylandSurfaceKHR( m_instance, reinterpret_cast<const VkWaylandSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createWaylandSurfaceKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createWaylandSurfaceKHRUnique( const WaylandSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateWaylandSurfaceKHR( m_instance, reinterpret_cast<const VkWaylandSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createWaylandSurfaceKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createWin32SurfaceKHR( const vk::Win32SurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateWin32SurfaceKHR( m_instance, reinterpret_cast<const VkWin32SurfaceCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createWin32SurfaceKHR( const Win32SurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateWin32SurfaceKHR( m_instance, reinterpret_cast<const VkWin32SurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createWin32SurfaceKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createWin32SurfaceKHRUnique( const Win32SurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateWin32SurfaceKHR( m_instance, reinterpret_cast<const VkWin32SurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createWin32SurfaceKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_XCB_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createXcbSurfaceKHR( const vk::XcbSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateXcbSurfaceKHR( m_instance, reinterpret_cast<const VkXcbSurfaceCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createXcbSurfaceKHR( const XcbSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateXcbSurfaceKHR( m_instance, reinterpret_cast<const VkXcbSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createXcbSurfaceKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createXcbSurfaceKHRUnique( const XcbSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateXcbSurfaceKHR( m_instance, reinterpret_cast<const VkXcbSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createXcbSurfaceKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::createXlibSurfaceKHR( const vk::XlibSurfaceCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::SurfaceKHR* pSurface, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateXlibSurfaceKHR( m_instance, reinterpret_cast<const VkXlibSurfaceCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkSurfaceKHR*>( pSurface ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceKHR>::type Instance::createXlibSurfaceKHR( const XlibSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateXlibSurfaceKHR( m_instance, reinterpret_cast<const VkXlibSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );
    return createResultValue( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createXlibSurfaceKHR" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<SurfaceKHR,Dispatch>>::type Instance::createXlibSurfaceKHRUnique( const XlibSurfaceCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::SurfaceKHR surface;
    Result result = static_cast<Result>( d.vkCreateXlibSurfaceKHR( m_instance, reinterpret_cast<const VkXlibSurfaceCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkSurfaceKHR*>( &surface ) ) );

    ObjectDestroy<Instance,Dispatch> deleter( *this, allocator, d );
    return createResultValue<SurfaceKHR,Dispatch>( result, surface, VULKAN_HPP_NAMESPACE_STRING"::Instance::createXlibSurfaceKHRUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::debugReportMessageEXT( vk::DebugReportFlagsEXT flags, vk::DebugReportObjectTypeEXT objectType, uint64_t object, size_t location, int32_t messageCode, const char* pLayerPrefix, const char* pMessage, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDebugReportMessageEXT( m_instance, static_cast<VkDebugReportFlagsEXT>( flags ), static_cast<VkDebugReportObjectTypeEXT>( objectType ), object, location, messageCode, pLayerPrefix, pMessage );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::debugReportMessageEXT( vk::DebugReportFlagsEXT flags, vk::DebugReportObjectTypeEXT objectType, uint64_t object, size_t location, int32_t messageCode, const std::string & layerPrefix, const std::string & message, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    VULKAN_HPP_ASSERT( layerPrefix.size() == message.size() );
#else
    if ( layerPrefix.size() != message.size() )
    {
      throw LogicError( VULKAN_HPP_NAMESPACE_STRING "::VkInstance::debugReportMessageEXT: layerPrefix.size() != message.size()" );
    }
#endif  /*VULKAN_HPP_NO_EXCEPTIONS*/
    d.vkDebugReportMessageEXT( m_instance, static_cast<VkDebugReportFlagsEXT>( flags ), static_cast<VkDebugReportObjectTypeEXT>( objectType ), object, location, messageCode, layerPrefix.c_str(), message.c_str() );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroyDebugReportCallbackEXT( vk::DebugReportCallbackEXT callback, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugReportCallbackEXT( m_instance, static_cast<VkDebugReportCallbackEXT>( callback ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroyDebugReportCallbackEXT( vk::DebugReportCallbackEXT callback, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugReportCallbackEXT( m_instance, static_cast<VkDebugReportCallbackEXT>( callback ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( vk::DebugReportCallbackEXT callback, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugReportCallbackEXT( m_instance, static_cast<VkDebugReportCallbackEXT>( callback ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( vk::DebugReportCallbackEXT callback, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugReportCallbackEXT( m_instance, static_cast<VkDebugReportCallbackEXT>( callback ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroyDebugUtilsMessengerEXT( vk::DebugUtilsMessengerEXT messenger, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugUtilsMessengerEXT( m_instance, static_cast<VkDebugUtilsMessengerEXT>( messenger ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroyDebugUtilsMessengerEXT( vk::DebugUtilsMessengerEXT messenger, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugUtilsMessengerEXT( m_instance, static_cast<VkDebugUtilsMessengerEXT>( messenger ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( vk::DebugUtilsMessengerEXT messenger, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugUtilsMessengerEXT( m_instance, static_cast<VkDebugUtilsMessengerEXT>( messenger ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( vk::DebugUtilsMessengerEXT messenger, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyDebugUtilsMessengerEXT( m_instance, static_cast<VkDebugUtilsMessengerEXT>( messenger ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyInstance( m_instance, reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroyInstance( m_instance, reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroySurfaceKHR( vk::SurfaceKHR surface, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySurfaceKHR( m_instance, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroySurfaceKHR( vk::SurfaceKHR surface, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySurfaceKHR( m_instance, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( vk::SurfaceKHR surface, const vk::AllocationCallbacks* pAllocator, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySurfaceKHR( m_instance, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::destroy( vk::SurfaceKHR surface, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkDestroySurfaceKHR( m_instance, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::enumeratePhysicalDeviceGroups( uint32_t* pPhysicalDeviceGroupCount, vk::PhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkEnumeratePhysicalDeviceGroups( m_instance, pPhysicalDeviceGroupCount, reinterpret_cast<VkPhysicalDeviceGroupProperties*>( pPhysicalDeviceGroupProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type Instance::enumeratePhysicalDeviceGroups(Dispatch const &d ) const
  {
    std::vector<PhysicalDeviceGroupProperties,Allocator> physicalDeviceGroupProperties;
    uint32_t physicalDeviceGroupCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroups( m_instance, &physicalDeviceGroupCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && physicalDeviceGroupCount )
      {
        physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
        result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroups( m_instance, &physicalDeviceGroupCount, reinterpret_cast<VkPhysicalDeviceGroupProperties*>( physicalDeviceGroupProperties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( physicalDeviceGroupCount <= physicalDeviceGroupProperties.size() );
      physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
    }
    return createResultValue( result, physicalDeviceGroupProperties, VULKAN_HPP_NAMESPACE_STRING"::Instance::enumeratePhysicalDeviceGroups" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type Instance::enumeratePhysicalDeviceGroups(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PhysicalDeviceGroupProperties,Allocator> physicalDeviceGroupProperties( vectorAllocator );
    uint32_t physicalDeviceGroupCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroups( m_instance, &physicalDeviceGroupCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && physicalDeviceGroupCount )
      {
        physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
        result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroups( m_instance, &physicalDeviceGroupCount, reinterpret_cast<VkPhysicalDeviceGroupProperties*>( physicalDeviceGroupProperties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( physicalDeviceGroupCount <= physicalDeviceGroupProperties.size() );
      physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
    }
    return createResultValue( result, physicalDeviceGroupProperties, VULKAN_HPP_NAMESPACE_STRING"::Instance::enumeratePhysicalDeviceGroups" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::enumeratePhysicalDeviceGroupsKHR( uint32_t* pPhysicalDeviceGroupCount, vk::PhysicalDeviceGroupProperties* pPhysicalDeviceGroupProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkEnumeratePhysicalDeviceGroupsKHR( m_instance, pPhysicalDeviceGroupCount, reinterpret_cast<VkPhysicalDeviceGroupProperties*>( pPhysicalDeviceGroupProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type Instance::enumeratePhysicalDeviceGroupsKHR(Dispatch const &d ) const
  {
    std::vector<PhysicalDeviceGroupProperties,Allocator> physicalDeviceGroupProperties;
    uint32_t physicalDeviceGroupCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroupsKHR( m_instance, &physicalDeviceGroupCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && physicalDeviceGroupCount )
      {
        physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
        result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroupsKHR( m_instance, &physicalDeviceGroupCount, reinterpret_cast<VkPhysicalDeviceGroupProperties*>( physicalDeviceGroupProperties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( physicalDeviceGroupCount <= physicalDeviceGroupProperties.size() );
      physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
    }
    return createResultValue( result, physicalDeviceGroupProperties, VULKAN_HPP_NAMESPACE_STRING"::Instance::enumeratePhysicalDeviceGroupsKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PhysicalDeviceGroupProperties,Allocator>>::type Instance::enumeratePhysicalDeviceGroupsKHR(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PhysicalDeviceGroupProperties,Allocator> physicalDeviceGroupProperties( vectorAllocator );
    uint32_t physicalDeviceGroupCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroupsKHR( m_instance, &physicalDeviceGroupCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && physicalDeviceGroupCount )
      {
        physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
        result = static_cast<Result>( d.vkEnumeratePhysicalDeviceGroupsKHR( m_instance, &physicalDeviceGroupCount, reinterpret_cast<VkPhysicalDeviceGroupProperties*>( physicalDeviceGroupProperties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( physicalDeviceGroupCount <= physicalDeviceGroupProperties.size() );
      physicalDeviceGroupProperties.resize( physicalDeviceGroupCount );
    }
    return createResultValue( result, physicalDeviceGroupProperties, VULKAN_HPP_NAMESPACE_STRING"::Instance::enumeratePhysicalDeviceGroupsKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Instance::enumeratePhysicalDevices( uint32_t* pPhysicalDeviceCount, vk::PhysicalDevice* pPhysicalDevices, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkEnumeratePhysicalDevices( m_instance, pPhysicalDeviceCount, reinterpret_cast<VkPhysicalDevice*>( pPhysicalDevices ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PhysicalDevice,Allocator>>::type Instance::enumeratePhysicalDevices(Dispatch const &d ) const
  {
    std::vector<PhysicalDevice,Allocator> physicalDevices;
    uint32_t physicalDeviceCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumeratePhysicalDevices( m_instance, &physicalDeviceCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && physicalDeviceCount )
      {
        physicalDevices.resize( physicalDeviceCount );
        result = static_cast<Result>( d.vkEnumeratePhysicalDevices( m_instance, &physicalDeviceCount, reinterpret_cast<VkPhysicalDevice*>( physicalDevices.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( physicalDeviceCount <= physicalDevices.size() );
      physicalDevices.resize( physicalDeviceCount );
    }
    return createResultValue( result, physicalDevices, VULKAN_HPP_NAMESPACE_STRING"::Instance::enumeratePhysicalDevices" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PhysicalDevice,Allocator>>::type Instance::enumeratePhysicalDevices(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PhysicalDevice,Allocator> physicalDevices( vectorAllocator );
    uint32_t physicalDeviceCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumeratePhysicalDevices( m_instance, &physicalDeviceCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && physicalDeviceCount )
      {
        physicalDevices.resize( physicalDeviceCount );
        result = static_cast<Result>( d.vkEnumeratePhysicalDevices( m_instance, &physicalDeviceCount, reinterpret_cast<VkPhysicalDevice*>( physicalDevices.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( physicalDeviceCount <= physicalDevices.size() );
      physicalDevices.resize( physicalDeviceCount );
    }
    return createResultValue( result, physicalDevices, VULKAN_HPP_NAMESPACE_STRING"::Instance::enumeratePhysicalDevices" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE PFN_vkVoidFunction Instance::getProcAddr( const char* pName, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetInstanceProcAddr( m_instance, pName );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE PFN_vkVoidFunction Instance::getProcAddr( const std::string & name, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetInstanceProcAddr( m_instance, name.c_str() );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::submitDebugUtilsMessageEXT( vk::DebugUtilsMessageSeverityFlagBitsEXT messageSeverity, vk::DebugUtilsMessageTypeFlagsEXT messageTypes, const vk::DebugUtilsMessengerCallbackDataEXT* pCallbackData, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkSubmitDebugUtilsMessageEXT( m_instance, static_cast<VkDebugUtilsMessageSeverityFlagBitsEXT>( messageSeverity ), static_cast<VkDebugUtilsMessageTypeFlagsEXT>( messageTypes ), reinterpret_cast<const VkDebugUtilsMessengerCallbackDataEXT*>( pCallbackData ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Instance::submitDebugUtilsMessageEXT( vk::DebugUtilsMessageSeverityFlagBitsEXT messageSeverity, vk::DebugUtilsMessageTypeFlagsEXT messageTypes, const DebugUtilsMessengerCallbackDataEXT & callbackData, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkSubmitDebugUtilsMessageEXT( m_instance, static_cast<VkDebugUtilsMessageSeverityFlagBitsEXT>( messageSeverity ), static_cast<VkDebugUtilsMessageTypeFlagsEXT>( messageTypes ), reinterpret_cast<const VkDebugUtilsMessengerCallbackDataEXT*>( &callbackData ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::acquireXlibDisplayEXT( Display* dpy, vk::DisplayKHR display, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkAcquireXlibDisplayEXT( m_physicalDevice, dpy, static_cast<VkDisplayKHR>( display ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<Display>::type PhysicalDevice::acquireXlibDisplayEXT( vk::DisplayKHR display, Dispatch const &d ) const
  {
    Display dpy;
    Result result = static_cast<Result>( d.vkAcquireXlibDisplayEXT( m_physicalDevice, &dpy, static_cast<VkDisplayKHR>( display ) ) );
    return createResultValue( result, dpy, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::acquireXlibDisplayEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::createDevice( const vk::DeviceCreateInfo* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::Device* pDevice, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDevice( m_physicalDevice, reinterpret_cast<const VkDeviceCreateInfo*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDevice*>( pDevice ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Device>::type PhysicalDevice::createDevice( const DeviceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Device device;
    Result result = static_cast<Result>( d.vkCreateDevice( m_physicalDevice, reinterpret_cast<const VkDeviceCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDevice*>( &device ) ) );
    return createResultValue( result, device, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::createDevice" );
  }
#ifndef VULKAN_HPP_NO_SMART_HANDLE
  template<typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<UniqueHandle<Device,Dispatch>>::type PhysicalDevice::createDeviceUnique( const DeviceCreateInfo & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::Device device;
    Result result = static_cast<Result>( d.vkCreateDevice( m_physicalDevice, reinterpret_cast<const VkDeviceCreateInfo*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDevice*>( &device ) ) );

    ObjectDestroy<NoParent,Dispatch> deleter( allocator, d );
    return createResultValue<Device,Dispatch>( result, device, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::createDeviceUnique", deleter );
  }
#endif /*VULKAN_HPP_NO_SMART_HANDLE*/
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::createDisplayModeKHR( vk::DisplayKHR display, const vk::DisplayModeCreateInfoKHR* pCreateInfo, const vk::AllocationCallbacks* pAllocator, vk::DisplayModeKHR* pMode, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkCreateDisplayModeKHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), reinterpret_cast<const VkDisplayModeCreateInfoKHR*>( pCreateInfo ), reinterpret_cast<const VkAllocationCallbacks*>( pAllocator ), reinterpret_cast<VkDisplayModeKHR*>( pMode ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DisplayModeKHR>::type PhysicalDevice::createDisplayModeKHR( vk::DisplayKHR display, const DisplayModeCreateInfoKHR & createInfo, Optional<const AllocationCallbacks> allocator, Dispatch const &d ) const
  {
    vk::DisplayModeKHR mode;
    Result result = static_cast<Result>( d.vkCreateDisplayModeKHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), reinterpret_cast<const VkDisplayModeCreateInfoKHR*>( &createInfo ), reinterpret_cast<const VkAllocationCallbacks*>( static_cast<const AllocationCallbacks*>( allocator ) ), reinterpret_cast<VkDisplayModeKHR*>( &mode ) ) );
    return createResultValue( result, mode, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::createDisplayModeKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::enumerateDeviceExtensionProperties( const char* pLayerName, uint32_t* pPropertyCount, vk::ExtensionProperties* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkEnumerateDeviceExtensionProperties( m_physicalDevice, pLayerName, pPropertyCount, reinterpret_cast<VkExtensionProperties*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type PhysicalDevice::enumerateDeviceExtensionProperties( Optional<const std::string> layerName, Dispatch const &d ) const
  {
    std::vector<ExtensionProperties,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateDeviceExtensionProperties( m_physicalDevice, layerName ? layerName->c_str() : nullptr, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateDeviceExtensionProperties( m_physicalDevice, layerName ? layerName->c_str() : nullptr, &propertyCount, reinterpret_cast<VkExtensionProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::enumerateDeviceExtensionProperties" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<ExtensionProperties,Allocator>>::type PhysicalDevice::enumerateDeviceExtensionProperties( Optional<const std::string> layerName, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<ExtensionProperties,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateDeviceExtensionProperties( m_physicalDevice, layerName ? layerName->c_str() : nullptr, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateDeviceExtensionProperties( m_physicalDevice, layerName ? layerName->c_str() : nullptr, &propertyCount, reinterpret_cast<VkExtensionProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::enumerateDeviceExtensionProperties" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::enumerateDeviceLayerProperties( uint32_t* pPropertyCount, vk::LayerProperties* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkEnumerateDeviceLayerProperties( m_physicalDevice, pPropertyCount, reinterpret_cast<VkLayerProperties*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<LayerProperties,Allocator>>::type PhysicalDevice::enumerateDeviceLayerProperties(Dispatch const &d ) const
  {
    std::vector<LayerProperties,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateDeviceLayerProperties( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateDeviceLayerProperties( m_physicalDevice, &propertyCount, reinterpret_cast<VkLayerProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::enumerateDeviceLayerProperties" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<LayerProperties,Allocator>>::type PhysicalDevice::enumerateDeviceLayerProperties(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<LayerProperties,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkEnumerateDeviceLayerProperties( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkEnumerateDeviceLayerProperties( m_physicalDevice, &propertyCount, reinterpret_cast<VkLayerProperties*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::enumerateDeviceLayerProperties" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayModeProperties2KHR( vk::DisplayKHR display, uint32_t* pPropertyCount, vk::DisplayModeProperties2KHR* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDisplayModeProperties2KHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), pPropertyCount, reinterpret_cast<VkDisplayModeProperties2KHR*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayModeProperties2KHR,Allocator>>::type PhysicalDevice::getDisplayModeProperties2KHR( vk::DisplayKHR display, Dispatch const &d ) const
  {
    std::vector<DisplayModeProperties2KHR,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetDisplayModeProperties2KHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetDisplayModeProperties2KHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, reinterpret_cast<VkDisplayModeProperties2KHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayModeProperties2KHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayModeProperties2KHR,Allocator>>::type PhysicalDevice::getDisplayModeProperties2KHR( vk::DisplayKHR display, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DisplayModeProperties2KHR,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetDisplayModeProperties2KHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetDisplayModeProperties2KHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, reinterpret_cast<VkDisplayModeProperties2KHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayModeProperties2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayModePropertiesKHR( vk::DisplayKHR display, uint32_t* pPropertyCount, vk::DisplayModePropertiesKHR* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDisplayModePropertiesKHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), pPropertyCount, reinterpret_cast<VkDisplayModePropertiesKHR*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayModePropertiesKHR,Allocator>>::type PhysicalDevice::getDisplayModePropertiesKHR( vk::DisplayKHR display, Dispatch const &d ) const
  {
    std::vector<DisplayModePropertiesKHR,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetDisplayModePropertiesKHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetDisplayModePropertiesKHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, reinterpret_cast<VkDisplayModePropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayModePropertiesKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayModePropertiesKHR,Allocator>>::type PhysicalDevice::getDisplayModePropertiesKHR( vk::DisplayKHR display, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DisplayModePropertiesKHR,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetDisplayModePropertiesKHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetDisplayModePropertiesKHR( m_physicalDevice, static_cast<VkDisplayKHR>( display ), &propertyCount, reinterpret_cast<VkDisplayModePropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayModePropertiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayPlaneCapabilities2KHR( const vk::DisplayPlaneInfo2KHR* pDisplayPlaneInfo, vk::DisplayPlaneCapabilities2KHR* pCapabilities, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDisplayPlaneCapabilities2KHR( m_physicalDevice, reinterpret_cast<const VkDisplayPlaneInfo2KHR*>( pDisplayPlaneInfo ), reinterpret_cast<VkDisplayPlaneCapabilities2KHR*>( pCapabilities ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DisplayPlaneCapabilities2KHR>::type PhysicalDevice::getDisplayPlaneCapabilities2KHR( const DisplayPlaneInfo2KHR & displayPlaneInfo, Dispatch const &d ) const
  {
    vk::DisplayPlaneCapabilities2KHR capabilities;
    Result result = static_cast<Result>( d.vkGetDisplayPlaneCapabilities2KHR( m_physicalDevice, reinterpret_cast<const VkDisplayPlaneInfo2KHR*>( &displayPlaneInfo ), reinterpret_cast<VkDisplayPlaneCapabilities2KHR*>( &capabilities ) ) );
    return createResultValue( result, capabilities, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlaneCapabilities2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayPlaneCapabilitiesKHR( vk::DisplayModeKHR mode, uint32_t planeIndex, vk::DisplayPlaneCapabilitiesKHR* pCapabilities, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDisplayPlaneCapabilitiesKHR( m_physicalDevice, static_cast<VkDisplayModeKHR>( mode ), planeIndex, reinterpret_cast<VkDisplayPlaneCapabilitiesKHR*>( pCapabilities ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DisplayPlaneCapabilitiesKHR>::type PhysicalDevice::getDisplayPlaneCapabilitiesKHR( vk::DisplayModeKHR mode, uint32_t planeIndex, Dispatch const &d ) const
  {
    vk::DisplayPlaneCapabilitiesKHR capabilities;
    Result result = static_cast<Result>( d.vkGetDisplayPlaneCapabilitiesKHR( m_physicalDevice, static_cast<VkDisplayModeKHR>( mode ), planeIndex, reinterpret_cast<VkDisplayPlaneCapabilitiesKHR*>( &capabilities ) ) );
    return createResultValue( result, capabilities, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlaneCapabilitiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayPlaneSupportedDisplaysKHR( uint32_t planeIndex, uint32_t* pDisplayCount, vk::DisplayKHR* pDisplays, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetDisplayPlaneSupportedDisplaysKHR( m_physicalDevice, planeIndex, pDisplayCount, reinterpret_cast<VkDisplayKHR*>( pDisplays ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayKHR,Allocator>>::type PhysicalDevice::getDisplayPlaneSupportedDisplaysKHR( uint32_t planeIndex, Dispatch const &d ) const
  {
    std::vector<DisplayKHR,Allocator> displays;
    uint32_t displayCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetDisplayPlaneSupportedDisplaysKHR( m_physicalDevice, planeIndex, &displayCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && displayCount )
      {
        displays.resize( displayCount );
        result = static_cast<Result>( d.vkGetDisplayPlaneSupportedDisplaysKHR( m_physicalDevice, planeIndex, &displayCount, reinterpret_cast<VkDisplayKHR*>( displays.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( displayCount <= displays.size() );
      displays.resize( displayCount );
    }
    return createResultValue( result, displays, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlaneSupportedDisplaysKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayKHR,Allocator>>::type PhysicalDevice::getDisplayPlaneSupportedDisplaysKHR( uint32_t planeIndex, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DisplayKHR,Allocator> displays( vectorAllocator );
    uint32_t displayCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetDisplayPlaneSupportedDisplaysKHR( m_physicalDevice, planeIndex, &displayCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && displayCount )
      {
        displays.resize( displayCount );
        result = static_cast<Result>( d.vkGetDisplayPlaneSupportedDisplaysKHR( m_physicalDevice, planeIndex, &displayCount, reinterpret_cast<VkDisplayKHR*>( displays.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( displayCount <= displays.size() );
      displays.resize( displayCount );
    }
    return createResultValue( result, displays, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlaneSupportedDisplaysKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getCalibrateableTimeDomainsEXT( uint32_t* pTimeDomainCount, vk::TimeDomainEXT* pTimeDomains, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( m_physicalDevice, pTimeDomainCount, reinterpret_cast<VkTimeDomainEXT*>( pTimeDomains ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<TimeDomainEXT,Allocator>>::type PhysicalDevice::getCalibrateableTimeDomainsEXT(Dispatch const &d ) const
  {
    std::vector<TimeDomainEXT,Allocator> timeDomains;
    uint32_t timeDomainCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( m_physicalDevice, &timeDomainCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && timeDomainCount )
      {
        timeDomains.resize( timeDomainCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( m_physicalDevice, &timeDomainCount, reinterpret_cast<VkTimeDomainEXT*>( timeDomains.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( timeDomainCount <= timeDomains.size() );
      timeDomains.resize( timeDomainCount );
    }
    return createResultValue( result, timeDomains, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getCalibrateableTimeDomainsEXT" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<TimeDomainEXT,Allocator>>::type PhysicalDevice::getCalibrateableTimeDomainsEXT(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<TimeDomainEXT,Allocator> timeDomains( vectorAllocator );
    uint32_t timeDomainCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( m_physicalDevice, &timeDomainCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && timeDomainCount )
      {
        timeDomains.resize( timeDomainCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( m_physicalDevice, &timeDomainCount, reinterpret_cast<VkTimeDomainEXT*>( timeDomains.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( timeDomainCount <= timeDomains.size() );
      timeDomains.resize( timeDomainCount );
    }
    return createResultValue( result, timeDomains, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getCalibrateableTimeDomainsEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getCooperativeMatrixPropertiesNV( uint32_t* pPropertyCount, vk::CooperativeMatrixPropertiesNV* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( m_physicalDevice, pPropertyCount, reinterpret_cast<VkCooperativeMatrixPropertiesNV*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<CooperativeMatrixPropertiesNV,Allocator>>::type PhysicalDevice::getCooperativeMatrixPropertiesNV(Dispatch const &d ) const
  {
    std::vector<CooperativeMatrixPropertiesNV,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( m_physicalDevice, &propertyCount, reinterpret_cast<VkCooperativeMatrixPropertiesNV*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getCooperativeMatrixPropertiesNV" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<CooperativeMatrixPropertiesNV,Allocator>>::type PhysicalDevice::getCooperativeMatrixPropertiesNV(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<CooperativeMatrixPropertiesNV,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( m_physicalDevice, &propertyCount, reinterpret_cast<VkCooperativeMatrixPropertiesNV*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getCooperativeMatrixPropertiesNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayPlaneProperties2KHR( uint32_t* pPropertyCount, vk::DisplayPlaneProperties2KHR* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlaneProperties2KHR( m_physicalDevice, pPropertyCount, reinterpret_cast<VkDisplayPlaneProperties2KHR*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayPlaneProperties2KHR,Allocator>>::type PhysicalDevice::getDisplayPlaneProperties2KHR(Dispatch const &d ) const
  {
    std::vector<DisplayPlaneProperties2KHR,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlaneProperties2KHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlaneProperties2KHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayPlaneProperties2KHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlaneProperties2KHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayPlaneProperties2KHR,Allocator>>::type PhysicalDevice::getDisplayPlaneProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DisplayPlaneProperties2KHR,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlaneProperties2KHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlaneProperties2KHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayPlaneProperties2KHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlaneProperties2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayPlanePropertiesKHR( uint32_t* pPropertyCount, vk::DisplayPlanePropertiesKHR* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlanePropertiesKHR( m_physicalDevice, pPropertyCount, reinterpret_cast<VkDisplayPlanePropertiesKHR*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayPlanePropertiesKHR,Allocator>>::type PhysicalDevice::getDisplayPlanePropertiesKHR(Dispatch const &d ) const
  {
    std::vector<DisplayPlanePropertiesKHR,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlanePropertiesKHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlanePropertiesKHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayPlanePropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlanePropertiesKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayPlanePropertiesKHR,Allocator>>::type PhysicalDevice::getDisplayPlanePropertiesKHR(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DisplayPlanePropertiesKHR,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlanePropertiesKHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPlanePropertiesKHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayPlanePropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPlanePropertiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayProperties2KHR( uint32_t* pPropertyCount, vk::DisplayProperties2KHR* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceDisplayProperties2KHR( m_physicalDevice, pPropertyCount, reinterpret_cast<VkDisplayProperties2KHR*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayProperties2KHR,Allocator>>::type PhysicalDevice::getDisplayProperties2KHR(Dispatch const &d ) const
  {
    std::vector<DisplayProperties2KHR,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayProperties2KHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayProperties2KHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayProperties2KHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayProperties2KHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayProperties2KHR,Allocator>>::type PhysicalDevice::getDisplayProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DisplayProperties2KHR,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayProperties2KHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayProperties2KHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayProperties2KHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayProperties2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getDisplayPropertiesKHR( uint32_t* pPropertyCount, vk::DisplayPropertiesKHR* pProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceDisplayPropertiesKHR( m_physicalDevice, pPropertyCount, reinterpret_cast<VkDisplayPropertiesKHR*>( pProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayPropertiesKHR,Allocator>>::type PhysicalDevice::getDisplayPropertiesKHR(Dispatch const &d ) const
  {
    std::vector<DisplayPropertiesKHR,Allocator> properties;
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPropertiesKHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPropertiesKHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayPropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPropertiesKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<DisplayPropertiesKHR,Allocator>>::type PhysicalDevice::getDisplayPropertiesKHR(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<DisplayPropertiesKHR,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPropertiesKHR( m_physicalDevice, &propertyCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && propertyCount )
      {
        properties.resize( propertyCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceDisplayPropertiesKHR( m_physicalDevice, &propertyCount, reinterpret_cast<VkDisplayPropertiesKHR*>( properties.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( propertyCount <= properties.size() );
      properties.resize( propertyCount );
    }
    return createResultValue( result, properties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getDisplayPropertiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getExternalBufferProperties( const vk::PhysicalDeviceExternalBufferInfo* pExternalBufferInfo, vk::ExternalBufferProperties* pExternalBufferProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceExternalBufferProperties( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalBufferInfo*>( pExternalBufferInfo ), reinterpret_cast<VkExternalBufferProperties*>( pExternalBufferProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::ExternalBufferProperties PhysicalDevice::getExternalBufferProperties( const PhysicalDeviceExternalBufferInfo & externalBufferInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::ExternalBufferProperties externalBufferProperties;
    d.vkGetPhysicalDeviceExternalBufferProperties( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalBufferInfo*>( &externalBufferInfo ), reinterpret_cast<VkExternalBufferProperties*>( &externalBufferProperties ) );
    return externalBufferProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getExternalBufferPropertiesKHR( const vk::PhysicalDeviceExternalBufferInfo* pExternalBufferInfo, vk::ExternalBufferProperties* pExternalBufferProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceExternalBufferPropertiesKHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalBufferInfo*>( pExternalBufferInfo ), reinterpret_cast<VkExternalBufferProperties*>( pExternalBufferProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::ExternalBufferProperties PhysicalDevice::getExternalBufferPropertiesKHR( const PhysicalDeviceExternalBufferInfo & externalBufferInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::ExternalBufferProperties externalBufferProperties;
    d.vkGetPhysicalDeviceExternalBufferPropertiesKHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalBufferInfo*>( &externalBufferInfo ), reinterpret_cast<VkExternalBufferProperties*>( &externalBufferProperties ) );
    return externalBufferProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getExternalFenceProperties( const vk::PhysicalDeviceExternalFenceInfo* pExternalFenceInfo, vk::ExternalFenceProperties* pExternalFenceProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceExternalFenceProperties( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalFenceInfo*>( pExternalFenceInfo ), reinterpret_cast<VkExternalFenceProperties*>( pExternalFenceProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::ExternalFenceProperties PhysicalDevice::getExternalFenceProperties( const PhysicalDeviceExternalFenceInfo & externalFenceInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::ExternalFenceProperties externalFenceProperties;
    d.vkGetPhysicalDeviceExternalFenceProperties( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalFenceInfo*>( &externalFenceInfo ), reinterpret_cast<VkExternalFenceProperties*>( &externalFenceProperties ) );
    return externalFenceProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getExternalFencePropertiesKHR( const vk::PhysicalDeviceExternalFenceInfo* pExternalFenceInfo, vk::ExternalFenceProperties* pExternalFenceProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceExternalFencePropertiesKHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalFenceInfo*>( pExternalFenceInfo ), reinterpret_cast<VkExternalFenceProperties*>( pExternalFenceProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::ExternalFenceProperties PhysicalDevice::getExternalFencePropertiesKHR( const PhysicalDeviceExternalFenceInfo & externalFenceInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::ExternalFenceProperties externalFenceProperties;
    d.vkGetPhysicalDeviceExternalFencePropertiesKHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalFenceInfo*>( &externalFenceInfo ), reinterpret_cast<VkExternalFenceProperties*>( &externalFenceProperties ) );
    return externalFenceProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getExternalImageFormatPropertiesNV( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, vk::ExternalMemoryHandleTypeFlagsNV externalHandleType, vk::ExternalImageFormatPropertiesNV* pExternalImageFormatProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceExternalImageFormatPropertiesNV( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkImageTiling>( tiling ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageCreateFlags>( flags ), static_cast<VkExternalMemoryHandleTypeFlagsNV>( externalHandleType ), reinterpret_cast<VkExternalImageFormatPropertiesNV*>( pExternalImageFormatProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ExternalImageFormatPropertiesNV>::type PhysicalDevice::getExternalImageFormatPropertiesNV( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, vk::ExternalMemoryHandleTypeFlagsNV externalHandleType, Dispatch const &d ) const
  {
    vk::ExternalImageFormatPropertiesNV externalImageFormatProperties;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceExternalImageFormatPropertiesNV( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkImageTiling>( tiling ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageCreateFlags>( flags ), static_cast<VkExternalMemoryHandleTypeFlagsNV>( externalHandleType ), reinterpret_cast<VkExternalImageFormatPropertiesNV*>( &externalImageFormatProperties ) ) );
    return createResultValue( result, externalImageFormatProperties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getExternalImageFormatPropertiesNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getExternalSemaphoreProperties( const vk::PhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, vk::ExternalSemaphoreProperties* pExternalSemaphoreProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceExternalSemaphoreProperties( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalSemaphoreInfo*>( pExternalSemaphoreInfo ), reinterpret_cast<VkExternalSemaphoreProperties*>( pExternalSemaphoreProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::ExternalSemaphoreProperties PhysicalDevice::getExternalSemaphoreProperties( const PhysicalDeviceExternalSemaphoreInfo & externalSemaphoreInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::ExternalSemaphoreProperties externalSemaphoreProperties;
    d.vkGetPhysicalDeviceExternalSemaphoreProperties( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalSemaphoreInfo*>( &externalSemaphoreInfo ), reinterpret_cast<VkExternalSemaphoreProperties*>( &externalSemaphoreProperties ) );
    return externalSemaphoreProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getExternalSemaphorePropertiesKHR( const vk::PhysicalDeviceExternalSemaphoreInfo* pExternalSemaphoreInfo, vk::ExternalSemaphoreProperties* pExternalSemaphoreProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceExternalSemaphorePropertiesKHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalSemaphoreInfo*>( pExternalSemaphoreInfo ), reinterpret_cast<VkExternalSemaphoreProperties*>( pExternalSemaphoreProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::ExternalSemaphoreProperties PhysicalDevice::getExternalSemaphorePropertiesKHR( const PhysicalDeviceExternalSemaphoreInfo & externalSemaphoreInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::ExternalSemaphoreProperties externalSemaphoreProperties;
    d.vkGetPhysicalDeviceExternalSemaphorePropertiesKHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceExternalSemaphoreInfo*>( &externalSemaphoreInfo ), reinterpret_cast<VkExternalSemaphoreProperties*>( &externalSemaphoreProperties ) );
    return externalSemaphoreProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getFeatures( vk::PhysicalDeviceFeatures* pFeatures, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceFeatures( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures*>( pFeatures ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceFeatures PhysicalDevice::getFeatures(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceFeatures features;
    d.vkGetPhysicalDeviceFeatures( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures*>( &features ) );
    return features;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getFeatures2( vk::PhysicalDeviceFeatures2* pFeatures, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceFeatures2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures2*>( pFeatures ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceFeatures2 PhysicalDevice::getFeatures2(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceFeatures2 features;
    d.vkGetPhysicalDeviceFeatures2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures2*>( &features ) );
    return features;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getFeatures2(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::PhysicalDeviceFeatures2& features = structureChain.template get<vk::PhysicalDeviceFeatures2>();
    d.vkGetPhysicalDeviceFeatures2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures2*>( &features ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getFeatures2KHR( vk::PhysicalDeviceFeatures2* pFeatures, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceFeatures2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures2*>( pFeatures ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceFeatures2 PhysicalDevice::getFeatures2KHR(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceFeatures2 features;
    d.vkGetPhysicalDeviceFeatures2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures2*>( &features ) );
    return features;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getFeatures2KHR(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::PhysicalDeviceFeatures2& features = structureChain.template get<vk::PhysicalDeviceFeatures2>();
    d.vkGetPhysicalDeviceFeatures2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceFeatures2*>( &features ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getFormatProperties( vk::Format format, vk::FormatProperties* pFormatProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties*>( pFormatProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::FormatProperties PhysicalDevice::getFormatProperties( vk::Format format, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::FormatProperties formatProperties;
    d.vkGetPhysicalDeviceFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties*>( &formatProperties ) );
    return formatProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getFormatProperties2( vk::Format format, vk::FormatProperties2* pFormatProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceFormatProperties2( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties2*>( pFormatProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::FormatProperties2 PhysicalDevice::getFormatProperties2( vk::Format format, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::FormatProperties2 formatProperties;
    d.vkGetPhysicalDeviceFormatProperties2( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties2*>( &formatProperties ) );
    return formatProperties;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getFormatProperties2( vk::Format format, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::FormatProperties2& formatProperties = structureChain.template get<vk::FormatProperties2>();
    d.vkGetPhysicalDeviceFormatProperties2( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties2*>( &formatProperties ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getFormatProperties2KHR( vk::Format format, vk::FormatProperties2* pFormatProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceFormatProperties2KHR( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties2*>( pFormatProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::FormatProperties2 PhysicalDevice::getFormatProperties2KHR( vk::Format format, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::FormatProperties2 formatProperties;
    d.vkGetPhysicalDeviceFormatProperties2KHR( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties2*>( &formatProperties ) );
    return formatProperties;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getFormatProperties2KHR( vk::Format format, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::FormatProperties2& formatProperties = structureChain.template get<vk::FormatProperties2>();
    d.vkGetPhysicalDeviceFormatProperties2KHR( m_physicalDevice, static_cast<VkFormat>( format ), reinterpret_cast<VkFormatProperties2*>( &formatProperties ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getGeneratedCommandsPropertiesNVX( vk::DeviceGeneratedCommandsFeaturesNVX* pFeatures, vk::DeviceGeneratedCommandsLimitsNVX* pLimits, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX( m_physicalDevice, reinterpret_cast<VkDeviceGeneratedCommandsFeaturesNVX*>( pFeatures ), reinterpret_cast<VkDeviceGeneratedCommandsLimitsNVX*>( pLimits ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::DeviceGeneratedCommandsLimitsNVX PhysicalDevice::getGeneratedCommandsPropertiesNVX( DeviceGeneratedCommandsFeaturesNVX & features, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::DeviceGeneratedCommandsLimitsNVX limits;
    d.vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX( m_physicalDevice, reinterpret_cast<VkDeviceGeneratedCommandsFeaturesNVX*>( &features ), reinterpret_cast<VkDeviceGeneratedCommandsLimitsNVX*>( &limits ) );
    return limits;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getImageFormatProperties( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, vk::ImageFormatProperties* pImageFormatProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkImageTiling>( tiling ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageCreateFlags>( flags ), reinterpret_cast<VkImageFormatProperties*>( pImageFormatProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ImageFormatProperties>::type PhysicalDevice::getImageFormatProperties( vk::Format format, vk::ImageType type, vk::ImageTiling tiling, vk::ImageUsageFlags usage, vk::ImageCreateFlags flags, Dispatch const &d ) const
  {
    vk::ImageFormatProperties imageFormatProperties;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkImageTiling>( tiling ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageCreateFlags>( flags ), reinterpret_cast<VkImageFormatProperties*>( &imageFormatProperties ) ) );
    return createResultValue( result, imageFormatProperties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getImageFormatProperties" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getImageFormatProperties2( const vk::PhysicalDeviceImageFormatInfo2* pImageFormatInfo, vk::ImageFormatProperties2* pImageFormatProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>( pImageFormatInfo ), reinterpret_cast<VkImageFormatProperties2*>( pImageFormatProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ImageFormatProperties2>::type PhysicalDevice::getImageFormatProperties2( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d ) const
  {
    vk::ImageFormatProperties2 imageFormatProperties;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>( &imageFormatInfo ), reinterpret_cast<VkImageFormatProperties2*>( &imageFormatProperties ) ) );
    return createResultValue( result, imageFormatProperties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getImageFormatProperties2" );
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<StructureChain<X, Y, Z...>>::type PhysicalDevice::getImageFormatProperties2( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d ) const
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::ImageFormatProperties2& imageFormatProperties = structureChain.template get<vk::ImageFormatProperties2>();
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>( &imageFormatInfo ), reinterpret_cast<VkImageFormatProperties2*>( &imageFormatProperties ) ) );
    return createResultValue( result, structureChain, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getImageFormatProperties2" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getImageFormatProperties2KHR( const vk::PhysicalDeviceImageFormatInfo2* pImageFormatInfo, vk::ImageFormatProperties2* pImageFormatProperties, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>( pImageFormatInfo ), reinterpret_cast<VkImageFormatProperties2*>( pImageFormatProperties ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::ImageFormatProperties2>::type PhysicalDevice::getImageFormatProperties2KHR( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d ) const
  {
    vk::ImageFormatProperties2 imageFormatProperties;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>( &imageFormatInfo ), reinterpret_cast<VkImageFormatProperties2*>( &imageFormatProperties ) ) );
    return createResultValue( result, imageFormatProperties, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getImageFormatProperties2KHR" );
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<StructureChain<X, Y, Z...>>::type PhysicalDevice::getImageFormatProperties2KHR( const PhysicalDeviceImageFormatInfo2 & imageFormatInfo, Dispatch const &d ) const
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::ImageFormatProperties2& imageFormatProperties = structureChain.template get<vk::ImageFormatProperties2>();
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceImageFormatInfo2*>( &imageFormatInfo ), reinterpret_cast<VkImageFormatProperties2*>( &imageFormatProperties ) ) );
    return createResultValue( result, structureChain, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getImageFormatProperties2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getMemoryProperties( vk::PhysicalDeviceMemoryProperties* pMemoryProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceMemoryProperties( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties*>( pMemoryProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceMemoryProperties PhysicalDevice::getMemoryProperties(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceMemoryProperties memoryProperties;
    d.vkGetPhysicalDeviceMemoryProperties( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties*>( &memoryProperties ) );
    return memoryProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getMemoryProperties2( vk::PhysicalDeviceMemoryProperties2* pMemoryProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceMemoryProperties2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>( pMemoryProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceMemoryProperties2 PhysicalDevice::getMemoryProperties2(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceMemoryProperties2 memoryProperties;
    d.vkGetPhysicalDeviceMemoryProperties2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>( &memoryProperties ) );
    return memoryProperties;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getMemoryProperties2(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::PhysicalDeviceMemoryProperties2& memoryProperties = structureChain.template get<vk::PhysicalDeviceMemoryProperties2>();
    d.vkGetPhysicalDeviceMemoryProperties2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>( &memoryProperties ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getMemoryProperties2KHR( vk::PhysicalDeviceMemoryProperties2* pMemoryProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceMemoryProperties2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>( pMemoryProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceMemoryProperties2 PhysicalDevice::getMemoryProperties2KHR(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceMemoryProperties2 memoryProperties;
    d.vkGetPhysicalDeviceMemoryProperties2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>( &memoryProperties ) );
    return memoryProperties;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getMemoryProperties2KHR(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::PhysicalDeviceMemoryProperties2& memoryProperties = structureChain.template get<vk::PhysicalDeviceMemoryProperties2>();
    d.vkGetPhysicalDeviceMemoryProperties2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceMemoryProperties2*>( &memoryProperties ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getMultisamplePropertiesEXT( vk::SampleCountFlagBits samples, vk::MultisamplePropertiesEXT* pMultisampleProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceMultisamplePropertiesEXT( m_physicalDevice, static_cast<VkSampleCountFlagBits>( samples ), reinterpret_cast<VkMultisamplePropertiesEXT*>( pMultisampleProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::MultisamplePropertiesEXT PhysicalDevice::getMultisamplePropertiesEXT( vk::SampleCountFlagBits samples, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::MultisamplePropertiesEXT multisampleProperties;
    d.vkGetPhysicalDeviceMultisamplePropertiesEXT( m_physicalDevice, static_cast<VkSampleCountFlagBits>( samples ), reinterpret_cast<VkMultisamplePropertiesEXT*>( &multisampleProperties ) );
    return multisampleProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getPresentRectanglesKHR( vk::SurfaceKHR surface, uint32_t* pRectCount, vk::Rect2D* pRects, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDevicePresentRectanglesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), pRectCount, reinterpret_cast<VkRect2D*>( pRects ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Rect2D,Allocator>>::type PhysicalDevice::getPresentRectanglesKHR( vk::SurfaceKHR surface, Dispatch const &d ) const
  {
    std::vector<Rect2D,Allocator> rects;
    uint32_t rectCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDevicePresentRectanglesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &rectCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && rectCount )
      {
        rects.resize( rectCount );
        result = static_cast<Result>( d.vkGetPhysicalDevicePresentRectanglesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &rectCount, reinterpret_cast<VkRect2D*>( rects.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( rectCount <= rects.size() );
      rects.resize( rectCount );
    }
    return createResultValue( result, rects, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getPresentRectanglesKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<Rect2D,Allocator>>::type PhysicalDevice::getPresentRectanglesKHR( vk::SurfaceKHR surface, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<Rect2D,Allocator> rects( vectorAllocator );
    uint32_t rectCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDevicePresentRectanglesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &rectCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && rectCount )
      {
        rects.resize( rectCount );
        result = static_cast<Result>( d.vkGetPhysicalDevicePresentRectanglesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &rectCount, reinterpret_cast<VkRect2D*>( rects.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( rectCount <= rects.size() );
      rects.resize( rectCount );
    }
    return createResultValue( result, rects, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getPresentRectanglesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getProperties( vk::PhysicalDeviceProperties* pProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceProperties( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties*>( pProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceProperties PhysicalDevice::getProperties(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceProperties properties;
    d.vkGetPhysicalDeviceProperties( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties*>( &properties ) );
    return properties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getProperties2( vk::PhysicalDeviceProperties2* pProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceProperties2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties2*>( pProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceProperties2 PhysicalDevice::getProperties2(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceProperties2 properties;
    d.vkGetPhysicalDeviceProperties2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties2*>( &properties ) );
    return properties;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getProperties2(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::PhysicalDeviceProperties2& properties = structureChain.template get<vk::PhysicalDeviceProperties2>();
    d.vkGetPhysicalDeviceProperties2( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties2*>( &properties ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getProperties2KHR( vk::PhysicalDeviceProperties2* pProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceProperties2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties2*>( pProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE vk::PhysicalDeviceProperties2 PhysicalDevice::getProperties2KHR(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    vk::PhysicalDeviceProperties2 properties;
    d.vkGetPhysicalDeviceProperties2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties2*>( &properties ) );
    return properties;
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE StructureChain<X, Y, Z...> PhysicalDevice::getProperties2KHR(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::PhysicalDeviceProperties2& properties = structureChain.template get<vk::PhysicalDeviceProperties2>();
    d.vkGetPhysicalDeviceProperties2KHR( m_physicalDevice, reinterpret_cast<VkPhysicalDeviceProperties2*>( &properties ) );
    return structureChain;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getQueueFamilyProperties( uint32_t* pQueueFamilyPropertyCount, vk::QueueFamilyProperties* pQueueFamilyProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceQueueFamilyProperties( m_physicalDevice, pQueueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties*>( pQueueFamilyProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<QueueFamilyProperties,Allocator> PhysicalDevice::getQueueFamilyProperties(Dispatch const &d ) const
  {
    std::vector<QueueFamilyProperties,Allocator> queueFamilyProperties;
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<QueueFamilyProperties,Allocator> PhysicalDevice::getQueueFamilyProperties(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<QueueFamilyProperties,Allocator> queueFamilyProperties( vectorAllocator );
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getQueueFamilyProperties2( uint32_t* pQueueFamilyPropertyCount, vk::QueueFamilyProperties2* pQueueFamilyProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, pQueueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( pQueueFamilyProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<QueueFamilyProperties2,Allocator> PhysicalDevice::getQueueFamilyProperties2(Dispatch const &d ) const
  {
    std::vector<QueueFamilyProperties2,Allocator> queueFamilyProperties;
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<QueueFamilyProperties2,Allocator> PhysicalDevice::getQueueFamilyProperties2(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<QueueFamilyProperties2,Allocator> queueFamilyProperties( vectorAllocator );
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
  template<typename StructureChain, typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<StructureChain,Allocator> PhysicalDevice::getQueueFamilyProperties2(Dispatch const &d ) const
  {
    std::vector<StructureChain,Allocator> queueFamilyProperties;
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
  template<typename StructureChain, typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<StructureChain,Allocator> PhysicalDevice::getQueueFamilyProperties2(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<StructureChain,Allocator> queueFamilyProperties( vectorAllocator );
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getQueueFamilyProperties2KHR( uint32_t* pQueueFamilyPropertyCount, vk::QueueFamilyProperties2* pQueueFamilyProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, pQueueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( pQueueFamilyProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<QueueFamilyProperties2,Allocator> PhysicalDevice::getQueueFamilyProperties2KHR(Dispatch const &d ) const
  {
    std::vector<QueueFamilyProperties2,Allocator> queueFamilyProperties;
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<QueueFamilyProperties2,Allocator> PhysicalDevice::getQueueFamilyProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<QueueFamilyProperties2,Allocator> queueFamilyProperties( vectorAllocator );
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
  template<typename StructureChain, typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<StructureChain,Allocator> PhysicalDevice::getQueueFamilyProperties2KHR(Dispatch const &d ) const
  {
    std::vector<StructureChain,Allocator> queueFamilyProperties;
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
  template<typename StructureChain, typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<StructureChain,Allocator> PhysicalDevice::getQueueFamilyProperties2KHR(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<StructureChain,Allocator> queueFamilyProperties( vectorAllocator );
    uint32_t queueFamilyPropertyCount;
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, nullptr );
    queueFamilyProperties.resize( queueFamilyPropertyCount );
    d.vkGetPhysicalDeviceQueueFamilyProperties2KHR( m_physicalDevice, &queueFamilyPropertyCount, reinterpret_cast<VkQueueFamilyProperties2*>( queueFamilyProperties.data() ) );
    return queueFamilyProperties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getSparseImageFormatProperties( vk::Format format, vk::ImageType type, vk::SampleCountFlagBits samples, vk::ImageUsageFlags usage, vk::ImageTiling tiling, uint32_t* pPropertyCount, vk::SparseImageFormatProperties* pProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceSparseImageFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkSampleCountFlagBits>( samples ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageTiling>( tiling ), pPropertyCount, reinterpret_cast<VkSparseImageFormatProperties*>( pProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageFormatProperties,Allocator> PhysicalDevice::getSparseImageFormatProperties( vk::Format format, vk::ImageType type, vk::SampleCountFlagBits samples, vk::ImageUsageFlags usage, vk::ImageTiling tiling, Dispatch const &d ) const
  {
    std::vector<SparseImageFormatProperties,Allocator> properties;
    uint32_t propertyCount;
    d.vkGetPhysicalDeviceSparseImageFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkSampleCountFlagBits>( samples ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageTiling>( tiling ), &propertyCount, nullptr );
    properties.resize( propertyCount );
    d.vkGetPhysicalDeviceSparseImageFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkSampleCountFlagBits>( samples ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageTiling>( tiling ), &propertyCount, reinterpret_cast<VkSparseImageFormatProperties*>( properties.data() ) );
    return properties;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageFormatProperties,Allocator> PhysicalDevice::getSparseImageFormatProperties( vk::Format format, vk::ImageType type, vk::SampleCountFlagBits samples, vk::ImageUsageFlags usage, vk::ImageTiling tiling, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SparseImageFormatProperties,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    d.vkGetPhysicalDeviceSparseImageFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkSampleCountFlagBits>( samples ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageTiling>( tiling ), &propertyCount, nullptr );
    properties.resize( propertyCount );
    d.vkGetPhysicalDeviceSparseImageFormatProperties( m_physicalDevice, static_cast<VkFormat>( format ), static_cast<VkImageType>( type ), static_cast<VkSampleCountFlagBits>( samples ), static_cast<VkImageUsageFlags>( usage ), static_cast<VkImageTiling>( tiling ), &propertyCount, reinterpret_cast<VkSparseImageFormatProperties*>( properties.data() ) );
    return properties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getSparseImageFormatProperties2( const vk::PhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, vk::SparseImageFormatProperties2* pProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceSparseImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( pFormatInfo ), pPropertyCount, reinterpret_cast<VkSparseImageFormatProperties2*>( pProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageFormatProperties2,Allocator> PhysicalDevice::getSparseImageFormatProperties2( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Dispatch const &d ) const
  {
    std::vector<SparseImageFormatProperties2,Allocator> properties;
    uint32_t propertyCount;
    d.vkGetPhysicalDeviceSparseImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, nullptr );
    properties.resize( propertyCount );
    d.vkGetPhysicalDeviceSparseImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, reinterpret_cast<VkSparseImageFormatProperties2*>( properties.data() ) );
    return properties;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageFormatProperties2,Allocator> PhysicalDevice::getSparseImageFormatProperties2( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SparseImageFormatProperties2,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    d.vkGetPhysicalDeviceSparseImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, nullptr );
    properties.resize( propertyCount );
    d.vkGetPhysicalDeviceSparseImageFormatProperties2( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, reinterpret_cast<VkSparseImageFormatProperties2*>( properties.data() ) );
    return properties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void PhysicalDevice::getSparseImageFormatProperties2KHR( const vk::PhysicalDeviceSparseImageFormatInfo2* pFormatInfo, uint32_t* pPropertyCount, vk::SparseImageFormatProperties2* pProperties, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetPhysicalDeviceSparseImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( pFormatInfo ), pPropertyCount, reinterpret_cast<VkSparseImageFormatProperties2*>( pProperties ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageFormatProperties2,Allocator> PhysicalDevice::getSparseImageFormatProperties2KHR( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Dispatch const &d ) const
  {
    std::vector<SparseImageFormatProperties2,Allocator> properties;
    uint32_t propertyCount;
    d.vkGetPhysicalDeviceSparseImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, nullptr );
    properties.resize( propertyCount );
    d.vkGetPhysicalDeviceSparseImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, reinterpret_cast<VkSparseImageFormatProperties2*>( properties.data() ) );
    return properties;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<SparseImageFormatProperties2,Allocator> PhysicalDevice::getSparseImageFormatProperties2KHR( const PhysicalDeviceSparseImageFormatInfo2 & formatInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SparseImageFormatProperties2,Allocator> properties( vectorAllocator );
    uint32_t propertyCount;
    d.vkGetPhysicalDeviceSparseImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, nullptr );
    properties.resize( propertyCount );
    d.vkGetPhysicalDeviceSparseImageFormatProperties2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSparseImageFormatInfo2*>( &formatInfo ), &propertyCount, reinterpret_cast<VkSparseImageFormatProperties2*>( properties.data() ) );
    return properties;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSupportedFramebufferMixedSamplesCombinationsNV( uint32_t* pCombinationCount, vk::FramebufferMixedSamplesCombinationNV* pCombinations, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( m_physicalDevice, pCombinationCount, reinterpret_cast<VkFramebufferMixedSamplesCombinationNV*>( pCombinations ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<FramebufferMixedSamplesCombinationNV,Allocator>>::type PhysicalDevice::getSupportedFramebufferMixedSamplesCombinationsNV(Dispatch const &d ) const
  {
    std::vector<FramebufferMixedSamplesCombinationNV,Allocator> combinations;
    uint32_t combinationCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( m_physicalDevice, &combinationCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && combinationCount )
      {
        combinations.resize( combinationCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( m_physicalDevice, &combinationCount, reinterpret_cast<VkFramebufferMixedSamplesCombinationNV*>( combinations.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( combinationCount <= combinations.size() );
      combinations.resize( combinationCount );
    }
    return createResultValue( result, combinations, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSupportedFramebufferMixedSamplesCombinationsNV" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<FramebufferMixedSamplesCombinationNV,Allocator>>::type PhysicalDevice::getSupportedFramebufferMixedSamplesCombinationsNV(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<FramebufferMixedSamplesCombinationNV,Allocator> combinations( vectorAllocator );
    uint32_t combinationCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( m_physicalDevice, &combinationCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && combinationCount )
      {
        combinations.resize( combinationCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( m_physicalDevice, &combinationCount, reinterpret_cast<VkFramebufferMixedSamplesCombinationNV*>( combinations.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( combinationCount <= combinations.size() );
      combinations.resize( combinationCount );
    }
    return createResultValue( result, combinations, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSupportedFramebufferMixedSamplesCombinationsNV" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfaceCapabilities2EXT( vk::SurfaceKHR surface, vk::SurfaceCapabilities2EXT* pSurfaceCapabilities, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfaceCapabilities2EXT( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkSurfaceCapabilities2EXT*>( pSurfaceCapabilities ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceCapabilities2EXT>::type PhysicalDevice::getSurfaceCapabilities2EXT( vk::SurfaceKHR surface, Dispatch const &d ) const
  {
    vk::SurfaceCapabilities2EXT surfaceCapabilities;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceCapabilities2EXT( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkSurfaceCapabilities2EXT*>( &surfaceCapabilities ) ) );
    return createResultValue( result, surfaceCapabilities, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceCapabilities2EXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfaceCapabilities2KHR( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, vk::SurfaceCapabilities2KHR* pSurfaceCapabilities, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfaceCapabilities2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( pSurfaceInfo ), reinterpret_cast<VkSurfaceCapabilities2KHR*>( pSurfaceCapabilities ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceCapabilities2KHR>::type PhysicalDevice::getSurfaceCapabilities2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d ) const
  {
    vk::SurfaceCapabilities2KHR surfaceCapabilities;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceCapabilities2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), reinterpret_cast<VkSurfaceCapabilities2KHR*>( &surfaceCapabilities ) ) );
    return createResultValue( result, surfaceCapabilities, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceCapabilities2KHR" );
  }
  template<typename X, typename Y, typename ...Z, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<StructureChain<X, Y, Z...>>::type PhysicalDevice::getSurfaceCapabilities2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d ) const
  {
    StructureChain<X, Y, Z...> structureChain;
    vk::SurfaceCapabilities2KHR& surfaceCapabilities = structureChain.template get<vk::SurfaceCapabilities2KHR>();
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceCapabilities2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), reinterpret_cast<VkSurfaceCapabilities2KHR*>( &surfaceCapabilities ) ) );
    return createResultValue( result, structureChain, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceCapabilities2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfaceCapabilitiesKHR( vk::SurfaceKHR surface, vk::SurfaceCapabilitiesKHR* pSurfaceCapabilities, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfaceCapabilitiesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkSurfaceCapabilitiesKHR*>( pSurfaceCapabilities ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::SurfaceCapabilitiesKHR>::type PhysicalDevice::getSurfaceCapabilitiesKHR( vk::SurfaceKHR surface, Dispatch const &d ) const
  {
    vk::SurfaceCapabilitiesKHR surfaceCapabilities;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceCapabilitiesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkSurfaceCapabilitiesKHR*>( &surfaceCapabilities ) ) );
    return createResultValue( result, surfaceCapabilities, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceCapabilitiesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfaceFormats2KHR( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, uint32_t* pSurfaceFormatCount, vk::SurfaceFormat2KHR* pSurfaceFormats, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormats2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( pSurfaceInfo ), pSurfaceFormatCount, reinterpret_cast<VkSurfaceFormat2KHR*>( pSurfaceFormats ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<SurfaceFormat2KHR,Allocator>>::type PhysicalDevice::getSurfaceFormats2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d ) const
  {
    std::vector<SurfaceFormat2KHR,Allocator> surfaceFormats;
    uint32_t surfaceFormatCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormats2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &surfaceFormatCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && surfaceFormatCount )
      {
        surfaceFormats.resize( surfaceFormatCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormats2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &surfaceFormatCount, reinterpret_cast<VkSurfaceFormat2KHR*>( surfaceFormats.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( surfaceFormatCount <= surfaceFormats.size() );
      surfaceFormats.resize( surfaceFormatCount );
    }
    return createResultValue( result, surfaceFormats, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceFormats2KHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<SurfaceFormat2KHR,Allocator>>::type PhysicalDevice::getSurfaceFormats2KHR( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SurfaceFormat2KHR,Allocator> surfaceFormats( vectorAllocator );
    uint32_t surfaceFormatCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormats2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &surfaceFormatCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && surfaceFormatCount )
      {
        surfaceFormats.resize( surfaceFormatCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormats2KHR( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &surfaceFormatCount, reinterpret_cast<VkSurfaceFormat2KHR*>( surfaceFormats.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( surfaceFormatCount <= surfaceFormats.size() );
      surfaceFormats.resize( surfaceFormatCount );
    }
    return createResultValue( result, surfaceFormats, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceFormats2KHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfaceFormatsKHR( vk::SurfaceKHR surface, uint32_t* pSurfaceFormatCount, vk::SurfaceFormatKHR* pSurfaceFormats, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormatsKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), pSurfaceFormatCount, reinterpret_cast<VkSurfaceFormatKHR*>( pSurfaceFormats ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<SurfaceFormatKHR,Allocator>>::type PhysicalDevice::getSurfaceFormatsKHR( vk::SurfaceKHR surface, Dispatch const &d ) const
  {
    std::vector<SurfaceFormatKHR,Allocator> surfaceFormats;
    uint32_t surfaceFormatCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormatsKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &surfaceFormatCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && surfaceFormatCount )
      {
        surfaceFormats.resize( surfaceFormatCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormatsKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &surfaceFormatCount, reinterpret_cast<VkSurfaceFormatKHR*>( surfaceFormats.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( surfaceFormatCount <= surfaceFormats.size() );
      surfaceFormats.resize( surfaceFormatCount );
    }
    return createResultValue( result, surfaceFormats, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceFormatsKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<SurfaceFormatKHR,Allocator>>::type PhysicalDevice::getSurfaceFormatsKHR( vk::SurfaceKHR surface, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<SurfaceFormatKHR,Allocator> surfaceFormats( vectorAllocator );
    uint32_t surfaceFormatCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormatsKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &surfaceFormatCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && surfaceFormatCount )
      {
        surfaceFormats.resize( surfaceFormatCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceFormatsKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &surfaceFormatCount, reinterpret_cast<VkSurfaceFormatKHR*>( surfaceFormats.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( surfaceFormatCount <= surfaceFormats.size() );
      surfaceFormats.resize( surfaceFormatCount );
    }
    return createResultValue( result, surfaceFormats, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceFormatsKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfacePresentModes2EXT( const vk::PhysicalDeviceSurfaceInfo2KHR* pSurfaceInfo, uint32_t* pPresentModeCount, vk::PresentModeKHR* pPresentModes, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModes2EXT( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( pSurfaceInfo ), pPresentModeCount, reinterpret_cast<VkPresentModeKHR*>( pPresentModes ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type PhysicalDevice::getSurfacePresentModes2EXT( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Dispatch const &d ) const
  {
    std::vector<PresentModeKHR,Allocator> presentModes;
    uint32_t presentModeCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModes2EXT( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &presentModeCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && presentModeCount )
      {
        presentModes.resize( presentModeCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModes2EXT( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &presentModeCount, reinterpret_cast<VkPresentModeKHR*>( presentModes.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( presentModeCount <= presentModes.size() );
      presentModes.resize( presentModeCount );
    }
    return createResultValue( result, presentModes, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfacePresentModes2EXT" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type PhysicalDevice::getSurfacePresentModes2EXT( const PhysicalDeviceSurfaceInfo2KHR & surfaceInfo, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PresentModeKHR,Allocator> presentModes( vectorAllocator );
    uint32_t presentModeCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModes2EXT( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &presentModeCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && presentModeCount )
      {
        presentModes.resize( presentModeCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModes2EXT( m_physicalDevice, reinterpret_cast<const VkPhysicalDeviceSurfaceInfo2KHR*>( &surfaceInfo ), &presentModeCount, reinterpret_cast<VkPresentModeKHR*>( presentModes.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( presentModeCount <= presentModes.size() );
      presentModes.resize( presentModeCount );
    }
    return createResultValue( result, presentModes, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfacePresentModes2EXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfacePresentModesKHR( vk::SurfaceKHR surface, uint32_t* pPresentModeCount, vk::PresentModeKHR* pPresentModes, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), pPresentModeCount, reinterpret_cast<VkPresentModeKHR*>( pPresentModes ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type PhysicalDevice::getSurfacePresentModesKHR( vk::SurfaceKHR surface, Dispatch const &d ) const
  {
    std::vector<PresentModeKHR,Allocator> presentModes;
    uint32_t presentModeCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &presentModeCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && presentModeCount )
      {
        presentModes.resize( presentModeCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &presentModeCount, reinterpret_cast<VkPresentModeKHR*>( presentModes.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( presentModeCount <= presentModes.size() );
      presentModes.resize( presentModeCount );
    }
    return createResultValue( result, presentModes, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfacePresentModesKHR" );
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE typename ResultValueType<std::vector<PresentModeKHR,Allocator>>::type PhysicalDevice::getSurfacePresentModesKHR( vk::SurfaceKHR surface, Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<PresentModeKHR,Allocator> presentModes( vectorAllocator );
    uint32_t presentModeCount;
    Result result;
    do
    {
      result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &presentModeCount, nullptr ) );
      if ( ( result == Result::eSuccess ) && presentModeCount )
      {
        presentModes.resize( presentModeCount );
        result = static_cast<Result>( d.vkGetPhysicalDeviceSurfacePresentModesKHR( m_physicalDevice, static_cast<VkSurfaceKHR>( surface ), &presentModeCount, reinterpret_cast<VkPresentModeKHR*>( presentModes.data() ) ) );
      }
    } while ( result == Result::eIncomplete );
    if ( result == Result::eSuccess )
    {
      VULKAN_HPP_ASSERT( presentModeCount <= presentModes.size() );
      presentModes.resize( presentModeCount );
    }
    return createResultValue( result, presentModes, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfacePresentModesKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getSurfaceSupportKHR( uint32_t queueFamilyIndex, vk::SurfaceKHR surface, vk::Bool32* pSupported, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetPhysicalDeviceSurfaceSupportKHR( m_physicalDevice, queueFamilyIndex, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkBool32*>( pSupported ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::Bool32>::type PhysicalDevice::getSurfaceSupportKHR( uint32_t queueFamilyIndex, vk::SurfaceKHR surface, Dispatch const &d ) const
  {
    vk::Bool32 supported;
    Result result = static_cast<Result>( d.vkGetPhysicalDeviceSurfaceSupportKHR( m_physicalDevice, queueFamilyIndex, static_cast<VkSurfaceKHR>( surface ), reinterpret_cast<VkBool32*>( &supported ) ) );
    return createResultValue( result, supported, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getSurfaceSupportKHR" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_WAYLAND_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getWaylandPresentationSupportKHR( uint32_t queueFamilyIndex, struct wl_display* display, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return static_cast<Bool32>( d.vkGetPhysicalDeviceWaylandPresentationSupportKHR( m_physicalDevice, queueFamilyIndex, display ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getWaylandPresentationSupportKHR( uint32_t queueFamilyIndex, struct wl_display & display, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetPhysicalDeviceWaylandPresentationSupportKHR( m_physicalDevice, queueFamilyIndex, &display );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/

#ifdef VK_USE_PLATFORM_WIN32_KHR
#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getWin32PresentationSupportKHR( uint32_t queueFamilyIndex, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return static_cast<Bool32>( d.vkGetPhysicalDeviceWin32PresentationSupportKHR( m_physicalDevice, queueFamilyIndex ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getWin32PresentationSupportKHR( uint32_t queueFamilyIndex, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetPhysicalDeviceWin32PresentationSupportKHR( m_physicalDevice, queueFamilyIndex );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_WIN32_KHR*/

#ifdef VK_USE_PLATFORM_XCB_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getXcbPresentationSupportKHR( uint32_t queueFamilyIndex, xcb_connection_t* connection, xcb_visualid_t visual_id, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return static_cast<Bool32>( d.vkGetPhysicalDeviceXcbPresentationSupportKHR( m_physicalDevice, queueFamilyIndex, connection, visual_id ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getXcbPresentationSupportKHR( uint32_t queueFamilyIndex, xcb_connection_t & connection, xcb_visualid_t visual_id, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetPhysicalDeviceXcbPresentationSupportKHR( m_physicalDevice, queueFamilyIndex, &connection, visual_id );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XCB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_KHR
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getXlibPresentationSupportKHR( uint32_t queueFamilyIndex, Display* dpy, VisualID visualID, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    return static_cast<Bool32>( d.vkGetPhysicalDeviceXlibPresentationSupportKHR( m_physicalDevice, queueFamilyIndex, dpy, visualID ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Bool32 PhysicalDevice::getXlibPresentationSupportKHR( uint32_t queueFamilyIndex, Display & dpy, VisualID visualID, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    return d.vkGetPhysicalDeviceXlibPresentationSupportKHR( m_physicalDevice, queueFamilyIndex, &dpy, visualID );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_KHR*/

#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::getRandROutputDisplayEXT( Display* dpy, RROutput rrOutput, vk::DisplayKHR* pDisplay, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkGetRandROutputDisplayEXT( m_physicalDevice, dpy, rrOutput, reinterpret_cast<VkDisplayKHR*>( pDisplay ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<vk::DisplayKHR>::type PhysicalDevice::getRandROutputDisplayEXT( Display & dpy, RROutput rrOutput, Dispatch const &d ) const
  {
    vk::DisplayKHR display;
    Result result = static_cast<Result>( d.vkGetRandROutputDisplayEXT( m_physicalDevice, &dpy, rrOutput, reinterpret_cast<VkDisplayKHR*>( &display ) ) );
    return createResultValue( result, display, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::getRandROutputDisplayEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result PhysicalDevice::releaseDisplayEXT( vk::DisplayKHR display, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkReleaseDisplayEXT( m_physicalDevice, static_cast<VkDisplayKHR>( display ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type PhysicalDevice::releaseDisplayEXT( vk::DisplayKHR display, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkReleaseDisplayEXT( m_physicalDevice, static_cast<VkDisplayKHR>( display ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::PhysicalDevice::releaseDisplayEXT" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Queue::getCheckpointDataNV( uint32_t* pCheckpointDataCount, vk::CheckpointDataNV* pCheckpointData, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkGetQueueCheckpointDataNV( m_queue, pCheckpointDataCount, reinterpret_cast<VkCheckpointDataNV*>( pCheckpointData ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<CheckpointDataNV,Allocator> Queue::getCheckpointDataNV(Dispatch const &d ) const
  {
    std::vector<CheckpointDataNV,Allocator> checkpointData;
    uint32_t checkpointDataCount;
    d.vkGetQueueCheckpointDataNV( m_queue, &checkpointDataCount, nullptr );
    checkpointData.resize( checkpointDataCount );
    d.vkGetQueueCheckpointDataNV( m_queue, &checkpointDataCount, reinterpret_cast<VkCheckpointDataNV*>( checkpointData.data() ) );
    return checkpointData;
  }
  template<typename Allocator, typename Dispatch>
  VULKAN_HPP_INLINE std::vector<CheckpointDataNV,Allocator> Queue::getCheckpointDataNV(Allocator const& vectorAllocator, Dispatch const &d ) const
  {
    std::vector<CheckpointDataNV,Allocator> checkpointData( vectorAllocator );
    uint32_t checkpointDataCount;
    d.vkGetQueueCheckpointDataNV( m_queue, &checkpointDataCount, nullptr );
    checkpointData.resize( checkpointDataCount );
    d.vkGetQueueCheckpointDataNV( m_queue, &checkpointDataCount, reinterpret_cast<VkCheckpointDataNV*>( checkpointData.data() ) );
    return checkpointData;
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Queue::beginDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkQueueBeginDebugUtilsLabelEXT( m_queue, reinterpret_cast<const VkDebugUtilsLabelEXT*>( pLabelInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Queue::beginDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkQueueBeginDebugUtilsLabelEXT( m_queue, reinterpret_cast<const VkDebugUtilsLabelEXT*>( &labelInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Queue::bindSparse( uint32_t bindInfoCount, const vk::BindSparseInfo* pBindInfo, vk::Fence fence, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkQueueBindSparse( m_queue, bindInfoCount, reinterpret_cast<const VkBindSparseInfo*>( pBindInfo ), static_cast<VkFence>( fence ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Queue::bindSparse( ArrayProxy<const vk::BindSparseInfo> bindInfo, vk::Fence fence, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkQueueBindSparse( m_queue, bindInfo.size() , reinterpret_cast<const VkBindSparseInfo*>( bindInfo.data() ), static_cast<VkFence>( fence ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Queue::bindSparse" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Queue::endDebugUtilsLabelEXT(Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkQueueEndDebugUtilsLabelEXT( m_queue );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Queue::endDebugUtilsLabelEXT(Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkQueueEndDebugUtilsLabelEXT( m_queue );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE void Queue::insertDebugUtilsLabelEXT( const vk::DebugUtilsLabelEXT* pLabelInfo, Dispatch const &d) const VULKAN_HPP_NOEXCEPT
  {
    d.vkQueueInsertDebugUtilsLabelEXT( m_queue, reinterpret_cast<const VkDebugUtilsLabelEXT*>( pLabelInfo ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE void Queue::insertDebugUtilsLabelEXT( const DebugUtilsLabelEXT & labelInfo, Dispatch const &d ) const VULKAN_HPP_NOEXCEPT
  {
    d.vkQueueInsertDebugUtilsLabelEXT( m_queue, reinterpret_cast<const VkDebugUtilsLabelEXT*>( &labelInfo ) );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Queue::presentKHR( const vk::PresentInfoKHR* pPresentInfo, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkQueuePresentKHR( m_queue, reinterpret_cast<const VkPresentInfoKHR*>( pPresentInfo ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Queue::presentKHR( const PresentInfoKHR & presentInfo, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkQueuePresentKHR( m_queue, reinterpret_cast<const VkPresentInfoKHR*>( &presentInfo ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Queue::presentKHR", { Result::eSuccess, Result::eSuboptimalKHR } );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Queue::setPerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkQueueSetPerformanceConfigurationINTEL( m_queue, static_cast<VkPerformanceConfigurationINTEL>( configuration ) ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Queue::setPerformanceConfigurationINTEL( vk::PerformanceConfigurationINTEL configuration, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkQueueSetPerformanceConfigurationINTEL( m_queue, static_cast<VkPerformanceConfigurationINTEL>( configuration ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Queue::setPerformanceConfigurationINTEL" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Queue::submit( uint32_t submitCount, const vk::SubmitInfo* pSubmits, vk::Fence fence, Dispatch const &d) const
  {
    return static_cast<Result>( d.vkQueueSubmit( m_queue, submitCount, reinterpret_cast<const VkSubmitInfo*>( pSubmits ), static_cast<VkFence>( fence ) ) );
  }
#ifndef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Queue::submit( ArrayProxy<const vk::SubmitInfo> submits, vk::Fence fence, Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkQueueSubmit( m_queue, submits.size() , reinterpret_cast<const VkSubmitInfo*>( submits.data() ), static_cast<VkFence>( fence ) ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Queue::submit" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VULKAN_HPP_DISABLE_ENHANCED_MODE
  template<typename Dispatch>
  VULKAN_HPP_INLINE Result Queue::waitIdle(Dispatch const &d) const
  {
    return static_cast<Result>( d.vkQueueWaitIdle( m_queue ) );
  }
#else
  template<typename Dispatch>
  VULKAN_HPP_INLINE ResultValueType<void>::type Queue::waitIdle(Dispatch const &d ) const
  {
    Result result = static_cast<Result>( d.vkQueueWaitIdle( m_queue ) );
    return createResultValue( result, VULKAN_HPP_NAMESPACE_STRING"::Queue::waitIdle" );
  }
#endif /*VULKAN_HPP_DISABLE_ENHANCED_MODE*/

#ifdef VK_USE_PLATFORM_ANDROID_KHR
  template <> struct isStructureChainValid<AndroidHardwareBufferPropertiesANDROID, AndroidHardwareBufferFormatPropertiesANDROID>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  template <> struct isStructureChainValid<ImageFormatProperties2, AndroidHardwareBufferUsageANDROID>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
  template <> struct isStructureChainValid<BindBufferMemoryInfo, BindBufferMemoryDeviceGroupInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<BindImageMemoryInfo, BindImageMemoryDeviceGroupInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<BindImageMemoryInfo, BindImageMemorySwapchainInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<BindImageMemoryInfo, BindImagePlaneMemoryInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<BufferCreateInfo, BufferDeviceAddressCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<CommandBufferInheritanceInfo, CommandBufferInheritanceConditionalRenderingInfoEXT>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<SubmitInfo, D3D12FenceSubmitInfoKHR>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  template <> struct isStructureChainValid<InstanceCreateInfo, DebugReportCallbackCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<InstanceCreateInfo, DebugUtilsMessengerCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<BufferCreateInfo, DedicatedAllocationBufferCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, DedicatedAllocationImageCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<MemoryAllocateInfo, DedicatedAllocationMemoryAllocateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DescriptorPoolCreateInfo, DescriptorPoolInlineUniformBlockCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DescriptorSetLayoutCreateInfo, DescriptorSetLayoutBindingFlagsCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DescriptorSetAllocateInfo, DescriptorSetVariableDescriptorCountAllocateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DescriptorSetLayoutSupport, DescriptorSetVariableDescriptorCountLayoutSupportEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<BindSparseInfo, DeviceGroupBindSparseInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<CommandBufferBeginInfo, DeviceGroupCommandBufferBeginInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, DeviceGroupDeviceCreateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<PresentInfoKHR, DeviceGroupPresentInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<RenderPassBeginInfo, DeviceGroupRenderPassBeginInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<SubmitInfo, DeviceGroupSubmitInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<SwapchainCreateInfoKHR, DeviceGroupSwapchainCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, DeviceMemoryOverallocationCreateInfoAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceQueueCreateInfo, DeviceQueueGlobalPriorityCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<SurfaceCapabilities2KHR, DisplayNativeHdrSurfaceCapabilitiesAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<PresentInfoKHR, DisplayPresentInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<FormatProperties2, DrmFormatModifierPropertiesListEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<FenceCreateInfo, ExportFenceCreateInfo>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<FenceCreateInfo, ExportFenceWin32HandleInfoKHR>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  template <> struct isStructureChainValid<MemoryAllocateInfo, ExportMemoryAllocateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<MemoryAllocateInfo, ExportMemoryAllocateInfoNV>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<MemoryAllocateInfo, ExportMemoryWin32HandleInfoKHR>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<MemoryAllocateInfo, ExportMemoryWin32HandleInfoNV>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  template <> struct isStructureChainValid<SemaphoreCreateInfo, ExportSemaphoreCreateInfo>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<SemaphoreCreateInfo, ExportSemaphoreWin32HandleInfoKHR>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  template <> struct isStructureChainValid<ImageCreateInfo, ExternalFormatANDROID>{ enum { value = true }; };
  template <> struct isStructureChainValid<SamplerYcbcrConversionCreateInfo, ExternalFormatANDROID>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
  template <> struct isStructureChainValid<ImageFormatProperties2, ExternalImageFormatProperties>{ enum { value = true }; };
  template <> struct isStructureChainValid<BufferCreateInfo, ExternalMemoryBufferCreateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, ExternalMemoryImageCreateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, ExternalMemoryImageCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageFormatProperties2, FilterCubicImageViewImageFormatPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<FramebufferCreateInfo, FramebufferAttachmentsCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, ImageDrmFormatModifierExplicitCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, ImageDrmFormatModifierListCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, ImageFormatListCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<SwapchainCreateInfoKHR, ImageFormatListCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceImageFormatInfo2, ImageFormatListCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageMemoryRequirementsInfo2, ImagePlaneMemoryRequirementsInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, ImageStencilUsageCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceImageFormatInfo2, ImageStencilUsageCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageCreateInfo, ImageSwapchainCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageViewCreateInfo, ImageViewASTCDecodeModeEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageViewCreateInfo, ImageViewUsageCreateInfo>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_ANDROID_KHR
  template <> struct isStructureChainValid<MemoryAllocateInfo, ImportAndroidHardwareBufferInfoANDROID>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
  template <> struct isStructureChainValid<MemoryAllocateInfo, ImportMemoryFdInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<MemoryAllocateInfo, ImportMemoryHostPointerInfoEXT>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<MemoryAllocateInfo, ImportMemoryWin32HandleInfoKHR>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<MemoryAllocateInfo, ImportMemoryWin32HandleInfoNV>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  template <> struct isStructureChainValid<MemoryAllocateInfo, MemoryAllocateFlagsInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<MemoryAllocateInfo, MemoryDedicatedAllocateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<MemoryRequirements2, MemoryDedicatedRequirements>{ enum { value = true }; };
  template <> struct isStructureChainValid<MemoryAllocateInfo, MemoryPriorityAllocateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDevice16BitStorageFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDevice16BitStorageFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDevice8BitStorageFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDevice8BitStorageFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceASTCDecodeFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceASTCDecodeFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceBlendOperationAdvancedFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceBlendOperationAdvancedFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceBlendOperationAdvancedPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceBufferDeviceAddressFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceBufferDeviceAddressFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceCoherentMemoryFeaturesAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceCoherentMemoryFeaturesAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceComputeShaderDerivativesFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceComputeShaderDerivativesFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceConditionalRenderingFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceConditionalRenderingFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceConservativeRasterizationPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceCooperativeMatrixFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceCooperativeMatrixFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceCooperativeMatrixPropertiesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceCornerSampledImageFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceCornerSampledImageFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceCoverageReductionModeFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceCoverageReductionModeFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceDedicatedAllocationImageAliasingFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceDepthClipEnableFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceDepthClipEnableFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceDepthStencilResolvePropertiesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceDescriptorIndexingFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceDescriptorIndexingFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceDescriptorIndexingPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceDiscardRectanglePropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceDriverPropertiesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceExclusiveScissorFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceExclusiveScissorFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceImageFormatInfo2, PhysicalDeviceExternalImageFormatInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceExternalMemoryHostPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceFeatures2>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceFloatControlsPropertiesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceFragmentDensityMapFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceFragmentDensityMapFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceFragmentDensityMapPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceFragmentShaderBarycentricFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceFragmentShaderBarycentricFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceFragmentShaderInterlockFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceFragmentShaderInterlockFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceHostQueryResetFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceHostQueryResetFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceIDProperties>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceImageFormatInfo2, PhysicalDeviceImageDrmFormatModifierInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceImageFormatInfo2, PhysicalDeviceImageViewImageFormatInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceImagelessFramebufferFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceImagelessFramebufferFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceIndexTypeUint8FeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceIndexTypeUint8FeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceInlineUniformBlockFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceInlineUniformBlockFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceInlineUniformBlockPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceLineRasterizationFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceLineRasterizationFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceLineRasterizationPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceMaintenance3Properties>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceMemoryProperties2, PhysicalDeviceMemoryBudgetPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceMemoryPriorityFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceMemoryPriorityFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceMeshShaderFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceMeshShaderFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceMeshShaderPropertiesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceMultiviewFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceMultiviewFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceMultiviewPerViewAttributesPropertiesNVX>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceMultiviewProperties>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDevicePCIBusInfoPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDevicePipelineExecutablePropertiesFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDevicePipelineExecutablePropertiesFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDevicePointClippingProperties>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceProtectedMemoryFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceProtectedMemoryFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceProtectedMemoryProperties>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDevicePushDescriptorPropertiesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceRayTracingPropertiesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceRepresentativeFragmentTestFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceRepresentativeFragmentTestFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceSampleLocationsPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceSamplerFilterMinmaxPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceSamplerYcbcrConversionFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceSamplerYcbcrConversionFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceScalarBlockLayoutFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceScalarBlockLayoutFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderAtomicInt64FeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderAtomicInt64FeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderClockFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderClockFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceShaderCoreProperties2AMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceShaderCorePropertiesAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderDemoteToHelperInvocationFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderDrawParametersFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderDrawParametersFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderFloat16Int8FeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderFloat16Int8FeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderImageFootprintFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderImageFootprintFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderIntegerFunctions2FeaturesINTEL>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderSMBuiltinsFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderSMBuiltinsFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceShaderSMBuiltinsPropertiesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShaderSubgroupExtendedTypesFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceShadingRateImageFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceShadingRateImageFeaturesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceShadingRateImagePropertiesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceSubgroupProperties>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceSubgroupSizeControlFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceSubgroupSizeControlFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceSubgroupSizeControlPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceTexelBufferAlignmentFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceTexelBufferAlignmentFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceTexelBufferAlignmentPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceTextureCompressionASTCHDRFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceTimelineSemaphoreFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceTimelineSemaphoreFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceTimelineSemaphorePropertiesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceTransformFeedbackFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceTransformFeedbackFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceTransformFeedbackPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceUniformBufferStandardLayoutFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceVariablePointersFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceVariablePointersFeatures>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceVertexAttributeDivisorFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceVertexAttributeDivisorFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceProperties2, PhysicalDeviceVertexAttributeDivisorPropertiesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceVulkanMemoryModelFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceVulkanMemoryModelFeaturesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceFeatures2, PhysicalDeviceYcbcrImageArraysFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<DeviceCreateInfo, PhysicalDeviceYcbcrImageArraysFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineColorBlendStateCreateInfo, PipelineColorBlendAdvancedStateCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<GraphicsPipelineCreateInfo, PipelineCompilerControlCreateInfoAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<ComputePipelineCreateInfo, PipelineCompilerControlCreateInfoAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineMultisampleStateCreateInfo, PipelineCoverageModulationStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineMultisampleStateCreateInfo, PipelineCoverageReductionStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineMultisampleStateCreateInfo, PipelineCoverageToColorStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<GraphicsPipelineCreateInfo, PipelineCreationFeedbackCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<ComputePipelineCreateInfo, PipelineCreationFeedbackCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<RayTracingPipelineCreateInfoNV, PipelineCreationFeedbackCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<GraphicsPipelineCreateInfo, PipelineDiscardRectangleStateCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineRasterizationStateCreateInfo, PipelineRasterizationConservativeStateCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineRasterizationStateCreateInfo, PipelineRasterizationDepthClipStateCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineRasterizationStateCreateInfo, PipelineRasterizationLineStateCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineRasterizationStateCreateInfo, PipelineRasterizationStateRasterizationOrderAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineRasterizationStateCreateInfo, PipelineRasterizationStateStreamCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<GraphicsPipelineCreateInfo, PipelineRepresentativeFragmentTestStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineMultisampleStateCreateInfo, PipelineSampleLocationsStateCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineShaderStageCreateInfo, PipelineShaderStageRequiredSubgroupSizeCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineTessellationStateCreateInfo, PipelineTessellationDomainOriginStateCreateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineVertexInputStateCreateInfo, PipelineVertexInputDivisorStateCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineViewportStateCreateInfo, PipelineViewportCoarseSampleOrderStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineViewportStateCreateInfo, PipelineViewportExclusiveScissorStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineViewportStateCreateInfo, PipelineViewportShadingRateImageStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineViewportStateCreateInfo, PipelineViewportSwizzleStateCreateInfoNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<PipelineViewportStateCreateInfo, PipelineViewportWScalingStateCreateInfoNV>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_GGP
  template <> struct isStructureChainValid<PresentInfoKHR, PresentFrameTokenGGP>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_GGP*/
  template <> struct isStructureChainValid<PresentInfoKHR, PresentRegionsKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PresentInfoKHR, PresentTimesInfoGOOGLE>{ enum { value = true }; };
  template <> struct isStructureChainValid<SubmitInfo, ProtectedSubmitInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<QueueFamilyProperties2, QueueFamilyCheckpointPropertiesNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<RenderPassBeginInfo, RenderPassAttachmentBeginInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<RenderPassCreateInfo, RenderPassFragmentDensityMapCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<RenderPassCreateInfo2KHR, RenderPassFragmentDensityMapCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<RenderPassCreateInfo, RenderPassInputAttachmentAspectCreateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<RenderPassCreateInfo, RenderPassMultiviewCreateInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<RenderPassBeginInfo, RenderPassSampleLocationsBeginInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageMemoryBarrier, SampleLocationsInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<SamplerCreateInfo, SamplerReductionModeCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageFormatProperties2, SamplerYcbcrConversionImageFormatProperties>{ enum { value = true }; };
  template <> struct isStructureChainValid<SamplerCreateInfo, SamplerYcbcrConversionInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageViewCreateInfo, SamplerYcbcrConversionInfo>{ enum { value = true }; };
  template <> struct isStructureChainValid<SemaphoreCreateInfo, SemaphoreTypeCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<PhysicalDeviceExternalSemaphoreInfo, SemaphoreTypeCreateInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<ShaderModuleCreateInfo, ShaderModuleValidationCacheCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<SurfaceCapabilities2KHR, SharedPresentSurfaceCapabilitiesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<SubpassDescription2KHR, SubpassDescriptionDepthStencilResolveKHR>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<SurfaceCapabilities2KHR, SurfaceCapabilitiesFullScreenExclusiveEXT>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<PhysicalDeviceSurfaceInfo2KHR, SurfaceFullScreenExclusiveInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<SwapchainCreateInfoKHR, SurfaceFullScreenExclusiveInfoEXT>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<PhysicalDeviceSurfaceInfo2KHR, SurfaceFullScreenExclusiveWin32InfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<SwapchainCreateInfoKHR, SurfaceFullScreenExclusiveWin32InfoEXT>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  template <> struct isStructureChainValid<SurfaceCapabilities2KHR, SurfaceProtectedCapabilitiesKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<SwapchainCreateInfoKHR, SwapchainCounterCreateInfoEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<SwapchainCreateInfoKHR, SwapchainDisplayNativeHdrCreateInfoAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<ImageFormatProperties2, TextureLODGatherFormatPropertiesAMD>{ enum { value = true }; };
  template <> struct isStructureChainValid<SubmitInfo, TimelineSemaphoreSubmitInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<BindSparseInfo, TimelineSemaphoreSubmitInfoKHR>{ enum { value = true }; };
  template <> struct isStructureChainValid<InstanceCreateInfo, ValidationFeaturesEXT>{ enum { value = true }; };
  template <> struct isStructureChainValid<InstanceCreateInfo, ValidationFlagsEXT>{ enum { value = true }; };
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<SubmitInfo, Win32KeyedMutexAcquireReleaseInfoKHR>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
  template <> struct isStructureChainValid<SubmitInfo, Win32KeyedMutexAcquireReleaseInfoNV>{ enum { value = true }; };
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
  template <> struct isStructureChainValid<WriteDescriptorSet, WriteDescriptorSetAccelerationStructureNV>{ enum { value = true }; };
  template <> struct isStructureChainValid<WriteDescriptorSet, WriteDescriptorSetInlineUniformBlockEXT>{ enum { value = true }; };

#if !defined(VULKAN_HPP_ENABLE_DYNAMIC_LOADER_TOOL)
# define VULKAN_HPP_ENABLE_DYNAMIC_LOADER_TOOL  1
#endif

#if VULKAN_HPP_ENABLE_DYNAMIC_LOADER_TOOL
  class DynamicLoader
  {
  public:
#ifdef VULKAN_HPP_NO_EXCEPTIONS
    DynamicLoader() VULKAN_HPP_NOEXCEPT : m_success( false )
#else
    DynamicLoader() : m_success( false )
#endif
    {
#if defined(__linux__)
      m_library = dlopen( "libvulkan.so", RTLD_NOW | RTLD_LOCAL );
#elif defined(__APPLE__)
      m_library = dlopen( "libvulkan.dylib", RTLD_NOW | RTLD_LOCAL );
#elif defined(_WIN32)
      m_library = LoadLibrary( "vulkan-1.dll" );
#else
      assert( false && "unsupported platform" );
#endif

      m_success = m_library != 0;
#ifndef VULKAN_HPP_NO_EXCEPTIONS
      if ( !m_success )
      {
        // NOTE there should be an InitializationFailedError, but msvc insists on the symbol does not exist within the scope of this function.
        throw std::runtime_error( "Failed to load vulkan library!" );
      }
#endif
    }

    ~DynamicLoader() VULKAN_HPP_NOEXCEPT
    {
      if ( m_library )
      {
#if defined(__linux__) || defined(__APPLE__)
        dlclose( m_library );
#elif defined(_WIN32)
        FreeLibrary( m_library );
#endif
      }
    }

    template <typename T>
    T getProcAddress( const char* function ) const VULKAN_HPP_NOEXCEPT
    {
#if defined(__linux__) || defined(__APPLE__)
      return (T)dlsym( m_library, function );
#elif defined(_WIN32)
      return (T)GetProcAddress( m_library, function );
#endif
    }

    bool success() const VULKAN_HPP_NOEXCEPT { return m_success; }

  private:
    bool m_success;
#if defined(__linux__) || defined(__APPLE__)
    void *m_library;
#elif defined(_WIN32)
    HMODULE m_library;
#else
#error unsupported platform
#endif
  };
#endif

  class DispatchLoaderDynamic
  {
  public:
    PFN_vkCreateInstance vkCreateInstance = 0;
    PFN_vkEnumerateInstanceExtensionProperties vkEnumerateInstanceExtensionProperties = 0;
    PFN_vkEnumerateInstanceLayerProperties vkEnumerateInstanceLayerProperties = 0;
    PFN_vkEnumerateInstanceVersion vkEnumerateInstanceVersion = 0;
    PFN_vkBeginCommandBuffer vkBeginCommandBuffer = 0;
    PFN_vkCmdBeginConditionalRenderingEXT vkCmdBeginConditionalRenderingEXT = 0;
    PFN_vkCmdBeginDebugUtilsLabelEXT vkCmdBeginDebugUtilsLabelEXT = 0;
    PFN_vkCmdBeginQuery vkCmdBeginQuery = 0;
    PFN_vkCmdBeginQueryIndexedEXT vkCmdBeginQueryIndexedEXT = 0;
    PFN_vkCmdBeginRenderPass vkCmdBeginRenderPass = 0;
    PFN_vkCmdBeginRenderPass2KHR vkCmdBeginRenderPass2KHR = 0;
    PFN_vkCmdBeginTransformFeedbackEXT vkCmdBeginTransformFeedbackEXT = 0;
    PFN_vkCmdBindDescriptorSets vkCmdBindDescriptorSets = 0;
    PFN_vkCmdBindIndexBuffer vkCmdBindIndexBuffer = 0;
    PFN_vkCmdBindPipeline vkCmdBindPipeline = 0;
    PFN_vkCmdBindShadingRateImageNV vkCmdBindShadingRateImageNV = 0;
    PFN_vkCmdBindTransformFeedbackBuffersEXT vkCmdBindTransformFeedbackBuffersEXT = 0;
    PFN_vkCmdBindVertexBuffers vkCmdBindVertexBuffers = 0;
    PFN_vkCmdBlitImage vkCmdBlitImage = 0;
    PFN_vkCmdBuildAccelerationStructureNV vkCmdBuildAccelerationStructureNV = 0;
    PFN_vkCmdClearAttachments vkCmdClearAttachments = 0;
    PFN_vkCmdClearColorImage vkCmdClearColorImage = 0;
    PFN_vkCmdClearDepthStencilImage vkCmdClearDepthStencilImage = 0;
    PFN_vkCmdCopyAccelerationStructureNV vkCmdCopyAccelerationStructureNV = 0;
    PFN_vkCmdCopyBuffer vkCmdCopyBuffer = 0;
    PFN_vkCmdCopyBufferToImage vkCmdCopyBufferToImage = 0;
    PFN_vkCmdCopyImage vkCmdCopyImage = 0;
    PFN_vkCmdCopyImageToBuffer vkCmdCopyImageToBuffer = 0;
    PFN_vkCmdCopyQueryPoolResults vkCmdCopyQueryPoolResults = 0;
    PFN_vkCmdDebugMarkerBeginEXT vkCmdDebugMarkerBeginEXT = 0;
    PFN_vkCmdDebugMarkerEndEXT vkCmdDebugMarkerEndEXT = 0;
    PFN_vkCmdDebugMarkerInsertEXT vkCmdDebugMarkerInsertEXT = 0;
    PFN_vkCmdDispatch vkCmdDispatch = 0;
    PFN_vkCmdDispatchBase vkCmdDispatchBase = 0;
    PFN_vkCmdDispatchBaseKHR vkCmdDispatchBaseKHR = 0;
    PFN_vkCmdDispatchIndirect vkCmdDispatchIndirect = 0;
    PFN_vkCmdDraw vkCmdDraw = 0;
    PFN_vkCmdDrawIndexed vkCmdDrawIndexed = 0;
    PFN_vkCmdDrawIndexedIndirect vkCmdDrawIndexedIndirect = 0;
    PFN_vkCmdDrawIndexedIndirectCountAMD vkCmdDrawIndexedIndirectCountAMD = 0;
    PFN_vkCmdDrawIndexedIndirectCountKHR vkCmdDrawIndexedIndirectCountKHR = 0;
    PFN_vkCmdDrawIndirect vkCmdDrawIndirect = 0;
    PFN_vkCmdDrawIndirectByteCountEXT vkCmdDrawIndirectByteCountEXT = 0;
    PFN_vkCmdDrawIndirectCountAMD vkCmdDrawIndirectCountAMD = 0;
    PFN_vkCmdDrawIndirectCountKHR vkCmdDrawIndirectCountKHR = 0;
    PFN_vkCmdDrawMeshTasksIndirectCountNV vkCmdDrawMeshTasksIndirectCountNV = 0;
    PFN_vkCmdDrawMeshTasksIndirectNV vkCmdDrawMeshTasksIndirectNV = 0;
    PFN_vkCmdDrawMeshTasksNV vkCmdDrawMeshTasksNV = 0;
    PFN_vkCmdEndConditionalRenderingEXT vkCmdEndConditionalRenderingEXT = 0;
    PFN_vkCmdEndDebugUtilsLabelEXT vkCmdEndDebugUtilsLabelEXT = 0;
    PFN_vkCmdEndQuery vkCmdEndQuery = 0;
    PFN_vkCmdEndQueryIndexedEXT vkCmdEndQueryIndexedEXT = 0;
    PFN_vkCmdEndRenderPass vkCmdEndRenderPass = 0;
    PFN_vkCmdEndRenderPass2KHR vkCmdEndRenderPass2KHR = 0;
    PFN_vkCmdEndTransformFeedbackEXT vkCmdEndTransformFeedbackEXT = 0;
    PFN_vkCmdExecuteCommands vkCmdExecuteCommands = 0;
    PFN_vkCmdFillBuffer vkCmdFillBuffer = 0;
    PFN_vkCmdInsertDebugUtilsLabelEXT vkCmdInsertDebugUtilsLabelEXT = 0;
    PFN_vkCmdNextSubpass vkCmdNextSubpass = 0;
    PFN_vkCmdNextSubpass2KHR vkCmdNextSubpass2KHR = 0;
    PFN_vkCmdPipelineBarrier vkCmdPipelineBarrier = 0;
    PFN_vkCmdProcessCommandsNVX vkCmdProcessCommandsNVX = 0;
    PFN_vkCmdPushConstants vkCmdPushConstants = 0;
    PFN_vkCmdPushDescriptorSetKHR vkCmdPushDescriptorSetKHR = 0;
    PFN_vkCmdPushDescriptorSetWithTemplateKHR vkCmdPushDescriptorSetWithTemplateKHR = 0;
    PFN_vkCmdReserveSpaceForCommandsNVX vkCmdReserveSpaceForCommandsNVX = 0;
    PFN_vkCmdResetEvent vkCmdResetEvent = 0;
    PFN_vkCmdResetQueryPool vkCmdResetQueryPool = 0;
    PFN_vkCmdResolveImage vkCmdResolveImage = 0;
    PFN_vkCmdSetBlendConstants vkCmdSetBlendConstants = 0;
    PFN_vkCmdSetCheckpointNV vkCmdSetCheckpointNV = 0;
    PFN_vkCmdSetCoarseSampleOrderNV vkCmdSetCoarseSampleOrderNV = 0;
    PFN_vkCmdSetDepthBias vkCmdSetDepthBias = 0;
    PFN_vkCmdSetDepthBounds vkCmdSetDepthBounds = 0;
    PFN_vkCmdSetDeviceMask vkCmdSetDeviceMask = 0;
    PFN_vkCmdSetDeviceMaskKHR vkCmdSetDeviceMaskKHR = 0;
    PFN_vkCmdSetDiscardRectangleEXT vkCmdSetDiscardRectangleEXT = 0;
    PFN_vkCmdSetEvent vkCmdSetEvent = 0;
    PFN_vkCmdSetExclusiveScissorNV vkCmdSetExclusiveScissorNV = 0;
    PFN_vkCmdSetLineStippleEXT vkCmdSetLineStippleEXT = 0;
    PFN_vkCmdSetLineWidth vkCmdSetLineWidth = 0;
    PFN_vkCmdSetPerformanceMarkerINTEL vkCmdSetPerformanceMarkerINTEL = 0;
    PFN_vkCmdSetPerformanceOverrideINTEL vkCmdSetPerformanceOverrideINTEL = 0;
    PFN_vkCmdSetPerformanceStreamMarkerINTEL vkCmdSetPerformanceStreamMarkerINTEL = 0;
    PFN_vkCmdSetSampleLocationsEXT vkCmdSetSampleLocationsEXT = 0;
    PFN_vkCmdSetScissor vkCmdSetScissor = 0;
    PFN_vkCmdSetStencilCompareMask vkCmdSetStencilCompareMask = 0;
    PFN_vkCmdSetStencilReference vkCmdSetStencilReference = 0;
    PFN_vkCmdSetStencilWriteMask vkCmdSetStencilWriteMask = 0;
    PFN_vkCmdSetViewport vkCmdSetViewport = 0;
    PFN_vkCmdSetViewportShadingRatePaletteNV vkCmdSetViewportShadingRatePaletteNV = 0;
    PFN_vkCmdSetViewportWScalingNV vkCmdSetViewportWScalingNV = 0;
    PFN_vkCmdTraceRaysNV vkCmdTraceRaysNV = 0;
    PFN_vkCmdUpdateBuffer vkCmdUpdateBuffer = 0;
    PFN_vkCmdWaitEvents vkCmdWaitEvents = 0;
    PFN_vkCmdWriteAccelerationStructuresPropertiesNV vkCmdWriteAccelerationStructuresPropertiesNV = 0;
    PFN_vkCmdWriteBufferMarkerAMD vkCmdWriteBufferMarkerAMD = 0;
    PFN_vkCmdWriteTimestamp vkCmdWriteTimestamp = 0;
    PFN_vkEndCommandBuffer vkEndCommandBuffer = 0;
    PFN_vkResetCommandBuffer vkResetCommandBuffer = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkAcquireFullScreenExclusiveModeEXT vkAcquireFullScreenExclusiveModeEXT = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkAcquireNextImage2KHR vkAcquireNextImage2KHR = 0;
    PFN_vkAcquireNextImageKHR vkAcquireNextImageKHR = 0;
    PFN_vkAcquirePerformanceConfigurationINTEL vkAcquirePerformanceConfigurationINTEL = 0;
    PFN_vkAllocateCommandBuffers vkAllocateCommandBuffers = 0;
    PFN_vkAllocateDescriptorSets vkAllocateDescriptorSets = 0;
    PFN_vkAllocateMemory vkAllocateMemory = 0;
    PFN_vkBindAccelerationStructureMemoryNV vkBindAccelerationStructureMemoryNV = 0;
    PFN_vkBindBufferMemory vkBindBufferMemory = 0;
    PFN_vkBindBufferMemory2 vkBindBufferMemory2 = 0;
    PFN_vkBindBufferMemory2KHR vkBindBufferMemory2KHR = 0;
    PFN_vkBindImageMemory vkBindImageMemory = 0;
    PFN_vkBindImageMemory2 vkBindImageMemory2 = 0;
    PFN_vkBindImageMemory2KHR vkBindImageMemory2KHR = 0;
    PFN_vkCompileDeferredNV vkCompileDeferredNV = 0;
    PFN_vkCreateAccelerationStructureNV vkCreateAccelerationStructureNV = 0;
    PFN_vkCreateBuffer vkCreateBuffer = 0;
    PFN_vkCreateBufferView vkCreateBufferView = 0;
    PFN_vkCreateCommandPool vkCreateCommandPool = 0;
    PFN_vkCreateComputePipelines vkCreateComputePipelines = 0;
    PFN_vkCreateDescriptorPool vkCreateDescriptorPool = 0;
    PFN_vkCreateDescriptorSetLayout vkCreateDescriptorSetLayout = 0;
    PFN_vkCreateDescriptorUpdateTemplate vkCreateDescriptorUpdateTemplate = 0;
    PFN_vkCreateDescriptorUpdateTemplateKHR vkCreateDescriptorUpdateTemplateKHR = 0;
    PFN_vkCreateEvent vkCreateEvent = 0;
    PFN_vkCreateFence vkCreateFence = 0;
    PFN_vkCreateFramebuffer vkCreateFramebuffer = 0;
    PFN_vkCreateGraphicsPipelines vkCreateGraphicsPipelines = 0;
    PFN_vkCreateImage vkCreateImage = 0;
    PFN_vkCreateImageView vkCreateImageView = 0;
    PFN_vkCreateIndirectCommandsLayoutNVX vkCreateIndirectCommandsLayoutNVX = 0;
    PFN_vkCreateObjectTableNVX vkCreateObjectTableNVX = 0;
    PFN_vkCreatePipelineCache vkCreatePipelineCache = 0;
    PFN_vkCreatePipelineLayout vkCreatePipelineLayout = 0;
    PFN_vkCreateQueryPool vkCreateQueryPool = 0;
    PFN_vkCreateRayTracingPipelinesNV vkCreateRayTracingPipelinesNV = 0;
    PFN_vkCreateRenderPass vkCreateRenderPass = 0;
    PFN_vkCreateRenderPass2KHR vkCreateRenderPass2KHR = 0;
    PFN_vkCreateSampler vkCreateSampler = 0;
    PFN_vkCreateSamplerYcbcrConversion vkCreateSamplerYcbcrConversion = 0;
    PFN_vkCreateSamplerYcbcrConversionKHR vkCreateSamplerYcbcrConversionKHR = 0;
    PFN_vkCreateSemaphore vkCreateSemaphore = 0;
    PFN_vkCreateShaderModule vkCreateShaderModule = 0;
    PFN_vkCreateSharedSwapchainsKHR vkCreateSharedSwapchainsKHR = 0;
    PFN_vkCreateSwapchainKHR vkCreateSwapchainKHR = 0;
    PFN_vkCreateValidationCacheEXT vkCreateValidationCacheEXT = 0;
    PFN_vkDebugMarkerSetObjectNameEXT vkDebugMarkerSetObjectNameEXT = 0;
    PFN_vkDebugMarkerSetObjectTagEXT vkDebugMarkerSetObjectTagEXT = 0;
    PFN_vkDestroyAccelerationStructureNV vkDestroyAccelerationStructureNV = 0;
    PFN_vkDestroyBuffer vkDestroyBuffer = 0;
    PFN_vkDestroyBufferView vkDestroyBufferView = 0;
    PFN_vkDestroyCommandPool vkDestroyCommandPool = 0;
    PFN_vkDestroyDescriptorPool vkDestroyDescriptorPool = 0;
    PFN_vkDestroyDescriptorSetLayout vkDestroyDescriptorSetLayout = 0;
    PFN_vkDestroyDescriptorUpdateTemplate vkDestroyDescriptorUpdateTemplate = 0;
    PFN_vkDestroyDescriptorUpdateTemplateKHR vkDestroyDescriptorUpdateTemplateKHR = 0;
    PFN_vkDestroyDevice vkDestroyDevice = 0;
    PFN_vkDestroyEvent vkDestroyEvent = 0;
    PFN_vkDestroyFence vkDestroyFence = 0;
    PFN_vkDestroyFramebuffer vkDestroyFramebuffer = 0;
    PFN_vkDestroyImage vkDestroyImage = 0;
    PFN_vkDestroyImageView vkDestroyImageView = 0;
    PFN_vkDestroyIndirectCommandsLayoutNVX vkDestroyIndirectCommandsLayoutNVX = 0;
    PFN_vkDestroyObjectTableNVX vkDestroyObjectTableNVX = 0;
    PFN_vkDestroyPipeline vkDestroyPipeline = 0;
    PFN_vkDestroyPipelineCache vkDestroyPipelineCache = 0;
    PFN_vkDestroyPipelineLayout vkDestroyPipelineLayout = 0;
    PFN_vkDestroyQueryPool vkDestroyQueryPool = 0;
    PFN_vkDestroyRenderPass vkDestroyRenderPass = 0;
    PFN_vkDestroySampler vkDestroySampler = 0;
    PFN_vkDestroySamplerYcbcrConversion vkDestroySamplerYcbcrConversion = 0;
    PFN_vkDestroySamplerYcbcrConversionKHR vkDestroySamplerYcbcrConversionKHR = 0;
    PFN_vkDestroySemaphore vkDestroySemaphore = 0;
    PFN_vkDestroyShaderModule vkDestroyShaderModule = 0;
    PFN_vkDestroySwapchainKHR vkDestroySwapchainKHR = 0;
    PFN_vkDestroyValidationCacheEXT vkDestroyValidationCacheEXT = 0;
    PFN_vkDeviceWaitIdle vkDeviceWaitIdle = 0;
    PFN_vkDisplayPowerControlEXT vkDisplayPowerControlEXT = 0;
    PFN_vkFlushMappedMemoryRanges vkFlushMappedMemoryRanges = 0;
    PFN_vkFreeCommandBuffers vkFreeCommandBuffers = 0;
    PFN_vkFreeDescriptorSets vkFreeDescriptorSets = 0;
    PFN_vkFreeMemory vkFreeMemory = 0;
    PFN_vkGetAccelerationStructureHandleNV vkGetAccelerationStructureHandleNV = 0;
    PFN_vkGetAccelerationStructureMemoryRequirementsNV vkGetAccelerationStructureMemoryRequirementsNV = 0;
#ifdef VK_USE_PLATFORM_ANDROID_KHR
    PFN_vkGetAndroidHardwareBufferPropertiesANDROID vkGetAndroidHardwareBufferPropertiesANDROID = 0;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
    PFN_vkGetBufferDeviceAddressEXT vkGetBufferDeviceAddressEXT = 0;
    PFN_vkGetBufferMemoryRequirements vkGetBufferMemoryRequirements = 0;
    PFN_vkGetBufferMemoryRequirements2 vkGetBufferMemoryRequirements2 = 0;
    PFN_vkGetBufferMemoryRequirements2KHR vkGetBufferMemoryRequirements2KHR = 0;
    PFN_vkGetCalibratedTimestampsEXT vkGetCalibratedTimestampsEXT = 0;
    PFN_vkGetDescriptorSetLayoutSupport vkGetDescriptorSetLayoutSupport = 0;
    PFN_vkGetDescriptorSetLayoutSupportKHR vkGetDescriptorSetLayoutSupportKHR = 0;
    PFN_vkGetDeviceGroupPeerMemoryFeatures vkGetDeviceGroupPeerMemoryFeatures = 0;
    PFN_vkGetDeviceGroupPeerMemoryFeaturesKHR vkGetDeviceGroupPeerMemoryFeaturesKHR = 0;
    PFN_vkGetDeviceGroupPresentCapabilitiesKHR vkGetDeviceGroupPresentCapabilitiesKHR = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetDeviceGroupSurfacePresentModes2EXT vkGetDeviceGroupSurfacePresentModes2EXT = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkGetDeviceGroupSurfacePresentModesKHR vkGetDeviceGroupSurfacePresentModesKHR = 0;
    PFN_vkGetDeviceMemoryCommitment vkGetDeviceMemoryCommitment = 0;
    PFN_vkGetDeviceProcAddr vkGetDeviceProcAddr = 0;
    PFN_vkGetDeviceQueue vkGetDeviceQueue = 0;
    PFN_vkGetDeviceQueue2 vkGetDeviceQueue2 = 0;
    PFN_vkGetEventStatus vkGetEventStatus = 0;
    PFN_vkGetFenceFdKHR vkGetFenceFdKHR = 0;
    PFN_vkGetFenceStatus vkGetFenceStatus = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetFenceWin32HandleKHR vkGetFenceWin32HandleKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkGetImageDrmFormatModifierPropertiesEXT vkGetImageDrmFormatModifierPropertiesEXT = 0;
    PFN_vkGetImageMemoryRequirements vkGetImageMemoryRequirements = 0;
    PFN_vkGetImageMemoryRequirements2 vkGetImageMemoryRequirements2 = 0;
    PFN_vkGetImageMemoryRequirements2KHR vkGetImageMemoryRequirements2KHR = 0;
    PFN_vkGetImageSparseMemoryRequirements vkGetImageSparseMemoryRequirements = 0;
    PFN_vkGetImageSparseMemoryRequirements2 vkGetImageSparseMemoryRequirements2 = 0;
    PFN_vkGetImageSparseMemoryRequirements2KHR vkGetImageSparseMemoryRequirements2KHR = 0;
    PFN_vkGetImageSubresourceLayout vkGetImageSubresourceLayout = 0;
    PFN_vkGetImageViewHandleNVX vkGetImageViewHandleNVX = 0;
#ifdef VK_USE_PLATFORM_ANDROID_KHR
    PFN_vkGetMemoryAndroidHardwareBufferANDROID vkGetMemoryAndroidHardwareBufferANDROID = 0;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
    PFN_vkGetMemoryFdKHR vkGetMemoryFdKHR = 0;
    PFN_vkGetMemoryFdPropertiesKHR vkGetMemoryFdPropertiesKHR = 0;
    PFN_vkGetMemoryHostPointerPropertiesEXT vkGetMemoryHostPointerPropertiesEXT = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetMemoryWin32HandleKHR vkGetMemoryWin32HandleKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetMemoryWin32HandleNV vkGetMemoryWin32HandleNV = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetMemoryWin32HandlePropertiesKHR vkGetMemoryWin32HandlePropertiesKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkGetPastPresentationTimingGOOGLE vkGetPastPresentationTimingGOOGLE = 0;
    PFN_vkGetPerformanceParameterINTEL vkGetPerformanceParameterINTEL = 0;
    PFN_vkGetPipelineCacheData vkGetPipelineCacheData = 0;
    PFN_vkGetPipelineExecutableInternalRepresentationsKHR vkGetPipelineExecutableInternalRepresentationsKHR = 0;
    PFN_vkGetPipelineExecutablePropertiesKHR vkGetPipelineExecutablePropertiesKHR = 0;
    PFN_vkGetPipelineExecutableStatisticsKHR vkGetPipelineExecutableStatisticsKHR = 0;
    PFN_vkGetQueryPoolResults vkGetQueryPoolResults = 0;
    PFN_vkGetRayTracingShaderGroupHandlesNV vkGetRayTracingShaderGroupHandlesNV = 0;
    PFN_vkGetRefreshCycleDurationGOOGLE vkGetRefreshCycleDurationGOOGLE = 0;
    PFN_vkGetRenderAreaGranularity vkGetRenderAreaGranularity = 0;
    PFN_vkGetSemaphoreCounterValueKHR vkGetSemaphoreCounterValueKHR = 0;
    PFN_vkGetSemaphoreFdKHR vkGetSemaphoreFdKHR = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetSemaphoreWin32HandleKHR vkGetSemaphoreWin32HandleKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkGetShaderInfoAMD vkGetShaderInfoAMD = 0;
    PFN_vkGetSwapchainCounterEXT vkGetSwapchainCounterEXT = 0;
    PFN_vkGetSwapchainImagesKHR vkGetSwapchainImagesKHR = 0;
    PFN_vkGetSwapchainStatusKHR vkGetSwapchainStatusKHR = 0;
    PFN_vkGetValidationCacheDataEXT vkGetValidationCacheDataEXT = 0;
    PFN_vkImportFenceFdKHR vkImportFenceFdKHR = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkImportFenceWin32HandleKHR vkImportFenceWin32HandleKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkImportSemaphoreFdKHR vkImportSemaphoreFdKHR = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkImportSemaphoreWin32HandleKHR vkImportSemaphoreWin32HandleKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkInitializePerformanceApiINTEL vkInitializePerformanceApiINTEL = 0;
    PFN_vkInvalidateMappedMemoryRanges vkInvalidateMappedMemoryRanges = 0;
    PFN_vkMapMemory vkMapMemory = 0;
    PFN_vkMergePipelineCaches vkMergePipelineCaches = 0;
    PFN_vkMergeValidationCachesEXT vkMergeValidationCachesEXT = 0;
    PFN_vkRegisterDeviceEventEXT vkRegisterDeviceEventEXT = 0;
    PFN_vkRegisterDisplayEventEXT vkRegisterDisplayEventEXT = 0;
    PFN_vkRegisterObjectsNVX vkRegisterObjectsNVX = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkReleaseFullScreenExclusiveModeEXT vkReleaseFullScreenExclusiveModeEXT = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkReleasePerformanceConfigurationINTEL vkReleasePerformanceConfigurationINTEL = 0;
    PFN_vkResetCommandPool vkResetCommandPool = 0;
    PFN_vkResetDescriptorPool vkResetDescriptorPool = 0;
    PFN_vkResetEvent vkResetEvent = 0;
    PFN_vkResetFences vkResetFences = 0;
    PFN_vkResetQueryPoolEXT vkResetQueryPoolEXT = 0;
    PFN_vkSetDebugUtilsObjectNameEXT vkSetDebugUtilsObjectNameEXT = 0;
    PFN_vkSetDebugUtilsObjectTagEXT vkSetDebugUtilsObjectTagEXT = 0;
    PFN_vkSetEvent vkSetEvent = 0;
    PFN_vkSetHdrMetadataEXT vkSetHdrMetadataEXT = 0;
    PFN_vkSetLocalDimmingAMD vkSetLocalDimmingAMD = 0;
    PFN_vkSignalSemaphoreKHR vkSignalSemaphoreKHR = 0;
    PFN_vkTrimCommandPool vkTrimCommandPool = 0;
    PFN_vkTrimCommandPoolKHR vkTrimCommandPoolKHR = 0;
    PFN_vkUninitializePerformanceApiINTEL vkUninitializePerformanceApiINTEL = 0;
    PFN_vkUnmapMemory vkUnmapMemory = 0;
    PFN_vkUnregisterObjectsNVX vkUnregisterObjectsNVX = 0;
    PFN_vkUpdateDescriptorSetWithTemplate vkUpdateDescriptorSetWithTemplate = 0;
    PFN_vkUpdateDescriptorSetWithTemplateKHR vkUpdateDescriptorSetWithTemplateKHR = 0;
    PFN_vkUpdateDescriptorSets vkUpdateDescriptorSets = 0;
    PFN_vkWaitForFences vkWaitForFences = 0;
    PFN_vkWaitSemaphoresKHR vkWaitSemaphoresKHR = 0;
#ifdef VK_USE_PLATFORM_ANDROID_KHR
    PFN_vkCreateAndroidSurfaceKHR vkCreateAndroidSurfaceKHR = 0;
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
    PFN_vkCreateDebugReportCallbackEXT vkCreateDebugReportCallbackEXT = 0;
    PFN_vkCreateDebugUtilsMessengerEXT vkCreateDebugUtilsMessengerEXT = 0;
    PFN_vkCreateDisplayPlaneSurfaceKHR vkCreateDisplayPlaneSurfaceKHR = 0;
    PFN_vkCreateHeadlessSurfaceEXT vkCreateHeadlessSurfaceEXT = 0;
#ifdef VK_USE_PLATFORM_IOS_MVK
    PFN_vkCreateIOSSurfaceMVK vkCreateIOSSurfaceMVK = 0;
#endif /*VK_USE_PLATFORM_IOS_MVK*/
#ifdef VK_USE_PLATFORM_FUCHSIA
    PFN_vkCreateImagePipeSurfaceFUCHSIA vkCreateImagePipeSurfaceFUCHSIA = 0;
#endif /*VK_USE_PLATFORM_FUCHSIA*/
#ifdef VK_USE_PLATFORM_MACOS_MVK
    PFN_vkCreateMacOSSurfaceMVK vkCreateMacOSSurfaceMVK = 0;
#endif /*VK_USE_PLATFORM_MACOS_MVK*/
#ifdef VK_USE_PLATFORM_METAL_EXT
    PFN_vkCreateMetalSurfaceEXT vkCreateMetalSurfaceEXT = 0;
#endif /*VK_USE_PLATFORM_METAL_EXT*/
#ifdef VK_USE_PLATFORM_GGP
    PFN_vkCreateStreamDescriptorSurfaceGGP vkCreateStreamDescriptorSurfaceGGP = 0;
#endif /*VK_USE_PLATFORM_GGP*/
#ifdef VK_USE_PLATFORM_VI_NN
    PFN_vkCreateViSurfaceNN vkCreateViSurfaceNN = 0;
#endif /*VK_USE_PLATFORM_VI_NN*/
#ifdef VK_USE_PLATFORM_WAYLAND_KHR
    PFN_vkCreateWaylandSurfaceKHR vkCreateWaylandSurfaceKHR = 0;
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkCreateWin32SurfaceKHR vkCreateWin32SurfaceKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_XCB_KHR
    PFN_vkCreateXcbSurfaceKHR vkCreateXcbSurfaceKHR = 0;
#endif /*VK_USE_PLATFORM_XCB_KHR*/
#ifdef VK_USE_PLATFORM_XLIB_KHR
    PFN_vkCreateXlibSurfaceKHR vkCreateXlibSurfaceKHR = 0;
#endif /*VK_USE_PLATFORM_XLIB_KHR*/
    PFN_vkDebugReportMessageEXT vkDebugReportMessageEXT = 0;
    PFN_vkDestroyDebugReportCallbackEXT vkDestroyDebugReportCallbackEXT = 0;
    PFN_vkDestroyDebugUtilsMessengerEXT vkDestroyDebugUtilsMessengerEXT = 0;
    PFN_vkDestroyInstance vkDestroyInstance = 0;
    PFN_vkDestroySurfaceKHR vkDestroySurfaceKHR = 0;
    PFN_vkEnumeratePhysicalDeviceGroups vkEnumeratePhysicalDeviceGroups = 0;
    PFN_vkEnumeratePhysicalDeviceGroupsKHR vkEnumeratePhysicalDeviceGroupsKHR = 0;
    PFN_vkEnumeratePhysicalDevices vkEnumeratePhysicalDevices = 0;
    PFN_vkGetInstanceProcAddr vkGetInstanceProcAddr = 0;
    PFN_vkSubmitDebugUtilsMessageEXT vkSubmitDebugUtilsMessageEXT = 0;
#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
    PFN_vkAcquireXlibDisplayEXT vkAcquireXlibDisplayEXT = 0;
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/
    PFN_vkCreateDevice vkCreateDevice = 0;
    PFN_vkCreateDisplayModeKHR vkCreateDisplayModeKHR = 0;
    PFN_vkEnumerateDeviceExtensionProperties vkEnumerateDeviceExtensionProperties = 0;
    PFN_vkEnumerateDeviceLayerProperties vkEnumerateDeviceLayerProperties = 0;
    PFN_vkGetDisplayModeProperties2KHR vkGetDisplayModeProperties2KHR = 0;
    PFN_vkGetDisplayModePropertiesKHR vkGetDisplayModePropertiesKHR = 0;
    PFN_vkGetDisplayPlaneCapabilities2KHR vkGetDisplayPlaneCapabilities2KHR = 0;
    PFN_vkGetDisplayPlaneCapabilitiesKHR vkGetDisplayPlaneCapabilitiesKHR = 0;
    PFN_vkGetDisplayPlaneSupportedDisplaysKHR vkGetDisplayPlaneSupportedDisplaysKHR = 0;
    PFN_vkGetPhysicalDeviceCalibrateableTimeDomainsEXT vkGetPhysicalDeviceCalibrateableTimeDomainsEXT = 0;
    PFN_vkGetPhysicalDeviceCooperativeMatrixPropertiesNV vkGetPhysicalDeviceCooperativeMatrixPropertiesNV = 0;
    PFN_vkGetPhysicalDeviceDisplayPlaneProperties2KHR vkGetPhysicalDeviceDisplayPlaneProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceDisplayPlanePropertiesKHR vkGetPhysicalDeviceDisplayPlanePropertiesKHR = 0;
    PFN_vkGetPhysicalDeviceDisplayProperties2KHR vkGetPhysicalDeviceDisplayProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceDisplayPropertiesKHR vkGetPhysicalDeviceDisplayPropertiesKHR = 0;
    PFN_vkGetPhysicalDeviceExternalBufferProperties vkGetPhysicalDeviceExternalBufferProperties = 0;
    PFN_vkGetPhysicalDeviceExternalBufferPropertiesKHR vkGetPhysicalDeviceExternalBufferPropertiesKHR = 0;
    PFN_vkGetPhysicalDeviceExternalFenceProperties vkGetPhysicalDeviceExternalFenceProperties = 0;
    PFN_vkGetPhysicalDeviceExternalFencePropertiesKHR vkGetPhysicalDeviceExternalFencePropertiesKHR = 0;
    PFN_vkGetPhysicalDeviceExternalImageFormatPropertiesNV vkGetPhysicalDeviceExternalImageFormatPropertiesNV = 0;
    PFN_vkGetPhysicalDeviceExternalSemaphoreProperties vkGetPhysicalDeviceExternalSemaphoreProperties = 0;
    PFN_vkGetPhysicalDeviceExternalSemaphorePropertiesKHR vkGetPhysicalDeviceExternalSemaphorePropertiesKHR = 0;
    PFN_vkGetPhysicalDeviceFeatures vkGetPhysicalDeviceFeatures = 0;
    PFN_vkGetPhysicalDeviceFeatures2 vkGetPhysicalDeviceFeatures2 = 0;
    PFN_vkGetPhysicalDeviceFeatures2KHR vkGetPhysicalDeviceFeatures2KHR = 0;
    PFN_vkGetPhysicalDeviceFormatProperties vkGetPhysicalDeviceFormatProperties = 0;
    PFN_vkGetPhysicalDeviceFormatProperties2 vkGetPhysicalDeviceFormatProperties2 = 0;
    PFN_vkGetPhysicalDeviceFormatProperties2KHR vkGetPhysicalDeviceFormatProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX = 0;
    PFN_vkGetPhysicalDeviceImageFormatProperties vkGetPhysicalDeviceImageFormatProperties = 0;
    PFN_vkGetPhysicalDeviceImageFormatProperties2 vkGetPhysicalDeviceImageFormatProperties2 = 0;
    PFN_vkGetPhysicalDeviceImageFormatProperties2KHR vkGetPhysicalDeviceImageFormatProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceMemoryProperties vkGetPhysicalDeviceMemoryProperties = 0;
    PFN_vkGetPhysicalDeviceMemoryProperties2 vkGetPhysicalDeviceMemoryProperties2 = 0;
    PFN_vkGetPhysicalDeviceMemoryProperties2KHR vkGetPhysicalDeviceMemoryProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceMultisamplePropertiesEXT vkGetPhysicalDeviceMultisamplePropertiesEXT = 0;
    PFN_vkGetPhysicalDevicePresentRectanglesKHR vkGetPhysicalDevicePresentRectanglesKHR = 0;
    PFN_vkGetPhysicalDeviceProperties vkGetPhysicalDeviceProperties = 0;
    PFN_vkGetPhysicalDeviceProperties2 vkGetPhysicalDeviceProperties2 = 0;
    PFN_vkGetPhysicalDeviceProperties2KHR vkGetPhysicalDeviceProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceQueueFamilyProperties vkGetPhysicalDeviceQueueFamilyProperties = 0;
    PFN_vkGetPhysicalDeviceQueueFamilyProperties2 vkGetPhysicalDeviceQueueFamilyProperties2 = 0;
    PFN_vkGetPhysicalDeviceQueueFamilyProperties2KHR vkGetPhysicalDeviceQueueFamilyProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceSparseImageFormatProperties vkGetPhysicalDeviceSparseImageFormatProperties = 0;
    PFN_vkGetPhysicalDeviceSparseImageFormatProperties2 vkGetPhysicalDeviceSparseImageFormatProperties2 = 0;
    PFN_vkGetPhysicalDeviceSparseImageFormatProperties2KHR vkGetPhysicalDeviceSparseImageFormatProperties2KHR = 0;
    PFN_vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV = 0;
    PFN_vkGetPhysicalDeviceSurfaceCapabilities2EXT vkGetPhysicalDeviceSurfaceCapabilities2EXT = 0;
    PFN_vkGetPhysicalDeviceSurfaceCapabilities2KHR vkGetPhysicalDeviceSurfaceCapabilities2KHR = 0;
    PFN_vkGetPhysicalDeviceSurfaceCapabilitiesKHR vkGetPhysicalDeviceSurfaceCapabilitiesKHR = 0;
    PFN_vkGetPhysicalDeviceSurfaceFormats2KHR vkGetPhysicalDeviceSurfaceFormats2KHR = 0;
    PFN_vkGetPhysicalDeviceSurfaceFormatsKHR vkGetPhysicalDeviceSurfaceFormatsKHR = 0;
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetPhysicalDeviceSurfacePresentModes2EXT vkGetPhysicalDeviceSurfacePresentModes2EXT = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
    PFN_vkGetPhysicalDeviceSurfacePresentModesKHR vkGetPhysicalDeviceSurfacePresentModesKHR = 0;
    PFN_vkGetPhysicalDeviceSurfaceSupportKHR vkGetPhysicalDeviceSurfaceSupportKHR = 0;
#ifdef VK_USE_PLATFORM_WAYLAND_KHR
    PFN_vkGetPhysicalDeviceWaylandPresentationSupportKHR vkGetPhysicalDeviceWaylandPresentationSupportKHR = 0;
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
    PFN_vkGetPhysicalDeviceWin32PresentationSupportKHR vkGetPhysicalDeviceWin32PresentationSupportKHR = 0;
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_XCB_KHR
    PFN_vkGetPhysicalDeviceXcbPresentationSupportKHR vkGetPhysicalDeviceXcbPresentationSupportKHR = 0;
#endif /*VK_USE_PLATFORM_XCB_KHR*/
#ifdef VK_USE_PLATFORM_XLIB_KHR
    PFN_vkGetPhysicalDeviceXlibPresentationSupportKHR vkGetPhysicalDeviceXlibPresentationSupportKHR = 0;
#endif /*VK_USE_PLATFORM_XLIB_KHR*/
#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
    PFN_vkGetRandROutputDisplayEXT vkGetRandROutputDisplayEXT = 0;
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/
    PFN_vkReleaseDisplayEXT vkReleaseDisplayEXT = 0;
    PFN_vkGetQueueCheckpointDataNV vkGetQueueCheckpointDataNV = 0;
    PFN_vkQueueBeginDebugUtilsLabelEXT vkQueueBeginDebugUtilsLabelEXT = 0;
    PFN_vkQueueBindSparse vkQueueBindSparse = 0;
    PFN_vkQueueEndDebugUtilsLabelEXT vkQueueEndDebugUtilsLabelEXT = 0;
    PFN_vkQueueInsertDebugUtilsLabelEXT vkQueueInsertDebugUtilsLabelEXT = 0;
    PFN_vkQueuePresentKHR vkQueuePresentKHR = 0;
    PFN_vkQueueSetPerformanceConfigurationINTEL vkQueueSetPerformanceConfigurationINTEL = 0;
    PFN_vkQueueSubmit vkQueueSubmit = 0;
    PFN_vkQueueWaitIdle vkQueueWaitIdle = 0;

  public:
    DispatchLoaderDynamic() VULKAN_HPP_NOEXCEPT = default;

#if !defined(VK_NO_PROTOTYPES)
    // This interface is designed to be used for per-device function pointers in combination with a linked vulkan library.
    DispatchLoaderDynamic(vk::Instance const& instance, vk::Device const& device) VULKAN_HPP_NOEXCEPT
    {
      init(instance, device);
    }

    // This interface is designed to be used for per-device function pointers in combination with a linked vulkan library.
    void init(vk::Instance const& instance, vk::Device const& device) VULKAN_HPP_NOEXCEPT
    {
      init(static_cast<VkInstance>(instance), ::vkGetInstanceProcAddr, static_cast<VkDevice>(device), device ? ::vkGetDeviceProcAddr : nullptr);
    }
#endif // !defined(VK_NO_PROTOTYPES)

    DispatchLoaderDynamic(PFN_vkGetInstanceProcAddr getInstanceProcAddr) VULKAN_HPP_NOEXCEPT
    {
      init(getInstanceProcAddr);
    }

    void init( PFN_vkGetInstanceProcAddr getInstanceProcAddr ) VULKAN_HPP_NOEXCEPT
    {
      VULKAN_HPP_ASSERT(getInstanceProcAddr);

      vkGetInstanceProcAddr = getInstanceProcAddr;
      vkCreateInstance = PFN_vkCreateInstance( vkGetInstanceProcAddr( NULL, "vkCreateInstance" ) );
      vkEnumerateInstanceExtensionProperties = PFN_vkEnumerateInstanceExtensionProperties( vkGetInstanceProcAddr( NULL, "vkEnumerateInstanceExtensionProperties" ) );
      vkEnumerateInstanceLayerProperties = PFN_vkEnumerateInstanceLayerProperties( vkGetInstanceProcAddr( NULL, "vkEnumerateInstanceLayerProperties" ) );
      vkEnumerateInstanceVersion = PFN_vkEnumerateInstanceVersion( vkGetInstanceProcAddr( NULL, "vkEnumerateInstanceVersion" ) );
    }

    // This interface does not require a linked vulkan library.
    DispatchLoaderDynamic( VkInstance instance, PFN_vkGetInstanceProcAddr getInstanceProcAddr, VkDevice device = VK_NULL_HANDLE, PFN_vkGetDeviceProcAddr getDeviceProcAddr = nullptr ) VULKAN_HPP_NOEXCEPT
    {
      init( instance, getInstanceProcAddr, device, getDeviceProcAddr );
    }

    // This interface does not require a linked vulkan library.
    void init( VkInstance instance, PFN_vkGetInstanceProcAddr getInstanceProcAddr, VkDevice device = VK_NULL_HANDLE, PFN_vkGetDeviceProcAddr /*getDeviceProcAddr*/ = nullptr ) VULKAN_HPP_NOEXCEPT
    {
      VULKAN_HPP_ASSERT(instance && getInstanceProcAddr);
      vkGetInstanceProcAddr = getInstanceProcAddr;
      init( vk::Instance(instance) );
      if (device) {
        init( vk::Device(device) );
      }
    }

    void init( vk::Instance instance ) VULKAN_HPP_NOEXCEPT
    {
#ifdef VK_USE_PLATFORM_ANDROID_KHR
      vkCreateAndroidSurfaceKHR = PFN_vkCreateAndroidSurfaceKHR( vkGetInstanceProcAddr( instance, "vkCreateAndroidSurfaceKHR" ) );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
      vkCreateDebugReportCallbackEXT = PFN_vkCreateDebugReportCallbackEXT( vkGetInstanceProcAddr( instance, "vkCreateDebugReportCallbackEXT" ) );
      vkCreateDebugUtilsMessengerEXT = PFN_vkCreateDebugUtilsMessengerEXT( vkGetInstanceProcAddr( instance, "vkCreateDebugUtilsMessengerEXT" ) );
      vkCreateDisplayPlaneSurfaceKHR = PFN_vkCreateDisplayPlaneSurfaceKHR( vkGetInstanceProcAddr( instance, "vkCreateDisplayPlaneSurfaceKHR" ) );
      vkCreateHeadlessSurfaceEXT = PFN_vkCreateHeadlessSurfaceEXT( vkGetInstanceProcAddr( instance, "vkCreateHeadlessSurfaceEXT" ) );
#ifdef VK_USE_PLATFORM_IOS_MVK
      vkCreateIOSSurfaceMVK = PFN_vkCreateIOSSurfaceMVK( vkGetInstanceProcAddr( instance, "vkCreateIOSSurfaceMVK" ) );
#endif /*VK_USE_PLATFORM_IOS_MVK*/
#ifdef VK_USE_PLATFORM_FUCHSIA
      vkCreateImagePipeSurfaceFUCHSIA = PFN_vkCreateImagePipeSurfaceFUCHSIA( vkGetInstanceProcAddr( instance, "vkCreateImagePipeSurfaceFUCHSIA" ) );
#endif /*VK_USE_PLATFORM_FUCHSIA*/
#ifdef VK_USE_PLATFORM_MACOS_MVK
      vkCreateMacOSSurfaceMVK = PFN_vkCreateMacOSSurfaceMVK( vkGetInstanceProcAddr( instance, "vkCreateMacOSSurfaceMVK" ) );
#endif /*VK_USE_PLATFORM_MACOS_MVK*/
#ifdef VK_USE_PLATFORM_METAL_EXT
      vkCreateMetalSurfaceEXT = PFN_vkCreateMetalSurfaceEXT( vkGetInstanceProcAddr( instance, "vkCreateMetalSurfaceEXT" ) );
#endif /*VK_USE_PLATFORM_METAL_EXT*/
#ifdef VK_USE_PLATFORM_GGP
      vkCreateStreamDescriptorSurfaceGGP = PFN_vkCreateStreamDescriptorSurfaceGGP( vkGetInstanceProcAddr( instance, "vkCreateStreamDescriptorSurfaceGGP" ) );
#endif /*VK_USE_PLATFORM_GGP*/
#ifdef VK_USE_PLATFORM_VI_NN
      vkCreateViSurfaceNN = PFN_vkCreateViSurfaceNN( vkGetInstanceProcAddr( instance, "vkCreateViSurfaceNN" ) );
#endif /*VK_USE_PLATFORM_VI_NN*/
#ifdef VK_USE_PLATFORM_WAYLAND_KHR
      vkCreateWaylandSurfaceKHR = PFN_vkCreateWaylandSurfaceKHR( vkGetInstanceProcAddr( instance, "vkCreateWaylandSurfaceKHR" ) );
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkCreateWin32SurfaceKHR = PFN_vkCreateWin32SurfaceKHR( vkGetInstanceProcAddr( instance, "vkCreateWin32SurfaceKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_XCB_KHR
      vkCreateXcbSurfaceKHR = PFN_vkCreateXcbSurfaceKHR( vkGetInstanceProcAddr( instance, "vkCreateXcbSurfaceKHR" ) );
#endif /*VK_USE_PLATFORM_XCB_KHR*/
#ifdef VK_USE_PLATFORM_XLIB_KHR
      vkCreateXlibSurfaceKHR = PFN_vkCreateXlibSurfaceKHR( vkGetInstanceProcAddr( instance, "vkCreateXlibSurfaceKHR" ) );
#endif /*VK_USE_PLATFORM_XLIB_KHR*/
      vkDebugReportMessageEXT = PFN_vkDebugReportMessageEXT( vkGetInstanceProcAddr( instance, "vkDebugReportMessageEXT" ) );
      vkDestroyDebugReportCallbackEXT = PFN_vkDestroyDebugReportCallbackEXT( vkGetInstanceProcAddr( instance, "vkDestroyDebugReportCallbackEXT" ) );
      vkDestroyDebugUtilsMessengerEXT = PFN_vkDestroyDebugUtilsMessengerEXT( vkGetInstanceProcAddr( instance, "vkDestroyDebugUtilsMessengerEXT" ) );
      vkDestroyInstance = PFN_vkDestroyInstance( vkGetInstanceProcAddr( instance, "vkDestroyInstance" ) );
      vkDestroySurfaceKHR = PFN_vkDestroySurfaceKHR( vkGetInstanceProcAddr( instance, "vkDestroySurfaceKHR" ) );
      vkEnumeratePhysicalDeviceGroups = PFN_vkEnumeratePhysicalDeviceGroups( vkGetInstanceProcAddr( instance, "vkEnumeratePhysicalDeviceGroups" ) );
      vkEnumeratePhysicalDeviceGroupsKHR = PFN_vkEnumeratePhysicalDeviceGroupsKHR( vkGetInstanceProcAddr( instance, "vkEnumeratePhysicalDeviceGroupsKHR" ) );
      vkEnumeratePhysicalDevices = PFN_vkEnumeratePhysicalDevices( vkGetInstanceProcAddr( instance, "vkEnumeratePhysicalDevices" ) );
      vkSubmitDebugUtilsMessageEXT = PFN_vkSubmitDebugUtilsMessageEXT( vkGetInstanceProcAddr( instance, "vkSubmitDebugUtilsMessageEXT" ) );
#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
      vkAcquireXlibDisplayEXT = PFN_vkAcquireXlibDisplayEXT( vkGetInstanceProcAddr( instance, "vkAcquireXlibDisplayEXT" ) );
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/
      vkCreateDevice = PFN_vkCreateDevice( vkGetInstanceProcAddr( instance, "vkCreateDevice" ) );
      vkCreateDisplayModeKHR = PFN_vkCreateDisplayModeKHR( vkGetInstanceProcAddr( instance, "vkCreateDisplayModeKHR" ) );
      vkEnumerateDeviceExtensionProperties = PFN_vkEnumerateDeviceExtensionProperties( vkGetInstanceProcAddr( instance, "vkEnumerateDeviceExtensionProperties" ) );
      vkEnumerateDeviceLayerProperties = PFN_vkEnumerateDeviceLayerProperties( vkGetInstanceProcAddr( instance, "vkEnumerateDeviceLayerProperties" ) );
      vkGetDisplayModeProperties2KHR = PFN_vkGetDisplayModeProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetDisplayModeProperties2KHR" ) );
      vkGetDisplayModePropertiesKHR = PFN_vkGetDisplayModePropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetDisplayModePropertiesKHR" ) );
      vkGetDisplayPlaneCapabilities2KHR = PFN_vkGetDisplayPlaneCapabilities2KHR( vkGetInstanceProcAddr( instance, "vkGetDisplayPlaneCapabilities2KHR" ) );
      vkGetDisplayPlaneCapabilitiesKHR = PFN_vkGetDisplayPlaneCapabilitiesKHR( vkGetInstanceProcAddr( instance, "vkGetDisplayPlaneCapabilitiesKHR" ) );
      vkGetDisplayPlaneSupportedDisplaysKHR = PFN_vkGetDisplayPlaneSupportedDisplaysKHR( vkGetInstanceProcAddr( instance, "vkGetDisplayPlaneSupportedDisplaysKHR" ) );
      vkGetPhysicalDeviceCalibrateableTimeDomainsEXT = PFN_vkGetPhysicalDeviceCalibrateableTimeDomainsEXT( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceCalibrateableTimeDomainsEXT" ) );
      vkGetPhysicalDeviceCooperativeMatrixPropertiesNV = PFN_vkGetPhysicalDeviceCooperativeMatrixPropertiesNV( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceCooperativeMatrixPropertiesNV" ) );
      vkGetPhysicalDeviceDisplayPlaneProperties2KHR = PFN_vkGetPhysicalDeviceDisplayPlaneProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceDisplayPlaneProperties2KHR" ) );
      vkGetPhysicalDeviceDisplayPlanePropertiesKHR = PFN_vkGetPhysicalDeviceDisplayPlanePropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceDisplayPlanePropertiesKHR" ) );
      vkGetPhysicalDeviceDisplayProperties2KHR = PFN_vkGetPhysicalDeviceDisplayProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceDisplayProperties2KHR" ) );
      vkGetPhysicalDeviceDisplayPropertiesKHR = PFN_vkGetPhysicalDeviceDisplayPropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceDisplayPropertiesKHR" ) );
      vkGetPhysicalDeviceExternalBufferProperties = PFN_vkGetPhysicalDeviceExternalBufferProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceExternalBufferProperties" ) );
      vkGetPhysicalDeviceExternalBufferPropertiesKHR = PFN_vkGetPhysicalDeviceExternalBufferPropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceExternalBufferPropertiesKHR" ) );
      vkGetPhysicalDeviceExternalFenceProperties = PFN_vkGetPhysicalDeviceExternalFenceProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceExternalFenceProperties" ) );
      vkGetPhysicalDeviceExternalFencePropertiesKHR = PFN_vkGetPhysicalDeviceExternalFencePropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceExternalFencePropertiesKHR" ) );
      vkGetPhysicalDeviceExternalImageFormatPropertiesNV = PFN_vkGetPhysicalDeviceExternalImageFormatPropertiesNV( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceExternalImageFormatPropertiesNV" ) );
      vkGetPhysicalDeviceExternalSemaphoreProperties = PFN_vkGetPhysicalDeviceExternalSemaphoreProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceExternalSemaphoreProperties" ) );
      vkGetPhysicalDeviceExternalSemaphorePropertiesKHR = PFN_vkGetPhysicalDeviceExternalSemaphorePropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceExternalSemaphorePropertiesKHR" ) );
      vkGetPhysicalDeviceFeatures = PFN_vkGetPhysicalDeviceFeatures( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceFeatures" ) );
      vkGetPhysicalDeviceFeatures2 = PFN_vkGetPhysicalDeviceFeatures2( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceFeatures2" ) );
      vkGetPhysicalDeviceFeatures2KHR = PFN_vkGetPhysicalDeviceFeatures2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceFeatures2KHR" ) );
      vkGetPhysicalDeviceFormatProperties = PFN_vkGetPhysicalDeviceFormatProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceFormatProperties" ) );
      vkGetPhysicalDeviceFormatProperties2 = PFN_vkGetPhysicalDeviceFormatProperties2( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceFormatProperties2" ) );
      vkGetPhysicalDeviceFormatProperties2KHR = PFN_vkGetPhysicalDeviceFormatProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceFormatProperties2KHR" ) );
      vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX = PFN_vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceGeneratedCommandsPropertiesNVX" ) );
      vkGetPhysicalDeviceImageFormatProperties = PFN_vkGetPhysicalDeviceImageFormatProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceImageFormatProperties" ) );
      vkGetPhysicalDeviceImageFormatProperties2 = PFN_vkGetPhysicalDeviceImageFormatProperties2( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceImageFormatProperties2" ) );
      vkGetPhysicalDeviceImageFormatProperties2KHR = PFN_vkGetPhysicalDeviceImageFormatProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceImageFormatProperties2KHR" ) );
      vkGetPhysicalDeviceMemoryProperties = PFN_vkGetPhysicalDeviceMemoryProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceMemoryProperties" ) );
      vkGetPhysicalDeviceMemoryProperties2 = PFN_vkGetPhysicalDeviceMemoryProperties2( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceMemoryProperties2" ) );
      vkGetPhysicalDeviceMemoryProperties2KHR = PFN_vkGetPhysicalDeviceMemoryProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceMemoryProperties2KHR" ) );
      vkGetPhysicalDeviceMultisamplePropertiesEXT = PFN_vkGetPhysicalDeviceMultisamplePropertiesEXT( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceMultisamplePropertiesEXT" ) );
      vkGetPhysicalDevicePresentRectanglesKHR = PFN_vkGetPhysicalDevicePresentRectanglesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDevicePresentRectanglesKHR" ) );
      vkGetPhysicalDeviceProperties = PFN_vkGetPhysicalDeviceProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceProperties" ) );
      vkGetPhysicalDeviceProperties2 = PFN_vkGetPhysicalDeviceProperties2( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceProperties2" ) );
      vkGetPhysicalDeviceProperties2KHR = PFN_vkGetPhysicalDeviceProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceProperties2KHR" ) );
      vkGetPhysicalDeviceQueueFamilyProperties = PFN_vkGetPhysicalDeviceQueueFamilyProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceQueueFamilyProperties" ) );
      vkGetPhysicalDeviceQueueFamilyProperties2 = PFN_vkGetPhysicalDeviceQueueFamilyProperties2( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceQueueFamilyProperties2" ) );
      vkGetPhysicalDeviceQueueFamilyProperties2KHR = PFN_vkGetPhysicalDeviceQueueFamilyProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceQueueFamilyProperties2KHR" ) );
      vkGetPhysicalDeviceSparseImageFormatProperties = PFN_vkGetPhysicalDeviceSparseImageFormatProperties( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSparseImageFormatProperties" ) );
      vkGetPhysicalDeviceSparseImageFormatProperties2 = PFN_vkGetPhysicalDeviceSparseImageFormatProperties2( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSparseImageFormatProperties2" ) );
      vkGetPhysicalDeviceSparseImageFormatProperties2KHR = PFN_vkGetPhysicalDeviceSparseImageFormatProperties2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSparseImageFormatProperties2KHR" ) );
      vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV = PFN_vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSupportedFramebufferMixedSamplesCombinationsNV" ) );
      vkGetPhysicalDeviceSurfaceCapabilities2EXT = PFN_vkGetPhysicalDeviceSurfaceCapabilities2EXT( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfaceCapabilities2EXT" ) );
      vkGetPhysicalDeviceSurfaceCapabilities2KHR = PFN_vkGetPhysicalDeviceSurfaceCapabilities2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfaceCapabilities2KHR" ) );
      vkGetPhysicalDeviceSurfaceCapabilitiesKHR = PFN_vkGetPhysicalDeviceSurfaceCapabilitiesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfaceCapabilitiesKHR" ) );
      vkGetPhysicalDeviceSurfaceFormats2KHR = PFN_vkGetPhysicalDeviceSurfaceFormats2KHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfaceFormats2KHR" ) );
      vkGetPhysicalDeviceSurfaceFormatsKHR = PFN_vkGetPhysicalDeviceSurfaceFormatsKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfaceFormatsKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetPhysicalDeviceSurfacePresentModes2EXT = PFN_vkGetPhysicalDeviceSurfacePresentModes2EXT( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfacePresentModes2EXT" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetPhysicalDeviceSurfacePresentModesKHR = PFN_vkGetPhysicalDeviceSurfacePresentModesKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfacePresentModesKHR" ) );
      vkGetPhysicalDeviceSurfaceSupportKHR = PFN_vkGetPhysicalDeviceSurfaceSupportKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceSurfaceSupportKHR" ) );
#ifdef VK_USE_PLATFORM_WAYLAND_KHR
      vkGetPhysicalDeviceWaylandPresentationSupportKHR = PFN_vkGetPhysicalDeviceWaylandPresentationSupportKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceWaylandPresentationSupportKHR" ) );
#endif /*VK_USE_PLATFORM_WAYLAND_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetPhysicalDeviceWin32PresentationSupportKHR = PFN_vkGetPhysicalDeviceWin32PresentationSupportKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceWin32PresentationSupportKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_XCB_KHR
      vkGetPhysicalDeviceXcbPresentationSupportKHR = PFN_vkGetPhysicalDeviceXcbPresentationSupportKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceXcbPresentationSupportKHR" ) );
#endif /*VK_USE_PLATFORM_XCB_KHR*/
#ifdef VK_USE_PLATFORM_XLIB_KHR
      vkGetPhysicalDeviceXlibPresentationSupportKHR = PFN_vkGetPhysicalDeviceXlibPresentationSupportKHR( vkGetInstanceProcAddr( instance, "vkGetPhysicalDeviceXlibPresentationSupportKHR" ) );
#endif /*VK_USE_PLATFORM_XLIB_KHR*/
#ifdef VK_USE_PLATFORM_XLIB_XRANDR_EXT
      vkGetRandROutputDisplayEXT = PFN_vkGetRandROutputDisplayEXT( vkGetInstanceProcAddr( instance, "vkGetRandROutputDisplayEXT" ) );
#endif /*VK_USE_PLATFORM_XLIB_XRANDR_EXT*/
      vkReleaseDisplayEXT = PFN_vkReleaseDisplayEXT( vkGetInstanceProcAddr( instance, "vkReleaseDisplayEXT" ) );
      vkBeginCommandBuffer = PFN_vkBeginCommandBuffer( vkGetInstanceProcAddr( instance, "vkBeginCommandBuffer" ) );
      vkCmdBeginConditionalRenderingEXT = PFN_vkCmdBeginConditionalRenderingEXT( vkGetInstanceProcAddr( instance, "vkCmdBeginConditionalRenderingEXT" ) );
      vkCmdBeginDebugUtilsLabelEXT = PFN_vkCmdBeginDebugUtilsLabelEXT( vkGetInstanceProcAddr( instance, "vkCmdBeginDebugUtilsLabelEXT" ) );
      vkCmdBeginQuery = PFN_vkCmdBeginQuery( vkGetInstanceProcAddr( instance, "vkCmdBeginQuery" ) );
      vkCmdBeginQueryIndexedEXT = PFN_vkCmdBeginQueryIndexedEXT( vkGetInstanceProcAddr( instance, "vkCmdBeginQueryIndexedEXT" ) );
      vkCmdBeginRenderPass = PFN_vkCmdBeginRenderPass( vkGetInstanceProcAddr( instance, "vkCmdBeginRenderPass" ) );
      vkCmdBeginRenderPass2KHR = PFN_vkCmdBeginRenderPass2KHR( vkGetInstanceProcAddr( instance, "vkCmdBeginRenderPass2KHR" ) );
      vkCmdBeginTransformFeedbackEXT = PFN_vkCmdBeginTransformFeedbackEXT( vkGetInstanceProcAddr( instance, "vkCmdBeginTransformFeedbackEXT" ) );
      vkCmdBindDescriptorSets = PFN_vkCmdBindDescriptorSets( vkGetInstanceProcAddr( instance, "vkCmdBindDescriptorSets" ) );
      vkCmdBindIndexBuffer = PFN_vkCmdBindIndexBuffer( vkGetInstanceProcAddr( instance, "vkCmdBindIndexBuffer" ) );
      vkCmdBindPipeline = PFN_vkCmdBindPipeline( vkGetInstanceProcAddr( instance, "vkCmdBindPipeline" ) );
      vkCmdBindShadingRateImageNV = PFN_vkCmdBindShadingRateImageNV( vkGetInstanceProcAddr( instance, "vkCmdBindShadingRateImageNV" ) );
      vkCmdBindTransformFeedbackBuffersEXT = PFN_vkCmdBindTransformFeedbackBuffersEXT( vkGetInstanceProcAddr( instance, "vkCmdBindTransformFeedbackBuffersEXT" ) );
      vkCmdBindVertexBuffers = PFN_vkCmdBindVertexBuffers( vkGetInstanceProcAddr( instance, "vkCmdBindVertexBuffers" ) );
      vkCmdBlitImage = PFN_vkCmdBlitImage( vkGetInstanceProcAddr( instance, "vkCmdBlitImage" ) );
      vkCmdBuildAccelerationStructureNV = PFN_vkCmdBuildAccelerationStructureNV( vkGetInstanceProcAddr( instance, "vkCmdBuildAccelerationStructureNV" ) );
      vkCmdClearAttachments = PFN_vkCmdClearAttachments( vkGetInstanceProcAddr( instance, "vkCmdClearAttachments" ) );
      vkCmdClearColorImage = PFN_vkCmdClearColorImage( vkGetInstanceProcAddr( instance, "vkCmdClearColorImage" ) );
      vkCmdClearDepthStencilImage = PFN_vkCmdClearDepthStencilImage( vkGetInstanceProcAddr( instance, "vkCmdClearDepthStencilImage" ) );
      vkCmdCopyAccelerationStructureNV = PFN_vkCmdCopyAccelerationStructureNV( vkGetInstanceProcAddr( instance, "vkCmdCopyAccelerationStructureNV" ) );
      vkCmdCopyBuffer = PFN_vkCmdCopyBuffer( vkGetInstanceProcAddr( instance, "vkCmdCopyBuffer" ) );
      vkCmdCopyBufferToImage = PFN_vkCmdCopyBufferToImage( vkGetInstanceProcAddr( instance, "vkCmdCopyBufferToImage" ) );
      vkCmdCopyImage = PFN_vkCmdCopyImage( vkGetInstanceProcAddr( instance, "vkCmdCopyImage" ) );
      vkCmdCopyImageToBuffer = PFN_vkCmdCopyImageToBuffer( vkGetInstanceProcAddr( instance, "vkCmdCopyImageToBuffer" ) );
      vkCmdCopyQueryPoolResults = PFN_vkCmdCopyQueryPoolResults( vkGetInstanceProcAddr( instance, "vkCmdCopyQueryPoolResults" ) );
      vkCmdDebugMarkerBeginEXT = PFN_vkCmdDebugMarkerBeginEXT( vkGetInstanceProcAddr( instance, "vkCmdDebugMarkerBeginEXT" ) );
      vkCmdDebugMarkerEndEXT = PFN_vkCmdDebugMarkerEndEXT( vkGetInstanceProcAddr( instance, "vkCmdDebugMarkerEndEXT" ) );
      vkCmdDebugMarkerInsertEXT = PFN_vkCmdDebugMarkerInsertEXT( vkGetInstanceProcAddr( instance, "vkCmdDebugMarkerInsertEXT" ) );
      vkCmdDispatch = PFN_vkCmdDispatch( vkGetInstanceProcAddr( instance, "vkCmdDispatch" ) );
      vkCmdDispatchBase = PFN_vkCmdDispatchBase( vkGetInstanceProcAddr( instance, "vkCmdDispatchBase" ) );
      vkCmdDispatchBaseKHR = PFN_vkCmdDispatchBaseKHR( vkGetInstanceProcAddr( instance, "vkCmdDispatchBaseKHR" ) );
      vkCmdDispatchIndirect = PFN_vkCmdDispatchIndirect( vkGetInstanceProcAddr( instance, "vkCmdDispatchIndirect" ) );
      vkCmdDraw = PFN_vkCmdDraw( vkGetInstanceProcAddr( instance, "vkCmdDraw" ) );
      vkCmdDrawIndexed = PFN_vkCmdDrawIndexed( vkGetInstanceProcAddr( instance, "vkCmdDrawIndexed" ) );
      vkCmdDrawIndexedIndirect = PFN_vkCmdDrawIndexedIndirect( vkGetInstanceProcAddr( instance, "vkCmdDrawIndexedIndirect" ) );
      vkCmdDrawIndexedIndirectCountAMD = PFN_vkCmdDrawIndexedIndirectCountAMD( vkGetInstanceProcAddr( instance, "vkCmdDrawIndexedIndirectCountAMD" ) );
      vkCmdDrawIndexedIndirectCountKHR = PFN_vkCmdDrawIndexedIndirectCountKHR( vkGetInstanceProcAddr( instance, "vkCmdDrawIndexedIndirectCountKHR" ) );
      vkCmdDrawIndirect = PFN_vkCmdDrawIndirect( vkGetInstanceProcAddr( instance, "vkCmdDrawIndirect" ) );
      vkCmdDrawIndirectByteCountEXT = PFN_vkCmdDrawIndirectByteCountEXT( vkGetInstanceProcAddr( instance, "vkCmdDrawIndirectByteCountEXT" ) );
      vkCmdDrawIndirectCountAMD = PFN_vkCmdDrawIndirectCountAMD( vkGetInstanceProcAddr( instance, "vkCmdDrawIndirectCountAMD" ) );
      vkCmdDrawIndirectCountKHR = PFN_vkCmdDrawIndirectCountKHR( vkGetInstanceProcAddr( instance, "vkCmdDrawIndirectCountKHR" ) );
      vkCmdDrawMeshTasksIndirectCountNV = PFN_vkCmdDrawMeshTasksIndirectCountNV( vkGetInstanceProcAddr( instance, "vkCmdDrawMeshTasksIndirectCountNV" ) );
      vkCmdDrawMeshTasksIndirectNV = PFN_vkCmdDrawMeshTasksIndirectNV( vkGetInstanceProcAddr( instance, "vkCmdDrawMeshTasksIndirectNV" ) );
      vkCmdDrawMeshTasksNV = PFN_vkCmdDrawMeshTasksNV( vkGetInstanceProcAddr( instance, "vkCmdDrawMeshTasksNV" ) );
      vkCmdEndConditionalRenderingEXT = PFN_vkCmdEndConditionalRenderingEXT( vkGetInstanceProcAddr( instance, "vkCmdEndConditionalRenderingEXT" ) );
      vkCmdEndDebugUtilsLabelEXT = PFN_vkCmdEndDebugUtilsLabelEXT( vkGetInstanceProcAddr( instance, "vkCmdEndDebugUtilsLabelEXT" ) );
      vkCmdEndQuery = PFN_vkCmdEndQuery( vkGetInstanceProcAddr( instance, "vkCmdEndQuery" ) );
      vkCmdEndQueryIndexedEXT = PFN_vkCmdEndQueryIndexedEXT( vkGetInstanceProcAddr( instance, "vkCmdEndQueryIndexedEXT" ) );
      vkCmdEndRenderPass = PFN_vkCmdEndRenderPass( vkGetInstanceProcAddr( instance, "vkCmdEndRenderPass" ) );
      vkCmdEndRenderPass2KHR = PFN_vkCmdEndRenderPass2KHR( vkGetInstanceProcAddr( instance, "vkCmdEndRenderPass2KHR" ) );
      vkCmdEndTransformFeedbackEXT = PFN_vkCmdEndTransformFeedbackEXT( vkGetInstanceProcAddr( instance, "vkCmdEndTransformFeedbackEXT" ) );
      vkCmdExecuteCommands = PFN_vkCmdExecuteCommands( vkGetInstanceProcAddr( instance, "vkCmdExecuteCommands" ) );
      vkCmdFillBuffer = PFN_vkCmdFillBuffer( vkGetInstanceProcAddr( instance, "vkCmdFillBuffer" ) );
      vkCmdInsertDebugUtilsLabelEXT = PFN_vkCmdInsertDebugUtilsLabelEXT( vkGetInstanceProcAddr( instance, "vkCmdInsertDebugUtilsLabelEXT" ) );
      vkCmdNextSubpass = PFN_vkCmdNextSubpass( vkGetInstanceProcAddr( instance, "vkCmdNextSubpass" ) );
      vkCmdNextSubpass2KHR = PFN_vkCmdNextSubpass2KHR( vkGetInstanceProcAddr( instance, "vkCmdNextSubpass2KHR" ) );
      vkCmdPipelineBarrier = PFN_vkCmdPipelineBarrier( vkGetInstanceProcAddr( instance, "vkCmdPipelineBarrier" ) );
      vkCmdProcessCommandsNVX = PFN_vkCmdProcessCommandsNVX( vkGetInstanceProcAddr( instance, "vkCmdProcessCommandsNVX" ) );
      vkCmdPushConstants = PFN_vkCmdPushConstants( vkGetInstanceProcAddr( instance, "vkCmdPushConstants" ) );
      vkCmdPushDescriptorSetKHR = PFN_vkCmdPushDescriptorSetKHR( vkGetInstanceProcAddr( instance, "vkCmdPushDescriptorSetKHR" ) );
      vkCmdPushDescriptorSetWithTemplateKHR = PFN_vkCmdPushDescriptorSetWithTemplateKHR( vkGetInstanceProcAddr( instance, "vkCmdPushDescriptorSetWithTemplateKHR" ) );
      vkCmdReserveSpaceForCommandsNVX = PFN_vkCmdReserveSpaceForCommandsNVX( vkGetInstanceProcAddr( instance, "vkCmdReserveSpaceForCommandsNVX" ) );
      vkCmdResetEvent = PFN_vkCmdResetEvent( vkGetInstanceProcAddr( instance, "vkCmdResetEvent" ) );
      vkCmdResetQueryPool = PFN_vkCmdResetQueryPool( vkGetInstanceProcAddr( instance, "vkCmdResetQueryPool" ) );
      vkCmdResolveImage = PFN_vkCmdResolveImage( vkGetInstanceProcAddr( instance, "vkCmdResolveImage" ) );
      vkCmdSetBlendConstants = PFN_vkCmdSetBlendConstants( vkGetInstanceProcAddr( instance, "vkCmdSetBlendConstants" ) );
      vkCmdSetCheckpointNV = PFN_vkCmdSetCheckpointNV( vkGetInstanceProcAddr( instance, "vkCmdSetCheckpointNV" ) );
      vkCmdSetCoarseSampleOrderNV = PFN_vkCmdSetCoarseSampleOrderNV( vkGetInstanceProcAddr( instance, "vkCmdSetCoarseSampleOrderNV" ) );
      vkCmdSetDepthBias = PFN_vkCmdSetDepthBias( vkGetInstanceProcAddr( instance, "vkCmdSetDepthBias" ) );
      vkCmdSetDepthBounds = PFN_vkCmdSetDepthBounds( vkGetInstanceProcAddr( instance, "vkCmdSetDepthBounds" ) );
      vkCmdSetDeviceMask = PFN_vkCmdSetDeviceMask( vkGetInstanceProcAddr( instance, "vkCmdSetDeviceMask" ) );
      vkCmdSetDeviceMaskKHR = PFN_vkCmdSetDeviceMaskKHR( vkGetInstanceProcAddr( instance, "vkCmdSetDeviceMaskKHR" ) );
      vkCmdSetDiscardRectangleEXT = PFN_vkCmdSetDiscardRectangleEXT( vkGetInstanceProcAddr( instance, "vkCmdSetDiscardRectangleEXT" ) );
      vkCmdSetEvent = PFN_vkCmdSetEvent( vkGetInstanceProcAddr( instance, "vkCmdSetEvent" ) );
      vkCmdSetExclusiveScissorNV = PFN_vkCmdSetExclusiveScissorNV( vkGetInstanceProcAddr( instance, "vkCmdSetExclusiveScissorNV" ) );
      vkCmdSetLineStippleEXT = PFN_vkCmdSetLineStippleEXT( vkGetInstanceProcAddr( instance, "vkCmdSetLineStippleEXT" ) );
      vkCmdSetLineWidth = PFN_vkCmdSetLineWidth( vkGetInstanceProcAddr( instance, "vkCmdSetLineWidth" ) );
      vkCmdSetPerformanceMarkerINTEL = PFN_vkCmdSetPerformanceMarkerINTEL( vkGetInstanceProcAddr( instance, "vkCmdSetPerformanceMarkerINTEL" ) );
      vkCmdSetPerformanceOverrideINTEL = PFN_vkCmdSetPerformanceOverrideINTEL( vkGetInstanceProcAddr( instance, "vkCmdSetPerformanceOverrideINTEL" ) );
      vkCmdSetPerformanceStreamMarkerINTEL = PFN_vkCmdSetPerformanceStreamMarkerINTEL( vkGetInstanceProcAddr( instance, "vkCmdSetPerformanceStreamMarkerINTEL" ) );
      vkCmdSetSampleLocationsEXT = PFN_vkCmdSetSampleLocationsEXT( vkGetInstanceProcAddr( instance, "vkCmdSetSampleLocationsEXT" ) );
      vkCmdSetScissor = PFN_vkCmdSetScissor( vkGetInstanceProcAddr( instance, "vkCmdSetScissor" ) );
      vkCmdSetStencilCompareMask = PFN_vkCmdSetStencilCompareMask( vkGetInstanceProcAddr( instance, "vkCmdSetStencilCompareMask" ) );
      vkCmdSetStencilReference = PFN_vkCmdSetStencilReference( vkGetInstanceProcAddr( instance, "vkCmdSetStencilReference" ) );
      vkCmdSetStencilWriteMask = PFN_vkCmdSetStencilWriteMask( vkGetInstanceProcAddr( instance, "vkCmdSetStencilWriteMask" ) );
      vkCmdSetViewport = PFN_vkCmdSetViewport( vkGetInstanceProcAddr( instance, "vkCmdSetViewport" ) );
      vkCmdSetViewportShadingRatePaletteNV = PFN_vkCmdSetViewportShadingRatePaletteNV( vkGetInstanceProcAddr( instance, "vkCmdSetViewportShadingRatePaletteNV" ) );
      vkCmdSetViewportWScalingNV = PFN_vkCmdSetViewportWScalingNV( vkGetInstanceProcAddr( instance, "vkCmdSetViewportWScalingNV" ) );
      vkCmdTraceRaysNV = PFN_vkCmdTraceRaysNV( vkGetInstanceProcAddr( instance, "vkCmdTraceRaysNV" ) );
      vkCmdUpdateBuffer = PFN_vkCmdUpdateBuffer( vkGetInstanceProcAddr( instance, "vkCmdUpdateBuffer" ) );
      vkCmdWaitEvents = PFN_vkCmdWaitEvents( vkGetInstanceProcAddr( instance, "vkCmdWaitEvents" ) );
      vkCmdWriteAccelerationStructuresPropertiesNV = PFN_vkCmdWriteAccelerationStructuresPropertiesNV( vkGetInstanceProcAddr( instance, "vkCmdWriteAccelerationStructuresPropertiesNV" ) );
      vkCmdWriteBufferMarkerAMD = PFN_vkCmdWriteBufferMarkerAMD( vkGetInstanceProcAddr( instance, "vkCmdWriteBufferMarkerAMD" ) );
      vkCmdWriteTimestamp = PFN_vkCmdWriteTimestamp( vkGetInstanceProcAddr( instance, "vkCmdWriteTimestamp" ) );
      vkEndCommandBuffer = PFN_vkEndCommandBuffer( vkGetInstanceProcAddr( instance, "vkEndCommandBuffer" ) );
      vkResetCommandBuffer = PFN_vkResetCommandBuffer( vkGetInstanceProcAddr( instance, "vkResetCommandBuffer" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkAcquireFullScreenExclusiveModeEXT = PFN_vkAcquireFullScreenExclusiveModeEXT( vkGetInstanceProcAddr( instance, "vkAcquireFullScreenExclusiveModeEXT" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkAcquireNextImage2KHR = PFN_vkAcquireNextImage2KHR( vkGetInstanceProcAddr( instance, "vkAcquireNextImage2KHR" ) );
      vkAcquireNextImageKHR = PFN_vkAcquireNextImageKHR( vkGetInstanceProcAddr( instance, "vkAcquireNextImageKHR" ) );
      vkAcquirePerformanceConfigurationINTEL = PFN_vkAcquirePerformanceConfigurationINTEL( vkGetInstanceProcAddr( instance, "vkAcquirePerformanceConfigurationINTEL" ) );
      vkAllocateCommandBuffers = PFN_vkAllocateCommandBuffers( vkGetInstanceProcAddr( instance, "vkAllocateCommandBuffers" ) );
      vkAllocateDescriptorSets = PFN_vkAllocateDescriptorSets( vkGetInstanceProcAddr( instance, "vkAllocateDescriptorSets" ) );
      vkAllocateMemory = PFN_vkAllocateMemory( vkGetInstanceProcAddr( instance, "vkAllocateMemory" ) );
      vkBindAccelerationStructureMemoryNV = PFN_vkBindAccelerationStructureMemoryNV( vkGetInstanceProcAddr( instance, "vkBindAccelerationStructureMemoryNV" ) );
      vkBindBufferMemory = PFN_vkBindBufferMemory( vkGetInstanceProcAddr( instance, "vkBindBufferMemory" ) );
      vkBindBufferMemory2 = PFN_vkBindBufferMemory2( vkGetInstanceProcAddr( instance, "vkBindBufferMemory2" ) );
      vkBindBufferMemory2KHR = PFN_vkBindBufferMemory2KHR( vkGetInstanceProcAddr( instance, "vkBindBufferMemory2KHR" ) );
      vkBindImageMemory = PFN_vkBindImageMemory( vkGetInstanceProcAddr( instance, "vkBindImageMemory" ) );
      vkBindImageMemory2 = PFN_vkBindImageMemory2( vkGetInstanceProcAddr( instance, "vkBindImageMemory2" ) );
      vkBindImageMemory2KHR = PFN_vkBindImageMemory2KHR( vkGetInstanceProcAddr( instance, "vkBindImageMemory2KHR" ) );
      vkCompileDeferredNV = PFN_vkCompileDeferredNV( vkGetInstanceProcAddr( instance, "vkCompileDeferredNV" ) );
      vkCreateAccelerationStructureNV = PFN_vkCreateAccelerationStructureNV( vkGetInstanceProcAddr( instance, "vkCreateAccelerationStructureNV" ) );
      vkCreateBuffer = PFN_vkCreateBuffer( vkGetInstanceProcAddr( instance, "vkCreateBuffer" ) );
      vkCreateBufferView = PFN_vkCreateBufferView( vkGetInstanceProcAddr( instance, "vkCreateBufferView" ) );
      vkCreateCommandPool = PFN_vkCreateCommandPool( vkGetInstanceProcAddr( instance, "vkCreateCommandPool" ) );
      vkCreateComputePipelines = PFN_vkCreateComputePipelines( vkGetInstanceProcAddr( instance, "vkCreateComputePipelines" ) );
      vkCreateDescriptorPool = PFN_vkCreateDescriptorPool( vkGetInstanceProcAddr( instance, "vkCreateDescriptorPool" ) );
      vkCreateDescriptorSetLayout = PFN_vkCreateDescriptorSetLayout( vkGetInstanceProcAddr( instance, "vkCreateDescriptorSetLayout" ) );
      vkCreateDescriptorUpdateTemplate = PFN_vkCreateDescriptorUpdateTemplate( vkGetInstanceProcAddr( instance, "vkCreateDescriptorUpdateTemplate" ) );
      vkCreateDescriptorUpdateTemplateKHR = PFN_vkCreateDescriptorUpdateTemplateKHR( vkGetInstanceProcAddr( instance, "vkCreateDescriptorUpdateTemplateKHR" ) );
      vkCreateEvent = PFN_vkCreateEvent( vkGetInstanceProcAddr( instance, "vkCreateEvent" ) );
      vkCreateFence = PFN_vkCreateFence( vkGetInstanceProcAddr( instance, "vkCreateFence" ) );
      vkCreateFramebuffer = PFN_vkCreateFramebuffer( vkGetInstanceProcAddr( instance, "vkCreateFramebuffer" ) );
      vkCreateGraphicsPipelines = PFN_vkCreateGraphicsPipelines( vkGetInstanceProcAddr( instance, "vkCreateGraphicsPipelines" ) );
      vkCreateImage = PFN_vkCreateImage( vkGetInstanceProcAddr( instance, "vkCreateImage" ) );
      vkCreateImageView = PFN_vkCreateImageView( vkGetInstanceProcAddr( instance, "vkCreateImageView" ) );
      vkCreateIndirectCommandsLayoutNVX = PFN_vkCreateIndirectCommandsLayoutNVX( vkGetInstanceProcAddr( instance, "vkCreateIndirectCommandsLayoutNVX" ) );
      vkCreateObjectTableNVX = PFN_vkCreateObjectTableNVX( vkGetInstanceProcAddr( instance, "vkCreateObjectTableNVX" ) );
      vkCreatePipelineCache = PFN_vkCreatePipelineCache( vkGetInstanceProcAddr( instance, "vkCreatePipelineCache" ) );
      vkCreatePipelineLayout = PFN_vkCreatePipelineLayout( vkGetInstanceProcAddr( instance, "vkCreatePipelineLayout" ) );
      vkCreateQueryPool = PFN_vkCreateQueryPool( vkGetInstanceProcAddr( instance, "vkCreateQueryPool" ) );
      vkCreateRayTracingPipelinesNV = PFN_vkCreateRayTracingPipelinesNV( vkGetInstanceProcAddr( instance, "vkCreateRayTracingPipelinesNV" ) );
      vkCreateRenderPass = PFN_vkCreateRenderPass( vkGetInstanceProcAddr( instance, "vkCreateRenderPass" ) );
      vkCreateRenderPass2KHR = PFN_vkCreateRenderPass2KHR( vkGetInstanceProcAddr( instance, "vkCreateRenderPass2KHR" ) );
      vkCreateSampler = PFN_vkCreateSampler( vkGetInstanceProcAddr( instance, "vkCreateSampler" ) );
      vkCreateSamplerYcbcrConversion = PFN_vkCreateSamplerYcbcrConversion( vkGetInstanceProcAddr( instance, "vkCreateSamplerYcbcrConversion" ) );
      vkCreateSamplerYcbcrConversionKHR = PFN_vkCreateSamplerYcbcrConversionKHR( vkGetInstanceProcAddr( instance, "vkCreateSamplerYcbcrConversionKHR" ) );
      vkCreateSemaphore = PFN_vkCreateSemaphore( vkGetInstanceProcAddr( instance, "vkCreateSemaphore" ) );
      vkCreateShaderModule = PFN_vkCreateShaderModule( vkGetInstanceProcAddr( instance, "vkCreateShaderModule" ) );
      vkCreateSharedSwapchainsKHR = PFN_vkCreateSharedSwapchainsKHR( vkGetInstanceProcAddr( instance, "vkCreateSharedSwapchainsKHR" ) );
      vkCreateSwapchainKHR = PFN_vkCreateSwapchainKHR( vkGetInstanceProcAddr( instance, "vkCreateSwapchainKHR" ) );
      vkCreateValidationCacheEXT = PFN_vkCreateValidationCacheEXT( vkGetInstanceProcAddr( instance, "vkCreateValidationCacheEXT" ) );
      vkDebugMarkerSetObjectNameEXT = PFN_vkDebugMarkerSetObjectNameEXT( vkGetInstanceProcAddr( instance, "vkDebugMarkerSetObjectNameEXT" ) );
      vkDebugMarkerSetObjectTagEXT = PFN_vkDebugMarkerSetObjectTagEXT( vkGetInstanceProcAddr( instance, "vkDebugMarkerSetObjectTagEXT" ) );
      vkDestroyAccelerationStructureNV = PFN_vkDestroyAccelerationStructureNV( vkGetInstanceProcAddr( instance, "vkDestroyAccelerationStructureNV" ) );
      vkDestroyBuffer = PFN_vkDestroyBuffer( vkGetInstanceProcAddr( instance, "vkDestroyBuffer" ) );
      vkDestroyBufferView = PFN_vkDestroyBufferView( vkGetInstanceProcAddr( instance, "vkDestroyBufferView" ) );
      vkDestroyCommandPool = PFN_vkDestroyCommandPool( vkGetInstanceProcAddr( instance, "vkDestroyCommandPool" ) );
      vkDestroyDescriptorPool = PFN_vkDestroyDescriptorPool( vkGetInstanceProcAddr( instance, "vkDestroyDescriptorPool" ) );
      vkDestroyDescriptorSetLayout = PFN_vkDestroyDescriptorSetLayout( vkGetInstanceProcAddr( instance, "vkDestroyDescriptorSetLayout" ) );
      vkDestroyDescriptorUpdateTemplate = PFN_vkDestroyDescriptorUpdateTemplate( vkGetInstanceProcAddr( instance, "vkDestroyDescriptorUpdateTemplate" ) );
      vkDestroyDescriptorUpdateTemplateKHR = PFN_vkDestroyDescriptorUpdateTemplateKHR( vkGetInstanceProcAddr( instance, "vkDestroyDescriptorUpdateTemplateKHR" ) );
      vkDestroyDevice = PFN_vkDestroyDevice( vkGetInstanceProcAddr( instance, "vkDestroyDevice" ) );
      vkDestroyEvent = PFN_vkDestroyEvent( vkGetInstanceProcAddr( instance, "vkDestroyEvent" ) );
      vkDestroyFence = PFN_vkDestroyFence( vkGetInstanceProcAddr( instance, "vkDestroyFence" ) );
      vkDestroyFramebuffer = PFN_vkDestroyFramebuffer( vkGetInstanceProcAddr( instance, "vkDestroyFramebuffer" ) );
      vkDestroyImage = PFN_vkDestroyImage( vkGetInstanceProcAddr( instance, "vkDestroyImage" ) );
      vkDestroyImageView = PFN_vkDestroyImageView( vkGetInstanceProcAddr( instance, "vkDestroyImageView" ) );
      vkDestroyIndirectCommandsLayoutNVX = PFN_vkDestroyIndirectCommandsLayoutNVX( vkGetInstanceProcAddr( instance, "vkDestroyIndirectCommandsLayoutNVX" ) );
      vkDestroyObjectTableNVX = PFN_vkDestroyObjectTableNVX( vkGetInstanceProcAddr( instance, "vkDestroyObjectTableNVX" ) );
      vkDestroyPipeline = PFN_vkDestroyPipeline( vkGetInstanceProcAddr( instance, "vkDestroyPipeline" ) );
      vkDestroyPipelineCache = PFN_vkDestroyPipelineCache( vkGetInstanceProcAddr( instance, "vkDestroyPipelineCache" ) );
      vkDestroyPipelineLayout = PFN_vkDestroyPipelineLayout( vkGetInstanceProcAddr( instance, "vkDestroyPipelineLayout" ) );
      vkDestroyQueryPool = PFN_vkDestroyQueryPool( vkGetInstanceProcAddr( instance, "vkDestroyQueryPool" ) );
      vkDestroyRenderPass = PFN_vkDestroyRenderPass( vkGetInstanceProcAddr( instance, "vkDestroyRenderPass" ) );
      vkDestroySampler = PFN_vkDestroySampler( vkGetInstanceProcAddr( instance, "vkDestroySampler" ) );
      vkDestroySamplerYcbcrConversion = PFN_vkDestroySamplerYcbcrConversion( vkGetInstanceProcAddr( instance, "vkDestroySamplerYcbcrConversion" ) );
      vkDestroySamplerYcbcrConversionKHR = PFN_vkDestroySamplerYcbcrConversionKHR( vkGetInstanceProcAddr( instance, "vkDestroySamplerYcbcrConversionKHR" ) );
      vkDestroySemaphore = PFN_vkDestroySemaphore( vkGetInstanceProcAddr( instance, "vkDestroySemaphore" ) );
      vkDestroyShaderModule = PFN_vkDestroyShaderModule( vkGetInstanceProcAddr( instance, "vkDestroyShaderModule" ) );
      vkDestroySwapchainKHR = PFN_vkDestroySwapchainKHR( vkGetInstanceProcAddr( instance, "vkDestroySwapchainKHR" ) );
      vkDestroyValidationCacheEXT = PFN_vkDestroyValidationCacheEXT( vkGetInstanceProcAddr( instance, "vkDestroyValidationCacheEXT" ) );
      vkDeviceWaitIdle = PFN_vkDeviceWaitIdle( vkGetInstanceProcAddr( instance, "vkDeviceWaitIdle" ) );
      vkDisplayPowerControlEXT = PFN_vkDisplayPowerControlEXT( vkGetInstanceProcAddr( instance, "vkDisplayPowerControlEXT" ) );
      vkFlushMappedMemoryRanges = PFN_vkFlushMappedMemoryRanges( vkGetInstanceProcAddr( instance, "vkFlushMappedMemoryRanges" ) );
      vkFreeCommandBuffers = PFN_vkFreeCommandBuffers( vkGetInstanceProcAddr( instance, "vkFreeCommandBuffers" ) );
      vkFreeDescriptorSets = PFN_vkFreeDescriptorSets( vkGetInstanceProcAddr( instance, "vkFreeDescriptorSets" ) );
      vkFreeMemory = PFN_vkFreeMemory( vkGetInstanceProcAddr( instance, "vkFreeMemory" ) );
      vkGetAccelerationStructureHandleNV = PFN_vkGetAccelerationStructureHandleNV( vkGetInstanceProcAddr( instance, "vkGetAccelerationStructureHandleNV" ) );
      vkGetAccelerationStructureMemoryRequirementsNV = PFN_vkGetAccelerationStructureMemoryRequirementsNV( vkGetInstanceProcAddr( instance, "vkGetAccelerationStructureMemoryRequirementsNV" ) );
#ifdef VK_USE_PLATFORM_ANDROID_KHR
      vkGetAndroidHardwareBufferPropertiesANDROID = PFN_vkGetAndroidHardwareBufferPropertiesANDROID( vkGetInstanceProcAddr( instance, "vkGetAndroidHardwareBufferPropertiesANDROID" ) );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
      vkGetBufferDeviceAddressEXT = PFN_vkGetBufferDeviceAddressEXT( vkGetInstanceProcAddr( instance, "vkGetBufferDeviceAddressEXT" ) );
      vkGetBufferMemoryRequirements = PFN_vkGetBufferMemoryRequirements( vkGetInstanceProcAddr( instance, "vkGetBufferMemoryRequirements" ) );
      vkGetBufferMemoryRequirements2 = PFN_vkGetBufferMemoryRequirements2( vkGetInstanceProcAddr( instance, "vkGetBufferMemoryRequirements2" ) );
      vkGetBufferMemoryRequirements2KHR = PFN_vkGetBufferMemoryRequirements2KHR( vkGetInstanceProcAddr( instance, "vkGetBufferMemoryRequirements2KHR" ) );
      vkGetCalibratedTimestampsEXT = PFN_vkGetCalibratedTimestampsEXT( vkGetInstanceProcAddr( instance, "vkGetCalibratedTimestampsEXT" ) );
      vkGetDescriptorSetLayoutSupport = PFN_vkGetDescriptorSetLayoutSupport( vkGetInstanceProcAddr( instance, "vkGetDescriptorSetLayoutSupport" ) );
      vkGetDescriptorSetLayoutSupportKHR = PFN_vkGetDescriptorSetLayoutSupportKHR( vkGetInstanceProcAddr( instance, "vkGetDescriptorSetLayoutSupportKHR" ) );
      vkGetDeviceGroupPeerMemoryFeatures = PFN_vkGetDeviceGroupPeerMemoryFeatures( vkGetInstanceProcAddr( instance, "vkGetDeviceGroupPeerMemoryFeatures" ) );
      vkGetDeviceGroupPeerMemoryFeaturesKHR = PFN_vkGetDeviceGroupPeerMemoryFeaturesKHR( vkGetInstanceProcAddr( instance, "vkGetDeviceGroupPeerMemoryFeaturesKHR" ) );
      vkGetDeviceGroupPresentCapabilitiesKHR = PFN_vkGetDeviceGroupPresentCapabilitiesKHR( vkGetInstanceProcAddr( instance, "vkGetDeviceGroupPresentCapabilitiesKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetDeviceGroupSurfacePresentModes2EXT = PFN_vkGetDeviceGroupSurfacePresentModes2EXT( vkGetInstanceProcAddr( instance, "vkGetDeviceGroupSurfacePresentModes2EXT" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetDeviceGroupSurfacePresentModesKHR = PFN_vkGetDeviceGroupSurfacePresentModesKHR( vkGetInstanceProcAddr( instance, "vkGetDeviceGroupSurfacePresentModesKHR" ) );
      vkGetDeviceMemoryCommitment = PFN_vkGetDeviceMemoryCommitment( vkGetInstanceProcAddr( instance, "vkGetDeviceMemoryCommitment" ) );
      vkGetDeviceProcAddr = PFN_vkGetDeviceProcAddr( vkGetInstanceProcAddr( instance, "vkGetDeviceProcAddr" ) );
      vkGetDeviceQueue = PFN_vkGetDeviceQueue( vkGetInstanceProcAddr( instance, "vkGetDeviceQueue" ) );
      vkGetDeviceQueue2 = PFN_vkGetDeviceQueue2( vkGetInstanceProcAddr( instance, "vkGetDeviceQueue2" ) );
      vkGetEventStatus = PFN_vkGetEventStatus( vkGetInstanceProcAddr( instance, "vkGetEventStatus" ) );
      vkGetFenceFdKHR = PFN_vkGetFenceFdKHR( vkGetInstanceProcAddr( instance, "vkGetFenceFdKHR" ) );
      vkGetFenceStatus = PFN_vkGetFenceStatus( vkGetInstanceProcAddr( instance, "vkGetFenceStatus" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetFenceWin32HandleKHR = PFN_vkGetFenceWin32HandleKHR( vkGetInstanceProcAddr( instance, "vkGetFenceWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetImageDrmFormatModifierPropertiesEXT = PFN_vkGetImageDrmFormatModifierPropertiesEXT( vkGetInstanceProcAddr( instance, "vkGetImageDrmFormatModifierPropertiesEXT" ) );
      vkGetImageMemoryRequirements = PFN_vkGetImageMemoryRequirements( vkGetInstanceProcAddr( instance, "vkGetImageMemoryRequirements" ) );
      vkGetImageMemoryRequirements2 = PFN_vkGetImageMemoryRequirements2( vkGetInstanceProcAddr( instance, "vkGetImageMemoryRequirements2" ) );
      vkGetImageMemoryRequirements2KHR = PFN_vkGetImageMemoryRequirements2KHR( vkGetInstanceProcAddr( instance, "vkGetImageMemoryRequirements2KHR" ) );
      vkGetImageSparseMemoryRequirements = PFN_vkGetImageSparseMemoryRequirements( vkGetInstanceProcAddr( instance, "vkGetImageSparseMemoryRequirements" ) );
      vkGetImageSparseMemoryRequirements2 = PFN_vkGetImageSparseMemoryRequirements2( vkGetInstanceProcAddr( instance, "vkGetImageSparseMemoryRequirements2" ) );
      vkGetImageSparseMemoryRequirements2KHR = PFN_vkGetImageSparseMemoryRequirements2KHR( vkGetInstanceProcAddr( instance, "vkGetImageSparseMemoryRequirements2KHR" ) );
      vkGetImageSubresourceLayout = PFN_vkGetImageSubresourceLayout( vkGetInstanceProcAddr( instance, "vkGetImageSubresourceLayout" ) );
      vkGetImageViewHandleNVX = PFN_vkGetImageViewHandleNVX( vkGetInstanceProcAddr( instance, "vkGetImageViewHandleNVX" ) );
#ifdef VK_USE_PLATFORM_ANDROID_KHR
      vkGetMemoryAndroidHardwareBufferANDROID = PFN_vkGetMemoryAndroidHardwareBufferANDROID( vkGetInstanceProcAddr( instance, "vkGetMemoryAndroidHardwareBufferANDROID" ) );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
      vkGetMemoryFdKHR = PFN_vkGetMemoryFdKHR( vkGetInstanceProcAddr( instance, "vkGetMemoryFdKHR" ) );
      vkGetMemoryFdPropertiesKHR = PFN_vkGetMemoryFdPropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetMemoryFdPropertiesKHR" ) );
      vkGetMemoryHostPointerPropertiesEXT = PFN_vkGetMemoryHostPointerPropertiesEXT( vkGetInstanceProcAddr( instance, "vkGetMemoryHostPointerPropertiesEXT" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetMemoryWin32HandleKHR = PFN_vkGetMemoryWin32HandleKHR( vkGetInstanceProcAddr( instance, "vkGetMemoryWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetMemoryWin32HandleNV = PFN_vkGetMemoryWin32HandleNV( vkGetInstanceProcAddr( instance, "vkGetMemoryWin32HandleNV" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetMemoryWin32HandlePropertiesKHR = PFN_vkGetMemoryWin32HandlePropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetMemoryWin32HandlePropertiesKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetPastPresentationTimingGOOGLE = PFN_vkGetPastPresentationTimingGOOGLE( vkGetInstanceProcAddr( instance, "vkGetPastPresentationTimingGOOGLE" ) );
      vkGetPerformanceParameterINTEL = PFN_vkGetPerformanceParameterINTEL( vkGetInstanceProcAddr( instance, "vkGetPerformanceParameterINTEL" ) );
      vkGetPipelineCacheData = PFN_vkGetPipelineCacheData( vkGetInstanceProcAddr( instance, "vkGetPipelineCacheData" ) );
      vkGetPipelineExecutableInternalRepresentationsKHR = PFN_vkGetPipelineExecutableInternalRepresentationsKHR( vkGetInstanceProcAddr( instance, "vkGetPipelineExecutableInternalRepresentationsKHR" ) );
      vkGetPipelineExecutablePropertiesKHR = PFN_vkGetPipelineExecutablePropertiesKHR( vkGetInstanceProcAddr( instance, "vkGetPipelineExecutablePropertiesKHR" ) );
      vkGetPipelineExecutableStatisticsKHR = PFN_vkGetPipelineExecutableStatisticsKHR( vkGetInstanceProcAddr( instance, "vkGetPipelineExecutableStatisticsKHR" ) );
      vkGetQueryPoolResults = PFN_vkGetQueryPoolResults( vkGetInstanceProcAddr( instance, "vkGetQueryPoolResults" ) );
      vkGetRayTracingShaderGroupHandlesNV = PFN_vkGetRayTracingShaderGroupHandlesNV( vkGetInstanceProcAddr( instance, "vkGetRayTracingShaderGroupHandlesNV" ) );
      vkGetRefreshCycleDurationGOOGLE = PFN_vkGetRefreshCycleDurationGOOGLE( vkGetInstanceProcAddr( instance, "vkGetRefreshCycleDurationGOOGLE" ) );
      vkGetRenderAreaGranularity = PFN_vkGetRenderAreaGranularity( vkGetInstanceProcAddr( instance, "vkGetRenderAreaGranularity" ) );
      vkGetSemaphoreCounterValueKHR = PFN_vkGetSemaphoreCounterValueKHR( vkGetInstanceProcAddr( instance, "vkGetSemaphoreCounterValueKHR" ) );
      vkGetSemaphoreFdKHR = PFN_vkGetSemaphoreFdKHR( vkGetInstanceProcAddr( instance, "vkGetSemaphoreFdKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetSemaphoreWin32HandleKHR = PFN_vkGetSemaphoreWin32HandleKHR( vkGetInstanceProcAddr( instance, "vkGetSemaphoreWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetShaderInfoAMD = PFN_vkGetShaderInfoAMD( vkGetInstanceProcAddr( instance, "vkGetShaderInfoAMD" ) );
      vkGetSwapchainCounterEXT = PFN_vkGetSwapchainCounterEXT( vkGetInstanceProcAddr( instance, "vkGetSwapchainCounterEXT" ) );
      vkGetSwapchainImagesKHR = PFN_vkGetSwapchainImagesKHR( vkGetInstanceProcAddr( instance, "vkGetSwapchainImagesKHR" ) );
      vkGetSwapchainStatusKHR = PFN_vkGetSwapchainStatusKHR( vkGetInstanceProcAddr( instance, "vkGetSwapchainStatusKHR" ) );
      vkGetValidationCacheDataEXT = PFN_vkGetValidationCacheDataEXT( vkGetInstanceProcAddr( instance, "vkGetValidationCacheDataEXT" ) );
      vkImportFenceFdKHR = PFN_vkImportFenceFdKHR( vkGetInstanceProcAddr( instance, "vkImportFenceFdKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkImportFenceWin32HandleKHR = PFN_vkImportFenceWin32HandleKHR( vkGetInstanceProcAddr( instance, "vkImportFenceWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkImportSemaphoreFdKHR = PFN_vkImportSemaphoreFdKHR( vkGetInstanceProcAddr( instance, "vkImportSemaphoreFdKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkImportSemaphoreWin32HandleKHR = PFN_vkImportSemaphoreWin32HandleKHR( vkGetInstanceProcAddr( instance, "vkImportSemaphoreWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkInitializePerformanceApiINTEL = PFN_vkInitializePerformanceApiINTEL( vkGetInstanceProcAddr( instance, "vkInitializePerformanceApiINTEL" ) );
      vkInvalidateMappedMemoryRanges = PFN_vkInvalidateMappedMemoryRanges( vkGetInstanceProcAddr( instance, "vkInvalidateMappedMemoryRanges" ) );
      vkMapMemory = PFN_vkMapMemory( vkGetInstanceProcAddr( instance, "vkMapMemory" ) );
      vkMergePipelineCaches = PFN_vkMergePipelineCaches( vkGetInstanceProcAddr( instance, "vkMergePipelineCaches" ) );
      vkMergeValidationCachesEXT = PFN_vkMergeValidationCachesEXT( vkGetInstanceProcAddr( instance, "vkMergeValidationCachesEXT" ) );
      vkRegisterDeviceEventEXT = PFN_vkRegisterDeviceEventEXT( vkGetInstanceProcAddr( instance, "vkRegisterDeviceEventEXT" ) );
      vkRegisterDisplayEventEXT = PFN_vkRegisterDisplayEventEXT( vkGetInstanceProcAddr( instance, "vkRegisterDisplayEventEXT" ) );
      vkRegisterObjectsNVX = PFN_vkRegisterObjectsNVX( vkGetInstanceProcAddr( instance, "vkRegisterObjectsNVX" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkReleaseFullScreenExclusiveModeEXT = PFN_vkReleaseFullScreenExclusiveModeEXT( vkGetInstanceProcAddr( instance, "vkReleaseFullScreenExclusiveModeEXT" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkReleasePerformanceConfigurationINTEL = PFN_vkReleasePerformanceConfigurationINTEL( vkGetInstanceProcAddr( instance, "vkReleasePerformanceConfigurationINTEL" ) );
      vkResetCommandPool = PFN_vkResetCommandPool( vkGetInstanceProcAddr( instance, "vkResetCommandPool" ) );
      vkResetDescriptorPool = PFN_vkResetDescriptorPool( vkGetInstanceProcAddr( instance, "vkResetDescriptorPool" ) );
      vkResetEvent = PFN_vkResetEvent( vkGetInstanceProcAddr( instance, "vkResetEvent" ) );
      vkResetFences = PFN_vkResetFences( vkGetInstanceProcAddr( instance, "vkResetFences" ) );
      vkResetQueryPoolEXT = PFN_vkResetQueryPoolEXT( vkGetInstanceProcAddr( instance, "vkResetQueryPoolEXT" ) );
      vkSetDebugUtilsObjectNameEXT = PFN_vkSetDebugUtilsObjectNameEXT( vkGetInstanceProcAddr( instance, "vkSetDebugUtilsObjectNameEXT" ) );
      vkSetDebugUtilsObjectTagEXT = PFN_vkSetDebugUtilsObjectTagEXT( vkGetInstanceProcAddr( instance, "vkSetDebugUtilsObjectTagEXT" ) );
      vkSetEvent = PFN_vkSetEvent( vkGetInstanceProcAddr( instance, "vkSetEvent" ) );
      vkSetHdrMetadataEXT = PFN_vkSetHdrMetadataEXT( vkGetInstanceProcAddr( instance, "vkSetHdrMetadataEXT" ) );
      vkSetLocalDimmingAMD = PFN_vkSetLocalDimmingAMD( vkGetInstanceProcAddr( instance, "vkSetLocalDimmingAMD" ) );
      vkSignalSemaphoreKHR = PFN_vkSignalSemaphoreKHR( vkGetInstanceProcAddr( instance, "vkSignalSemaphoreKHR" ) );
      vkTrimCommandPool = PFN_vkTrimCommandPool( vkGetInstanceProcAddr( instance, "vkTrimCommandPool" ) );
      vkTrimCommandPoolKHR = PFN_vkTrimCommandPoolKHR( vkGetInstanceProcAddr( instance, "vkTrimCommandPoolKHR" ) );
      vkUninitializePerformanceApiINTEL = PFN_vkUninitializePerformanceApiINTEL( vkGetInstanceProcAddr( instance, "vkUninitializePerformanceApiINTEL" ) );
      vkUnmapMemory = PFN_vkUnmapMemory( vkGetInstanceProcAddr( instance, "vkUnmapMemory" ) );
      vkUnregisterObjectsNVX = PFN_vkUnregisterObjectsNVX( vkGetInstanceProcAddr( instance, "vkUnregisterObjectsNVX" ) );
      vkUpdateDescriptorSetWithTemplate = PFN_vkUpdateDescriptorSetWithTemplate( vkGetInstanceProcAddr( instance, "vkUpdateDescriptorSetWithTemplate" ) );
      vkUpdateDescriptorSetWithTemplateKHR = PFN_vkUpdateDescriptorSetWithTemplateKHR( vkGetInstanceProcAddr( instance, "vkUpdateDescriptorSetWithTemplateKHR" ) );
      vkUpdateDescriptorSets = PFN_vkUpdateDescriptorSets( vkGetInstanceProcAddr( instance, "vkUpdateDescriptorSets" ) );
      vkWaitForFences = PFN_vkWaitForFences( vkGetInstanceProcAddr( instance, "vkWaitForFences" ) );
      vkWaitSemaphoresKHR = PFN_vkWaitSemaphoresKHR( vkGetInstanceProcAddr( instance, "vkWaitSemaphoresKHR" ) );
      vkGetQueueCheckpointDataNV = PFN_vkGetQueueCheckpointDataNV( vkGetInstanceProcAddr( instance, "vkGetQueueCheckpointDataNV" ) );
      vkQueueBeginDebugUtilsLabelEXT = PFN_vkQueueBeginDebugUtilsLabelEXT( vkGetInstanceProcAddr( instance, "vkQueueBeginDebugUtilsLabelEXT" ) );
      vkQueueBindSparse = PFN_vkQueueBindSparse( vkGetInstanceProcAddr( instance, "vkQueueBindSparse" ) );
      vkQueueEndDebugUtilsLabelEXT = PFN_vkQueueEndDebugUtilsLabelEXT( vkGetInstanceProcAddr( instance, "vkQueueEndDebugUtilsLabelEXT" ) );
      vkQueueInsertDebugUtilsLabelEXT = PFN_vkQueueInsertDebugUtilsLabelEXT( vkGetInstanceProcAddr( instance, "vkQueueInsertDebugUtilsLabelEXT" ) );
      vkQueuePresentKHR = PFN_vkQueuePresentKHR( vkGetInstanceProcAddr( instance, "vkQueuePresentKHR" ) );
      vkQueueSetPerformanceConfigurationINTEL = PFN_vkQueueSetPerformanceConfigurationINTEL( vkGetInstanceProcAddr( instance, "vkQueueSetPerformanceConfigurationINTEL" ) );
      vkQueueSubmit = PFN_vkQueueSubmit( vkGetInstanceProcAddr( instance, "vkQueueSubmit" ) );
      vkQueueWaitIdle = PFN_vkQueueWaitIdle( vkGetInstanceProcAddr( instance, "vkQueueWaitIdle" ) );
    }

    void init( vk::Device device ) VULKAN_HPP_NOEXCEPT
    {
      vkBeginCommandBuffer = PFN_vkBeginCommandBuffer( vkGetDeviceProcAddr( device, "vkBeginCommandBuffer" ) );
      vkCmdBeginConditionalRenderingEXT = PFN_vkCmdBeginConditionalRenderingEXT( vkGetDeviceProcAddr( device, "vkCmdBeginConditionalRenderingEXT" ) );
      vkCmdBeginDebugUtilsLabelEXT = PFN_vkCmdBeginDebugUtilsLabelEXT( vkGetDeviceProcAddr( device, "vkCmdBeginDebugUtilsLabelEXT" ) );
      vkCmdBeginQuery = PFN_vkCmdBeginQuery( vkGetDeviceProcAddr( device, "vkCmdBeginQuery" ) );
      vkCmdBeginQueryIndexedEXT = PFN_vkCmdBeginQueryIndexedEXT( vkGetDeviceProcAddr( device, "vkCmdBeginQueryIndexedEXT" ) );
      vkCmdBeginRenderPass = PFN_vkCmdBeginRenderPass( vkGetDeviceProcAddr( device, "vkCmdBeginRenderPass" ) );
      vkCmdBeginRenderPass2KHR = PFN_vkCmdBeginRenderPass2KHR( vkGetDeviceProcAddr( device, "vkCmdBeginRenderPass2KHR" ) );
      vkCmdBeginTransformFeedbackEXT = PFN_vkCmdBeginTransformFeedbackEXT( vkGetDeviceProcAddr( device, "vkCmdBeginTransformFeedbackEXT" ) );
      vkCmdBindDescriptorSets = PFN_vkCmdBindDescriptorSets( vkGetDeviceProcAddr( device, "vkCmdBindDescriptorSets" ) );
      vkCmdBindIndexBuffer = PFN_vkCmdBindIndexBuffer( vkGetDeviceProcAddr( device, "vkCmdBindIndexBuffer" ) );
      vkCmdBindPipeline = PFN_vkCmdBindPipeline( vkGetDeviceProcAddr( device, "vkCmdBindPipeline" ) );
      vkCmdBindShadingRateImageNV = PFN_vkCmdBindShadingRateImageNV( vkGetDeviceProcAddr( device, "vkCmdBindShadingRateImageNV" ) );
      vkCmdBindTransformFeedbackBuffersEXT = PFN_vkCmdBindTransformFeedbackBuffersEXT( vkGetDeviceProcAddr( device, "vkCmdBindTransformFeedbackBuffersEXT" ) );
      vkCmdBindVertexBuffers = PFN_vkCmdBindVertexBuffers( vkGetDeviceProcAddr( device, "vkCmdBindVertexBuffers" ) );
      vkCmdBlitImage = PFN_vkCmdBlitImage( vkGetDeviceProcAddr( device, "vkCmdBlitImage" ) );
      vkCmdBuildAccelerationStructureNV = PFN_vkCmdBuildAccelerationStructureNV( vkGetDeviceProcAddr( device, "vkCmdBuildAccelerationStructureNV" ) );
      vkCmdClearAttachments = PFN_vkCmdClearAttachments( vkGetDeviceProcAddr( device, "vkCmdClearAttachments" ) );
      vkCmdClearColorImage = PFN_vkCmdClearColorImage( vkGetDeviceProcAddr( device, "vkCmdClearColorImage" ) );
      vkCmdClearDepthStencilImage = PFN_vkCmdClearDepthStencilImage( vkGetDeviceProcAddr( device, "vkCmdClearDepthStencilImage" ) );
      vkCmdCopyAccelerationStructureNV = PFN_vkCmdCopyAccelerationStructureNV( vkGetDeviceProcAddr( device, "vkCmdCopyAccelerationStructureNV" ) );
      vkCmdCopyBuffer = PFN_vkCmdCopyBuffer( vkGetDeviceProcAddr( device, "vkCmdCopyBuffer" ) );
      vkCmdCopyBufferToImage = PFN_vkCmdCopyBufferToImage( vkGetDeviceProcAddr( device, "vkCmdCopyBufferToImage" ) );
      vkCmdCopyImage = PFN_vkCmdCopyImage( vkGetDeviceProcAddr( device, "vkCmdCopyImage" ) );
      vkCmdCopyImageToBuffer = PFN_vkCmdCopyImageToBuffer( vkGetDeviceProcAddr( device, "vkCmdCopyImageToBuffer" ) );
      vkCmdCopyQueryPoolResults = PFN_vkCmdCopyQueryPoolResults( vkGetDeviceProcAddr( device, "vkCmdCopyQueryPoolResults" ) );
      vkCmdDebugMarkerBeginEXT = PFN_vkCmdDebugMarkerBeginEXT( vkGetDeviceProcAddr( device, "vkCmdDebugMarkerBeginEXT" ) );
      vkCmdDebugMarkerEndEXT = PFN_vkCmdDebugMarkerEndEXT( vkGetDeviceProcAddr( device, "vkCmdDebugMarkerEndEXT" ) );
      vkCmdDebugMarkerInsertEXT = PFN_vkCmdDebugMarkerInsertEXT( vkGetDeviceProcAddr( device, "vkCmdDebugMarkerInsertEXT" ) );
      vkCmdDispatch = PFN_vkCmdDispatch( vkGetDeviceProcAddr( device, "vkCmdDispatch" ) );
      vkCmdDispatchBase = PFN_vkCmdDispatchBase( vkGetDeviceProcAddr( device, "vkCmdDispatchBase" ) );
      vkCmdDispatchBaseKHR = PFN_vkCmdDispatchBaseKHR( vkGetDeviceProcAddr( device, "vkCmdDispatchBaseKHR" ) );
      vkCmdDispatchIndirect = PFN_vkCmdDispatchIndirect( vkGetDeviceProcAddr( device, "vkCmdDispatchIndirect" ) );
      vkCmdDraw = PFN_vkCmdDraw( vkGetDeviceProcAddr( device, "vkCmdDraw" ) );
      vkCmdDrawIndexed = PFN_vkCmdDrawIndexed( vkGetDeviceProcAddr( device, "vkCmdDrawIndexed" ) );
      vkCmdDrawIndexedIndirect = PFN_vkCmdDrawIndexedIndirect( vkGetDeviceProcAddr( device, "vkCmdDrawIndexedIndirect" ) );
      vkCmdDrawIndexedIndirectCountAMD = PFN_vkCmdDrawIndexedIndirectCountAMD( vkGetDeviceProcAddr( device, "vkCmdDrawIndexedIndirectCountAMD" ) );
      vkCmdDrawIndexedIndirectCountKHR = PFN_vkCmdDrawIndexedIndirectCountKHR( vkGetDeviceProcAddr( device, "vkCmdDrawIndexedIndirectCountKHR" ) );
      vkCmdDrawIndirect = PFN_vkCmdDrawIndirect( vkGetDeviceProcAddr( device, "vkCmdDrawIndirect" ) );
      vkCmdDrawIndirectByteCountEXT = PFN_vkCmdDrawIndirectByteCountEXT( vkGetDeviceProcAddr( device, "vkCmdDrawIndirectByteCountEXT" ) );
      vkCmdDrawIndirectCountAMD = PFN_vkCmdDrawIndirectCountAMD( vkGetDeviceProcAddr( device, "vkCmdDrawIndirectCountAMD" ) );
      vkCmdDrawIndirectCountKHR = PFN_vkCmdDrawIndirectCountKHR( vkGetDeviceProcAddr( device, "vkCmdDrawIndirectCountKHR" ) );
      vkCmdDrawMeshTasksIndirectCountNV = PFN_vkCmdDrawMeshTasksIndirectCountNV( vkGetDeviceProcAddr( device, "vkCmdDrawMeshTasksIndirectCountNV" ) );
      vkCmdDrawMeshTasksIndirectNV = PFN_vkCmdDrawMeshTasksIndirectNV( vkGetDeviceProcAddr( device, "vkCmdDrawMeshTasksIndirectNV" ) );
      vkCmdDrawMeshTasksNV = PFN_vkCmdDrawMeshTasksNV( vkGetDeviceProcAddr( device, "vkCmdDrawMeshTasksNV" ) );
      vkCmdEndConditionalRenderingEXT = PFN_vkCmdEndConditionalRenderingEXT( vkGetDeviceProcAddr( device, "vkCmdEndConditionalRenderingEXT" ) );
      vkCmdEndDebugUtilsLabelEXT = PFN_vkCmdEndDebugUtilsLabelEXT( vkGetDeviceProcAddr( device, "vkCmdEndDebugUtilsLabelEXT" ) );
      vkCmdEndQuery = PFN_vkCmdEndQuery( vkGetDeviceProcAddr( device, "vkCmdEndQuery" ) );
      vkCmdEndQueryIndexedEXT = PFN_vkCmdEndQueryIndexedEXT( vkGetDeviceProcAddr( device, "vkCmdEndQueryIndexedEXT" ) );
      vkCmdEndRenderPass = PFN_vkCmdEndRenderPass( vkGetDeviceProcAddr( device, "vkCmdEndRenderPass" ) );
      vkCmdEndRenderPass2KHR = PFN_vkCmdEndRenderPass2KHR( vkGetDeviceProcAddr( device, "vkCmdEndRenderPass2KHR" ) );
      vkCmdEndTransformFeedbackEXT = PFN_vkCmdEndTransformFeedbackEXT( vkGetDeviceProcAddr( device, "vkCmdEndTransformFeedbackEXT" ) );
      vkCmdExecuteCommands = PFN_vkCmdExecuteCommands( vkGetDeviceProcAddr( device, "vkCmdExecuteCommands" ) );
      vkCmdFillBuffer = PFN_vkCmdFillBuffer( vkGetDeviceProcAddr( device, "vkCmdFillBuffer" ) );
      vkCmdInsertDebugUtilsLabelEXT = PFN_vkCmdInsertDebugUtilsLabelEXT( vkGetDeviceProcAddr( device, "vkCmdInsertDebugUtilsLabelEXT" ) );
      vkCmdNextSubpass = PFN_vkCmdNextSubpass( vkGetDeviceProcAddr( device, "vkCmdNextSubpass" ) );
      vkCmdNextSubpass2KHR = PFN_vkCmdNextSubpass2KHR( vkGetDeviceProcAddr( device, "vkCmdNextSubpass2KHR" ) );
      vkCmdPipelineBarrier = PFN_vkCmdPipelineBarrier( vkGetDeviceProcAddr( device, "vkCmdPipelineBarrier" ) );
      vkCmdProcessCommandsNVX = PFN_vkCmdProcessCommandsNVX( vkGetDeviceProcAddr( device, "vkCmdProcessCommandsNVX" ) );
      vkCmdPushConstants = PFN_vkCmdPushConstants( vkGetDeviceProcAddr( device, "vkCmdPushConstants" ) );
      vkCmdPushDescriptorSetKHR = PFN_vkCmdPushDescriptorSetKHR( vkGetDeviceProcAddr( device, "vkCmdPushDescriptorSetKHR" ) );
      vkCmdPushDescriptorSetWithTemplateKHR = PFN_vkCmdPushDescriptorSetWithTemplateKHR( vkGetDeviceProcAddr( device, "vkCmdPushDescriptorSetWithTemplateKHR" ) );
      vkCmdReserveSpaceForCommandsNVX = PFN_vkCmdReserveSpaceForCommandsNVX( vkGetDeviceProcAddr( device, "vkCmdReserveSpaceForCommandsNVX" ) );
      vkCmdResetEvent = PFN_vkCmdResetEvent( vkGetDeviceProcAddr( device, "vkCmdResetEvent" ) );
      vkCmdResetQueryPool = PFN_vkCmdResetQueryPool( vkGetDeviceProcAddr( device, "vkCmdResetQueryPool" ) );
      vkCmdResolveImage = PFN_vkCmdResolveImage( vkGetDeviceProcAddr( device, "vkCmdResolveImage" ) );
      vkCmdSetBlendConstants = PFN_vkCmdSetBlendConstants( vkGetDeviceProcAddr( device, "vkCmdSetBlendConstants" ) );
      vkCmdSetCheckpointNV = PFN_vkCmdSetCheckpointNV( vkGetDeviceProcAddr( device, "vkCmdSetCheckpointNV" ) );
      vkCmdSetCoarseSampleOrderNV = PFN_vkCmdSetCoarseSampleOrderNV( vkGetDeviceProcAddr( device, "vkCmdSetCoarseSampleOrderNV" ) );
      vkCmdSetDepthBias = PFN_vkCmdSetDepthBias( vkGetDeviceProcAddr( device, "vkCmdSetDepthBias" ) );
      vkCmdSetDepthBounds = PFN_vkCmdSetDepthBounds( vkGetDeviceProcAddr( device, "vkCmdSetDepthBounds" ) );
      vkCmdSetDeviceMask = PFN_vkCmdSetDeviceMask( vkGetDeviceProcAddr( device, "vkCmdSetDeviceMask" ) );
      vkCmdSetDeviceMaskKHR = PFN_vkCmdSetDeviceMaskKHR( vkGetDeviceProcAddr( device, "vkCmdSetDeviceMaskKHR" ) );
      vkCmdSetDiscardRectangleEXT = PFN_vkCmdSetDiscardRectangleEXT( vkGetDeviceProcAddr( device, "vkCmdSetDiscardRectangleEXT" ) );
      vkCmdSetEvent = PFN_vkCmdSetEvent( vkGetDeviceProcAddr( device, "vkCmdSetEvent" ) );
      vkCmdSetExclusiveScissorNV = PFN_vkCmdSetExclusiveScissorNV( vkGetDeviceProcAddr( device, "vkCmdSetExclusiveScissorNV" ) );
      vkCmdSetLineStippleEXT = PFN_vkCmdSetLineStippleEXT( vkGetDeviceProcAddr( device, "vkCmdSetLineStippleEXT" ) );
      vkCmdSetLineWidth = PFN_vkCmdSetLineWidth( vkGetDeviceProcAddr( device, "vkCmdSetLineWidth" ) );
      vkCmdSetPerformanceMarkerINTEL = PFN_vkCmdSetPerformanceMarkerINTEL( vkGetDeviceProcAddr( device, "vkCmdSetPerformanceMarkerINTEL" ) );
      vkCmdSetPerformanceOverrideINTEL = PFN_vkCmdSetPerformanceOverrideINTEL( vkGetDeviceProcAddr( device, "vkCmdSetPerformanceOverrideINTEL" ) );
      vkCmdSetPerformanceStreamMarkerINTEL = PFN_vkCmdSetPerformanceStreamMarkerINTEL( vkGetDeviceProcAddr( device, "vkCmdSetPerformanceStreamMarkerINTEL" ) );
      vkCmdSetSampleLocationsEXT = PFN_vkCmdSetSampleLocationsEXT( vkGetDeviceProcAddr( device, "vkCmdSetSampleLocationsEXT" ) );
      vkCmdSetScissor = PFN_vkCmdSetScissor( vkGetDeviceProcAddr( device, "vkCmdSetScissor" ) );
      vkCmdSetStencilCompareMask = PFN_vkCmdSetStencilCompareMask( vkGetDeviceProcAddr( device, "vkCmdSetStencilCompareMask" ) );
      vkCmdSetStencilReference = PFN_vkCmdSetStencilReference( vkGetDeviceProcAddr( device, "vkCmdSetStencilReference" ) );
      vkCmdSetStencilWriteMask = PFN_vkCmdSetStencilWriteMask( vkGetDeviceProcAddr( device, "vkCmdSetStencilWriteMask" ) );
      vkCmdSetViewport = PFN_vkCmdSetViewport( vkGetDeviceProcAddr( device, "vkCmdSetViewport" ) );
      vkCmdSetViewportShadingRatePaletteNV = PFN_vkCmdSetViewportShadingRatePaletteNV( vkGetDeviceProcAddr( device, "vkCmdSetViewportShadingRatePaletteNV" ) );
      vkCmdSetViewportWScalingNV = PFN_vkCmdSetViewportWScalingNV( vkGetDeviceProcAddr( device, "vkCmdSetViewportWScalingNV" ) );
      vkCmdTraceRaysNV = PFN_vkCmdTraceRaysNV( vkGetDeviceProcAddr( device, "vkCmdTraceRaysNV" ) );
      vkCmdUpdateBuffer = PFN_vkCmdUpdateBuffer( vkGetDeviceProcAddr( device, "vkCmdUpdateBuffer" ) );
      vkCmdWaitEvents = PFN_vkCmdWaitEvents( vkGetDeviceProcAddr( device, "vkCmdWaitEvents" ) );
      vkCmdWriteAccelerationStructuresPropertiesNV = PFN_vkCmdWriteAccelerationStructuresPropertiesNV( vkGetDeviceProcAddr( device, "vkCmdWriteAccelerationStructuresPropertiesNV" ) );
      vkCmdWriteBufferMarkerAMD = PFN_vkCmdWriteBufferMarkerAMD( vkGetDeviceProcAddr( device, "vkCmdWriteBufferMarkerAMD" ) );
      vkCmdWriteTimestamp = PFN_vkCmdWriteTimestamp( vkGetDeviceProcAddr( device, "vkCmdWriteTimestamp" ) );
      vkEndCommandBuffer = PFN_vkEndCommandBuffer( vkGetDeviceProcAddr( device, "vkEndCommandBuffer" ) );
      vkResetCommandBuffer = PFN_vkResetCommandBuffer( vkGetDeviceProcAddr( device, "vkResetCommandBuffer" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkAcquireFullScreenExclusiveModeEXT = PFN_vkAcquireFullScreenExclusiveModeEXT( vkGetDeviceProcAddr( device, "vkAcquireFullScreenExclusiveModeEXT" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkAcquireNextImage2KHR = PFN_vkAcquireNextImage2KHR( vkGetDeviceProcAddr( device, "vkAcquireNextImage2KHR" ) );
      vkAcquireNextImageKHR = PFN_vkAcquireNextImageKHR( vkGetDeviceProcAddr( device, "vkAcquireNextImageKHR" ) );
      vkAcquirePerformanceConfigurationINTEL = PFN_vkAcquirePerformanceConfigurationINTEL( vkGetDeviceProcAddr( device, "vkAcquirePerformanceConfigurationINTEL" ) );
      vkAllocateCommandBuffers = PFN_vkAllocateCommandBuffers( vkGetDeviceProcAddr( device, "vkAllocateCommandBuffers" ) );
      vkAllocateDescriptorSets = PFN_vkAllocateDescriptorSets( vkGetDeviceProcAddr( device, "vkAllocateDescriptorSets" ) );
      vkAllocateMemory = PFN_vkAllocateMemory( vkGetDeviceProcAddr( device, "vkAllocateMemory" ) );
      vkBindAccelerationStructureMemoryNV = PFN_vkBindAccelerationStructureMemoryNV( vkGetDeviceProcAddr( device, "vkBindAccelerationStructureMemoryNV" ) );
      vkBindBufferMemory = PFN_vkBindBufferMemory( vkGetDeviceProcAddr( device, "vkBindBufferMemory" ) );
      vkBindBufferMemory2 = PFN_vkBindBufferMemory2( vkGetDeviceProcAddr( device, "vkBindBufferMemory2" ) );
      vkBindBufferMemory2KHR = PFN_vkBindBufferMemory2KHR( vkGetDeviceProcAddr( device, "vkBindBufferMemory2KHR" ) );
      vkBindImageMemory = PFN_vkBindImageMemory( vkGetDeviceProcAddr( device, "vkBindImageMemory" ) );
      vkBindImageMemory2 = PFN_vkBindImageMemory2( vkGetDeviceProcAddr( device, "vkBindImageMemory2" ) );
      vkBindImageMemory2KHR = PFN_vkBindImageMemory2KHR( vkGetDeviceProcAddr( device, "vkBindImageMemory2KHR" ) );
      vkCompileDeferredNV = PFN_vkCompileDeferredNV( vkGetDeviceProcAddr( device, "vkCompileDeferredNV" ) );
      vkCreateAccelerationStructureNV = PFN_vkCreateAccelerationStructureNV( vkGetDeviceProcAddr( device, "vkCreateAccelerationStructureNV" ) );
      vkCreateBuffer = PFN_vkCreateBuffer( vkGetDeviceProcAddr( device, "vkCreateBuffer" ) );
      vkCreateBufferView = PFN_vkCreateBufferView( vkGetDeviceProcAddr( device, "vkCreateBufferView" ) );
      vkCreateCommandPool = PFN_vkCreateCommandPool( vkGetDeviceProcAddr( device, "vkCreateCommandPool" ) );
      vkCreateComputePipelines = PFN_vkCreateComputePipelines( vkGetDeviceProcAddr( device, "vkCreateComputePipelines" ) );
      vkCreateDescriptorPool = PFN_vkCreateDescriptorPool( vkGetDeviceProcAddr( device, "vkCreateDescriptorPool" ) );
      vkCreateDescriptorSetLayout = PFN_vkCreateDescriptorSetLayout( vkGetDeviceProcAddr( device, "vkCreateDescriptorSetLayout" ) );
      vkCreateDescriptorUpdateTemplate = PFN_vkCreateDescriptorUpdateTemplate( vkGetDeviceProcAddr( device, "vkCreateDescriptorUpdateTemplate" ) );
      vkCreateDescriptorUpdateTemplateKHR = PFN_vkCreateDescriptorUpdateTemplateKHR( vkGetDeviceProcAddr( device, "vkCreateDescriptorUpdateTemplateKHR" ) );
      vkCreateEvent = PFN_vkCreateEvent( vkGetDeviceProcAddr( device, "vkCreateEvent" ) );
      vkCreateFence = PFN_vkCreateFence( vkGetDeviceProcAddr( device, "vkCreateFence" ) );
      vkCreateFramebuffer = PFN_vkCreateFramebuffer( vkGetDeviceProcAddr( device, "vkCreateFramebuffer" ) );
      vkCreateGraphicsPipelines = PFN_vkCreateGraphicsPipelines( vkGetDeviceProcAddr( device, "vkCreateGraphicsPipelines" ) );
      vkCreateImage = PFN_vkCreateImage( vkGetDeviceProcAddr( device, "vkCreateImage" ) );
      vkCreateImageView = PFN_vkCreateImageView( vkGetDeviceProcAddr( device, "vkCreateImageView" ) );
      vkCreateIndirectCommandsLayoutNVX = PFN_vkCreateIndirectCommandsLayoutNVX( vkGetDeviceProcAddr( device, "vkCreateIndirectCommandsLayoutNVX" ) );
      vkCreateObjectTableNVX = PFN_vkCreateObjectTableNVX( vkGetDeviceProcAddr( device, "vkCreateObjectTableNVX" ) );
      vkCreatePipelineCache = PFN_vkCreatePipelineCache( vkGetDeviceProcAddr( device, "vkCreatePipelineCache" ) );
      vkCreatePipelineLayout = PFN_vkCreatePipelineLayout( vkGetDeviceProcAddr( device, "vkCreatePipelineLayout" ) );
      vkCreateQueryPool = PFN_vkCreateQueryPool( vkGetDeviceProcAddr( device, "vkCreateQueryPool" ) );
      vkCreateRayTracingPipelinesNV = PFN_vkCreateRayTracingPipelinesNV( vkGetDeviceProcAddr( device, "vkCreateRayTracingPipelinesNV" ) );
      vkCreateRenderPass = PFN_vkCreateRenderPass( vkGetDeviceProcAddr( device, "vkCreateRenderPass" ) );
      vkCreateRenderPass2KHR = PFN_vkCreateRenderPass2KHR( vkGetDeviceProcAddr( device, "vkCreateRenderPass2KHR" ) );
      vkCreateSampler = PFN_vkCreateSampler( vkGetDeviceProcAddr( device, "vkCreateSampler" ) );
      vkCreateSamplerYcbcrConversion = PFN_vkCreateSamplerYcbcrConversion( vkGetDeviceProcAddr( device, "vkCreateSamplerYcbcrConversion" ) );
      vkCreateSamplerYcbcrConversionKHR = PFN_vkCreateSamplerYcbcrConversionKHR( vkGetDeviceProcAddr( device, "vkCreateSamplerYcbcrConversionKHR" ) );
      vkCreateSemaphore = PFN_vkCreateSemaphore( vkGetDeviceProcAddr( device, "vkCreateSemaphore" ) );
      vkCreateShaderModule = PFN_vkCreateShaderModule( vkGetDeviceProcAddr( device, "vkCreateShaderModule" ) );
      vkCreateSharedSwapchainsKHR = PFN_vkCreateSharedSwapchainsKHR( vkGetDeviceProcAddr( device, "vkCreateSharedSwapchainsKHR" ) );
      vkCreateSwapchainKHR = PFN_vkCreateSwapchainKHR( vkGetDeviceProcAddr( device, "vkCreateSwapchainKHR" ) );
      vkCreateValidationCacheEXT = PFN_vkCreateValidationCacheEXT( vkGetDeviceProcAddr( device, "vkCreateValidationCacheEXT" ) );
      vkDebugMarkerSetObjectNameEXT = PFN_vkDebugMarkerSetObjectNameEXT( vkGetDeviceProcAddr( device, "vkDebugMarkerSetObjectNameEXT" ) );
      vkDebugMarkerSetObjectTagEXT = PFN_vkDebugMarkerSetObjectTagEXT( vkGetDeviceProcAddr( device, "vkDebugMarkerSetObjectTagEXT" ) );
      vkDestroyAccelerationStructureNV = PFN_vkDestroyAccelerationStructureNV( vkGetDeviceProcAddr( device, "vkDestroyAccelerationStructureNV" ) );
      vkDestroyBuffer = PFN_vkDestroyBuffer( vkGetDeviceProcAddr( device, "vkDestroyBuffer" ) );
      vkDestroyBufferView = PFN_vkDestroyBufferView( vkGetDeviceProcAddr( device, "vkDestroyBufferView" ) );
      vkDestroyCommandPool = PFN_vkDestroyCommandPool( vkGetDeviceProcAddr( device, "vkDestroyCommandPool" ) );
      vkDestroyDescriptorPool = PFN_vkDestroyDescriptorPool( vkGetDeviceProcAddr( device, "vkDestroyDescriptorPool" ) );
      vkDestroyDescriptorSetLayout = PFN_vkDestroyDescriptorSetLayout( vkGetDeviceProcAddr( device, "vkDestroyDescriptorSetLayout" ) );
      vkDestroyDescriptorUpdateTemplate = PFN_vkDestroyDescriptorUpdateTemplate( vkGetDeviceProcAddr( device, "vkDestroyDescriptorUpdateTemplate" ) );
      vkDestroyDescriptorUpdateTemplateKHR = PFN_vkDestroyDescriptorUpdateTemplateKHR( vkGetDeviceProcAddr( device, "vkDestroyDescriptorUpdateTemplateKHR" ) );
      vkDestroyDevice = PFN_vkDestroyDevice( vkGetDeviceProcAddr( device, "vkDestroyDevice" ) );
      vkDestroyEvent = PFN_vkDestroyEvent( vkGetDeviceProcAddr( device, "vkDestroyEvent" ) );
      vkDestroyFence = PFN_vkDestroyFence( vkGetDeviceProcAddr( device, "vkDestroyFence" ) );
      vkDestroyFramebuffer = PFN_vkDestroyFramebuffer( vkGetDeviceProcAddr( device, "vkDestroyFramebuffer" ) );
      vkDestroyImage = PFN_vkDestroyImage( vkGetDeviceProcAddr( device, "vkDestroyImage" ) );
      vkDestroyImageView = PFN_vkDestroyImageView( vkGetDeviceProcAddr( device, "vkDestroyImageView" ) );
      vkDestroyIndirectCommandsLayoutNVX = PFN_vkDestroyIndirectCommandsLayoutNVX( vkGetDeviceProcAddr( device, "vkDestroyIndirectCommandsLayoutNVX" ) );
      vkDestroyObjectTableNVX = PFN_vkDestroyObjectTableNVX( vkGetDeviceProcAddr( device, "vkDestroyObjectTableNVX" ) );
      vkDestroyPipeline = PFN_vkDestroyPipeline( vkGetDeviceProcAddr( device, "vkDestroyPipeline" ) );
      vkDestroyPipelineCache = PFN_vkDestroyPipelineCache( vkGetDeviceProcAddr( device, "vkDestroyPipelineCache" ) );
      vkDestroyPipelineLayout = PFN_vkDestroyPipelineLayout( vkGetDeviceProcAddr( device, "vkDestroyPipelineLayout" ) );
      vkDestroyQueryPool = PFN_vkDestroyQueryPool( vkGetDeviceProcAddr( device, "vkDestroyQueryPool" ) );
      vkDestroyRenderPass = PFN_vkDestroyRenderPass( vkGetDeviceProcAddr( device, "vkDestroyRenderPass" ) );
      vkDestroySampler = PFN_vkDestroySampler( vkGetDeviceProcAddr( device, "vkDestroySampler" ) );
      vkDestroySamplerYcbcrConversion = PFN_vkDestroySamplerYcbcrConversion( vkGetDeviceProcAddr( device, "vkDestroySamplerYcbcrConversion" ) );
      vkDestroySamplerYcbcrConversionKHR = PFN_vkDestroySamplerYcbcrConversionKHR( vkGetDeviceProcAddr( device, "vkDestroySamplerYcbcrConversionKHR" ) );
      vkDestroySemaphore = PFN_vkDestroySemaphore( vkGetDeviceProcAddr( device, "vkDestroySemaphore" ) );
      vkDestroyShaderModule = PFN_vkDestroyShaderModule( vkGetDeviceProcAddr( device, "vkDestroyShaderModule" ) );
      vkDestroySwapchainKHR = PFN_vkDestroySwapchainKHR( vkGetDeviceProcAddr( device, "vkDestroySwapchainKHR" ) );
      vkDestroyValidationCacheEXT = PFN_vkDestroyValidationCacheEXT( vkGetDeviceProcAddr( device, "vkDestroyValidationCacheEXT" ) );
      vkDeviceWaitIdle = PFN_vkDeviceWaitIdle( vkGetDeviceProcAddr( device, "vkDeviceWaitIdle" ) );
      vkDisplayPowerControlEXT = PFN_vkDisplayPowerControlEXT( vkGetDeviceProcAddr( device, "vkDisplayPowerControlEXT" ) );
      vkFlushMappedMemoryRanges = PFN_vkFlushMappedMemoryRanges( vkGetDeviceProcAddr( device, "vkFlushMappedMemoryRanges" ) );
      vkFreeCommandBuffers = PFN_vkFreeCommandBuffers( vkGetDeviceProcAddr( device, "vkFreeCommandBuffers" ) );
      vkFreeDescriptorSets = PFN_vkFreeDescriptorSets( vkGetDeviceProcAddr( device, "vkFreeDescriptorSets" ) );
      vkFreeMemory = PFN_vkFreeMemory( vkGetDeviceProcAddr( device, "vkFreeMemory" ) );
      vkGetAccelerationStructureHandleNV = PFN_vkGetAccelerationStructureHandleNV( vkGetDeviceProcAddr( device, "vkGetAccelerationStructureHandleNV" ) );
      vkGetAccelerationStructureMemoryRequirementsNV = PFN_vkGetAccelerationStructureMemoryRequirementsNV( vkGetDeviceProcAddr( device, "vkGetAccelerationStructureMemoryRequirementsNV" ) );
#ifdef VK_USE_PLATFORM_ANDROID_KHR
      vkGetAndroidHardwareBufferPropertiesANDROID = PFN_vkGetAndroidHardwareBufferPropertiesANDROID( vkGetDeviceProcAddr( device, "vkGetAndroidHardwareBufferPropertiesANDROID" ) );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
      vkGetBufferDeviceAddressEXT = PFN_vkGetBufferDeviceAddressEXT( vkGetDeviceProcAddr( device, "vkGetBufferDeviceAddressEXT" ) );
      vkGetBufferMemoryRequirements = PFN_vkGetBufferMemoryRequirements( vkGetDeviceProcAddr( device, "vkGetBufferMemoryRequirements" ) );
      vkGetBufferMemoryRequirements2 = PFN_vkGetBufferMemoryRequirements2( vkGetDeviceProcAddr( device, "vkGetBufferMemoryRequirements2" ) );
      vkGetBufferMemoryRequirements2KHR = PFN_vkGetBufferMemoryRequirements2KHR( vkGetDeviceProcAddr( device, "vkGetBufferMemoryRequirements2KHR" ) );
      vkGetCalibratedTimestampsEXT = PFN_vkGetCalibratedTimestampsEXT( vkGetDeviceProcAddr( device, "vkGetCalibratedTimestampsEXT" ) );
      vkGetDescriptorSetLayoutSupport = PFN_vkGetDescriptorSetLayoutSupport( vkGetDeviceProcAddr( device, "vkGetDescriptorSetLayoutSupport" ) );
      vkGetDescriptorSetLayoutSupportKHR = PFN_vkGetDescriptorSetLayoutSupportKHR( vkGetDeviceProcAddr( device, "vkGetDescriptorSetLayoutSupportKHR" ) );
      vkGetDeviceGroupPeerMemoryFeatures = PFN_vkGetDeviceGroupPeerMemoryFeatures( vkGetDeviceProcAddr( device, "vkGetDeviceGroupPeerMemoryFeatures" ) );
      vkGetDeviceGroupPeerMemoryFeaturesKHR = PFN_vkGetDeviceGroupPeerMemoryFeaturesKHR( vkGetDeviceProcAddr( device, "vkGetDeviceGroupPeerMemoryFeaturesKHR" ) );
      vkGetDeviceGroupPresentCapabilitiesKHR = PFN_vkGetDeviceGroupPresentCapabilitiesKHR( vkGetDeviceProcAddr( device, "vkGetDeviceGroupPresentCapabilitiesKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetDeviceGroupSurfacePresentModes2EXT = PFN_vkGetDeviceGroupSurfacePresentModes2EXT( vkGetDeviceProcAddr( device, "vkGetDeviceGroupSurfacePresentModes2EXT" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetDeviceGroupSurfacePresentModesKHR = PFN_vkGetDeviceGroupSurfacePresentModesKHR( vkGetDeviceProcAddr( device, "vkGetDeviceGroupSurfacePresentModesKHR" ) );
      vkGetDeviceMemoryCommitment = PFN_vkGetDeviceMemoryCommitment( vkGetDeviceProcAddr( device, "vkGetDeviceMemoryCommitment" ) );
      vkGetDeviceProcAddr = PFN_vkGetDeviceProcAddr( vkGetDeviceProcAddr( device, "vkGetDeviceProcAddr" ) );
      vkGetDeviceQueue = PFN_vkGetDeviceQueue( vkGetDeviceProcAddr( device, "vkGetDeviceQueue" ) );
      vkGetDeviceQueue2 = PFN_vkGetDeviceQueue2( vkGetDeviceProcAddr( device, "vkGetDeviceQueue2" ) );
      vkGetEventStatus = PFN_vkGetEventStatus( vkGetDeviceProcAddr( device, "vkGetEventStatus" ) );
      vkGetFenceFdKHR = PFN_vkGetFenceFdKHR( vkGetDeviceProcAddr( device, "vkGetFenceFdKHR" ) );
      vkGetFenceStatus = PFN_vkGetFenceStatus( vkGetDeviceProcAddr( device, "vkGetFenceStatus" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetFenceWin32HandleKHR = PFN_vkGetFenceWin32HandleKHR( vkGetDeviceProcAddr( device, "vkGetFenceWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetImageDrmFormatModifierPropertiesEXT = PFN_vkGetImageDrmFormatModifierPropertiesEXT( vkGetDeviceProcAddr( device, "vkGetImageDrmFormatModifierPropertiesEXT" ) );
      vkGetImageMemoryRequirements = PFN_vkGetImageMemoryRequirements( vkGetDeviceProcAddr( device, "vkGetImageMemoryRequirements" ) );
      vkGetImageMemoryRequirements2 = PFN_vkGetImageMemoryRequirements2( vkGetDeviceProcAddr( device, "vkGetImageMemoryRequirements2" ) );
      vkGetImageMemoryRequirements2KHR = PFN_vkGetImageMemoryRequirements2KHR( vkGetDeviceProcAddr( device, "vkGetImageMemoryRequirements2KHR" ) );
      vkGetImageSparseMemoryRequirements = PFN_vkGetImageSparseMemoryRequirements( vkGetDeviceProcAddr( device, "vkGetImageSparseMemoryRequirements" ) );
      vkGetImageSparseMemoryRequirements2 = PFN_vkGetImageSparseMemoryRequirements2( vkGetDeviceProcAddr( device, "vkGetImageSparseMemoryRequirements2" ) );
      vkGetImageSparseMemoryRequirements2KHR = PFN_vkGetImageSparseMemoryRequirements2KHR( vkGetDeviceProcAddr( device, "vkGetImageSparseMemoryRequirements2KHR" ) );
      vkGetImageSubresourceLayout = PFN_vkGetImageSubresourceLayout( vkGetDeviceProcAddr( device, "vkGetImageSubresourceLayout" ) );
      vkGetImageViewHandleNVX = PFN_vkGetImageViewHandleNVX( vkGetDeviceProcAddr( device, "vkGetImageViewHandleNVX" ) );
#ifdef VK_USE_PLATFORM_ANDROID_KHR
      vkGetMemoryAndroidHardwareBufferANDROID = PFN_vkGetMemoryAndroidHardwareBufferANDROID( vkGetDeviceProcAddr( device, "vkGetMemoryAndroidHardwareBufferANDROID" ) );
#endif /*VK_USE_PLATFORM_ANDROID_KHR*/
      vkGetMemoryFdKHR = PFN_vkGetMemoryFdKHR( vkGetDeviceProcAddr( device, "vkGetMemoryFdKHR" ) );
      vkGetMemoryFdPropertiesKHR = PFN_vkGetMemoryFdPropertiesKHR( vkGetDeviceProcAddr( device, "vkGetMemoryFdPropertiesKHR" ) );
      vkGetMemoryHostPointerPropertiesEXT = PFN_vkGetMemoryHostPointerPropertiesEXT( vkGetDeviceProcAddr( device, "vkGetMemoryHostPointerPropertiesEXT" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetMemoryWin32HandleKHR = PFN_vkGetMemoryWin32HandleKHR( vkGetDeviceProcAddr( device, "vkGetMemoryWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetMemoryWin32HandleNV = PFN_vkGetMemoryWin32HandleNV( vkGetDeviceProcAddr( device, "vkGetMemoryWin32HandleNV" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetMemoryWin32HandlePropertiesKHR = PFN_vkGetMemoryWin32HandlePropertiesKHR( vkGetDeviceProcAddr( device, "vkGetMemoryWin32HandlePropertiesKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetPastPresentationTimingGOOGLE = PFN_vkGetPastPresentationTimingGOOGLE( vkGetDeviceProcAddr( device, "vkGetPastPresentationTimingGOOGLE" ) );
      vkGetPerformanceParameterINTEL = PFN_vkGetPerformanceParameterINTEL( vkGetDeviceProcAddr( device, "vkGetPerformanceParameterINTEL" ) );
      vkGetPipelineCacheData = PFN_vkGetPipelineCacheData( vkGetDeviceProcAddr( device, "vkGetPipelineCacheData" ) );
      vkGetPipelineExecutableInternalRepresentationsKHR = PFN_vkGetPipelineExecutableInternalRepresentationsKHR( vkGetDeviceProcAddr( device, "vkGetPipelineExecutableInternalRepresentationsKHR" ) );
      vkGetPipelineExecutablePropertiesKHR = PFN_vkGetPipelineExecutablePropertiesKHR( vkGetDeviceProcAddr( device, "vkGetPipelineExecutablePropertiesKHR" ) );
      vkGetPipelineExecutableStatisticsKHR = PFN_vkGetPipelineExecutableStatisticsKHR( vkGetDeviceProcAddr( device, "vkGetPipelineExecutableStatisticsKHR" ) );
      vkGetQueryPoolResults = PFN_vkGetQueryPoolResults( vkGetDeviceProcAddr( device, "vkGetQueryPoolResults" ) );
      vkGetRayTracingShaderGroupHandlesNV = PFN_vkGetRayTracingShaderGroupHandlesNV( vkGetDeviceProcAddr( device, "vkGetRayTracingShaderGroupHandlesNV" ) );
      vkGetRefreshCycleDurationGOOGLE = PFN_vkGetRefreshCycleDurationGOOGLE( vkGetDeviceProcAddr( device, "vkGetRefreshCycleDurationGOOGLE" ) );
      vkGetRenderAreaGranularity = PFN_vkGetRenderAreaGranularity( vkGetDeviceProcAddr( device, "vkGetRenderAreaGranularity" ) );
      vkGetSemaphoreCounterValueKHR = PFN_vkGetSemaphoreCounterValueKHR( vkGetDeviceProcAddr( device, "vkGetSemaphoreCounterValueKHR" ) );
      vkGetSemaphoreFdKHR = PFN_vkGetSemaphoreFdKHR( vkGetDeviceProcAddr( device, "vkGetSemaphoreFdKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkGetSemaphoreWin32HandleKHR = PFN_vkGetSemaphoreWin32HandleKHR( vkGetDeviceProcAddr( device, "vkGetSemaphoreWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkGetShaderInfoAMD = PFN_vkGetShaderInfoAMD( vkGetDeviceProcAddr( device, "vkGetShaderInfoAMD" ) );
      vkGetSwapchainCounterEXT = PFN_vkGetSwapchainCounterEXT( vkGetDeviceProcAddr( device, "vkGetSwapchainCounterEXT" ) );
      vkGetSwapchainImagesKHR = PFN_vkGetSwapchainImagesKHR( vkGetDeviceProcAddr( device, "vkGetSwapchainImagesKHR" ) );
      vkGetSwapchainStatusKHR = PFN_vkGetSwapchainStatusKHR( vkGetDeviceProcAddr( device, "vkGetSwapchainStatusKHR" ) );
      vkGetValidationCacheDataEXT = PFN_vkGetValidationCacheDataEXT( vkGetDeviceProcAddr( device, "vkGetValidationCacheDataEXT" ) );
      vkImportFenceFdKHR = PFN_vkImportFenceFdKHR( vkGetDeviceProcAddr( device, "vkImportFenceFdKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkImportFenceWin32HandleKHR = PFN_vkImportFenceWin32HandleKHR( vkGetDeviceProcAddr( device, "vkImportFenceWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkImportSemaphoreFdKHR = PFN_vkImportSemaphoreFdKHR( vkGetDeviceProcAddr( device, "vkImportSemaphoreFdKHR" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkImportSemaphoreWin32HandleKHR = PFN_vkImportSemaphoreWin32HandleKHR( vkGetDeviceProcAddr( device, "vkImportSemaphoreWin32HandleKHR" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkInitializePerformanceApiINTEL = PFN_vkInitializePerformanceApiINTEL( vkGetDeviceProcAddr( device, "vkInitializePerformanceApiINTEL" ) );
      vkInvalidateMappedMemoryRanges = PFN_vkInvalidateMappedMemoryRanges( vkGetDeviceProcAddr( device, "vkInvalidateMappedMemoryRanges" ) );
      vkMapMemory = PFN_vkMapMemory( vkGetDeviceProcAddr( device, "vkMapMemory" ) );
      vkMergePipelineCaches = PFN_vkMergePipelineCaches( vkGetDeviceProcAddr( device, "vkMergePipelineCaches" ) );
      vkMergeValidationCachesEXT = PFN_vkMergeValidationCachesEXT( vkGetDeviceProcAddr( device, "vkMergeValidationCachesEXT" ) );
      vkRegisterDeviceEventEXT = PFN_vkRegisterDeviceEventEXT( vkGetDeviceProcAddr( device, "vkRegisterDeviceEventEXT" ) );
      vkRegisterDisplayEventEXT = PFN_vkRegisterDisplayEventEXT( vkGetDeviceProcAddr( device, "vkRegisterDisplayEventEXT" ) );
      vkRegisterObjectsNVX = PFN_vkRegisterObjectsNVX( vkGetDeviceProcAddr( device, "vkRegisterObjectsNVX" ) );
#ifdef VK_USE_PLATFORM_WIN32_KHR
      vkReleaseFullScreenExclusiveModeEXT = PFN_vkReleaseFullScreenExclusiveModeEXT( vkGetDeviceProcAddr( device, "vkReleaseFullScreenExclusiveModeEXT" ) );
#endif /*VK_USE_PLATFORM_WIN32_KHR*/
      vkReleasePerformanceConfigurationINTEL = PFN_vkReleasePerformanceConfigurationINTEL( vkGetDeviceProcAddr( device, "vkReleasePerformanceConfigurationINTEL" ) );
      vkResetCommandPool = PFN_vkResetCommandPool( vkGetDeviceProcAddr( device, "vkResetCommandPool" ) );
      vkResetDescriptorPool = PFN_vkResetDescriptorPool( vkGetDeviceProcAddr( device, "vkResetDescriptorPool" ) );
      vkResetEvent = PFN_vkResetEvent( vkGetDeviceProcAddr( device, "vkResetEvent" ) );
      vkResetFences = PFN_vkResetFences( vkGetDeviceProcAddr( device, "vkResetFences" ) );
      vkResetQueryPoolEXT = PFN_vkResetQueryPoolEXT( vkGetDeviceProcAddr( device, "vkResetQueryPoolEXT" ) );
      vkSetDebugUtilsObjectNameEXT = PFN_vkSetDebugUtilsObjectNameEXT( vkGetDeviceProcAddr( device, "vkSetDebugUtilsObjectNameEXT" ) );
      vkSetDebugUtilsObjectTagEXT = PFN_vkSetDebugUtilsObjectTagEXT( vkGetDeviceProcAddr( device, "vkSetDebugUtilsObjectTagEXT" ) );
      vkSetEvent = PFN_vkSetEvent( vkGetDeviceProcAddr( device, "vkSetEvent" ) );
      vkSetHdrMetadataEXT = PFN_vkSetHdrMetadataEXT( vkGetDeviceProcAddr( device, "vkSetHdrMetadataEXT" ) );
      vkSetLocalDimmingAMD = PFN_vkSetLocalDimmingAMD( vkGetDeviceProcAddr( device, "vkSetLocalDimmingAMD" ) );
      vkSignalSemaphoreKHR = PFN_vkSignalSemaphoreKHR( vkGetDeviceProcAddr( device, "vkSignalSemaphoreKHR" ) );
      vkTrimCommandPool = PFN_vkTrimCommandPool( vkGetDeviceProcAddr( device, "vkTrimCommandPool" ) );
      vkTrimCommandPoolKHR = PFN_vkTrimCommandPoolKHR( vkGetDeviceProcAddr( device, "vkTrimCommandPoolKHR" ) );
      vkUninitializePerformanceApiINTEL = PFN_vkUninitializePerformanceApiINTEL( vkGetDeviceProcAddr( device, "vkUninitializePerformanceApiINTEL" ) );
      vkUnmapMemory = PFN_vkUnmapMemory( vkGetDeviceProcAddr( device, "vkUnmapMemory" ) );
      vkUnregisterObjectsNVX = PFN_vkUnregisterObjectsNVX( vkGetDeviceProcAddr( device, "vkUnregisterObjectsNVX" ) );
      vkUpdateDescriptorSetWithTemplate = PFN_vkUpdateDescriptorSetWithTemplate( vkGetDeviceProcAddr( device, "vkUpdateDescriptorSetWithTemplate" ) );
      vkUpdateDescriptorSetWithTemplateKHR = PFN_vkUpdateDescriptorSetWithTemplateKHR( vkGetDeviceProcAddr( device, "vkUpdateDescriptorSetWithTemplateKHR" ) );
      vkUpdateDescriptorSets = PFN_vkUpdateDescriptorSets( vkGetDeviceProcAddr( device, "vkUpdateDescriptorSets" ) );
      vkWaitForFences = PFN_vkWaitForFences( vkGetDeviceProcAddr( device, "vkWaitForFences" ) );
      vkWaitSemaphoresKHR = PFN_vkWaitSemaphoresKHR( vkGetDeviceProcAddr( device, "vkWaitSemaphoresKHR" ) );
      vkGetQueueCheckpointDataNV = PFN_vkGetQueueCheckpointDataNV( vkGetDeviceProcAddr( device, "vkGetQueueCheckpointDataNV" ) );
      vkQueueBeginDebugUtilsLabelEXT = PFN_vkQueueBeginDebugUtilsLabelEXT( vkGetDeviceProcAddr( device, "vkQueueBeginDebugUtilsLabelEXT" ) );
      vkQueueBindSparse = PFN_vkQueueBindSparse( vkGetDeviceProcAddr( device, "vkQueueBindSparse" ) );
      vkQueueEndDebugUtilsLabelEXT = PFN_vkQueueEndDebugUtilsLabelEXT( vkGetDeviceProcAddr( device, "vkQueueEndDebugUtilsLabelEXT" ) );
      vkQueueInsertDebugUtilsLabelEXT = PFN_vkQueueInsertDebugUtilsLabelEXT( vkGetDeviceProcAddr( device, "vkQueueInsertDebugUtilsLabelEXT" ) );
      vkQueuePresentKHR = PFN_vkQueuePresentKHR( vkGetDeviceProcAddr( device, "vkQueuePresentKHR" ) );
      vkQueueSetPerformanceConfigurationINTEL = PFN_vkQueueSetPerformanceConfigurationINTEL( vkGetDeviceProcAddr( device, "vkQueueSetPerformanceConfigurationINTEL" ) );
      vkQueueSubmit = PFN_vkQueueSubmit( vkGetDeviceProcAddr( device, "vkQueueSubmit" ) );
      vkQueueWaitIdle = PFN_vkQueueWaitIdle( vkGetDeviceProcAddr( device, "vkQueueWaitIdle" ) );
    }
  };

} // namespace VULKAN_HPP_NAMESPACE
#endif
